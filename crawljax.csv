ead1530fe8a18b0ed663f430e147397f3dfd1c84,Danny Roest,PrettyHTML.java,MODIFY,"prettyHTML -> [String html] | [String html, String strIndent]","diff --git a/src/main/java/com/crawljax/util/PrettyHTML.java b/src/main/java/com/crawljax/util/PrettyHTML.java
index a77ae6e..cbc4881 100644
--- a/src/main/java/com/crawljax/util/PrettyHTML.java
+++ b/src/main/java/com/crawljax/util/PrettyHTML.java
@@ -46,7 +46,9 @@
 					// only indent if element is not a single element (like
 					// <img src='..' />)
 					if (!temp[0].endsWith(""/"") || temp.length == 1) {
-						indent++;
+						if (!temp[0].startsWith(""!--"")) {
+							indent++;
+						}
 					}
 					// if there is text after the element, print it
 					if (temp.length > 1 && !temp[1].trim().equals("""")) {
"
c77ac34ab8fa920fdcca191bc32b7ffc2bdf7a8b,Ali Mesbah,PrettyHTML.java,MODIFY,"prettyHTML -> [String html] | [String html, String strIndent]","diff --git a/src/main/java/com/crawljax/util/PrettyHTML.java b/src/main/java/com/crawljax/util/PrettyHTML.java
index a77ae6e..cbc4881 100644
--- a/src/main/java/com/crawljax/util/PrettyHTML.java
+++ b/src/main/java/com/crawljax/util/PrettyHTML.java
@@ -46,7 +46,9 @@
 					// only indent if element is not a single element (like
 					// <img src='..' />)
 					if (!temp[0].endsWith(""/"") || temp.length == 1) {
-						indent++;
+						if (!temp[0].startsWith(""!--"")) {
+							indent++;
+						}
 					}
 					// if there is text after the element, print it
 					if (temp.length > 1 && !temp[1].trim().equals("""")) {
"
3434074bd10930770a4c9014d6393628825ee8a8,Frank Groeneveld,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 3389868..06293ee 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -71,7 +71,7 @@
 					if (text.equals("""")) {
 						return;
 					}
-					String js = Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
+					String js = getJSGetElement(XPathHelper.getXpathExpression(element));
 					js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
 					browser.executeJavaScript(js);
 				}
@@ -79,8 +79,7 @@
 				// check/uncheck checkboxes
 				if (input.getType().equals(""checkbox"")) {
 					for (InputValue inputValue : input.getInputValues()) {
-						String js =
-						        Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
+						String js = getJSGetElement(XPathHelper.getXpathExpression(element));
 						boolean check;
 						if (!randomFieldValue) {
 							check = inputValue.isChecked();
@@ -104,9 +103,7 @@
 				if (input.getType().equals(""radio"")) {
 					for (InputValue inputValue : input.getInputValues()) {
 						if (inputValue.isChecked()) {
-							String js =
-							        Helper.getJSGetElement(XPathHelper
-							                .getXpathExpression(element));
+							String js = getJSGetElement(XPathHelper.getXpathExpression(element));
 							js += ""try{ATUSA_element.checked=true;}catch(e){}"";
 							browser.executeJavaScript(js);
 						}
@@ -117,8 +114,7 @@
 				if (input.getType().startsWith(""select"")) {
 					for (InputValue inputValue : input.getInputValues()) {
 						// if(browser.getDriver()==null){
-						String js =
-						        Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
+						String js = getJSGetElement(XPathHelper.getXpathExpression(element));
 						js +=
 						        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
 						                + ""if(ATUSA_element.options[i].value=='""
@@ -223,4 +219,52 @@
 		}
 	}
 
+	/**
+	 * @param xpath
+	 *            The xpath of the element.
+	 * @return The JavaScript to get an element.
+	 */
+	private static String getJSGetElement(String xpath) {
+		String js =
+		        """"
+		                + ""function ATUSA_getElementInNodes(nodes, tagName, number){""
+		                + ""try{""
+		                + ""var pos = 1;""
+		                + ""for(i=0; i<nodes.length; i++){""
+		                + ""if(nodes[i]!=null && nodes[i].tagName!=null && ""
+		                + ""nodes[i].tagName.toLowerCase() == tagName){""
+		                + ""if(number==pos){""
+		                + ""return nodes[i];""
+		                + ""}else{""
+		                + ""pos++;""
+		                + ""}""
+		                + ""}""
+		                + ""}""
+		                + ""}catch(e){}""
+		                + ""return null;""
+		                + ""}""
+		                + ""function ATUSA_getElementByXpath(xpath){""
+		                + ""try{""
+		                + ""var elements = xpath.toLowerCase().split('/');""
+		                + ""var curNode = document.body;""
+		                + ""var tagName, number;""
+		                + ""for(j=0; j<elements.length; j++){""
+		                + ""if(elements[j]!=''){""
+		                + ""if(elements[j].indexOf('[')==-1){""
+		                + ""tagName = elements[j];""
+		                + ""number = 1;""
+		                + ""}else{""
+		                + ""tagName = elements[j].substring(0, elements[j].indexOf('['));""
+		                + ""number = elements[j].substring(elements[j].indexOf('[')+1, ""
+		                + ""elements[j].lastIndexOf(']'));""
+		                + ""}""
+		                + ""if(tagName!='body' && tagName!='html'){""
+		                + ""curNode = ATUSA_getElementInNodes(curNode.childNodes, tagName, number);""
+		                + ""if(curNode==null){"" + ""return null;"" + ""}"" + ""}"" + ""}"" + ""}""
+		                + ""}catch(e){return null;}"" + ""return curNode;"" + ""}""
+		                + ""try{var ATUSA_element = ATUSA_getElementByXpath('"" + xpath
+		                + ""');}catch(e){return null;}"";
+
+		return js;
+	}
 }
"
f5d69c9c8e3273eeece86c06e88da321f44c0b13,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 3389868..06293ee 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -71,7 +71,7 @@
 					if (text.equals("""")) {
 						return;
 					}
-					String js = Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
+					String js = getJSGetElement(XPathHelper.getXpathExpression(element));
 					js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
 					browser.executeJavaScript(js);
 				}
@@ -79,8 +79,7 @@
 				// check/uncheck checkboxes
 				if (input.getType().equals(""checkbox"")) {
 					for (InputValue inputValue : input.getInputValues()) {
-						String js =
-						        Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
+						String js = getJSGetElement(XPathHelper.getXpathExpression(element));
 						boolean check;
 						if (!randomFieldValue) {
 							check = inputValue.isChecked();
@@ -104,9 +103,7 @@
 				if (input.getType().equals(""radio"")) {
 					for (InputValue inputValue : input.getInputValues()) {
 						if (inputValue.isChecked()) {
-							String js =
-							        Helper.getJSGetElement(XPathHelper
-							                .getXpathExpression(element));
+							String js = getJSGetElement(XPathHelper.getXpathExpression(element));
 							js += ""try{ATUSA_element.checked=true;}catch(e){}"";
 							browser.executeJavaScript(js);
 						}
@@ -117,8 +114,7 @@
 				if (input.getType().startsWith(""select"")) {
 					for (InputValue inputValue : input.getInputValues()) {
 						// if(browser.getDriver()==null){
-						String js =
-						        Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
+						String js = getJSGetElement(XPathHelper.getXpathExpression(element));
 						js +=
 						        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
 						                + ""if(ATUSA_element.options[i].value=='""
@@ -223,4 +219,52 @@
 		}
 	}
 
+	/**
+	 * @param xpath
+	 *            The xpath of the element.
+	 * @return The JavaScript to get an element.
+	 */
+	private static String getJSGetElement(String xpath) {
+		String js =
+		        """"
+		                + ""function ATUSA_getElementInNodes(nodes, tagName, number){""
+		                + ""try{""
+		                + ""var pos = 1;""
+		                + ""for(i=0; i<nodes.length; i++){""
+		                + ""if(nodes[i]!=null && nodes[i].tagName!=null && ""
+		                + ""nodes[i].tagName.toLowerCase() == tagName){""
+		                + ""if(number==pos){""
+		                + ""return nodes[i];""
+		                + ""}else{""
+		                + ""pos++;""
+		                + ""}""
+		                + ""}""
+		                + ""}""
+		                + ""}catch(e){}""
+		                + ""return null;""
+		                + ""}""
+		                + ""function ATUSA_getElementByXpath(xpath){""
+		                + ""try{""
+		                + ""var elements = xpath.toLowerCase().split('/');""
+		                + ""var curNode = document.body;""
+		                + ""var tagName, number;""
+		                + ""for(j=0; j<elements.length; j++){""
+		                + ""if(elements[j]!=''){""
+		                + ""if(elements[j].indexOf('[')==-1){""
+		                + ""tagName = elements[j];""
+		                + ""number = 1;""
+		                + ""}else{""
+		                + ""tagName = elements[j].substring(0, elements[j].indexOf('['));""
+		                + ""number = elements[j].substring(elements[j].indexOf('[')+1, ""
+		                + ""elements[j].lastIndexOf(']'));""
+		                + ""}""
+		                + ""if(tagName!='body' && tagName!='html'){""
+		                + ""curNode = ATUSA_getElementInNodes(curNode.childNodes, tagName, number);""
+		                + ""if(curNode==null){"" + ""return null;"" + ""}"" + ""}"" + ""}"" + ""}""
+		                + ""}catch(e){return null;}"" + ""return curNode;"" + ""}""
+		                + ""try{var ATUSA_element = ATUSA_getElementByXpath('"" + xpath
+		                + ""');}catch(e){return null;}"";
+
+		return js;
+	}
 }
"
765257deb6d83d65d2301d3d9716d4a1d5289640,Frank Groeneveld,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index e75d0d4..70cc44a 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -134,12 +134,12 @@
 	}
 
 	/**
-	 * DOCUMENT ME!
+	 * TODO: DOCUMENT ME!
 	 * 
 	 * @param propertiesFile
-	 *            DOCUMENT ME!
+	 *            TODO: DOCUMENT ME!
 	 * @throws ConfigurationException
-	 *             DOCUMENT ME!
+	 *             TODO: DOCUMENT ME!
 	 */
 	public static void init(String propertiesFile) throws ConfigurationException {
 		PropertyHelper.propertiesFileName = propertiesFile;
@@ -546,28 +546,28 @@
 	}
 
 	/**
-	 * @return DOCUMENT ME!
+	 * @return TODO: DOCUMENT ME!
 	 */
 	public static String getCrawlMaxStates() {
 		return crawlMaxStates;
 	}
 
 	/**
-	 * @return DOCUMENT ME!
+	 * @return TODO: DOCUMENT ME!
 	 */
 	public static String getCrawlMaxTime() {
 		return crawlMaxTime;
 	}
 
 	/**
-	 * @return DOCUMENT ME!
+	 * @return TODO: DOCUMENT ME!
 	 */
 	public static int getCrawlMaxStatesValue() {
 		return crawlMaxStatesValue;
 	}
 
 	/**
-	 * @return DOCUMENT ME!
+	 * @returnTODO: DOCUMENT ME!
 	 */
 	public static int getCrawlMaxTimeValue() {
 		return crawlMaxTimeValue;
@@ -635,7 +635,7 @@
 
 	/**
 	 * @param args
-	 *            DOCUMENT ME!
+	 *            TODO: DOCUMENT ME!
 	 */
 	public static void main(String[] args) {
 		String text = ""div:{class=expandable-hitarea}"";
@@ -671,14 +671,14 @@
 	}
 
 	/**
-	 * @return DOCUMENT ME!
+	 * @return TODO: DOCUMENT ME!
 	 */
 	public static List<TagElement> getCrawlTagElements() {
 		return crawlTagElements;
 	}
 
 	/**
-	 * @return DOCUMENT ME!
+	 * @return TODO: DOCUMENT ME!
 	 */
 	public static List<TagElement> getCrawlExcludeTagElements() {
 		return crawlExcludeTagElements;
@@ -720,7 +720,7 @@
 	}
 
 	/**
-	 * @return DOCUMENT ME!
+	 * @return TODO: DOCUMENT ME!
 	 */
 	public static List<String> getAtusaPluginsValues() {
 		return atusaPluginsValues;
"
765257deb6d83d65d2301d3d9716d4a1d5289640,Frank Groeneveld,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 03ed87d..c1beb3f 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -21,7 +21,7 @@
 import org.w3c.dom.NodeList;
 
 /**
- * DOCUMENT ME!
+ * TODO: DOCUMENT ME!
  * 
  * @author mesbah
  * @version $Id: XPathHelper.java 6370 2009-12-29 07:59:21Z frank $
@@ -71,7 +71,7 @@
 	}
 
 	/**
-	 * DOCUMENT ME!
+	 * TODO: DOCUMENT ME!
 	 * 
 	 * @param parent
 	 *            parent node.
"
ae9c447249f70085fde6652fb79bc53b7c601460,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index e75d0d4..70cc44a 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -134,12 +134,12 @@
 	}
 
 	/**
-	 * DOCUMENT ME!
+	 * TODO: DOCUMENT ME!
 	 * 
 	 * @param propertiesFile
-	 *            DOCUMENT ME!
+	 *            TODO: DOCUMENT ME!
 	 * @throws ConfigurationException
-	 *             DOCUMENT ME!
+	 *             TODO: DOCUMENT ME!
 	 */
 	public static void init(String propertiesFile) throws ConfigurationException {
 		PropertyHelper.propertiesFileName = propertiesFile;
@@ -546,28 +546,28 @@
 	}
 
 	/**
-	 * @return DOCUMENT ME!
+	 * @return TODO: DOCUMENT ME!
 	 */
 	public static String getCrawlMaxStates() {
 		return crawlMaxStates;
 	}
 
 	/**
-	 * @return DOCUMENT ME!
+	 * @return TODO: DOCUMENT ME!
 	 */
 	public static String getCrawlMaxTime() {
 		return crawlMaxTime;
 	}
 
 	/**
-	 * @return DOCUMENT ME!
+	 * @return TODO: DOCUMENT ME!
 	 */
 	public static int getCrawlMaxStatesValue() {
 		return crawlMaxStatesValue;
 	}
 
 	/**
-	 * @return DOCUMENT ME!
+	 * @returnTODO: DOCUMENT ME!
 	 */
 	public static int getCrawlMaxTimeValue() {
 		return crawlMaxTimeValue;
@@ -635,7 +635,7 @@
 
 	/**
 	 * @param args
-	 *            DOCUMENT ME!
+	 *            TODO: DOCUMENT ME!
 	 */
 	public static void main(String[] args) {
 		String text = ""div:{class=expandable-hitarea}"";
@@ -671,14 +671,14 @@
 	}
 
 	/**
-	 * @return DOCUMENT ME!
+	 * @return TODO: DOCUMENT ME!
 	 */
 	public static List<TagElement> getCrawlTagElements() {
 		return crawlTagElements;
 	}
 
 	/**
-	 * @return DOCUMENT ME!
+	 * @return TODO: DOCUMENT ME!
 	 */
 	public static List<TagElement> getCrawlExcludeTagElements() {
 		return crawlExcludeTagElements;
@@ -720,7 +720,7 @@
 	}
 
 	/**
-	 * @return DOCUMENT ME!
+	 * @return TODO: DOCUMENT ME!
 	 */
 	public static List<String> getAtusaPluginsValues() {
 		return atusaPluginsValues;
"
ae9c447249f70085fde6652fb79bc53b7c601460,Ali Mesbah,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 03ed87d..c1beb3f 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -21,7 +21,7 @@
 import org.w3c.dom.NodeList;
 
 /**
- * DOCUMENT ME!
+ * TODO: DOCUMENT ME!
  * 
  * @author mesbah
  * @version $Id: XPathHelper.java 6370 2009-12-29 07:59:21Z frank $
@@ -71,7 +71,7 @@
 	}
 
 	/**
-	 * DOCUMENT ME!
+	 * TODO: DOCUMENT ME!
 	 * 
 	 * @param parent
 	 *            parent node.
"
010a2ce49423752359153f42b8aa5dc72b55c0a4,Danny Roest,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Oracle oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 066ab83..7ddd09d 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -8,8 +8,8 @@
 import com.crawljax.condition.browserwaiter.WaitCondition;
 import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.invariant.Invariant;
-import com.crawljax.oracle.ComparatorWithPreconditions;
-import com.crawljax.oracle.Oracle;
+import com.crawljax.oraclecomparator.OracleComparator;
+import com.crawljax.oraclecomparator.Comparator;
 
 /**
  * Specifies the crawl options for a single crawl session. The user must specify which HTML elements
@@ -54,8 +54,8 @@
 	private boolean testInvariantsWhileCrawling = true;
 	private final List<Invariant> invariants = new ArrayList<Invariant>();
 
-	private final List<ComparatorWithPreconditions> oracleComparators =
-	        new ArrayList<ComparatorWithPreconditions>();
+	private final List<OracleComparator> oracleComparators =
+	        new ArrayList<OracleComparator>();
 	private final List<WaitCondition> waitConditions = new ArrayList<WaitCondition>();
 	private final List<CrawlCondition> crawlConditions = new ArrayList<CrawlCondition>();
 
@@ -255,7 +255,7 @@
 	/**
 	 * @return the oracleComparators
 	 */
-	protected List<ComparatorWithPreconditions> getOracleComparators() {
+	protected List<OracleComparator> getOracleComparators() {
 		return oracleComparators;
 	}
 
@@ -267,8 +267,8 @@
 	 * @param oracleComparator
 	 *            the oracle to be added.
 	 */
-	public void addOracleComparator(String id, Oracle oracleComparator) {
-		this.oracleComparators.add(new ComparatorWithPreconditions(id, oracleComparator));
+	public void addOracleComparator(String id, Comparator oracleComparator) {
+		this.oracleComparators.add(new OracleComparator(id, oracleComparator));
 	}
 
 	/**
@@ -281,9 +281,9 @@
 	 * @param preConditions
 	 *            the preconditions to be met.
 	 */
-	public void addOracleComparator(String id, Oracle oracleComparator,
+	public void addOracleComparator(String id, Comparator oracleComparator,
 	        Condition... preConditions) {
-		this.oracleComparators.add(new ComparatorWithPreconditions(id, oracleComparator,
+		this.oracleComparators.add(new OracleComparator(id, oracleComparator,
 		        preConditions));
 	}
 
"
9f9e40448437359fabe6ed3c93c8efde620e5126,Ali Mesbah,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 066ab83..7ddd09d 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -8,8 +8,8 @@
 import com.crawljax.condition.browserwaiter.WaitCondition;
 import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.invariant.Invariant;
-import com.crawljax.oracle.ComparatorWithPreconditions;
-import com.crawljax.oracle.Oracle;
+import com.crawljax.oraclecomparator.OracleComparator;
+import com.crawljax.oraclecomparator.Comparator;
 
 /**
  * Specifies the crawl options for a single crawl session. The user must specify which HTML elements
@@ -54,8 +54,8 @@
 	private boolean testInvariantsWhileCrawling = true;
 	private final List<Invariant> invariants = new ArrayList<Invariant>();
 
-	private final List<ComparatorWithPreconditions> oracleComparators =
-	        new ArrayList<ComparatorWithPreconditions>();
+	private final List<OracleComparator> oracleComparators =
+	        new ArrayList<OracleComparator>();
 	private final List<WaitCondition> waitConditions = new ArrayList<WaitCondition>();
 	private final List<CrawlCondition> crawlConditions = new ArrayList<CrawlCondition>();
 
@@ -255,7 +255,7 @@
 	/**
 	 * @return the oracleComparators
 	 */
-	protected List<ComparatorWithPreconditions> getOracleComparators() {
+	protected List<OracleComparator> getOracleComparators() {
 		return oracleComparators;
 	}
 
@@ -267,8 +267,8 @@
 	 * @param oracleComparator
 	 *            the oracle to be added.
 	 */
-	public void addOracleComparator(String id, Oracle oracleComparator) {
-		this.oracleComparators.add(new ComparatorWithPreconditions(id, oracleComparator));
+	public void addOracleComparator(String id, Comparator oracleComparator) {
+		this.oracleComparators.add(new OracleComparator(id, oracleComparator));
 	}
 
 	/**
@@ -281,9 +281,9 @@
 	 * @param preConditions
 	 *            the preconditions to be met.
 	 */
-	public void addOracleComparator(String id, Oracle oracleComparator,
+	public void addOracleComparator(String id, Comparator oracleComparator,
 	        Condition... preConditions) {
-		this.oracleComparators.add(new ComparatorWithPreconditions(id, oracleComparator,
+		this.oracleComparators.add(new OracleComparator(id, oracleComparator,
 		        preConditions));
 	}
 
"
416e4ac15ea84267e0caad7bd7267cc18224a4ed,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 06293ee..50c8db6 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -224,7 +224,7 @@
 	 *            The xpath of the element.
 	 * @return The JavaScript to get an element.
 	 */
-	private static String getJSGetElement(String xpath) {
+	public static String getJSGetElement(String xpath) {
 		String js =
 		        """"
 		                + ""function ATUSA_getElementInNodes(nodes, tagName, number){""
"
416e4ac15ea84267e0caad7bd7267cc18224a4ed,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 70cc44a..5a3b2ac 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -567,7 +567,7 @@
 	}
 
 	/**
-	 * @returnTODO: DOCUMENT ME!
+	 * @return the max value for crawling time.
 	 */
 	public static int getCrawlMaxTimeValue() {
 		return crawlMaxTimeValue;
"
802473a247ee0c6ba54c2c78a8c00161746bcc94,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 06293ee..50c8db6 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -224,7 +224,7 @@
 	 *            The xpath of the element.
 	 * @return The JavaScript to get an element.
 	 */
-	private static String getJSGetElement(String xpath) {
+	public static String getJSGetElement(String xpath) {
 		String js =
 		        """"
 		                + ""function ATUSA_getElementInNodes(nodes, tagName, number){""
"
802473a247ee0c6ba54c2c78a8c00161746bcc94,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 70cc44a..5a3b2ac 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -567,7 +567,7 @@
 	}
 
 	/**
-	 * @returnTODO: DOCUMENT ME!
+	 * @return the max value for crawling time.
 	 */
 	public static int getCrawlMaxTimeValue() {
 		return crawlMaxTimeValue;
"
f9859d1b72675806374f701b6f84419b12b64f67,Danny Roest,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 50c8db6..3389868 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -71,7 +71,7 @@
 					if (text.equals("""")) {
 						return;
 					}
-					String js = getJSGetElement(XPathHelper.getXpathExpression(element));
+					String js = Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
 					js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
 					browser.executeJavaScript(js);
 				}
@@ -79,7 +79,8 @@
 				// check/uncheck checkboxes
 				if (input.getType().equals(""checkbox"")) {
 					for (InputValue inputValue : input.getInputValues()) {
-						String js = getJSGetElement(XPathHelper.getXpathExpression(element));
+						String js =
+						        Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
 						boolean check;
 						if (!randomFieldValue) {
 							check = inputValue.isChecked();
@@ -103,7 +104,9 @@
 				if (input.getType().equals(""radio"")) {
 					for (InputValue inputValue : input.getInputValues()) {
 						if (inputValue.isChecked()) {
-							String js = getJSGetElement(XPathHelper.getXpathExpression(element));
+							String js =
+							        Helper.getJSGetElement(XPathHelper
+							                .getXpathExpression(element));
 							js += ""try{ATUSA_element.checked=true;}catch(e){}"";
 							browser.executeJavaScript(js);
 						}
@@ -114,7 +117,8 @@
 				if (input.getType().startsWith(""select"")) {
 					for (InputValue inputValue : input.getInputValues()) {
 						// if(browser.getDriver()==null){
-						String js = getJSGetElement(XPathHelper.getXpathExpression(element));
+						String js =
+						        Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
 						js +=
 						        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
 						                + ""if(ATUSA_element.options[i].value=='""
@@ -219,52 +223,4 @@
 		}
 	}
 
-	/**
-	 * @param xpath
-	 *            The xpath of the element.
-	 * @return The JavaScript to get an element.
-	 */
-	public static String getJSGetElement(String xpath) {
-		String js =
-		        """"
-		                + ""function ATUSA_getElementInNodes(nodes, tagName, number){""
-		                + ""try{""
-		                + ""var pos = 1;""
-		                + ""for(i=0; i<nodes.length; i++){""
-		                + ""if(nodes[i]!=null && nodes[i].tagName!=null && ""
-		                + ""nodes[i].tagName.toLowerCase() == tagName){""
-		                + ""if(number==pos){""
-		                + ""return nodes[i];""
-		                + ""}else{""
-		                + ""pos++;""
-		                + ""}""
-		                + ""}""
-		                + ""}""
-		                + ""}catch(e){}""
-		                + ""return null;""
-		                + ""}""
-		                + ""function ATUSA_getElementByXpath(xpath){""
-		                + ""try{""
-		                + ""var elements = xpath.toLowerCase().split('/');""
-		                + ""var curNode = document.body;""
-		                + ""var tagName, number;""
-		                + ""for(j=0; j<elements.length; j++){""
-		                + ""if(elements[j]!=''){""
-		                + ""if(elements[j].indexOf('[')==-1){""
-		                + ""tagName = elements[j];""
-		                + ""number = 1;""
-		                + ""}else{""
-		                + ""tagName = elements[j].substring(0, elements[j].indexOf('['));""
-		                + ""number = elements[j].substring(elements[j].indexOf('[')+1, ""
-		                + ""elements[j].lastIndexOf(']'));""
-		                + ""}""
-		                + ""if(tagName!='body' && tagName!='html'){""
-		                + ""curNode = ATUSA_getElementInNodes(curNode.childNodes, tagName, number);""
-		                + ""if(curNode==null){"" + ""return null;"" + ""}"" + ""}"" + ""}"" + ""}""
-		                + ""}catch(e){return null;}"" + ""return curNode;"" + ""}""
-		                + ""try{var ATUSA_element = ATUSA_getElementByXpath('"" + xpath
-		                + ""');}catch(e){return null;}"";
-
-		return js;
-	}
 }
"
82b36207cedf4cd93f38beb28480086e65ceb847,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 50c8db6..3389868 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -71,7 +71,7 @@
 					if (text.equals("""")) {
 						return;
 					}
-					String js = getJSGetElement(XPathHelper.getXpathExpression(element));
+					String js = Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
 					js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
 					browser.executeJavaScript(js);
 				}
@@ -79,7 +79,8 @@
 				// check/uncheck checkboxes
 				if (input.getType().equals(""checkbox"")) {
 					for (InputValue inputValue : input.getInputValues()) {
-						String js = getJSGetElement(XPathHelper.getXpathExpression(element));
+						String js =
+						        Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
 						boolean check;
 						if (!randomFieldValue) {
 							check = inputValue.isChecked();
@@ -103,7 +104,9 @@
 				if (input.getType().equals(""radio"")) {
 					for (InputValue inputValue : input.getInputValues()) {
 						if (inputValue.isChecked()) {
-							String js = getJSGetElement(XPathHelper.getXpathExpression(element));
+							String js =
+							        Helper.getJSGetElement(XPathHelper
+							                .getXpathExpression(element));
 							js += ""try{ATUSA_element.checked=true;}catch(e){}"";
 							browser.executeJavaScript(js);
 						}
@@ -114,7 +117,8 @@
 				if (input.getType().startsWith(""select"")) {
 					for (InputValue inputValue : input.getInputValues()) {
 						// if(browser.getDriver()==null){
-						String js = getJSGetElement(XPathHelper.getXpathExpression(element));
+						String js =
+						        Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
 						js +=
 						        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
 						                + ""if(ATUSA_element.options[i].value=='""
@@ -219,52 +223,4 @@
 		}
 	}
 
-	/**
-	 * @param xpath
-	 *            The xpath of the element.
-	 * @return The JavaScript to get an element.
-	 */
-	public static String getJSGetElement(String xpath) {
-		String js =
-		        """"
-		                + ""function ATUSA_getElementInNodes(nodes, tagName, number){""
-		                + ""try{""
-		                + ""var pos = 1;""
-		                + ""for(i=0; i<nodes.length; i++){""
-		                + ""if(nodes[i]!=null && nodes[i].tagName!=null && ""
-		                + ""nodes[i].tagName.toLowerCase() == tagName){""
-		                + ""if(number==pos){""
-		                + ""return nodes[i];""
-		                + ""}else{""
-		                + ""pos++;""
-		                + ""}""
-		                + ""}""
-		                + ""}""
-		                + ""}catch(e){}""
-		                + ""return null;""
-		                + ""}""
-		                + ""function ATUSA_getElementByXpath(xpath){""
-		                + ""try{""
-		                + ""var elements = xpath.toLowerCase().split('/');""
-		                + ""var curNode = document.body;""
-		                + ""var tagName, number;""
-		                + ""for(j=0; j<elements.length; j++){""
-		                + ""if(elements[j]!=''){""
-		                + ""if(elements[j].indexOf('[')==-1){""
-		                + ""tagName = elements[j];""
-		                + ""number = 1;""
-		                + ""}else{""
-		                + ""tagName = elements[j].substring(0, elements[j].indexOf('['));""
-		                + ""number = elements[j].substring(elements[j].indexOf('[')+1, ""
-		                + ""elements[j].lastIndexOf(']'));""
-		                + ""}""
-		                + ""if(tagName!='body' && tagName!='html'){""
-		                + ""curNode = ATUSA_getElementInNodes(curNode.childNodes, tagName, number);""
-		                + ""if(curNode==null){"" + ""return null;"" + ""}"" + ""}"" + ""}"" + ""}""
-		                + ""}catch(e){return null;}"" + ""return curNode;"" + ""}""
-		                + ""try{var ATUSA_element = ATUSA_getElementByXpath('"" + xpath
-		                + ""');}catch(e){return null;}"";
-
-		return js;
-	}
 }
"
a49a9dcb1cfe6152a6805596c379b5a72b3f9612,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 3389868..8518614 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -189,7 +189,7 @@
 				}
 			}
 		} catch (Exception e) {
-			e.printStackTrace();
+			LOGGER.error(e.getMessage(), e);
 		}
 		return formInputs;
 	}
"
638d34f16ceb2d1a99e7d859e3c6514032785e00,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 3389868..8518614 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -189,7 +189,7 @@
 				}
 			}
 		} catch (Exception e) {
-			e.printStackTrace();
+			LOGGER.error(e.getMessage(), e);
 		}
 		return formInputs;
 	}
"
bb81d3e5e8ef1e62229564a9ba6e70e3f0475aba,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 5a3b2ac..0fbbe9e 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -134,15 +134,14 @@
 	}
 
 	/**
-	 * TODO: DOCUMENT ME!
-	 * 
 	 * @param propertiesFile
-	 *            TODO: DOCUMENT ME!
+	 *            thie properties file.
 	 * @throws ConfigurationException
-	 *             TODO: DOCUMENT ME!
+	 *             if configuration fails.
 	 */
 	public static void init(String propertiesFile) throws ConfigurationException {
 		PropertyHelper.propertiesFileName = propertiesFile;
+		crawljaxConfiguration = null;
 		init(new PropertiesConfiguration(propertiesFile));
 	}
 
@@ -161,6 +160,7 @@
 		if (PropertyHelper.crawljaxConfiguration.getConfiguration() == null) {
 			throw new ConfigurationException(""Configuration cannot be null!"");
 		}
+
 		init(PropertyHelper.crawljaxConfiguration.getConfiguration());
 	}
 
"
308434b99e3d9e38642ea1dde164233fb7b072fd,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 5a3b2ac..0fbbe9e 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -134,15 +134,14 @@
 	}
 
 	/**
-	 * TODO: DOCUMENT ME!
-	 * 
 	 * @param propertiesFile
-	 *            TODO: DOCUMENT ME!
+	 *            thie properties file.
 	 * @throws ConfigurationException
-	 *             TODO: DOCUMENT ME!
+	 *             if configuration fails.
 	 */
 	public static void init(String propertiesFile) throws ConfigurationException {
 		PropertyHelper.propertiesFileName = propertiesFile;
+		crawljaxConfiguration = null;
 		init(new PropertiesConfiguration(propertiesFile));
 	}
 
@@ -161,6 +160,7 @@
 		if (PropertyHelper.crawljaxConfiguration.getConfiguration() == null) {
 			throw new ConfigurationException(""Configuration cannot be null!"");
 		}
+
 		init(PropertyHelper.crawljaxConfiguration.getConfiguration());
 	}
 
"
9ec86eb60829678ea96d72afeaedb7bde262f342,Ali Mesbah,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 7ddd09d..f63e9ce 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -8,8 +8,8 @@
 import com.crawljax.condition.browserwaiter.WaitCondition;
 import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.invariant.Invariant;
-import com.crawljax.oraclecomparator.OracleComparator;
 import com.crawljax.oraclecomparator.Comparator;
+import com.crawljax.oraclecomparator.OracleComparator;
 
 /**
  * Specifies the crawl options for a single crawl session. The user must specify which HTML elements
@@ -54,10 +54,10 @@
 	private boolean testInvariantsWhileCrawling = true;
 	private final List<Invariant> invariants = new ArrayList<Invariant>();
 
-	private final List<OracleComparator> oracleComparators =
-	        new ArrayList<OracleComparator>();
+	private final List<OracleComparator> oracleComparators = new ArrayList<OracleComparator>();
 	private final List<WaitCondition> waitConditions = new ArrayList<WaitCondition>();
 	private final List<CrawlCondition> crawlConditions = new ArrayList<CrawlCondition>();
+	private boolean clicklOnce = true;
 
 	/**
 	 * @param url
@@ -283,8 +283,7 @@
 	 */
 	public void addOracleComparator(String id, Comparator oracleComparator,
 	        Condition... preConditions) {
-		this.oracleComparators.add(new OracleComparator(id, oracleComparator,
-		        preConditions));
+		this.oracleComparators.add(new OracleComparator(id, oracleComparator, preConditions));
 	}
 
 	/**
@@ -392,4 +391,23 @@
 		this.crawlConditions.add(new CrawlCondition(description, crawlCondition, preConditions));
 	}
 
+	/**
+	 * @return the crawl once value.
+	 */
+	public Integer getClickOnce() {
+		if (this.clicklOnce) {
+			return 1;
+		} else {
+			return 0;
+		}
+	}
+
+	/**
+	 * @param clickOnce
+	 *            the crawl once value;
+	 */
+	public void setClickOnce(boolean clickOnce) {
+		this.clicklOnce = clickOnce;
+	}
+
 }
"
9ec86eb60829678ea96d72afeaedb7bde262f342,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setBrowser -> [WebDriver driver] | [EmbeddedBrowser browser],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index fa97e34..2dd0887 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -118,6 +118,9 @@
 		// CrawlSpecificatoin
 		config.addProperty(""site.url"", getCrawlSpecification().getUrl());
 		config.addProperty(""database.use"", getUseDatabaseAsInt());
+
+		config.addProperty(""click.once"", getCrawlSpecification().getClickOnce());
+
 		config.addProperty(""robot.events"", ConfigurationHelper
 		        .listToString(getCrawlSpecification().getCrawlEvents()));
 		config.addProperty(""crawl.tags"", ConfigurationHelper
"
07f99a099cd1a0dc4b9ea3f5ef4460d2019d37a2,Ali Mesbah,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 7ddd09d..f63e9ce 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -8,8 +8,8 @@
 import com.crawljax.condition.browserwaiter.WaitCondition;
 import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.invariant.Invariant;
-import com.crawljax.oraclecomparator.OracleComparator;
 import com.crawljax.oraclecomparator.Comparator;
+import com.crawljax.oraclecomparator.OracleComparator;
 
 /**
  * Specifies the crawl options for a single crawl session. The user must specify which HTML elements
@@ -54,10 +54,10 @@
 	private boolean testInvariantsWhileCrawling = true;
 	private final List<Invariant> invariants = new ArrayList<Invariant>();
 
-	private final List<OracleComparator> oracleComparators =
-	        new ArrayList<OracleComparator>();
+	private final List<OracleComparator> oracleComparators = new ArrayList<OracleComparator>();
 	private final List<WaitCondition> waitConditions = new ArrayList<WaitCondition>();
 	private final List<CrawlCondition> crawlConditions = new ArrayList<CrawlCondition>();
+	private boolean clicklOnce = true;
 
 	/**
 	 * @param url
@@ -283,8 +283,7 @@
 	 */
 	public void addOracleComparator(String id, Comparator oracleComparator,
 	        Condition... preConditions) {
-		this.oracleComparators.add(new OracleComparator(id, oracleComparator,
-		        preConditions));
+		this.oracleComparators.add(new OracleComparator(id, oracleComparator, preConditions));
 	}
 
 	/**
@@ -392,4 +391,23 @@
 		this.crawlConditions.add(new CrawlCondition(description, crawlCondition, preConditions));
 	}
 
+	/**
+	 * @return the crawl once value.
+	 */
+	public Integer getClickOnce() {
+		if (this.clicklOnce) {
+			return 1;
+		} else {
+			return 0;
+		}
+	}
+
+	/**
+	 * @param clickOnce
+	 *            the crawl once value;
+	 */
+	public void setClickOnce(boolean clickOnce) {
+		this.clicklOnce = clickOnce;
+	}
+
 }
"
07f99a099cd1a0dc4b9ea3f5ef4460d2019d37a2,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setBrowser -> [WebDriver driver] | [EmbeddedBrowser browser],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index fa97e34..2dd0887 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -118,6 +118,9 @@
 		// CrawlSpecificatoin
 		config.addProperty(""site.url"", getCrawlSpecification().getUrl());
 		config.addProperty(""database.use"", getUseDatabaseAsInt());
+
+		config.addProperty(""click.once"", getCrawlSpecification().getClickOnce());
+
 		config.addProperty(""robot.events"", ConfigurationHelper
 		        .listToString(getCrawlSpecification().getCrawlEvents()));
 		config.addProperty(""crawl.tags"", ConfigurationHelper
"
8f57fb0703f8684e8dc80637e1513fadbb3468fa,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 0fbbe9e..e380c6a 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -76,6 +76,10 @@
 	private static String useDatabase = ""database.use"";
 	private static int useDatabaseValue = 0;
 
+	// if each candidate clickable should be clicked only once
+	private static String clickOnce = ""click.once"";
+	private static int clickOnceValue = 1;
+
 	private static int testInvariantsWhileCrawlingValue = 1;
 
 	private static String debugVariables = ""reportbuilder.debugvariables"";
@@ -201,6 +205,10 @@
 
 		useDatabaseValue = getPropertyAsInt(useDatabase);
 
+		if (config.containsKey(clickOnce)) {
+			clickOnceValue = getPropertyAsInt(clickOnce);
+		}
+
 		debugVariablesValues = getPropertyAsList(debugVariables);
 
 		setTagElements();
@@ -874,4 +882,11 @@
 	public static String getPropertiesFileName() {
 		return propertiesFileName;
 	}
+
+	/**
+	 * @return if each candidate clickable should be clicked only once.
+	 */
+	public static boolean getClickOnceValue() {
+		return clickOnceValue == 1;
+	}
 }
"
2f121c065262a2a8ed3cd0c8555a8184ef89e3ab,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 0fbbe9e..e380c6a 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -76,6 +76,10 @@
 	private static String useDatabase = ""database.use"";
 	private static int useDatabaseValue = 0;
 
+	// if each candidate clickable should be clicked only once
+	private static String clickOnce = ""click.once"";
+	private static int clickOnceValue = 1;
+
 	private static int testInvariantsWhileCrawlingValue = 1;
 
 	private static String debugVariables = ""reportbuilder.debugvariables"";
@@ -201,6 +205,10 @@
 
 		useDatabaseValue = getPropertyAsInt(useDatabase);
 
+		if (config.containsKey(clickOnce)) {
+			clickOnceValue = getPropertyAsInt(clickOnce);
+		}
+
 		debugVariablesValues = getPropertyAsList(debugVariables);
 
 		setTagElements();
@@ -874,4 +882,11 @@
 	public static String getPropertiesFileName() {
 		return propertiesFileName;
 	}
+
+	/**
+	 * @return if each candidate clickable should be clicked only once.
+	 */
+	public static boolean getClickOnceValue() {
+		return clickOnceValue == 1;
+	}
 }
"
2898acc9fed7444a80a9ebb5925ce91a703bae2c,Ali Mesbah,CandidateElementExtractor.java,MODIFY,"extract -> [] | [List crawlTagElements, List crawlExcludeTagElements, boolean clickOnce]","diff --git a/src/main/java/com/crawljax/core/CandidateElementExtractor.java b/src/main/java/com/crawljax/core/CandidateElementExtractor.java
index 650a352..9101478 100644
--- a/src/main/java/com/crawljax/core/CandidateElementExtractor.java
+++ b/src/main/java/com/crawljax/core/CandidateElementExtractor.java
@@ -13,6 +13,7 @@
 import org.apache.log4j.Logger;
 import org.w3c.dom.Document;
 import org.w3c.dom.Element;
+import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
 import org.xml.sax.SAXException;
 
@@ -22,12 +23,11 @@
 import com.crawljax.core.state.Eventable;
 import com.crawljax.forms.FormInputValueHelper;
 import com.crawljax.util.Helper;
-import com.crawljax.util.PropertyHelper;
 import com.crawljax.util.XPathHelper;
 
 /**
- * This class extracts candidate elements from the DOM tree, based on the crawl.tags provided by the
- * user.
+ * This class extracts candidate elements from the DOM tree, based on the tags provided by the user.
+ * Elements can also be excluded.
  * 
  * @author mesbah
  * @version $Id: CandidateElementExtractor.java 6399 2009-12-29 14:34:27Z mesbah $
@@ -39,7 +39,7 @@
 
 	private final EventableConditionChecker eventableConditionChecker;
 	private final EmbeddedBrowser browser;
-	private static final Set<String> CHECKEDELEMENTS = new LinkedHashSet<String>();
+	private final Set<String> checkedElements = new LinkedHashSet<String>();
 
 	/**
 	 * The number of checked elements, as a statistics measure to know how many elements were
@@ -70,18 +70,29 @@
 	 * This method extracts candidate elements from the current DOM tree in the browser, based on
 	 * the crawl tags defined by the user.
 	 * 
-	 * @return a list of candidate elements.
+	 * @param crawlTagElements
+	 *            a list of TagElements to include.
+	 * @param crawlExcludeTagElements
+	 *            a list of TagElements to exclude.
+	 * @param clickOnce
+	 *            true if each candidate elements should be included only once.
+	 * @return a list of candidate elements that are not excluded.
 	 * @throws CrawljaxException
 	 *             if the method fails.
 	 */
-	public List<CandidateElement> extract() throws CrawljaxException {
+	public List<CandidateElement> extract(List<TagElement> crawlTagElements,
+	        List<TagElement> crawlExcludeTagElements, boolean clickOnce) throws CrawljaxException {
 		List<CandidateElement> tagElements = new ArrayList<CandidateElement>();
-		for (TagElement tag : PropertyHelper.getCrawlTagElements()) {
+
+		for (TagElement tag : crawlTagElements) {
 			LOGGER.info(""TAG: "" + tag.toString());
 			// TODO DELTA DIFF
 			List<Element> temp;
 			try {
-				temp = getNodeListForTagElement(browser, tag, eventableConditionChecker);
+				temp =
+				        getNodeListForTagElement(browser, tag, eventableConditionChecker,
+				                crawlExcludeTagElements);
+
 			} catch (Exception e) {
 				throw new CrawljaxException(e.getMessage(), e);
 			}
@@ -110,8 +121,7 @@
 				for (CandidateElement candidateElement : candidateElements) {
 					String elementUniqueString = candidateElement.getUniqueString();
 
-					if (!PropertyHelper.getClickOnceValue()
-					        || !CHECKEDELEMENTS.contains(elementUniqueString)) {
+					if (!clickOnce || !checkedElements.contains(elementUniqueString)) {
 
 						LOGGER.info(""Found new candidate element: ""
 						        + new Eventable(candidateElement, """").toString());
@@ -122,12 +132,12 @@
 						tagElements.add(candidateElement);
 						// TODO add element to checkedElements after the
 						// event is fired!
-						CHECKEDELEMENTS.add(elementUniqueString);
+						checkedElements.add(elementUniqueString);
 						// also add string without 'atusa' attribute to
 						// make sure an
 						// form action element is only clicked for its
 						// defined values
-						CHECKEDELEMENTS.add(candidateElement.getGeneralString());
+						checkedElements.add(candidateElement.getGeneralString());
 					}
 				}
 			}
@@ -145,8 +155,9 @@
 	 * @throws XPathExpressionException
 	 */
 	private List<Element> getNodeListForTagElement(EmbeddedBrowser browser,
-	        TagElement tagElement, EventableConditionChecker eventableConditionChecker)
-	        throws SAXException, IOException, CrawljaxException, XPathExpressionException {
+	        TagElement tagElement, EventableConditionChecker eventableConditionChecker,
+	        List<TagElement> crawlExcludeTagElements) throws SAXException, IOException,
+	        CrawljaxException, XPathExpressionException {
 		Document dom = Helper.getDocument(browser.getDom());
 		NodeList nodeList = dom.getElementsByTagName(tagElement.getName());
 		Set<TagAttribute> attributes = tagElement.getAttributes();
@@ -174,16 +185,15 @@
 			}
 			// check if element is a candidate
 			if (matchesXpath
-			        && !CHECKEDELEMENTS.contains(element.getNodeName() + "": ""
+			        && !checkedElements.contains(element.getNodeName() + "": ""
 			                + Helper.getAllElementAttributes(element))
 			        && isElementVisible(dom, browser, element)
 			        && !filterElement(attributes, element)) {
 				if (""A"".equalsIgnoreCase(tagElement.getName())) {
 					String href = element.getAttribute(""href"");
-					boolean isExternal =
-					        Helper.isLinkExternal(PropertyHelper.getSiteUrlValue(), href);
+					boolean isExternal = Helper.isLinkExternal(browser.getCurrentUrl(), href);
 					boolean isEmail = isEmail(href);
-					Helper.LOGGER.debug(""HREF: "" + href + ""isExternal= "" + isExternal);
+					LOGGER.debug(""HREF: "" + href + ""isExternal= "" + isExternal);
 
 					if (!(isExternal || isEmail || isPDForPS(href))) {
 						result.add(element);
@@ -196,13 +206,12 @@
 			}
 		}
 
-		if ((PropertyHelper.getCrawlExcludeTagElements() == null)
-		        || (PropertyHelper.getCrawlExcludeTagElements().size() == 0)) {
+		if ((crawlExcludeTagElements == null) || (crawlExcludeTagElements.size() == 0)) {
 			return result;
 		} else {
 			List<Element> resultExcluded = new ArrayList<Element>();
 			for (Element e : result) {
-				if (!isExcluded(dom, e, eventableConditionChecker)) {
+				if (!isExcluded(dom, e, eventableConditionChecker, crawlExcludeTagElements)) {
 					resultExcluded.add(e);
 				}
 			}
@@ -234,7 +243,6 @@
 	 * @return true if href has the pdf or ps pattern.
 	 */
 	private boolean isPDForPS(String href) {
-		// Set the email pattern string
 		final Pattern p = Pattern.compile("".+.pdf|.+.ps"");
 		Matcher m = p.matcher(href);
 
@@ -246,11 +254,22 @@
 	}
 
 	/**
-	 * Returns true if element should be excluded.
+	 * @return true if element should be excluded. Also when an ancestor of the given element is
+	 *         marked for exclusion, which allows for recursive exclusion of elements from
+	 *         candidates.
 	 */
 	private boolean isExcluded(Document dom, Element element,
-	        EventableConditionChecker eventableConditionChecker) {
-		for (TagElement tag : PropertyHelper.getCrawlExcludeTagElements()) {
+	        EventableConditionChecker eventableConditionChecker, List<TagElement> excluded) {
+
+		Node parent = element.getParentNode();
+
+		if (parent instanceof Element) {
+			if (isExcluded(dom, (Element) parent, eventableConditionChecker, excluded)) {
+				return true;
+			}
+		}
+
+		for (TagElement tag : excluded) {
 
 			if (element.getTagName().equalsIgnoreCase(tag.getName())) {
 				boolean matchesXPath = false;
@@ -264,23 +283,24 @@
 					                                .getXpathExpression(element));
 				} catch (Exception e) {
 					// xpath could not be found or determined, so dont filter
-					// element element because of xpath
+					// element because of xpath
 					matchesXPath = false;
 				}
 
 				if (matchesXPath) {
-					Helper.LOGGER.info(""Excluded element because of xpath: ""
+					LOGGER.info(""Excluded element because of xpath: ""
 					        + new Eventable(element, """").toString());
 					return true;
 				}
 				if (!filterElement(tag.getAttributes(), element)
 				        && tag.getAttributes().size() > 0) {
-					Helper.LOGGER.info(""Excluded element because of attributes: ""
+					LOGGER.info(""Excluded element because of attributes: ""
 					        + new Eventable(element, """").toString());
 					return true;
 				}
 			}
 		}
+
 		return false;
 	}
 
@@ -301,8 +321,9 @@
 		NodeList nodes = Helper.getElementsByXpath(dom, xpath);
 
 		if (nodes.getLength() > 0) {
-			Helper.LOGGER.debug(""Element: "" + Helper.getAllElementAttributes(element)
-			        + "" is invisible!"");
+			LOGGER
+			        .debug(""Element: "" + Helper.getAllElementAttributes(element)
+			                + "" is invisible!"");
 
 			return false;
 		}
@@ -319,7 +340,7 @@
 			return false;
 		}
 		for (TagAttribute attr : attributes) {
-			Helper.LOGGER.debug(""Checking element "" + Helper.getElementString(element)
+			LOGGER.debug(""Checking element "" + Helper.getElementString(element)
 			        + ""AttributeName: "" + attr.getName() + "" value: "" + attr.getValue());
 
 			if (attr.matchesValue(element.getAttribute(attr.getName()))) {
"
f187cf151cd08312205bc183174a5a168a184f5c,Danny Roest,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index f63e9ce..265b6b8 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -394,12 +394,8 @@
 	/**
 	 * @return the crawl once value.
 	 */
-	public Integer getClickOnce() {
-		if (this.clicklOnce) {
-			return 1;
-		} else {
-			return 0;
-		}
+	protected boolean getClickOnce() {
+		return this.clicklOnce;
 	}
 
 	/**
"
f187cf151cd08312205bc183174a5a168a184f5c,Danny Roest,CrawljaxConfiguration.java,MODIFY,setBrowser -> [WebDriver driver] | [EmbeddedBrowser browser],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 2dd0887..4fdad0e 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -53,7 +53,6 @@
 
 	private CrawlSpecification crawlSpecification = new CrawlSpecification("""");
 	private HibernateConfiguration hibernateConfiguration = new HibernateConfiguration();
-	private ReportConfiguration reportConfiguration = new ReportConfiguration();
 	private ProxyConfiguration proxyConfiguration = null;
 
 	/**
@@ -101,25 +100,17 @@
 		config.addProperty(""output.path"", getOutputFolder());
 		config.addProperty(""project.path.relative"", getProjectRelativePath());
 
-		config.addProperty(""report.max.state.differences"", getReportConfiguration()
-		        .getReportMaxStateDifferences());
-		config.addProperty(""reportbuilder.debugvariables"", ConfigurationHelper
-		        .listToString(getReportConfiguration().getReportDebugVariables()));
-		config.addProperty(""report.differences.all"", ConfigurationHelper
-		        .booleanToInt(getReportConfiguration().getReportShowAllStateDifferences()));
-		config.addProperty(""report.screenshots"", ConfigurationHelper
-		        .booleanToInt(getReportConfiguration().getReportIncludeScreenshots()));
-
 		config.addProperty(""hibernate.hbm2ddl.auto"", getHibernateConfiguration()
 		        .getDatabaseScheme());
 		config.addProperty(""invariantcontroller.testcrawling"", ConfigurationHelper
 		        .booleanToInt(getCrawlSpecification().getTestInvariantsWhileCrawling()));
 
-		// CrawlSpecificatoin
+		// CrawlSpecification
 		config.addProperty(""site.url"", getCrawlSpecification().getUrl());
 		config.addProperty(""database.use"", getUseDatabaseAsInt());
 
-		config.addProperty(""click.once"", getCrawlSpecification().getClickOnce());
+		config.addProperty(""click.once"", ConfigurationHelper.booleanToInt(getCrawlSpecification()
+		        .getClickOnce()));
 
 		config.addProperty(""robot.events"", ConfigurationHelper
 		        .listToString(getCrawlSpecification().getCrawlEvents()));
@@ -148,21 +139,6 @@
 	}
 
 	/**
-	 * @return The reportConfiguration which contains report settings.
-	 */
-	protected ReportConfiguration getReportConfiguration() {
-		return reportConfiguration;
-	}
-
-	/**
-	 * @param reportConfiguration
-	 *            Which contains report settings.
-	 */
-	public void setReportConfiguration(ReportConfiguration reportConfiguration) {
-		this.reportConfiguration = reportConfiguration;
-	}
-
-	/**
 	 * Enable the crawljax proxy extension.
 	 * 
 	 * @param proxyConfiguration
"
f187cf151cd08312205bc183174a5a168a184f5c,Danny Roest,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index e380c6a..b67b90c 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -65,14 +65,6 @@
 	private static String hibernateSchema = ""hibernate.hbm2ddl.auto"";
 	private static String hibernateSchemaValue;
 
-	private static String reportMaxStateDifferences = ""report.max.state.differences"";
-	private static final int DEFAULT_MAX_STATE_DIFFERENCES = 15;
-	private static int reportMaxStateDifferencesValue = DEFAULT_MAX_STATE_DIFFERENCES;
-	private static String reportDifferencesAll = ""report.differences.all"";
-	private static int reportDifferencesAllValue = 0;
-	private static String reportScreenshots = ""report.screenshots"";
-	private static int reportScreenshotsValue = 1;
-
 	private static String useDatabase = ""database.use"";
 	private static int useDatabaseValue = 0;
 
@@ -199,10 +191,6 @@
 		}
 		hibernatePropertiesValue = getProperty(hibernateProperties);
 
-		reportMaxStateDifferencesValue = getPropertyAsInt(reportMaxStateDifferences);
-		reportDifferencesAllValue = getPropertyAsInt(reportDifferencesAll);
-		reportScreenshotsValue = getPropertyAsInt(reportScreenshots);
-
 		useDatabaseValue = getPropertyAsInt(useDatabase);
 
 		if (config.containsKey(clickOnce)) {
@@ -784,27 +772,6 @@
 	}
 
 	/**
-	 * @return the reportMaxStateDifferencesValue
-	 */
-	public static int getReportMaxStateDifferencesValue() {
-		return reportMaxStateDifferencesValue;
-	}
-
-	/**
-	 * @return the reportDifferencesAllValue
-	 */
-	public static boolean getReportDifferencesAllValue() {
-		return reportDifferencesAllValue == 1;
-	}
-
-	/**
-	 * @return the reportScreenshotsValue
-	 */
-	public static boolean getReportScreenshotsValue() {
-		return reportScreenshotsValue == 1;
-	}
-
-	/**
 	 * @return the testInvariantsWhileCrawlingValue
 	 */
 	public static boolean getTestInvariantsWhileCrawlingValue() {
"
bb857b72f765769a6cf93bef3a2d00c9b5ea4bea,Ali Mesbah,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index f63e9ce..265b6b8 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -394,12 +394,8 @@
 	/**
 	 * @return the crawl once value.
 	 */
-	public Integer getClickOnce() {
-		if (this.clicklOnce) {
-			return 1;
-		} else {
-			return 0;
-		}
+	protected boolean getClickOnce() {
+		return this.clicklOnce;
 	}
 
 	/**
"
bb857b72f765769a6cf93bef3a2d00c9b5ea4bea,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setBrowser -> [WebDriver driver] | [EmbeddedBrowser browser],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 2dd0887..4fdad0e 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -53,7 +53,6 @@
 
 	private CrawlSpecification crawlSpecification = new CrawlSpecification("""");
 	private HibernateConfiguration hibernateConfiguration = new HibernateConfiguration();
-	private ReportConfiguration reportConfiguration = new ReportConfiguration();
 	private ProxyConfiguration proxyConfiguration = null;
 
 	/**
@@ -101,25 +100,17 @@
 		config.addProperty(""output.path"", getOutputFolder());
 		config.addProperty(""project.path.relative"", getProjectRelativePath());
 
-		config.addProperty(""report.max.state.differences"", getReportConfiguration()
-		        .getReportMaxStateDifferences());
-		config.addProperty(""reportbuilder.debugvariables"", ConfigurationHelper
-		        .listToString(getReportConfiguration().getReportDebugVariables()));
-		config.addProperty(""report.differences.all"", ConfigurationHelper
-		        .booleanToInt(getReportConfiguration().getReportShowAllStateDifferences()));
-		config.addProperty(""report.screenshots"", ConfigurationHelper
-		        .booleanToInt(getReportConfiguration().getReportIncludeScreenshots()));
-
 		config.addProperty(""hibernate.hbm2ddl.auto"", getHibernateConfiguration()
 		        .getDatabaseScheme());
 		config.addProperty(""invariantcontroller.testcrawling"", ConfigurationHelper
 		        .booleanToInt(getCrawlSpecification().getTestInvariantsWhileCrawling()));
 
-		// CrawlSpecificatoin
+		// CrawlSpecification
 		config.addProperty(""site.url"", getCrawlSpecification().getUrl());
 		config.addProperty(""database.use"", getUseDatabaseAsInt());
 
-		config.addProperty(""click.once"", getCrawlSpecification().getClickOnce());
+		config.addProperty(""click.once"", ConfigurationHelper.booleanToInt(getCrawlSpecification()
+		        .getClickOnce()));
 
 		config.addProperty(""robot.events"", ConfigurationHelper
 		        .listToString(getCrawlSpecification().getCrawlEvents()));
@@ -148,21 +139,6 @@
 	}
 
 	/**
-	 * @return The reportConfiguration which contains report settings.
-	 */
-	protected ReportConfiguration getReportConfiguration() {
-		return reportConfiguration;
-	}
-
-	/**
-	 * @param reportConfiguration
-	 *            Which contains report settings.
-	 */
-	public void setReportConfiguration(ReportConfiguration reportConfiguration) {
-		this.reportConfiguration = reportConfiguration;
-	}
-
-	/**
 	 * Enable the crawljax proxy extension.
 	 * 
 	 * @param proxyConfiguration
"
bb857b72f765769a6cf93bef3a2d00c9b5ea4bea,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index e380c6a..b67b90c 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -65,14 +65,6 @@
 	private static String hibernateSchema = ""hibernate.hbm2ddl.auto"";
 	private static String hibernateSchemaValue;
 
-	private static String reportMaxStateDifferences = ""report.max.state.differences"";
-	private static final int DEFAULT_MAX_STATE_DIFFERENCES = 15;
-	private static int reportMaxStateDifferencesValue = DEFAULT_MAX_STATE_DIFFERENCES;
-	private static String reportDifferencesAll = ""report.differences.all"";
-	private static int reportDifferencesAllValue = 0;
-	private static String reportScreenshots = ""report.screenshots"";
-	private static int reportScreenshotsValue = 1;
-
 	private static String useDatabase = ""database.use"";
 	private static int useDatabaseValue = 0;
 
@@ -199,10 +191,6 @@
 		}
 		hibernatePropertiesValue = getProperty(hibernateProperties);
 
-		reportMaxStateDifferencesValue = getPropertyAsInt(reportMaxStateDifferences);
-		reportDifferencesAllValue = getPropertyAsInt(reportDifferencesAll);
-		reportScreenshotsValue = getPropertyAsInt(reportScreenshots);
-
 		useDatabaseValue = getPropertyAsInt(useDatabase);
 
 		if (config.containsKey(clickOnce)) {
@@ -784,27 +772,6 @@
 	}
 
 	/**
-	 * @return the reportMaxStateDifferencesValue
-	 */
-	public static int getReportMaxStateDifferencesValue() {
-		return reportMaxStateDifferencesValue;
-	}
-
-	/**
-	 * @return the reportDifferencesAllValue
-	 */
-	public static boolean getReportDifferencesAllValue() {
-		return reportDifferencesAllValue == 1;
-	}
-
-	/**
-	 * @return the reportScreenshotsValue
-	 */
-	public static boolean getReportScreenshotsValue() {
-		return reportScreenshotsValue == 1;
-	}
-
-	/**
 	 * @return the testInvariantsWhileCrawlingValue
 	 */
 	public static boolean getTestInvariantsWhileCrawlingValue() {
"
075c2f3582aae1ae21cef21446c1e1b2ec1aef79,Danny Roest,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 265b6b8..b986eaf 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -15,20 +15,31 @@
  * Specifies the crawl options for a single crawl session. The user must specify which HTML elements
  * should be clicked during the crawl session.
  * <p/>
- * The scope can be restricted using {@link #setDepth(int)}and {@link #setMaximumStates(int)}. The
- * duration can be restricted using {@link #setMaximumRuntime(int)}.
+ * The scope can be restricted using {@link #setDepth(int)}and {@link #setMaximumStates(int)}.<br />
+ * The duration can be restricted using {@link #setMaximumRuntime(int)}.
  * <p/>
  * By default Crawljax fills in random values for input fields
- * {@link #setRandomInputInForms(boolean)}. Specific input for form elements can be defined with
- * {@link #setInputSpecification(InputSpecification)}. Default values: Maximum runtime: 3600 seconds
- * Time to wait after initial pageload: 500 milliseconds Time to wait after clicking HTML elements:
- * 500 milliseconds Enter random form input data: true EXAMPLE: CrawlSpecification crawler = new
- * CrawlSpecification(""http://www.google.com""); //click these elements crawler.click(""a"");
- * crawler.click(""input"").withAttribute(""type"", ""submit""); onLoginPageCondition = new
- * UrlCondition(""#login""); crawler.when(onLoginPageCondition).click(""a"").withText(""Login""); //but
- * don't click these crawler.dontClick(""a"").underXpath(""//DIV[@id='guser']"");
- * crawler.dontClick(""a"").withText(""Language Tools""); //restrict the scope of the crawling
- * crawler.setCrawlMaximumStates(15); crawler.setCrawlDepth(2);
+ * {@link #setRandomInputInForms(boolean)}.<br />
+ * Specific input for form elements can be defined with
+ * {@link #setInputSpecification(InputSpecification)}.<br />
+ * Default values: Maximum runtime: 3600 seconds<br />
+ * Time to wait after initial pageload: 500 milliseconds<br />
+ * Time to wait after clicking HTML elements: 500 milliseconds<br />
+ * Enter random form input data: true
+ * <p/>
+ * EXAMPLE:<br />
+ * CrawlSpecification crawler = new CrawlSpecification(""http://www.google.com"");<br />
+ * //click these elements<br />
+ * crawler.click(""a"");<br />
+ * crawler.click(""input"").withAttribute(""type"", ""submit"");<br />
+ * onLoginPageCondition = new UrlCondition(""#login"");<br />
+ * crawler.when(onLoginPageCondition).click(""a"").withText(""Login"");<br />
+ * //but don't click these<br />
+ * crawler.dontClick(""a"").underXpath(""//DIV[@id='guser']"");
+ * crawler.dontClick(""a"").withText(""Language Tools""); <br />
+ * //restrict the scope of the crawling<br />
+ * crawler.setCrawlMaximumStates(15);<br />
+ * crawler.setCrawlDepth(2);
  * 
  * @author DannyRoest@gmail.com (Danny Roest)
  */
@@ -70,7 +81,7 @@
 
 	/**
 	 * Specifies that Crawljax should click all the default clickable elements. These include: All
-	 * anchor tags All buttons Any div
+	 * anchor tags All buttons
 	 */
 	public void clickDefaultElements() {
 		crawlActions.click(""a"");
"
d59ebb00349a276dc581c9973f3d387cdd962691,Ali Mesbah,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 265b6b8..b986eaf 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -15,20 +15,31 @@
  * Specifies the crawl options for a single crawl session. The user must specify which HTML elements
  * should be clicked during the crawl session.
  * <p/>
- * The scope can be restricted using {@link #setDepth(int)}and {@link #setMaximumStates(int)}. The
- * duration can be restricted using {@link #setMaximumRuntime(int)}.
+ * The scope can be restricted using {@link #setDepth(int)}and {@link #setMaximumStates(int)}.<br />
+ * The duration can be restricted using {@link #setMaximumRuntime(int)}.
  * <p/>
  * By default Crawljax fills in random values for input fields
- * {@link #setRandomInputInForms(boolean)}. Specific input for form elements can be defined with
- * {@link #setInputSpecification(InputSpecification)}. Default values: Maximum runtime: 3600 seconds
- * Time to wait after initial pageload: 500 milliseconds Time to wait after clicking HTML elements:
- * 500 milliseconds Enter random form input data: true EXAMPLE: CrawlSpecification crawler = new
- * CrawlSpecification(""http://www.google.com""); //click these elements crawler.click(""a"");
- * crawler.click(""input"").withAttribute(""type"", ""submit""); onLoginPageCondition = new
- * UrlCondition(""#login""); crawler.when(onLoginPageCondition).click(""a"").withText(""Login""); //but
- * don't click these crawler.dontClick(""a"").underXpath(""//DIV[@id='guser']"");
- * crawler.dontClick(""a"").withText(""Language Tools""); //restrict the scope of the crawling
- * crawler.setCrawlMaximumStates(15); crawler.setCrawlDepth(2);
+ * {@link #setRandomInputInForms(boolean)}.<br />
+ * Specific input for form elements can be defined with
+ * {@link #setInputSpecification(InputSpecification)}.<br />
+ * Default values: Maximum runtime: 3600 seconds<br />
+ * Time to wait after initial pageload: 500 milliseconds<br />
+ * Time to wait after clicking HTML elements: 500 milliseconds<br />
+ * Enter random form input data: true
+ * <p/>
+ * EXAMPLE:<br />
+ * CrawlSpecification crawler = new CrawlSpecification(""http://www.google.com"");<br />
+ * //click these elements<br />
+ * crawler.click(""a"");<br />
+ * crawler.click(""input"").withAttribute(""type"", ""submit"");<br />
+ * onLoginPageCondition = new UrlCondition(""#login"");<br />
+ * crawler.when(onLoginPageCondition).click(""a"").withText(""Login"");<br />
+ * //but don't click these<br />
+ * crawler.dontClick(""a"").underXpath(""//DIV[@id='guser']"");
+ * crawler.dontClick(""a"").withText(""Language Tools""); <br />
+ * //restrict the scope of the crawling<br />
+ * crawler.setCrawlMaximumStates(15);<br />
+ * crawler.setCrawlDepth(2);
  * 
  * @author DannyRoest@gmail.com (Danny Roest)
  */
@@ -70,7 +81,7 @@
 
 	/**
 	 * Specifies that Crawljax should click all the default clickable elements. These include: All
-	 * anchor tags All buttons Any div
+	 * anchor tags All buttons
 	 */
 	public void clickDefaultElements() {
 		crawlActions.click(""a"");
"
f23cf324e6b4e01778bae189d8755148e4252fe2,Frank Groeneveld,CrawljaxConfiguration.java,MODIFY,setBrowser -> [WebDriver driver] | [EmbeddedBrowser browser],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 4fdad0e..720b313 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -34,7 +34,7 @@
  * crawler = new CrawlSpecification(""http://www.google.com""); crawler.click(""a"");
  * crawljaxConfig.setCrawlSpecification(crawler);
  * 
- * @version $Id: CrawljaxConfiguration.java 6381 2009-12-29 12:26:47Z frank $
+ * @version $Id$
  */
 public final class CrawljaxConfiguration {
 
"
f23cf324e6b4e01778bae189d8755148e4252fe2,Frank Groeneveld,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 8518614..ba90bb7 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -23,7 +23,7 @@
  * values.
  * 
  * @author dannyroest@gmail.com (Danny Roest)
- * @version $Id: FormHandler.java 6320 2009-12-25 20:53:02Z danny $
+ * @version $Id$
  */
 public class FormHandler {
 	private static final Logger LOGGER = Logger.getLogger(FormHandler.class.getName());
"
f23cf324e6b4e01778bae189d8755148e4252fe2,Frank Groeneveld,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/src/main/java/com/crawljax/util/ElementResolver.java b/src/main/java/com/crawljax/util/ElementResolver.java
index 3094620..eda5bac 100644
--- a/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/src/main/java/com/crawljax/util/ElementResolver.java
@@ -13,7 +13,7 @@
 
 /**
  * @author danny
- * @version $Id: ElementResolver.java 6276 2009-12-23 15:37:09Z frank $ class for finding and
+ * @version $Id$ class for finding and
  *          checking elements
  */
 public class ElementResolver {
"
f23cf324e6b4e01778bae189d8755148e4252fe2,Frank Groeneveld,PrettyHTML.java,MODIFY,"prettyHTML -> [String html] | [String html, String strIndent]","diff --git a/src/main/java/com/crawljax/util/PrettyHTML.java b/src/main/java/com/crawljax/util/PrettyHTML.java
index cbc4881..f4be1ed 100644
--- a/src/main/java/com/crawljax/util/PrettyHTML.java
+++ b/src/main/java/com/crawljax/util/PrettyHTML.java
@@ -6,7 +6,7 @@
  * Class for making presenting HTML without changing it's structure.
  * 
  * @author Danny
- * @version $Id: PrettyHTML.java 6276 2009-12-23 15:37:09Z frank $
+ * @version $Id$
  */
 public final class PrettyHTML {
 
"
f23cf324e6b4e01778bae189d8755148e4252fe2,Frank Groeneveld,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index b67b90c..eb1f884 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -21,7 +21,7 @@
 
 /**
  * @author mesbah
- * @version $Id: PropertyHelper.java 6381 2009-12-29 12:26:47Z frank $
+ * @version $Id$
  */
 public final class PropertyHelper {
 	private static final Logger LOGGER = Logger.getLogger(PropertyHelper.class.getName());
"
f23cf324e6b4e01778bae189d8755148e4252fe2,Frank Groeneveld,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index c1beb3f..3ae76cc 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -24,7 +24,7 @@
  * TODO: DOCUMENT ME!
  * 
  * @author mesbah
- * @version $Id: XPathHelper.java 6370 2009-12-29 07:59:21Z frank $
+ * @version $Id$
  */
 public final class XPathHelper {
 	private static final Logger LOGGER = Logger.getLogger(XPathHelper.class.getName());
"
f23cf324e6b4e01778bae189d8755148e4252fe2,Frank Groeneveld,HibernateUtil.java,MODIFY,initialize -> [String hbm2ddlAuto] | [],"diff --git a/src/main/java/com/crawljax/util/database/HibernateUtil.java b/src/main/java/com/crawljax/util/database/HibernateUtil.java
index 014919c..6dcd3af 100644
--- a/src/main/java/com/crawljax/util/database/HibernateUtil.java
+++ b/src/main/java/com/crawljax/util/database/HibernateUtil.java
@@ -17,7 +17,7 @@
  * Hibernate Utility class.
  * 
  * @author mesbah
- * @version $Id: HibernateUtil.java 6312 2009-12-25 11:59:02Z mesbah $
+ * @version $Id$
  */
 public final class HibernateUtil {
 
"
15e32447fc8dfc69c462b50f1d8c99f8c56baefc,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setBrowser -> [WebDriver driver] | [EmbeddedBrowser browser],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 4fdad0e..720b313 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -34,7 +34,7 @@
  * crawler = new CrawlSpecification(""http://www.google.com""); crawler.click(""a"");
  * crawljaxConfig.setCrawlSpecification(crawler);
  * 
- * @version $Id: CrawljaxConfiguration.java 6381 2009-12-29 12:26:47Z frank $
+ * @version $Id$
  */
 public final class CrawljaxConfiguration {
 
"
15e32447fc8dfc69c462b50f1d8c99f8c56baefc,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 8518614..ba90bb7 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -23,7 +23,7 @@
  * values.
  * 
  * @author dannyroest@gmail.com (Danny Roest)
- * @version $Id: FormHandler.java 6320 2009-12-25 20:53:02Z danny $
+ * @version $Id$
  */
 public class FormHandler {
 	private static final Logger LOGGER = Logger.getLogger(FormHandler.class.getName());
"
15e32447fc8dfc69c462b50f1d8c99f8c56baefc,Ali Mesbah,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/src/main/java/com/crawljax/util/ElementResolver.java b/src/main/java/com/crawljax/util/ElementResolver.java
index 3094620..eda5bac 100644
--- a/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/src/main/java/com/crawljax/util/ElementResolver.java
@@ -13,7 +13,7 @@
 
 /**
  * @author danny
- * @version $Id: ElementResolver.java 6276 2009-12-23 15:37:09Z frank $ class for finding and
+ * @version $Id$ class for finding and
  *          checking elements
  */
 public class ElementResolver {
"
15e32447fc8dfc69c462b50f1d8c99f8c56baefc,Ali Mesbah,PrettyHTML.java,MODIFY,"prettyHTML -> [String html] | [String html, String strIndent]","diff --git a/src/main/java/com/crawljax/util/PrettyHTML.java b/src/main/java/com/crawljax/util/PrettyHTML.java
index cbc4881..f4be1ed 100644
--- a/src/main/java/com/crawljax/util/PrettyHTML.java
+++ b/src/main/java/com/crawljax/util/PrettyHTML.java
@@ -6,7 +6,7 @@
  * Class for making presenting HTML without changing it's structure.
  * 
  * @author Danny
- * @version $Id: PrettyHTML.java 6276 2009-12-23 15:37:09Z frank $
+ * @version $Id$
  */
 public final class PrettyHTML {
 
"
15e32447fc8dfc69c462b50f1d8c99f8c56baefc,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index b67b90c..eb1f884 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -21,7 +21,7 @@
 
 /**
  * @author mesbah
- * @version $Id: PropertyHelper.java 6381 2009-12-29 12:26:47Z frank $
+ * @version $Id$
  */
 public final class PropertyHelper {
 	private static final Logger LOGGER = Logger.getLogger(PropertyHelper.class.getName());
"
15e32447fc8dfc69c462b50f1d8c99f8c56baefc,Ali Mesbah,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index c1beb3f..3ae76cc 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -24,7 +24,7 @@
  * TODO: DOCUMENT ME!
  * 
  * @author mesbah
- * @version $Id: XPathHelper.java 6370 2009-12-29 07:59:21Z frank $
+ * @version $Id$
  */
 public final class XPathHelper {
 	private static final Logger LOGGER = Logger.getLogger(XPathHelper.class.getName());
"
15e32447fc8dfc69c462b50f1d8c99f8c56baefc,Ali Mesbah,HibernateUtil.java,MODIFY,initialize -> [String hbm2ddlAuto] | [],"diff --git a/src/main/java/com/crawljax/util/database/HibernateUtil.java b/src/main/java/com/crawljax/util/database/HibernateUtil.java
index 014919c..6dcd3af 100644
--- a/src/main/java/com/crawljax/util/database/HibernateUtil.java
+++ b/src/main/java/com/crawljax/util/database/HibernateUtil.java
@@ -17,7 +17,7 @@
  * Hibernate Utility class.
  * 
  * @author mesbah
- * @version $Id: HibernateUtil.java 6312 2009-12-25 11:59:02Z mesbah $
+ * @version $Id$
  */
 public final class HibernateUtil {
 
"
e3a32b9a4ef942468f5e9282f2e74cd7125eea75,Frank Groeneveld,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index b986eaf..c35518e 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -42,6 +42,7 @@
  * crawler.setCrawlDepth(2);
  * 
  * @author DannyRoest@gmail.com (Danny Roest)
+ * @version $Id$
  */
 public class CrawlSpecification {
 
"
e3a32b9a4ef942468f5e9282f2e74cd7125eea75,Frank Groeneveld,FormInputField.java,MODIFY,setValues -> [boolean values] | [String values],"diff --git a/src/main/java/com/crawljax/core/configuration/FormInputField.java b/src/main/java/com/crawljax/core/configuration/FormInputField.java
index 28c437e..4f97ad4 100644
--- a/src/main/java/com/crawljax/core/configuration/FormInputField.java
+++ b/src/main/java/com/crawljax/core/configuration/FormInputField.java
@@ -14,6 +14,7 @@
  * @see Form
  * @see Form#field(String)
  * @author DannyRoest@gmail.com (Danny Roest)
+ * @version $Id$
  */
 public class FormInputField extends InputField {
 
"
e3a32b9a4ef942468f5e9282f2e74cd7125eea75,Frank Groeneveld,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/src/main/java/com/crawljax/core/configuration/InputField.java b/src/main/java/com/crawljax/core/configuration/InputField.java
index a47aa61..b333e2d 100644
--- a/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -13,6 +13,7 @@
  * @see InputSpecification#field(String)
  * @see InputSpecification#fields(String...)
  * @author DannyRoest@gmail.com (Danny Roest)
+ * @version $Id$
  */
 public class InputField {
 
"
e3a32b9a4ef942468f5e9282f2e74cd7125eea75,Frank Groeneveld,AttributeInjector.java,MODIFY,"removeInjectedAttributes -> [HTMLElement element, String attrName] | [Vector injectedElements, String attrName]","diff --git a/src/main/java/com/crawljax/util/AttributeInjector.java b/src/main/java/com/crawljax/util/AttributeInjector.java
index a9c80f8..2f152b4 100644
--- a/src/main/java/com/crawljax/util/AttributeInjector.java
+++ b/src/main/java/com/crawljax/util/AttributeInjector.java
@@ -9,6 +9,8 @@
 
 /**
  * Attribute injector class.
+ * 
+ * @version $Id$
  */
 public final class AttributeInjector {
 
"
e3a32b9a4ef942468f5e9282f2e74cd7125eea75,Frank Groeneveld,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/src/main/java/com/crawljax/util/ElementResolver.java b/src/main/java/com/crawljax/util/ElementResolver.java
index eda5bac..c3734ff 100644
--- a/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/src/main/java/com/crawljax/util/ElementResolver.java
@@ -13,8 +13,8 @@
 
 /**
  * @author danny
- * @version $Id$ class for finding and
- *          checking elements
+ * @version $Id$ class for finding
+ *          and checking elements
  */
 public class ElementResolver {
 	private static final Logger LOGGER = Logger.getLogger(ElementResolver.class.getName());
"
4c75d783129a27a9fb9b75fe75c2e686dec3fb0a,Ali Mesbah,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index b986eaf..c35518e 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -42,6 +42,7 @@
  * crawler.setCrawlDepth(2);
  * 
  * @author DannyRoest@gmail.com (Danny Roest)
+ * @version $Id$
  */
 public class CrawlSpecification {
 
"
4c75d783129a27a9fb9b75fe75c2e686dec3fb0a,Ali Mesbah,FormInputField.java,MODIFY,setValues -> [boolean values] | [String values],"diff --git a/src/main/java/com/crawljax/core/configuration/FormInputField.java b/src/main/java/com/crawljax/core/configuration/FormInputField.java
index 28c437e..4f97ad4 100644
--- a/src/main/java/com/crawljax/core/configuration/FormInputField.java
+++ b/src/main/java/com/crawljax/core/configuration/FormInputField.java
@@ -14,6 +14,7 @@
  * @see Form
  * @see Form#field(String)
  * @author DannyRoest@gmail.com (Danny Roest)
+ * @version $Id$
  */
 public class FormInputField extends InputField {
 
"
4c75d783129a27a9fb9b75fe75c2e686dec3fb0a,Ali Mesbah,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/src/main/java/com/crawljax/core/configuration/InputField.java b/src/main/java/com/crawljax/core/configuration/InputField.java
index a47aa61..b333e2d 100644
--- a/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -13,6 +13,7 @@
  * @see InputSpecification#field(String)
  * @see InputSpecification#fields(String...)
  * @author DannyRoest@gmail.com (Danny Roest)
+ * @version $Id$
  */
 public class InputField {
 
"
4c75d783129a27a9fb9b75fe75c2e686dec3fb0a,Ali Mesbah,AttributeInjector.java,MODIFY,"removeInjectedAttributes -> [HTMLElement element, String attrName] | [Vector injectedElements, String attrName]","diff --git a/src/main/java/com/crawljax/util/AttributeInjector.java b/src/main/java/com/crawljax/util/AttributeInjector.java
index a9c80f8..2f152b4 100644
--- a/src/main/java/com/crawljax/util/AttributeInjector.java
+++ b/src/main/java/com/crawljax/util/AttributeInjector.java
@@ -9,6 +9,8 @@
 
 /**
  * Attribute injector class.
+ * 
+ * @version $Id$
  */
 public final class AttributeInjector {
 
"
4c75d783129a27a9fb9b75fe75c2e686dec3fb0a,Ali Mesbah,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/src/main/java/com/crawljax/util/ElementResolver.java b/src/main/java/com/crawljax/util/ElementResolver.java
index eda5bac..c3734ff 100644
--- a/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/src/main/java/com/crawljax/util/ElementResolver.java
@@ -13,8 +13,8 @@
 
 /**
  * @author danny
- * @version $Id$ class for finding and
- *          checking elements
+ * @version $Id$ class for finding
+ *          and checking elements
  */
 public class ElementResolver {
 	private static final Logger LOGGER = Logger.getLogger(ElementResolver.class.getName());
"
36451329f7009ea08adc36961a7e6f4772120137,Stefan Lenselink,ExpectedCondition.java,MODIFY,isSatisfied -> [] | [EmbeddedBrowser browser],"diff --git a/src/main/java/com/crawljax/condition/browserwaiter/ExpectedCondition.java b/src/main/java/com/crawljax/condition/browserwaiter/ExpectedCondition.java
index b992084..cb86c3a 100644
--- a/src/main/java/com/crawljax/condition/browserwaiter/ExpectedCondition.java
+++ b/src/main/java/com/crawljax/condition/browserwaiter/ExpectedCondition.java
@@ -1,5 +1,7 @@
 package com.crawljax.condition.browserwaiter;
 
+import net.jcip.annotations.ThreadSafe;
+
 import com.crawljax.browser.EmbeddedBrowser;
 
 /**
@@ -8,24 +10,16 @@
  * @author dannyroest@gmail.com (Danny Roest)
  * @version $Id$
  */
+@ThreadSafe
 public interface ExpectedCondition {
 
 	/**
+	 * Is the expected condition satisfied
 	 * 
-	 * @return Whether the condition is statisfied. 
+	 * @param browser
+	 *            the browser to execute the check on
+	 * @return Whether the condition is satisfied.
 	 */
-	boolean isSatisfied();
-
-	/**
-	 * Returns the browser.
-	 * @return The browser.
-	 */
-	EmbeddedBrowser getBrowser();
-
-	/**
-	 * Sets the browser.
-	 * @param browser The browser.
-	 */
-	void setBrowser(EmbeddedBrowser browser);
+	boolean isSatisfied(EmbeddedBrowser browser);
 
 }
"
36451329f7009ea08adc36961a7e6f4772120137,Stefan Lenselink,ExpectedElementCondition.java,MODIFY,isSatisfied -> [] | [EmbeddedBrowser browser],"diff --git a/src/main/java/com/crawljax/condition/browserwaiter/ExpectedElementCondition.java b/src/main/java/com/crawljax/condition/browserwaiter/ExpectedElementCondition.java
index adbe6d4..34b6439 100644
--- a/src/main/java/com/crawljax/condition/browserwaiter/ExpectedElementCondition.java
+++ b/src/main/java/com/crawljax/condition/browserwaiter/ExpectedElementCondition.java
@@ -1,10 +1,14 @@
 package com.crawljax.condition.browserwaiter;
 
+import net.jcip.annotations.GuardedBy;
+import net.jcip.annotations.ThreadSafe;
+
 import org.openqa.selenium.By;
 import org.openqa.selenium.WebDriver;
 import org.openqa.selenium.WebElement;
 
 import com.crawljax.browser.AbstractWebDriver;
+import com.crawljax.browser.EmbeddedBrowser;
 
 /**
  * Checks whether an elements exists.
@@ -12,7 +16,8 @@
  * @author dannyroest@gmail.com (Danny Roest)
  * @version $Id$
  */
-public class ExpectedElementCondition extends AbstractExpectedCondition {
+@ThreadSafe
+public class ExpectedElementCondition implements ExpectedCondition {
 
 	private final By locater;
 
@@ -27,17 +32,21 @@
 	}
 
 	@Override
-	public boolean isSatisfied() {
-		if (getBrowser() instanceof AbstractWebDriver) {
-			WebDriver driver = ((AbstractWebDriver) getBrowser()).getDriver();
-			try {
-				WebElement el = driver.findElement(locater);
-				return el != null;
-			} catch (Exception e) {
-				return false;
+	@GuardedBy(""browser, driver"")
+	public boolean isSatisfied(EmbeddedBrowser browser) {
+		if (browser instanceof AbstractWebDriver) {
+			WebDriver driver = ((AbstractWebDriver) browser).getDriver();
+			synchronized (browser) {
+				synchronized (driver) {
+					try {
+						WebElement el = driver.findElement(locater);
+						return el != null;
+					} catch (Exception e) {
+						return false;
+					}
+				}
 			}
 		}
-
 		return false;
 	}
 
"
36451329f7009ea08adc36961a7e6f4772120137,Stefan Lenselink,ExpectedVisibleCondition.java,MODIFY,isSatisfied -> [] | [EmbeddedBrowser browser],"diff --git a/src/main/java/com/crawljax/condition/browserwaiter/ExpectedVisibleCondition.java b/src/main/java/com/crawljax/condition/browserwaiter/ExpectedVisibleCondition.java
index 984bffa..ba62dd6 100644
--- a/src/main/java/com/crawljax/condition/browserwaiter/ExpectedVisibleCondition.java
+++ b/src/main/java/com/crawljax/condition/browserwaiter/ExpectedVisibleCondition.java
@@ -1,28 +1,39 @@
 package com.crawljax.condition.browserwaiter;
 
+import net.jcip.annotations.GuardedBy;
+import net.jcip.annotations.ThreadSafe;
+
 import org.openqa.selenium.By;
 
+import com.crawljax.browser.EmbeddedBrowser;
+
 /**
  * Checks whether an element is visible.
  * 
  * @author dannyroest@gmail.com (Danny Roest)
  * @version $Id$
  */
-public class ExpectedVisibleCondition extends AbstractExpectedCondition {
+@ThreadSafe
+public class ExpectedVisibleCondition implements ExpectedCondition {
 
 	private final By locater;
 
 	/**
 	 * Constructor.
-	 * @param locater Locater to use.
+	 * 
+	 * @param locater
+	 *            Locater to use.
 	 */
 	public ExpectedVisibleCondition(By locater) {
 		this.locater = locater;
 	}
 
 	@Override
-	public boolean isSatisfied() {
-		return getBrowser().isVisible(locater);
+	@GuardedBy(""browser"")
+	public boolean isSatisfied(EmbeddedBrowser browser) {
+		synchronized (browser) {
+			return browser.isVisible(locater);
+		}
 	}
 
 	@Override
"
36451329f7009ea08adc36961a7e6f4772120137,Stefan Lenselink,CrawljaxController.java,MODIFY,"updateStateMachine -> [StateVertix currentHold, Eventable event, StateVertix newState, boolean backTrack] | [StateVertix currentHold, Eventable event, StateVertix newState, Crawler crawler]","diff --git a/src/main/java/com/crawljax/core/CrawljaxController.java b/src/main/java/com/crawljax/core/CrawljaxController.java
index 0d20ecf..0556ec2 100644
--- a/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -1,9 +1,14 @@
 package com.crawljax.core;
 
 import java.util.ArrayList;
+import java.util.LinkedHashSet;
 import java.util.List;
+import java.util.Set;
+import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
 
+import net.jcip.annotations.GuardedBy;
+
 import org.apache.commons.configuration.ConfigurationException;
 import org.apache.log4j.Logger;
 
@@ -11,7 +16,6 @@
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.browserwaiter.WaitConditionChecker;
 import com.crawljax.condition.crawlcondition.CrawlConditionChecker;
-import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.condition.eventablecondition.EventableConditionChecker;
 import com.crawljax.condition.invariant.Invariant;
 import com.crawljax.condition.invariant.InvariantChecker;
@@ -35,7 +39,6 @@
  */
 public class CrawljaxController {
 	private static final Logger LOGGER = Logger.getLogger(CrawljaxController.class.getName());
-	private static int depth = 0;
 
 	private int stateCounter = 1;
 	private StateVertix indexState;
@@ -44,10 +47,6 @@
 	private CrawlSession session;
 
 	private long startCrawl;
-	private static final ArrayList<Eventable> EXACTEVENTPATH = new ArrayList<Eventable>();
-	private boolean fired = false;
-
-	private List<Eventable> currentCrawlPath;
 
 	private final String propertiesFile;
 
@@ -59,12 +58,21 @@
 
 	private final WaitConditionChecker waitConditionChecker = new WaitConditionChecker();
 	private Crawler crawler;
-	private CandidateElementExtractor candidateElementExtractor;
 
 	private final CrawljaxConfiguration crawljaxConfiguration;
 
 	private final List<OracleComparator> oracleComparator;
 
+	private final Set<String> checkedElements = new LinkedHashSet<String>();
+
+	private final ThreadPoolExecutor workQueue =
+	        new ThreadPoolExecutor(PropertyHelper.getCrawNumberOfThreadsValue(), PropertyHelper
+	                .getCrawNumberOfThreadsValue(), 0L, TimeUnit.MILLISECONDS, new CrawlQueue());
+
+	private boolean foundNewState;
+
+	private int numberofExaminedElements;
+
 	/**
 	 * The constructor.
 	 */
@@ -105,8 +113,9 @@
 	/**
 	 * @throws ConfigurationException
 	 *             if the configuration fails.
+	 * @NotThreadSafe
 	 */
-	private void init() throws ConfigurationException {
+	public void init() throws ConfigurationException {
 		LOGGER.info(""Starting Crawljax..."");
 		LOGGER.info(""Loading properties..."");
 
@@ -130,11 +139,9 @@
 			        .getProxyConfiguration());
 		}
 
-		browser = BrowserFactory.getBrowser();
-		LOGGER.info(""Embedded browser implementation: "" + browser.getClass().getName());
-		crawler = new Crawler(browser, waitConditionChecker);
-		candidateElementExtractor =
-		        new CandidateElementExtractor(browser, eventableConditionChecker);
+		LOGGER.info(""Embedded browser implementation: "" + BrowserFactory.getBrowserTypeString());
+		crawler = new Crawler(this);
+		browser = crawler.getBrowser();
 
 		LOGGER.info(""Crawljax initialized!"");
 	}
@@ -146,6 +153,7 @@
 	 *             If the browser cannot be instantiated.
 	 * @throws ConfigurationException
 	 *             if crawljax configuration fails.
+	 * @NotThreadSafe
 	 */
 	public final void run() throws CrawljaxException, ConfigurationException {
 		init();
@@ -179,17 +187,31 @@
 
 		try {
 
-			crawl();
+			addWorkToQueue(crawler);
 
-		} catch (CrawljaxException e) {
-			LOGGER.error(e.getMessage(), e);
+			// TODO Stefan Ok this is not so nice....
+			while (!BrowserFactory.isFinished()) {
+				try {
+					Thread.sleep(1000);
+				} catch (InterruptedException e) {
+					LOGGER.error(""The waiting on the browsers to be finished was Interruped"", e);
+				}
+			}
 		} catch (OutOfMemoryError om) {
 			LOGGER.error(om.getMessage(), om);
 		}
 
 		long timeCrawlCalc = System.currentTimeMillis() - startCrawl;
 
-		browser.close();
+		/**
+		 * Shutdown the ThreadPool, closing all the possible open Crawler instances
+		 */
+		this.workQueue.shutdownNow();
+
+		/**
+		 * Close all the opened browsers
+		 */
+		BrowserFactory.close();
 
 		for (Eventable c : stateMachine.getStateFlowGraph().getAllEdges()) {
 			LOGGER.info(""Interaction Element= "" + c.toString());
@@ -202,8 +224,7 @@
 		                TimeUnit.MILLISECONDS.toSeconds(timeCrawlCalc)
 		                        - TimeUnit.MINUTES.toSeconds(TimeUnit.MILLISECONDS
 		                                .toMinutes(timeCrawlCalc))));
-		LOGGER.info(""EXAMINED ELEMENTS: ""
-		        + candidateElementExtractor.getNumberofExaminedElements());
+		LOGGER.info(""EXAMINED ELEMENTS: "" + numberofExaminedElements);
 		LOGGER.info(""CLICKABLES: "" + stateMachine.getStateFlowGraph().getAllEdges().size());
 		LOGGER.info(""STATES: "" + stateMachine.getStateFlowGraph().getAllStates().size());
 		LOGGER.info(""Dom average size (byte): ""
@@ -217,179 +238,60 @@
 	}
 
 	/**
-	 * Crawl through the clickables.
+	 * Checks the state and time constraints. This function is ThreadSafe
 	 * 
 	 * @throws CrawljaxException
-	 *             if a failure occurs.
-	 * @return Whether to continue crawling.
+	 *             a crawljaxexception.
 	 */
-	private boolean crawl() throws CrawljaxException {
-		if (!checkConstraints()) {
-			/* stop crawling */
-			return false;
-		}
-
-		if (depth >= PropertyHelper.getCrawlDepthValue()
-		        && PropertyHelper.getCrawlDepthValue() != 0) {
-			LOGGER.info(""DEPTH "" + depth + "" reached returning from rec call. Given depth: ""
-			        + PropertyHelper.getCrawlDepthValue());
-
-			/* max depth reached doesn't mean completely stop crawling, so return true */
-			return true;
-		}
-
-		extractCandidates();
-
-		/* continue crawling */
-		return true;
-	}
-
-	/**
-	 * Find candidate elements.
-	 * 
-	 * @throws CrawljaxException
-	 *             if a failure occurs.
-	 */
-	private void extractCandidates() throws CrawljaxException {
-
-		if (crawlConditionChecker.check(browser)) {
-			LOGGER.info(""Looking in state: "" + stateMachine.getCurrentState().getName()
-			        + "" for candidate elements with "");
-			clickTags(candidateElementExtractor.extract(PropertyHelper.getCrawlTagElements(),
-			        PropertyHelper.getCrawlExcludeTagElements(), PropertyHelper
-			                .getClickOnceValue()));
-
-		} else {
-			LOGGER.info(""State "" + stateMachine.getCurrentState().getName()
-			        + "" dit not satisfy the CrawlConditions."");
-		}
-	}
-
-	/**
-	 * Checks the state and time constraints.
-	 * 
-	 * @return Whether to continue crawling.
-	 */
-	private boolean checkConstraints() {
+	@GuardedBy(""stateMachine"")
+	public boolean checkConstraints() throws CrawljaxException {
 		long timePassed = System.currentTimeMillis() - startCrawl;
 
 		if ((PropertyHelper.getCrawlMaxTimeValue() != 0)
 		        && (timePassed > PropertyHelper.getCrawlMaxTimeValue())) {
 
 			/* remove all possible candidates left */
-			EXACTEVENTPATH.clear();
-
-			LOGGER.info(""Max time "" + PropertyHelper.getCrawlMaxTimeValue() + "" passed!"");
-
+			// EXACTEVENTPATH.clear(); TODO Stefan: FIX this!
+			LOGGER.info(""Max time "" + PropertyHelper.getCrawlMaxTimeValue() + ""passed!"");
 			/* stop crawling */
 			return false;
-
 		}
 
-		if ((PropertyHelper.getCrawlMaxStatesValue() != 0)
-		        && (stateMachine.getStateFlowGraph().getAllStates().size() >= PropertyHelper
-		                .getCrawlMaxStatesValue())) {
+		synchronized (stateMachine) {
+			if ((PropertyHelper.getCrawlMaxStatesValue() != 0)
+			        && (stateMachine.getStateFlowGraph().getAllStates().size() >= PropertyHelper
+			                .getCrawlMaxStatesValue())) {
+				/* remove all possible candidates left */
+				// EXACTEVENTPATH.clear(); TODO Stefan: FIX this!
 
-			/* remove all possible candidates left */
-			EXACTEVENTPATH.clear();
+				LOGGER.info(""Max number of states "" + PropertyHelper.getCrawlMaxStatesValue()
+				        + "" reached!"");
 
-			LOGGER.info(""Max number of states "" + PropertyHelper.getCrawlMaxStatesValue()
-			        + "" reached!"");
-
-			/* stop crawling */
-			return false;
+				/* stop crawling */
+				return false;
+			}
 		}
 		/* continue crawling */
 		return true;
 	}
 
 	/**
-	 * @param elements
-	 *            the list of candidate elements.
-	 * @throws CrawljaxException
-	 *             if an exception occurs.
-	 */
-	private void clickTags(final List<CandidateElement> elements) throws CrawljaxException {
-		StateVertix currentHold = stateMachine.getCurrentState().clone();
-		List<String> eventTypes = PropertyHelper.getRobotEventsValues();
-
-		LOGGER.info(""Starting preStateCrawlingPlugins..."");
-		CrawljaxPluginsUtil.runPreStateCrawlingPlugins(session, elements);
-
-		boolean handleInputElements = true;
-		for (CandidateElement candidateElement : elements) {
-			EventableCondition eventableCondition = candidateElement.getEventableCondition();
-			boolean conditionsSatisifed = true;
-			if (eventableCondition != null) {
-				conditionsSatisifed = eventableCondition.checkAllConditionsSatisfied(browser);
-			}
-			if (conditionsSatisifed) {
-				for (String eventType : eventTypes) {
-					Eventable eventable = new Eventable(candidateElement, eventType);
-					// eventable.setSourceStateVertix(currentHold);
-
-					// load input element values
-					if (handleInputElements) {
-						crawler.handleInputElements(eventable);
-						handleInputElements = false;
-					}
-
-					LOGGER.info(""Firing "" + eventable.getEventType() + "" on element: ""
-					        + eventable + ""; State: "" + currentHold.getName());
-
-					if (crawler.fireEvent(eventable)) {
-						StateVertix newState =
-						        new StateVertix(browser.getCurrentUrl(), getStateName(), browser
-						                .getDom(), stateComparator.getStrippedDom(browser));
-
-						if (isDomChanged(currentHold, newState)) {
-							fired = true;
-							handleInputElements = true;
-							boolean backTrack = true;
-
-							LOGGER.info(""Starting onNewStatePlugins..."");
-
-							// if eventable is last eventable in state, do not
-							// backtrack
-							if (candidateElement.equals(elements.get(elements.size() - 1))
-							        && eventType.equals(eventTypes.get(eventTypes.size() - 1))) {
-								backTrack = false;
-							}
-							if (!updateStateMachine(currentHold, eventable, newState, backTrack)) {
-								return;
-							}
-						}
-					}
-
-				}
-			} else {
-				Eventable eventable = new Eventable(candidateElement, """");
-				LOGGER.info(""Conditions not satisfied for element: "" + eventable + ""; State: ""
-				        + currentHold.getName());
-
-			}
-		}
-	}
-
-	/**
 	 * @param currentHold
 	 *            the placeholder for the current stateVertix.
 	 * @param event
 	 *            the event edge.
 	 * @param newState
 	 *            the new state.
-	 * @param backTrack
-	 *            backtrack to a previous version.
-	 * @throws CrawljaxException
-	 *             an exception.
+	 * @param crawler
+	 *            used to feet to checkInvariants
+	 * @NotThreadSafe
 	 */
-	private boolean updateStateMachine(final StateVertix currentHold, final Eventable event,
-	        StateVertix newState, final boolean backTrack) throws CrawljaxException {
-
-		EXACTEVENTPATH.add(event);
-
+	public boolean updateStateMachine(final StateVertix currentHold, final Eventable event,
+	        StateVertix newState, Crawler crawler) throws Exception {
 		StateVertix cloneState = stateMachine.addStateToCurrentState(newState, event);
+		foundNewState = true;
 		if (cloneState != null) {
+			foundNewState = false;
 			newState = cloneState.clone();
 		}
 
@@ -398,70 +300,44 @@
 		        + stateMachine.getCurrentState().getName() + "" FROM "" + currentHold.getName());
 
 		if (PropertyHelper.getTestInvariantsWhileCrawlingValue()) {
-			checkInvariants(browser);
+			checkInvariants(crawler);
 		}
 
-		session.setCurrentState(newState);
+		synchronized (session) {
+			/**
+			 * Only one thread at the time may set the currentState in the session and expose it to
+			 * the OnNewStatePlugins. Garranty it will not be interleaved
+			 */
+			session.setCurrentState(newState);
 
-		updateCrawlPath(currentHold, newState, event);
-
-		if (cloneState == null) {
-			CrawljaxPluginsUtil.runOnNewStatePlugins(session);
-			depth++;
-
-			LOGGER.info(""RECURSIVE Call crawl; Current DEPTH= "" + depth);
-			if (!crawl()) {
-				/*
-				 * apparently one of the conditions was not satisfied anymore, so stop crawling by
-				 * returning false
-				 */
+			if (cloneState == null) {
+				CrawljaxPluginsUtil.runOnNewStatePlugins(session);
+				// recurse
+				return true;
+			} else {
+				// non recurse
 				return false;
 			}
-			depth--;
 		}
-
-		// go back to the previous state
-		LOGGER.debug(""AFTER: sm.current: "" + stateMachine.getCurrentState().getName()
-		        + "" hold.current: "" + currentHold.getName());
-
-		stateMachine.changeState(currentHold);
-		LOGGER.info(""StateMachine's Pointer changed back to: ""
-		        + stateMachine.getCurrentState().getName());
-
-		if (currentCrawlPath != null) {
-			// only save crawlPath when an event is actually fired
-			if (fired) {
-				session.addCrawlPath(currentCrawlPath);
-			}
-			currentCrawlPath = null;
-			fired = false;
-		}
-
-		if (backTrack) {
-			// go back via previous clickables
-			goBackExact(event);
-		} else {
-			// don't go back. only remove the currentEvent from the list
-			EXACTEVENTPATH.remove(EXACTEVENTPATH.indexOf(event));
-		}
-
-		/* continue crawling */
-		return true;
 	}
 
 	/**
+	 * Test to see if the (new) dom is changed with regards to the old dom. This method is Thread
+	 * safe, at least as the equals call of StateVertix is Thread safe and the stateBefor and
+	 * stateAfter do not change on interleaving.
+	 * 
 	 * @param stateBefore
 	 *            the state before the event.
 	 * @param stateAfter
 	 *            the state after the event.
 	 * @return true if the state is changed according to the compare method of the oracle.
 	 */
-	private boolean isDomChanged(final StateVertix stateBefore, final StateVertix stateAfter) {
+	public final boolean isDomChanged(final StateVertix stateBefore, final StateVertix stateAfter) {
 		boolean isChanged = false;
 
 		// do not need Oracle Comparators now, because hash of stripped domis
 		// already calculated
-		// isChanged = !oracleComparator.compare(stateBefore.getDom(),
+		// isChanged = !stateComparator.compare(stateBefore.getDom(),
 		// stateAfter.getDom(), browser);
 		isChanged = !stateAfter.equals(stateBefore);
 		if (isChanged) {
@@ -474,82 +350,174 @@
 	}
 
 	/**
-	 * @return State name
+	 * Return the name of the (new)State
+	 * 
+	 * @return State name the name of the state
 	 */
-	private String getStateName() {
-		stateCounter++;
+	@GuardedBy(""this"")
+	public synchronized String getStateName() {
+		if (foundNewState) {
+			stateCounter++;
+		}
 		String state = ""state"" + stateCounter;
 		return state;
 	}
 
 	/**
-	 * Adds current state and eventable to current crawlpath for exact test generation.
-	 * 
-	 * @param currentState
-	 *            the current state.
-	 * @param newState
-	 *            the new state.
-	 * @param eventable
-	 *            the edge.
+	 * @param crawler
+	 *            the Crawler to execute the invariants from
 	 */
-	private void updateCrawlPath(final StateVertix currentState, final StateVertix newState,
-	        final Eventable eventable) {
-		if (currentCrawlPath == null) {
-			currentCrawlPath = new ArrayList<Eventable>();
-		}
-		currentCrawlPath.add(eventable);
-	}
-
-	/**
-	 * @param currentEvent
-	 *            the current clickable.
-	 * @throws CrawljaxException
-	 *             if a failure occurs.
-	 */
-	private void goBackExact(final Eventable currentEvent) throws CrawljaxException {
-		LOGGER.info(""Reloading Page for navigating back."");
-		crawler.goToInitialURL();
-		StateVertix curState = stateMachine.getInitialState();
-		if (EXACTEVENTPATH.size() > 0) {
-			// remove the currentEvent from the list
-			EXACTEVENTPATH.remove(EXACTEVENTPATH.indexOf(currentEvent));
-			if (EXACTEVENTPATH.size() > 0) {
-				for (Eventable clickable : EXACTEVENTPATH) {
-					// Thread.sleep(500);
-					if (!crawlConditionChecker.check(browser)) {
-						return;
-					}
-					LOGGER.info(""Backtracking by firing "" + clickable.getEventType()
-					        + "" on element: "" + clickable);
-
-					updateCrawlPath(curState, clickable.getTargetStateVertix(), clickable);
-
-					crawler.handleInputElements(clickable);
-					crawler.fireEvent(clickable);
-					if (!crawlConditionChecker.check(browser)) {
-						return;
-					}
-					curState = clickable.getTargetStateVertix();
-					CrawljaxPluginsUtil.runOnRevisitStatePlugins(session, curState);
-				}
-			}
-		}
-
-	}
-
-	/**
-	 * Checks whether there are any invariants violated and runs the OnInvariantViolation plugins to
-	 * process the failed invariants.
-	 * 
-	 * @param embeddedBrowser
-	 *            the current browser instance
-	 */
-	private void checkInvariants(final EmbeddedBrowser embeddedBrowser) {
-		if (!invariantChecker.check(embeddedBrowser)) {
+	private void checkInvariants(Crawler crawler) {
+		if (!invariantChecker.check(crawler.getBrowser())) {
 			final List<Invariant> failedInvariants = invariantChecker.getFailedInvariants();
 			for (Invariant failedInvariant : failedInvariants) {
 				CrawljaxPluginsUtil.runOnInvriantViolationPlugins(failedInvariant, session);
 			}
 		}
 	}
+
+	/**
+	 * @return the eventableConditionChecker
+	 * @NotTheadSafe The Condition classes contains 1 not Thread safe implementation
+	 *               (XPathCondition)
+	 */
+	public final EventableConditionChecker getEventableConditionChecker() {
+		return eventableConditionChecker;
+	}
+
+	/**
+	 * @return the oracleComparator
+	 * @NotTheadSafe The Condition classes contains 1 not Thread safe implementation
+	 *               (XPathCondition)
+	 */
+	public final List<OracleComparator> getOracleComparator() {
+		return oracleComparator;
+	}
+
+	/**
+	 * @NotThreadSafe
+	 * @return the session
+	 */
+	public final CrawlSession getSession() {
+		return session;
+	}
+
+	/**
+	 * @NotThreadSafe
+	 * @param currentHold
+	 */
+	public void changeStateMachineState(StateVertix currentHold) {
+		synchronized (stateMachine) {
+			LOGGER.debug(""AFTER: sm.current: "" + stateMachine.getCurrentState().getName()
+			        + "" hold.current: "" + currentHold.getName());
+			stateMachine.changeState(currentHold);
+			LOGGER.info(""StateMachine's Pointer changed back to: ""
+			        + stateMachine.getCurrentState().getName());
+		}
+	}
+
+	/**
+	 * @NotThreadSafe
+	 */
+	public void rewindStateMachine() {
+		/**
+		 * TODO Stefan There is some performance loss using this technique The state machine can
+		 * also be hard forced into the new 'start' state...
+		 */
+		stateMachine.rewind();
+	}
+
+	/**
+	 * Add work (Crawler) to the Queue of work that need to be done.
+	 * 
+	 * @param work
+	 *            the work (Crawler) to add to the Queue
+	 */
+	@GuardedBy(""workQueue"")
+	public final void addWorkToQueue(Crawler work) {
+		synchronized (workQueue) {
+			workQueue.execute(work);
+		}
+	}
+
+	/**
+	 * Check if a given element is already checked, preventing duplicate work.
+	 * 
+	 * @param element
+	 *            the to search for if its already checked
+	 * @return true if the element is already checked
+	 */
+	@GuardedBy(""checkedElements"")
+	public boolean elementIsAlreadyChecked(String element) {
+		synchronized (checkedElements) {
+			return this.checkedElements.contains(element);
+		}
+	}
+
+	/**
+	 * Mark a given element as checked to prevent duplicate work
+	 * 
+	 * @param element
+	 *            the elements that is checked
+	 */
+	@GuardedBy(""checkedElements"")
+	public void markElementAsChecked(String element) {
+		synchronized (checkedElements) {
+			this.checkedElements.add(element);
+		}
+	}
+
+	/**
+	 * Wait for a given condition.
+	 * 
+	 * @param browser
+	 *            the browser which requires a wait condition
+	 */
+	public void doBrowserWait(EmbeddedBrowser browser) {
+		this.waitConditionChecker.wait(browser);
+	}
+
+	/**
+	 * Retrieve the index state
+	 * 
+	 * @return the indexState of the current crawl
+	 */
+	public final StateVertix getIndexState() {
+		return this.indexState;
+	}
+
+	/**
+	 * Return the Checker of the CrawlConditions
+	 * 
+	 * @return the crawlConditionChecker
+	 */
+	public final CrawlConditionChecker getCrawlConditionChecker() {
+		return crawlConditionChecker;
+	}
+
+	/**
+	 * increase the number of checked elements, as a statistics measure to know how many elements
+	 * were actually examined.
+	 */
+	@GuardedBy(""this"")
+	public synchronized void increaseNumberExaminedElements() {
+		numberofExaminedElements++;
+	}
+
+	/**
+	 * TODO Check thread safety
+	 * 
+	 * @param browser
+	 * @return
+	 */
+	public String getStripedDom(EmbeddedBrowser browser) {
+		return this.stateComparator.getStrippedDom(browser);
+	}
+
+	/**
+	 * @return the crawler
+	 */
+	public final Crawler getCrawler() {
+		return crawler;
+	}
 }
"
36451329f7009ea08adc36961a7e6f4772120137,Stefan Lenselink,CrawljaxConfiguration.java,MODIFY,setBrowser -> [WebDriver driver] | [EmbeddedBrowser browser],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 720b313..bdf7904 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -129,6 +129,7 @@
 		        * ONE_SECOND);
 		config.addProperty(""crawl.forms.randominput"", ConfigurationHelper
 		        .booleanToInt(getCrawlSpecification().getRandomInputInForms()));
+		config.addProperty(""crawl.numberOfThreads"", getCrawlSpecification().getNumberOfThreads());
 
 		if (getProxyConfiguration() != null) {
 			config.addProperty(""proxy.enabled"", 1);
"
36451329f7009ea08adc36961a7e6f4772120137,Stefan Lenselink,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index eb1f884..fba7426 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -46,6 +46,7 @@
 	private static String crawlTags = ""crawl.tags"";
 	private static String crawlExludeTags = ""crawl.tags.exclude"";
 	private static String crawlFilterAttributes = ""crawl.filter.attributes"";
+	private static String crawlNumberOfThreads = ""crawl.numberOfThreads"";
 
 	private static String hibernateProperties = ""hibernate.properties"";
 	private static String hibernatePropertiesValue = ""hibernate.properties"";
@@ -109,6 +110,8 @@
 
 	private static int domTidyValue = 0;
 
+	private static int crawNumberOfThreadsValue = 1;
+
 	private static String seleniumTestsuitePath = ""selenium.testsuite.path"";
 
 	private static String seleniumTestsuitePathValue;
@@ -174,6 +177,7 @@
 		siteIndexablePathValue = getProperty(siteIndexablePath);
 		baseUrlValue = getProperty(baseUrl);
 		crawlDepthValue = getPropertyAsInt(crawlDepth);
+		crawNumberOfThreadsValue = getPropertyAsInt(crawlNumberOfThreads);
 		// crawlThreholdValue = getPropertyAsDouble(crawlThrehold);
 		robotEventsValues = getPropertyAsList(robotEvents);
 		crawlTagsValues = getPropertyAsList(crawlTags);
@@ -851,6 +855,13 @@
 	}
 
 	/**
+	 * @return the crawNumberOfThreadsValue
+	 */
+	public static final int getCrawNumberOfThreadsValue() {
+		return crawNumberOfThreadsValue;
+	}
+
+	/**
 	 * @return if each candidate clickable should be clicked only once.
 	 */
 	public static boolean getClickOnceValue() {
"
a507c7b75d99f8c4111473444a38ba2b374809a6,Ali Mesbah,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index c35518e..9242130 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -58,6 +58,7 @@
 	private int maximumRuntime = DEFAULT_MAXIMUMRUNTIME; // in seconds
 	private int waitTimeAfterReloadUrl = DEFAULT_WAITTIMEAFTERRELOADURL; // in milliseconds
 	private int waitTimeAfterEvent = DEFAULT_WAITTIMEAFTEREVENT; // in milliseconds
+	private int numberOfThreads = 1;
 	private final CrawlActions crawlActions = new CrawlActions();
 
 	private boolean randomInputInForms = true;
@@ -258,6 +259,21 @@
 	}
 
 	/**
+	 * @param numberOfThreads
+	 *            the numberOfThreads to set
+	 */
+	public void setNumberOfThreads(int numberOfThreads) {
+		this.numberOfThreads = numberOfThreads;
+	}
+
+	/**
+	 * @return the numberOfThreads
+	 */
+	public int getNumberOfThreads() {
+		return numberOfThreads;
+	}
+
+	/**
 	 * @return the different crawl actions.
 	 */
 	protected CrawlActions crawlActions() {
"
a507c7b75d99f8c4111473444a38ba2b374809a6,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setBrowser -> [WebDriver driver] | [EmbeddedBrowser browser],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 720b313..bdf7904 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -129,6 +129,7 @@
 		        * ONE_SECOND);
 		config.addProperty(""crawl.forms.randominput"", ConfigurationHelper
 		        .booleanToInt(getCrawlSpecification().getRandomInputInForms()));
+		config.addProperty(""crawl.numberOfThreads"", getCrawlSpecification().getNumberOfThreads());
 
 		if (getProxyConfiguration() != null) {
 			config.addProperty(""proxy.enabled"", 1);
"
a507c7b75d99f8c4111473444a38ba2b374809a6,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index eb1f884..fba7426 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -46,6 +46,7 @@
 	private static String crawlTags = ""crawl.tags"";
 	private static String crawlExludeTags = ""crawl.tags.exclude"";
 	private static String crawlFilterAttributes = ""crawl.filter.attributes"";
+	private static String crawlNumberOfThreads = ""crawl.numberOfThreads"";
 
 	private static String hibernateProperties = ""hibernate.properties"";
 	private static String hibernatePropertiesValue = ""hibernate.properties"";
@@ -109,6 +110,8 @@
 
 	private static int domTidyValue = 0;
 
+	private static int crawNumberOfThreadsValue = 1;
+
 	private static String seleniumTestsuitePath = ""selenium.testsuite.path"";
 
 	private static String seleniumTestsuitePathValue;
@@ -174,6 +177,7 @@
 		siteIndexablePathValue = getProperty(siteIndexablePath);
 		baseUrlValue = getProperty(baseUrl);
 		crawlDepthValue = getPropertyAsInt(crawlDepth);
+		crawNumberOfThreadsValue = getPropertyAsInt(crawlNumberOfThreads);
 		// crawlThreholdValue = getPropertyAsDouble(crawlThrehold);
 		robotEventsValues = getPropertyAsList(robotEvents);
 		crawlTagsValues = getPropertyAsList(crawlTags);
@@ -851,6 +855,13 @@
 	}
 
 	/**
+	 * @return the crawNumberOfThreadsValue
+	 */
+	public static final int getCrawNumberOfThreadsValue() {
+		return crawNumberOfThreadsValue;
+	}
+
+	/**
 	 * @return if each candidate clickable should be clicked only once.
 	 */
 	public static boolean getClickOnceValue() {
"
2cac70aaf0ec7e3cc611b752cd29f127c42e6885,Ali Mesbah,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/src/main/java/com/crawljax/core/CrawlQueue.java b/src/main/java/com/crawljax/core/CrawlQueue.java
index 6c0d7f7..188edc1 100644
--- a/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -11,7 +11,7 @@
 /**
  * This class implements a BlockingQueue with Runnable as its Generic type and extends Stack with
  * also Runnable as generic type. This class is used in the ThreadPoolExecutor and its used to store
- * spearate threads in a Queue like fashion (FILO).
+ * separate threads in a Queue like fashion (FILO).
  * 
  * @author Stefan Lenselink <S.R.Lenselink@student.tudelft.nl>
  * @version $Id$
"
4354ca648c0c958e0586e61a581e58260a8a954c,Ali Mesbah,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/src/main/java/com/crawljax/core/CrawlQueue.java b/src/main/java/com/crawljax/core/CrawlQueue.java
index 6c0d7f7..188edc1 100644
--- a/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -11,7 +11,7 @@
 /**
  * This class implements a BlockingQueue with Runnable as its Generic type and extends Stack with
  * also Runnable as generic type. This class is used in the ThreadPoolExecutor and its used to store
- * spearate threads in a Queue like fashion (FILO).
+ * separate threads in a Queue like fashion (FILO).
  * 
  * @author Stefan Lenselink <S.R.Lenselink@student.tudelft.nl>
  * @version $Id$
"
2b9ea97ef515487bfb76bee4da25085a6ab4caa2,Ali Mesbah,CrawljaxController.java,MODIFY,changeStateMachineState -> [StateVertix currentHold] | [StateVertix state],"diff --git a/src/main/java/com/crawljax/core/CrawljaxController.java b/src/main/java/com/crawljax/core/CrawljaxController.java
index 0556ec2..673002f 100644
--- a/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -65,9 +65,7 @@
 
 	private final Set<String> checkedElements = new LinkedHashSet<String>();
 
-	private final ThreadPoolExecutor workQueue =
-	        new ThreadPoolExecutor(PropertyHelper.getCrawNumberOfThreadsValue(), PropertyHelper
-	                .getCrawNumberOfThreadsValue(), 0L, TimeUnit.MILLISECONDS, new CrawlQueue());
+	private final ThreadPoolExecutor workQueue;
 
 	private boolean foundNewState;
 
@@ -75,8 +73,11 @@
 
 	/**
 	 * The constructor.
+	 * 
+	 * @throws ConfigurationException
+	 *             if the configuration fails.
 	 */
-	public CrawljaxController() {
+	public CrawljaxController() throws ConfigurationException {
 		this(""crawljax.properties"");
 		LOGGER.warn(""No custom setting is provided! Using the default settings."");
 	}
@@ -84,19 +85,24 @@
 	/**
 	 * @param propertiesfile
 	 *            the properties file.
+	 * @throws ConfigurationException
+	 *             if the configuration fails.
 	 */
-	public CrawljaxController(final String propertiesfile) {
+	public CrawljaxController(final String propertiesfile) throws ConfigurationException {
 		this.propertiesFile = propertiesfile;
 		this.crawljaxConfiguration = null;
 		this.oracleComparator = new ArrayList<OracleComparator>();
 		stateComparator = new StateComparator(this.oracleComparator);
+		workQueue = init();
 	}
 
 	/**
 	 * @param config
 	 *            the crawljax configuration.
+	 * @throws ConfigurationException
+	 *             if the configuration fails.
 	 */
-	public CrawljaxController(final CrawljaxConfiguration config) {
+	public CrawljaxController(final CrawljaxConfiguration config) throws ConfigurationException {
 		this.propertiesFile = null;
 		this.crawljaxConfiguration = config;
 		CrawljaxConfigurationReader configReader = new CrawljaxConfigurationReader(config);
@@ -108,6 +114,7 @@
 		crawlConditionChecker.setCrawlConditions(crawlerReader.getCrawlConditions());
 		waitConditionChecker.setWaitConditions(crawlerReader.getWaitConditions());
 		eventableConditionChecker.setEventableConditions(configReader.getEventableConditions());
+		workQueue = init();
 	}
 
 	/**
@@ -115,7 +122,7 @@
 	 *             if the configuration fails.
 	 * @NotThreadSafe
 	 */
-	public void init() throws ConfigurationException {
+	private ThreadPoolExecutor init() throws ConfigurationException {
 		LOGGER.info(""Starting Crawljax..."");
 		LOGGER.info(""Loading properties..."");
 
@@ -139,11 +146,11 @@
 			        .getProxyConfiguration());
 		}
 
-		LOGGER.info(""Embedded browser implementation: "" + BrowserFactory.getBrowserTypeString());
-		crawler = new Crawler(this);
-		browser = crawler.getBrowser();
-
 		LOGGER.info(""Crawljax initialized!"");
+
+		return new ThreadPoolExecutor(PropertyHelper.getCrawNumberOfThreadsValue(),
+		        PropertyHelper.getCrawNumberOfThreadsValue(), 0L, TimeUnit.MILLISECONDS,
+		        new CrawlQueue());
 	}
 
 	/**
@@ -156,7 +163,10 @@
 	 * @NotThreadSafe
 	 */
 	public final void run() throws CrawljaxException, ConfigurationException {
-		init();
+
+		LOGGER.info(""Embedded browser implementation: "" + BrowserFactory.getBrowserTypeString());
+		crawler = new Crawler(this);
+		browser = crawler.getBrowser();
 
 		startCrawl = System.currentTimeMillis();
 
@@ -240,6 +250,7 @@
 	/**
 	 * Checks the state and time constraints. This function is ThreadSafe
 	 * 
+	 * @return true if all conditions are met.
 	 * @throws CrawljaxException
 	 *             a crawljaxexception.
 	 */
@@ -284,10 +295,11 @@
 	 *            the new state.
 	 * @param crawler
 	 *            used to feet to checkInvariants
+	 * @return true if the new state is not found in the state machine.
 	 * @NotThreadSafe
 	 */
 	public boolean updateStateMachine(final StateVertix currentHold, final Eventable event,
-	        StateVertix newState, Crawler crawler) throws Exception {
+	        StateVertix newState, Crawler crawler) {
 		StateVertix cloneState = stateMachine.addStateToCurrentState(newState, event);
 		foundNewState = true;
 		if (cloneState != null) {
@@ -350,7 +362,7 @@
 	}
 
 	/**
-	 * Return the name of the (new)State
+	 * Return the name of the (new)State.
 	 * 
 	 * @return State name the name of the state
 	 */
@@ -404,13 +416,14 @@
 
 	/**
 	 * @NotThreadSafe
-	 * @param currentHold
+	 * @param state
+	 *            the state to change the state machines pointer to.
 	 */
-	public void changeStateMachineState(StateVertix currentHold) {
+	public void changeStateMachineState(StateVertix state) {
 		synchronized (stateMachine) {
 			LOGGER.debug(""AFTER: sm.current: "" + stateMachine.getCurrentState().getName()
-			        + "" hold.current: "" + currentHold.getName());
-			stateMachine.changeState(currentHold);
+			        + "" hold.current: "" + state.getName());
+			stateMachine.changeState(state);
 			LOGGER.info(""StateMachine's Pointer changed back to: ""
 			        + stateMachine.getCurrentState().getName());
 		}
@@ -455,7 +468,7 @@
 	}
 
 	/**
-	 * Mark a given element as checked to prevent duplicate work
+	 * Mark a given element as checked to prevent duplicate work.
 	 * 
 	 * @param element
 	 *            the elements that is checked
@@ -478,7 +491,7 @@
 	}
 
 	/**
-	 * Retrieve the index state
+	 * Retrieve the index state.
 	 * 
 	 * @return the indexState of the current crawl
 	 */
@@ -487,7 +500,7 @@
 	}
 
 	/**
-	 * Return the Checker of the CrawlConditions
+	 * Return the Checker of the CrawlConditions.
 	 * 
 	 * @return the crawlConditionChecker
 	 */
@@ -505,10 +518,11 @@
 	}
 
 	/**
-	 * TODO Check thread safety
+	 * TODO Check thread safety.
 	 * 
 	 * @param browser
-	 * @return
+	 *            the browser instance.
+	 * @return a stripped string of the DOM tree taken from the browser.
 	 */
 	public String getStripedDom(EmbeddedBrowser browser) {
 		return this.stateComparator.getStrippedDom(browser);
"
bf2468d826e8f7a4e94d91353bc3b7454ae161a0,Ali Mesbah,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/src/main/java/com/crawljax/core/CrawlQueue.java b/src/main/java/com/crawljax/core/CrawlQueue.java
index 188edc1..820a85c 100644
--- a/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -19,7 +19,7 @@
 public class CrawlQueue extends Stack<Runnable> implements BlockingQueue<Runnable> {
 
 	/**
-	 * Auto generated serialVersionUID
+	 * Auto generated serialVersionUID.
 	 */
 	private static final long serialVersionUID = 4656244727801517204L;
 
"
1a5ba1a80028fce29f291a0c31000cc3aff75861,Ali Mesbah,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/src/main/java/com/crawljax/core/CrawlQueue.java b/src/main/java/com/crawljax/core/CrawlQueue.java
index 188edc1..820a85c 100644
--- a/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -19,7 +19,7 @@
 public class CrawlQueue extends Stack<Runnable> implements BlockingQueue<Runnable> {
 
 	/**
-	 * Auto generated serialVersionUID
+	 * Auto generated serialVersionUID.
 	 */
 	private static final long serialVersionUID = 4656244727801517204L;
 
"
65c74505d53377ccf622e8822c361c23653c0575,Frank Groeneveld,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index fba7426..97ea298 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -46,6 +46,7 @@
 	private static String crawlTags = ""crawl.tags"";
 	private static String crawlExludeTags = ""crawl.tags.exclude"";
 	private static String crawlFilterAttributes = ""crawl.filter.attributes"";
+	/* TODO: all, There is no implementation for this? */
 	private static String crawlNumberOfThreads = ""crawl.numberOfThreads"";
 
 	private static String hibernateProperties = ""hibernate.properties"";
"
05770ca83bd16ee5719efc0803bee2c21ee59dc6,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index fba7426..97ea298 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -46,6 +46,7 @@
 	private static String crawlTags = ""crawl.tags"";
 	private static String crawlExludeTags = ""crawl.tags.exclude"";
 	private static String crawlFilterAttributes = ""crawl.filter.attributes"";
+	/* TODO: all, There is no implementation for this? */
 	private static String crawlNumberOfThreads = ""crawl.numberOfThreads"";
 
 	private static String hibernateProperties = ""hibernate.properties"";
"
e71ab94c4cee8c5be4cbf785709663f7dbef1d96,Frank Groeneveld,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 97ea298..5b91d28 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -34,15 +34,13 @@
 	private static String outputFolderName = ""output.path"";
 	private static String outputFolder = """";
 
-	private static String genFilepath = ""generated.pages.filepath"";
 	private static String siteUrl = ""site.url"";
-	private static String siteIndexablePath = ""site.indexable.path"";
 	private static String baseUrl = ""site.base.url"";
 	private static String crawlDepth = ""crawl.depth"";
 	private static String crawlMaxStates = ""crawl.max.states"";
 	private static String crawlMaxTime = ""crawl.max.runtime"";
 	private static String crawlThrehold = ""crawl.threshold"";
-	private static String robotEvents = ""robot.events"";
+
 	private static String crawlTags = ""crawl.tags"";
 	private static String crawlExludeTags = ""crawl.tags.exclude"";
 	private static String crawlFilterAttributes = ""crawl.filter.attributes"";
@@ -52,7 +50,6 @@
 	private static String hibernateProperties = ""hibernate.properties"";
 	private static String hibernatePropertiesValue = ""hibernate.properties"";
 
-	private static String crawlManualEnterForm = ""crawl.forms.manual"";
 	private static String crawlFormRandomInput = ""crawl.forms.randominput"";
 	private static int crawlFormRandomInputValue = 1;
 
@@ -76,22 +73,11 @@
 
 	private static int testInvariantsWhileCrawlingValue = 1;
 
-	private static String debugVariables = ""reportbuilder.debugvariables"";
-	private static List<String> debugVariablesValues;
-
 	/* event handlers */
 	private static String detectEventHandlers = ""eventHandlers.detect"";
 	private static int detectEventHandlersValue = 1;
 
-	private static String supportDomEvents = ""eventHandlers.supportDomEvents"";
-	private static int supportDomEventsValue = 1;
-	private static String supportAddEvents = ""eventHandlers.supportAddEvents"";
-	private static int supportAddEventsValue = 1;
-	private static String supportJQuery = ""eventHandlers.supportJQuery"";
-	private static int supportJQueryValue = 1;
-
 	private static String siteUrlValue;
-	private static String genFilepathValue = ""target/generated-sources/"";
 	private static String siteIndexablePathValue;
 	private static String baseUrlValue;
 	private static int crawlDepthValue;
@@ -117,10 +103,6 @@
 
 	private static String seleniumTestsuitePathValue;
 
-	private static String maxHistorySizeText = ""history.maxsize"";
-
-	private static int maxHistorySize;
-
 	private static String propertiesFileName;
 
 	/**
@@ -174,13 +156,9 @@
 		projectRelativePathValue = getProperty(projectRelativePath);
 
 		siteUrlValue = getProperty(siteUrl);
-		genFilepathValue = getProperty(genFilepath);
-		siteIndexablePathValue = getProperty(siteIndexablePath);
 		baseUrlValue = getProperty(baseUrl);
 		crawlDepthValue = getPropertyAsInt(crawlDepth);
 		crawNumberOfThreadsValue = getPropertyAsInt(crawlNumberOfThreads);
-		// crawlThreholdValue = getPropertyAsDouble(crawlThrehold);
-		robotEventsValues = getPropertyAsList(robotEvents);
 		crawlTagsValues = getPropertyAsList(crawlTags);
 		crawlFilterAttributesValues = getPropertyAsList(crawlFilterAttributes);
 		browserValue = getProperty(browser);
@@ -202,8 +180,6 @@
 			clickOnceValue = getPropertyAsInt(clickOnce);
 		}
 
-		debugVariablesValues = getPropertyAsList(debugVariables);
-
 		setTagElements();
 		setTagExcludeElements();
 
@@ -214,9 +190,6 @@
 		if (config.containsKey(seleniumTestsuitePath)) {
 			seleniumTestsuitePathValue = getProperty(seleniumTestsuitePath);
 		}
-		if (config.containsKey(maxHistorySizeText)) {
-			maxHistorySize = getPropertyAsInt(maxHistorySizeText);
-		}
 
 		hibernateSchemaValue = getProperty(hibernateSchema);
 
@@ -300,16 +273,6 @@
 			return false;
 		}
 
-		try {
-			if (genFilepathValue != null && !genFilepathValue.equals("""")) {
-				Helper.directoryCheck(genFilepathValue);
-			}
-		} catch (IOException e) {
-			LOGGER.error(e.getMessage(), e);
-
-			return false;
-		}
-
 		if (isEmpty(hibernateSchemaValue)) {
 			LOGGER.error(""Property "" + hibernateSchema + "" is not set."");
 
@@ -393,13 +356,6 @@
 	}
 
 	/**
-	 * @return the genFilepath.
-	 */
-	public static String getGenFilepath() {
-		return genFilepath;
-	}
-
-	/**
 	 * @return the siteUrl
 	 */
 	public static String getSiteUrl() {
@@ -407,13 +363,6 @@
 	}
 
 	/**
-	 * @return the siteIndexablePath
-	 */
-	public static String getSiteIndexablePath() {
-		return siteIndexablePath;
-	}
-
-	/**
 	 * @return the baseUrl
 	 */
 	public static String getBaseUrl() {
@@ -435,13 +384,6 @@
 	}
 
 	/**
-	 * @return the robotEvents
-	 */
-	public static String getRobotEvents() {
-		return robotEvents;
-	}
-
-	/**
 	 * @return the crawlTags
 	 */
 	public static String getCrawlTags() {
@@ -470,13 +412,6 @@
 	}
 
 	/**
-	 * @return the genFilepathValue
-	 */
-	public static String getGenFilepathValue() {
-		return genFilepathValue;
-	}
-
-	/**
 	 * @return the siteIndexablePathValue
 	 */
 	public static String getSiteIndexablePathValue() {
@@ -693,13 +628,6 @@
 	}
 
 	/**
-	 * @return the crawlManualEnterForm
-	 */
-	public static String getCrawlManualEnterForm() {
-		return crawlManualEnterForm;
-	}
-
-	/**
 	 * @return the crawlManualEnterFormValue
 	 */
 	public static boolean getCrawlManualEnterFormValue() {
@@ -759,15 +687,6 @@
 	}
 
 	/**
-	 * Return the max history size.
-	 * 
-	 * @return Maximum history size.
-	 */
-	public static int getMaxHistorySize() {
-		return maxHistorySize;
-	}
-
-	/**
 	 * Returns the hibernate schema name.
 	 * 
 	 * @return The name.
@@ -784,13 +703,6 @@
 	}
 
 	/**
-	 * @return the debugVariablesValues
-	 */
-	public static List<String> getDebugVariablesValues() {
-		return debugVariablesValues;
-	}
-
-	/**
 	 * @return the detectEventHandlers
 	 */
 	public static String getDetectEventHandlers() {
@@ -805,48 +717,6 @@
 	}
 
 	/**
-	 * @return the supportDomEvents
-	 */
-	public static String getSupportDomEvents() {
-		return supportDomEvents;
-	}
-
-	/**
-	 * @return the supportDomEventsValue
-	 */
-	public static boolean getSupportDomEventsValue() {
-		return supportDomEventsValue == 1;
-	}
-
-	/**
-	 * @return the supportAddEvents
-	 */
-	public static String getSupportAddEvents() {
-		return supportAddEvents;
-	}
-
-	/**
-	 * @return the supportAddEventsValue
-	 */
-	public static boolean getSupportAddEventsValue() {
-		return supportAddEventsValue == 1;
-	}
-
-	/**
-	 * @return the supportJQuery
-	 */
-	public static String getSupportJQuery() {
-		return supportJQuery;
-	}
-
-	/**
-	 * @return the supportJQueryValue
-	 */
-	public static boolean getSupportJQueryValue() {
-		return supportJQueryValue == 1;
-	}
-
-	/**
 	 * Get filename of the properties file in use.
 	 * 
 	 * @return Filename.
@@ -858,7 +728,7 @@
 	/**
 	 * @return the crawNumberOfThreadsValue
 	 */
-	public static final int getCrawNumberOfThreadsValue() {
+	public static int getCrawNumberOfThreadsValue() {
 		return crawNumberOfThreadsValue;
 	}
 
"
a3dfe2a7d63b3995d455c8ccdc72726eb1c85896,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 97ea298..5b91d28 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -34,15 +34,13 @@
 	private static String outputFolderName = ""output.path"";
 	private static String outputFolder = """";
 
-	private static String genFilepath = ""generated.pages.filepath"";
 	private static String siteUrl = ""site.url"";
-	private static String siteIndexablePath = ""site.indexable.path"";
 	private static String baseUrl = ""site.base.url"";
 	private static String crawlDepth = ""crawl.depth"";
 	private static String crawlMaxStates = ""crawl.max.states"";
 	private static String crawlMaxTime = ""crawl.max.runtime"";
 	private static String crawlThrehold = ""crawl.threshold"";
-	private static String robotEvents = ""robot.events"";
+
 	private static String crawlTags = ""crawl.tags"";
 	private static String crawlExludeTags = ""crawl.tags.exclude"";
 	private static String crawlFilterAttributes = ""crawl.filter.attributes"";
@@ -52,7 +50,6 @@
 	private static String hibernateProperties = ""hibernate.properties"";
 	private static String hibernatePropertiesValue = ""hibernate.properties"";
 
-	private static String crawlManualEnterForm = ""crawl.forms.manual"";
 	private static String crawlFormRandomInput = ""crawl.forms.randominput"";
 	private static int crawlFormRandomInputValue = 1;
 
@@ -76,22 +73,11 @@
 
 	private static int testInvariantsWhileCrawlingValue = 1;
 
-	private static String debugVariables = ""reportbuilder.debugvariables"";
-	private static List<String> debugVariablesValues;
-
 	/* event handlers */
 	private static String detectEventHandlers = ""eventHandlers.detect"";
 	private static int detectEventHandlersValue = 1;
 
-	private static String supportDomEvents = ""eventHandlers.supportDomEvents"";
-	private static int supportDomEventsValue = 1;
-	private static String supportAddEvents = ""eventHandlers.supportAddEvents"";
-	private static int supportAddEventsValue = 1;
-	private static String supportJQuery = ""eventHandlers.supportJQuery"";
-	private static int supportJQueryValue = 1;
-
 	private static String siteUrlValue;
-	private static String genFilepathValue = ""target/generated-sources/"";
 	private static String siteIndexablePathValue;
 	private static String baseUrlValue;
 	private static int crawlDepthValue;
@@ -117,10 +103,6 @@
 
 	private static String seleniumTestsuitePathValue;
 
-	private static String maxHistorySizeText = ""history.maxsize"";
-
-	private static int maxHistorySize;
-
 	private static String propertiesFileName;
 
 	/**
@@ -174,13 +156,9 @@
 		projectRelativePathValue = getProperty(projectRelativePath);
 
 		siteUrlValue = getProperty(siteUrl);
-		genFilepathValue = getProperty(genFilepath);
-		siteIndexablePathValue = getProperty(siteIndexablePath);
 		baseUrlValue = getProperty(baseUrl);
 		crawlDepthValue = getPropertyAsInt(crawlDepth);
 		crawNumberOfThreadsValue = getPropertyAsInt(crawlNumberOfThreads);
-		// crawlThreholdValue = getPropertyAsDouble(crawlThrehold);
-		robotEventsValues = getPropertyAsList(robotEvents);
 		crawlTagsValues = getPropertyAsList(crawlTags);
 		crawlFilterAttributesValues = getPropertyAsList(crawlFilterAttributes);
 		browserValue = getProperty(browser);
@@ -202,8 +180,6 @@
 			clickOnceValue = getPropertyAsInt(clickOnce);
 		}
 
-		debugVariablesValues = getPropertyAsList(debugVariables);
-
 		setTagElements();
 		setTagExcludeElements();
 
@@ -214,9 +190,6 @@
 		if (config.containsKey(seleniumTestsuitePath)) {
 			seleniumTestsuitePathValue = getProperty(seleniumTestsuitePath);
 		}
-		if (config.containsKey(maxHistorySizeText)) {
-			maxHistorySize = getPropertyAsInt(maxHistorySizeText);
-		}
 
 		hibernateSchemaValue = getProperty(hibernateSchema);
 
@@ -300,16 +273,6 @@
 			return false;
 		}
 
-		try {
-			if (genFilepathValue != null && !genFilepathValue.equals("""")) {
-				Helper.directoryCheck(genFilepathValue);
-			}
-		} catch (IOException e) {
-			LOGGER.error(e.getMessage(), e);
-
-			return false;
-		}
-
 		if (isEmpty(hibernateSchemaValue)) {
 			LOGGER.error(""Property "" + hibernateSchema + "" is not set."");
 
@@ -393,13 +356,6 @@
 	}
 
 	/**
-	 * @return the genFilepath.
-	 */
-	public static String getGenFilepath() {
-		return genFilepath;
-	}
-
-	/**
 	 * @return the siteUrl
 	 */
 	public static String getSiteUrl() {
@@ -407,13 +363,6 @@
 	}
 
 	/**
-	 * @return the siteIndexablePath
-	 */
-	public static String getSiteIndexablePath() {
-		return siteIndexablePath;
-	}
-
-	/**
 	 * @return the baseUrl
 	 */
 	public static String getBaseUrl() {
@@ -435,13 +384,6 @@
 	}
 
 	/**
-	 * @return the robotEvents
-	 */
-	public static String getRobotEvents() {
-		return robotEvents;
-	}
-
-	/**
 	 * @return the crawlTags
 	 */
 	public static String getCrawlTags() {
@@ -470,13 +412,6 @@
 	}
 
 	/**
-	 * @return the genFilepathValue
-	 */
-	public static String getGenFilepathValue() {
-		return genFilepathValue;
-	}
-
-	/**
 	 * @return the siteIndexablePathValue
 	 */
 	public static String getSiteIndexablePathValue() {
@@ -693,13 +628,6 @@
 	}
 
 	/**
-	 * @return the crawlManualEnterForm
-	 */
-	public static String getCrawlManualEnterForm() {
-		return crawlManualEnterForm;
-	}
-
-	/**
 	 * @return the crawlManualEnterFormValue
 	 */
 	public static boolean getCrawlManualEnterFormValue() {
@@ -759,15 +687,6 @@
 	}
 
 	/**
-	 * Return the max history size.
-	 * 
-	 * @return Maximum history size.
-	 */
-	public static int getMaxHistorySize() {
-		return maxHistorySize;
-	}
-
-	/**
 	 * Returns the hibernate schema name.
 	 * 
 	 * @return The name.
@@ -784,13 +703,6 @@
 	}
 
 	/**
-	 * @return the debugVariablesValues
-	 */
-	public static List<String> getDebugVariablesValues() {
-		return debugVariablesValues;
-	}
-
-	/**
 	 * @return the detectEventHandlers
 	 */
 	public static String getDetectEventHandlers() {
@@ -805,48 +717,6 @@
 	}
 
 	/**
-	 * @return the supportDomEvents
-	 */
-	public static String getSupportDomEvents() {
-		return supportDomEvents;
-	}
-
-	/**
-	 * @return the supportDomEventsValue
-	 */
-	public static boolean getSupportDomEventsValue() {
-		return supportDomEventsValue == 1;
-	}
-
-	/**
-	 * @return the supportAddEvents
-	 */
-	public static String getSupportAddEvents() {
-		return supportAddEvents;
-	}
-
-	/**
-	 * @return the supportAddEventsValue
-	 */
-	public static boolean getSupportAddEventsValue() {
-		return supportAddEventsValue == 1;
-	}
-
-	/**
-	 * @return the supportJQuery
-	 */
-	public static String getSupportJQuery() {
-		return supportJQuery;
-	}
-
-	/**
-	 * @return the supportJQueryValue
-	 */
-	public static boolean getSupportJQueryValue() {
-		return supportJQueryValue == 1;
-	}
-
-	/**
 	 * Get filename of the properties file in use.
 	 * 
 	 * @return Filename.
@@ -858,7 +728,7 @@
 	/**
 	 * @return the crawNumberOfThreadsValue
 	 */
-	public static final int getCrawNumberOfThreadsValue() {
+	public static int getCrawNumberOfThreadsValue() {
 		return crawNumberOfThreadsValue;
 	}
 
"
24ab926862876d0360b62e91e7a0227bbd5f492e,Frank Groeneveld,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 5b91d28..43f0b9a 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -3,7 +3,6 @@
  */
 package com.crawljax.util;
 
-import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.regex.Matcher;
@@ -34,13 +33,12 @@
 	private static String outputFolderName = ""output.path"";
 	private static String outputFolder = """";
 
+	private static String genFilepath = ""generated.pages.filepath"";
 	private static String siteUrl = ""site.url"";
 	private static String baseUrl = ""site.base.url"";
 	private static String crawlDepth = ""crawl.depth"";
 	private static String crawlMaxStates = ""crawl.max.states"";
 	private static String crawlMaxTime = ""crawl.max.runtime"";
-	private static String crawlThrehold = ""crawl.threshold"";
-
 	private static String crawlTags = ""crawl.tags"";
 	private static String crawlExludeTags = ""crawl.tags.exclude"";
 	private static String crawlFilterAttributes = ""crawl.filter.attributes"";
@@ -50,6 +48,7 @@
 	private static String hibernateProperties = ""hibernate.properties"";
 	private static String hibernatePropertiesValue = ""hibernate.properties"";
 
+	private static String crawlManualEnterForm = ""crawl.forms.manual"";
 	private static String crawlFormRandomInput = ""crawl.forms.randominput"";
 	private static int crawlFormRandomInputValue = 1;
 
@@ -73,21 +72,21 @@
 
 	private static int testInvariantsWhileCrawlingValue = 1;
 
+	private static String debugVariables = ""reportbuilder.debugvariables"";
+	private static List<String> debugVariablesValues;
+
 	/* event handlers */
 	private static String detectEventHandlers = ""eventHandlers.detect"";
 	private static int detectEventHandlersValue = 1;
 
 	private static String siteUrlValue;
-	private static String siteIndexablePathValue;
 	private static String baseUrlValue;
 	private static int crawlDepthValue;
-	private static double crawlThreholdValue;
 	private static List<String> robotEventsValues;
 	private static List<String> crawlTagsValues;
 	private static List<String> crawlFilterAttributesValues;
 	private static List<TagElement> crawlTagElements = new ArrayList<TagElement>();
 	private static List<TagElement> crawlExcludeTagElements = new ArrayList<TagElement>();
-	private static List<String> atusaPluginsValues;
 	private static int crawlMaxStatesValue = 0;
 	private static int crawlMaxTimeValue = 0;
 
@@ -99,10 +98,6 @@
 
 	private static int crawNumberOfThreadsValue = 1;
 
-	private static String seleniumTestsuitePath = ""selenium.testsuite.path"";
-
-	private static String seleniumTestsuitePathValue;
-
 	private static String propertiesFileName;
 
 	/**
@@ -159,6 +154,7 @@
 		baseUrlValue = getProperty(baseUrl);
 		crawlDepthValue = getPropertyAsInt(crawlDepth);
 		crawNumberOfThreadsValue = getPropertyAsInt(crawlNumberOfThreads);
+
 		crawlTagsValues = getPropertyAsList(crawlTags);
 		crawlFilterAttributesValues = getPropertyAsList(crawlFilterAttributes);
 		browserValue = getProperty(browser);
@@ -180,6 +176,8 @@
 			clickOnceValue = getPropertyAsInt(clickOnce);
 		}
 
+		debugVariablesValues = getPropertyAsList(debugVariables);
+
 		setTagElements();
 		setTagExcludeElements();
 
@@ -187,10 +185,6 @@
 			proxyEnabledValue = getPropertyAsInt(proxyEnabled);
 		}
 
-		if (config.containsKey(seleniumTestsuitePath)) {
-			seleniumTestsuitePathValue = getProperty(seleniumTestsuitePath);
-		}
-
 		hibernateSchemaValue = getProperty(hibernateSchema);
 
 		if (!checkProperties()) {
@@ -279,16 +273,6 @@
 			return false;
 		}
 
-		try {
-			// make sure the report is written to an existing path
-			if (seleniumTestsuitePathValue != null) {
-				Helper.directoryCheck(seleniumTestsuitePathValue);
-			}
-		} catch (IOException e) {
-			LOGGER.error(e.getMessage(), e);
-			return false;
-		}
-
 		return true;
 	}
 
@@ -356,6 +340,13 @@
 	}
 
 	/**
+	 * @return the genFilepath.
+	 */
+	public static String getGenFilepath() {
+		return genFilepath;
+	}
+
+	/**
 	 * @return the siteUrl
 	 */
 	public static String getSiteUrl() {
@@ -377,13 +368,6 @@
 	}
 
 	/**
-	 * @return the crawlThrehold
-	 */
-	public static String getCrawlThrehold() {
-		return crawlThrehold;
-	}
-
-	/**
 	 * @return the crawlTags
 	 */
 	public static String getCrawlTags() {
@@ -412,13 +396,6 @@
 	}
 
 	/**
-	 * @return the siteIndexablePathValue
-	 */
-	public static String getSiteIndexablePathValue() {
-		return siteIndexablePathValue;
-	}
-
-	/**
 	 * @return the baseUrlValue
 	 */
 	public static String getBaseUrlValue() {
@@ -433,13 +410,6 @@
 	}
 
 	/**
-	 * @return the crawlThreholdValue
-	 */
-	public static double getCrawlThreholdValue() {
-		return crawlThreholdValue;
-	}
-
-	/**
 	 * @return the robotEventsValues
 	 */
 	public static List<String> getRobotEventsValues() {
@@ -628,6 +598,13 @@
 	}
 
 	/**
+	 * @return the crawlManualEnterForm
+	 */
+	public static String getCrawlManualEnterForm() {
+		return crawlManualEnterForm;
+	}
+
+	/**
 	 * @return the crawlManualEnterFormValue
 	 */
 	public static boolean getCrawlManualEnterFormValue() {
@@ -649,13 +626,6 @@
 	}
 
 	/**
-	 * @return TODO: DOCUMENT ME!
-	 */
-	public static List<String> getAtusaPluginsValues() {
-		return atusaPluginsValues;
-	}
-
-	/**
 	 * @return Whether to use the proxy.
 	 */
 	public static boolean getProxyEnabledValue() {
@@ -676,16 +646,6 @@
 		return domTidyValue == 1;
 	}
 
-	// selenium
-	/**
-	 * Return the path in which the Selenium report should be created.
-	 * 
-	 * @return the genFilepathValue
-	 */
-	public static String getSeleniumTestsuitePathValue() {
-		return seleniumTestsuitePathValue;
-	}
-
 	/**
 	 * Returns the hibernate schema name.
 	 * 
@@ -703,6 +663,13 @@
 	}
 
 	/**
+	 * @return the debugVariablesValues
+	 */
+	public static List<String> getDebugVariablesValues() {
+		return debugVariablesValues;
+	}
+
+	/**
 	 * @return the detectEventHandlers
 	 */
 	public static String getDetectEventHandlers() {
"
5cad296e0ba0ab77fe53f3996e304c55b7ffd697,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 5b91d28..43f0b9a 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -3,7 +3,6 @@
  */
 package com.crawljax.util;
 
-import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.regex.Matcher;
@@ -34,13 +33,12 @@
 	private static String outputFolderName = ""output.path"";
 	private static String outputFolder = """";
 
+	private static String genFilepath = ""generated.pages.filepath"";
 	private static String siteUrl = ""site.url"";
 	private static String baseUrl = ""site.base.url"";
 	private static String crawlDepth = ""crawl.depth"";
 	private static String crawlMaxStates = ""crawl.max.states"";
 	private static String crawlMaxTime = ""crawl.max.runtime"";
-	private static String crawlThrehold = ""crawl.threshold"";
-
 	private static String crawlTags = ""crawl.tags"";
 	private static String crawlExludeTags = ""crawl.tags.exclude"";
 	private static String crawlFilterAttributes = ""crawl.filter.attributes"";
@@ -50,6 +48,7 @@
 	private static String hibernateProperties = ""hibernate.properties"";
 	private static String hibernatePropertiesValue = ""hibernate.properties"";
 
+	private static String crawlManualEnterForm = ""crawl.forms.manual"";
 	private static String crawlFormRandomInput = ""crawl.forms.randominput"";
 	private static int crawlFormRandomInputValue = 1;
 
@@ -73,21 +72,21 @@
 
 	private static int testInvariantsWhileCrawlingValue = 1;
 
+	private static String debugVariables = ""reportbuilder.debugvariables"";
+	private static List<String> debugVariablesValues;
+
 	/* event handlers */
 	private static String detectEventHandlers = ""eventHandlers.detect"";
 	private static int detectEventHandlersValue = 1;
 
 	private static String siteUrlValue;
-	private static String siteIndexablePathValue;
 	private static String baseUrlValue;
 	private static int crawlDepthValue;
-	private static double crawlThreholdValue;
 	private static List<String> robotEventsValues;
 	private static List<String> crawlTagsValues;
 	private static List<String> crawlFilterAttributesValues;
 	private static List<TagElement> crawlTagElements = new ArrayList<TagElement>();
 	private static List<TagElement> crawlExcludeTagElements = new ArrayList<TagElement>();
-	private static List<String> atusaPluginsValues;
 	private static int crawlMaxStatesValue = 0;
 	private static int crawlMaxTimeValue = 0;
 
@@ -99,10 +98,6 @@
 
 	private static int crawNumberOfThreadsValue = 1;
 
-	private static String seleniumTestsuitePath = ""selenium.testsuite.path"";
-
-	private static String seleniumTestsuitePathValue;
-
 	private static String propertiesFileName;
 
 	/**
@@ -159,6 +154,7 @@
 		baseUrlValue = getProperty(baseUrl);
 		crawlDepthValue = getPropertyAsInt(crawlDepth);
 		crawNumberOfThreadsValue = getPropertyAsInt(crawlNumberOfThreads);
+
 		crawlTagsValues = getPropertyAsList(crawlTags);
 		crawlFilterAttributesValues = getPropertyAsList(crawlFilterAttributes);
 		browserValue = getProperty(browser);
@@ -180,6 +176,8 @@
 			clickOnceValue = getPropertyAsInt(clickOnce);
 		}
 
+		debugVariablesValues = getPropertyAsList(debugVariables);
+
 		setTagElements();
 		setTagExcludeElements();
 
@@ -187,10 +185,6 @@
 			proxyEnabledValue = getPropertyAsInt(proxyEnabled);
 		}
 
-		if (config.containsKey(seleniumTestsuitePath)) {
-			seleniumTestsuitePathValue = getProperty(seleniumTestsuitePath);
-		}
-
 		hibernateSchemaValue = getProperty(hibernateSchema);
 
 		if (!checkProperties()) {
@@ -279,16 +273,6 @@
 			return false;
 		}
 
-		try {
-			// make sure the report is written to an existing path
-			if (seleniumTestsuitePathValue != null) {
-				Helper.directoryCheck(seleniumTestsuitePathValue);
-			}
-		} catch (IOException e) {
-			LOGGER.error(e.getMessage(), e);
-			return false;
-		}
-
 		return true;
 	}
 
@@ -356,6 +340,13 @@
 	}
 
 	/**
+	 * @return the genFilepath.
+	 */
+	public static String getGenFilepath() {
+		return genFilepath;
+	}
+
+	/**
 	 * @return the siteUrl
 	 */
 	public static String getSiteUrl() {
@@ -377,13 +368,6 @@
 	}
 
 	/**
-	 * @return the crawlThrehold
-	 */
-	public static String getCrawlThrehold() {
-		return crawlThrehold;
-	}
-
-	/**
 	 * @return the crawlTags
 	 */
 	public static String getCrawlTags() {
@@ -412,13 +396,6 @@
 	}
 
 	/**
-	 * @return the siteIndexablePathValue
-	 */
-	public static String getSiteIndexablePathValue() {
-		return siteIndexablePathValue;
-	}
-
-	/**
 	 * @return the baseUrlValue
 	 */
 	public static String getBaseUrlValue() {
@@ -433,13 +410,6 @@
 	}
 
 	/**
-	 * @return the crawlThreholdValue
-	 */
-	public static double getCrawlThreholdValue() {
-		return crawlThreholdValue;
-	}
-
-	/**
 	 * @return the robotEventsValues
 	 */
 	public static List<String> getRobotEventsValues() {
@@ -628,6 +598,13 @@
 	}
 
 	/**
+	 * @return the crawlManualEnterForm
+	 */
+	public static String getCrawlManualEnterForm() {
+		return crawlManualEnterForm;
+	}
+
+	/**
 	 * @return the crawlManualEnterFormValue
 	 */
 	public static boolean getCrawlManualEnterFormValue() {
@@ -649,13 +626,6 @@
 	}
 
 	/**
-	 * @return TODO: DOCUMENT ME!
-	 */
-	public static List<String> getAtusaPluginsValues() {
-		return atusaPluginsValues;
-	}
-
-	/**
 	 * @return Whether to use the proxy.
 	 */
 	public static boolean getProxyEnabledValue() {
@@ -676,16 +646,6 @@
 		return domTidyValue == 1;
 	}
 
-	// selenium
-	/**
-	 * Return the path in which the Selenium report should be created.
-	 * 
-	 * @return the genFilepathValue
-	 */
-	public static String getSeleniumTestsuitePathValue() {
-		return seleniumTestsuitePathValue;
-	}
-
 	/**
 	 * Returns the hibernate schema name.
 	 * 
@@ -703,6 +663,13 @@
 	}
 
 	/**
+	 * @return the debugVariablesValues
+	 */
+	public static List<String> getDebugVariablesValues() {
+		return debugVariablesValues;
+	}
+
+	/**
 	 * @return the detectEventHandlers
 	 */
 	public static String getDetectEventHandlers() {
"
35ac8e5f9b20ae9e6a2191030bd6cff6a26f07e1,Frank Groeneveld,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 43f0b9a..fba7426 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -3,6 +3,7 @@
  */
 package com.crawljax.util;
 
+import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.regex.Matcher;
@@ -35,14 +36,16 @@
 
 	private static String genFilepath = ""generated.pages.filepath"";
 	private static String siteUrl = ""site.url"";
+	private static String siteIndexablePath = ""site.indexable.path"";
 	private static String baseUrl = ""site.base.url"";
 	private static String crawlDepth = ""crawl.depth"";
 	private static String crawlMaxStates = ""crawl.max.states"";
 	private static String crawlMaxTime = ""crawl.max.runtime"";
+	private static String crawlThrehold = ""crawl.threshold"";
+	private static String robotEvents = ""robot.events"";
 	private static String crawlTags = ""crawl.tags"";
 	private static String crawlExludeTags = ""crawl.tags.exclude"";
 	private static String crawlFilterAttributes = ""crawl.filter.attributes"";
-	/* TODO: all, There is no implementation for this? */
 	private static String crawlNumberOfThreads = ""crawl.numberOfThreads"";
 
 	private static String hibernateProperties = ""hibernate.properties"";
@@ -79,14 +82,25 @@
 	private static String detectEventHandlers = ""eventHandlers.detect"";
 	private static int detectEventHandlersValue = 1;
 
+	private static String supportDomEvents = ""eventHandlers.supportDomEvents"";
+	private static int supportDomEventsValue = 1;
+	private static String supportAddEvents = ""eventHandlers.supportAddEvents"";
+	private static int supportAddEventsValue = 1;
+	private static String supportJQuery = ""eventHandlers.supportJQuery"";
+	private static int supportJQueryValue = 1;
+
 	private static String siteUrlValue;
+	private static String genFilepathValue = ""target/generated-sources/"";
+	private static String siteIndexablePathValue;
 	private static String baseUrlValue;
 	private static int crawlDepthValue;
+	private static double crawlThreholdValue;
 	private static List<String> robotEventsValues;
 	private static List<String> crawlTagsValues;
 	private static List<String> crawlFilterAttributesValues;
 	private static List<TagElement> crawlTagElements = new ArrayList<TagElement>();
 	private static List<TagElement> crawlExcludeTagElements = new ArrayList<TagElement>();
+	private static List<String> atusaPluginsValues;
 	private static int crawlMaxStatesValue = 0;
 	private static int crawlMaxTimeValue = 0;
 
@@ -98,6 +112,14 @@
 
 	private static int crawNumberOfThreadsValue = 1;
 
+	private static String seleniumTestsuitePath = ""selenium.testsuite.path"";
+
+	private static String seleniumTestsuitePathValue;
+
+	private static String maxHistorySizeText = ""history.maxsize"";
+
+	private static int maxHistorySize;
+
 	private static String propertiesFileName;
 
 	/**
@@ -151,10 +173,13 @@
 		projectRelativePathValue = getProperty(projectRelativePath);
 
 		siteUrlValue = getProperty(siteUrl);
+		genFilepathValue = getProperty(genFilepath);
+		siteIndexablePathValue = getProperty(siteIndexablePath);
 		baseUrlValue = getProperty(baseUrl);
 		crawlDepthValue = getPropertyAsInt(crawlDepth);
 		crawNumberOfThreadsValue = getPropertyAsInt(crawlNumberOfThreads);
-
+		// crawlThreholdValue = getPropertyAsDouble(crawlThrehold);
+		robotEventsValues = getPropertyAsList(robotEvents);
 		crawlTagsValues = getPropertyAsList(crawlTags);
 		crawlFilterAttributesValues = getPropertyAsList(crawlFilterAttributes);
 		browserValue = getProperty(browser);
@@ -185,6 +210,13 @@
 			proxyEnabledValue = getPropertyAsInt(proxyEnabled);
 		}
 
+		if (config.containsKey(seleniumTestsuitePath)) {
+			seleniumTestsuitePathValue = getProperty(seleniumTestsuitePath);
+		}
+		if (config.containsKey(maxHistorySizeText)) {
+			maxHistorySize = getPropertyAsInt(maxHistorySizeText);
+		}
+
 		hibernateSchemaValue = getProperty(hibernateSchema);
 
 		if (!checkProperties()) {
@@ -267,12 +299,32 @@
 			return false;
 		}
 
+		try {
+			if (genFilepathValue != null && !genFilepathValue.equals("""")) {
+				Helper.directoryCheck(genFilepathValue);
+			}
+		} catch (IOException e) {
+			LOGGER.error(e.getMessage(), e);
+
+			return false;
+		}
+
 		if (isEmpty(hibernateSchemaValue)) {
 			LOGGER.error(""Property "" + hibernateSchema + "" is not set."");
 
 			return false;
 		}
 
+		try {
+			// make sure the report is written to an existing path
+			if (seleniumTestsuitePathValue != null) {
+				Helper.directoryCheck(seleniumTestsuitePathValue);
+			}
+		} catch (IOException e) {
+			LOGGER.error(e.getMessage(), e);
+			return false;
+		}
+
 		return true;
 	}
 
@@ -354,6 +406,13 @@
 	}
 
 	/**
+	 * @return the siteIndexablePath
+	 */
+	public static String getSiteIndexablePath() {
+		return siteIndexablePath;
+	}
+
+	/**
 	 * @return the baseUrl
 	 */
 	public static String getBaseUrl() {
@@ -368,6 +427,20 @@
 	}
 
 	/**
+	 * @return the crawlThrehold
+	 */
+	public static String getCrawlThrehold() {
+		return crawlThrehold;
+	}
+
+	/**
+	 * @return the robotEvents
+	 */
+	public static String getRobotEvents() {
+		return robotEvents;
+	}
+
+	/**
 	 * @return the crawlTags
 	 */
 	public static String getCrawlTags() {
@@ -396,6 +469,20 @@
 	}
 
 	/**
+	 * @return the genFilepathValue
+	 */
+	public static String getGenFilepathValue() {
+		return genFilepathValue;
+	}
+
+	/**
+	 * @return the siteIndexablePathValue
+	 */
+	public static String getSiteIndexablePathValue() {
+		return siteIndexablePathValue;
+	}
+
+	/**
 	 * @return the baseUrlValue
 	 */
 	public static String getBaseUrlValue() {
@@ -410,6 +497,13 @@
 	}
 
 	/**
+	 * @return the crawlThreholdValue
+	 */
+	public static double getCrawlThreholdValue() {
+		return crawlThreholdValue;
+	}
+
+	/**
 	 * @return the robotEventsValues
 	 */
 	public static List<String> getRobotEventsValues() {
@@ -626,6 +720,13 @@
 	}
 
 	/**
+	 * @return TODO: DOCUMENT ME!
+	 */
+	public static List<String> getAtusaPluginsValues() {
+		return atusaPluginsValues;
+	}
+
+	/**
 	 * @return Whether to use the proxy.
 	 */
 	public static boolean getProxyEnabledValue() {
@@ -646,6 +747,25 @@
 		return domTidyValue == 1;
 	}
 
+	// selenium
+	/**
+	 * Return the path in which the Selenium report should be created.
+	 * 
+	 * @return the genFilepathValue
+	 */
+	public static String getSeleniumTestsuitePathValue() {
+		return seleniumTestsuitePathValue;
+	}
+
+	/**
+	 * Return the max history size.
+	 * 
+	 * @return Maximum history size.
+	 */
+	public static int getMaxHistorySize() {
+		return maxHistorySize;
+	}
+
 	/**
 	 * Returns the hibernate schema name.
 	 * 
@@ -684,6 +804,48 @@
 	}
 
 	/**
+	 * @return the supportDomEvents
+	 */
+	public static String getSupportDomEvents() {
+		return supportDomEvents;
+	}
+
+	/**
+	 * @return the supportDomEventsValue
+	 */
+	public static boolean getSupportDomEventsValue() {
+		return supportDomEventsValue == 1;
+	}
+
+	/**
+	 * @return the supportAddEvents
+	 */
+	public static String getSupportAddEvents() {
+		return supportAddEvents;
+	}
+
+	/**
+	 * @return the supportAddEventsValue
+	 */
+	public static boolean getSupportAddEventsValue() {
+		return supportAddEventsValue == 1;
+	}
+
+	/**
+	 * @return the supportJQuery
+	 */
+	public static String getSupportJQuery() {
+		return supportJQuery;
+	}
+
+	/**
+	 * @return the supportJQueryValue
+	 */
+	public static boolean getSupportJQueryValue() {
+		return supportJQueryValue == 1;
+	}
+
+	/**
 	 * Get filename of the properties file in use.
 	 * 
 	 * @return Filename.
@@ -695,7 +857,7 @@
 	/**
 	 * @return the crawNumberOfThreadsValue
 	 */
-	public static int getCrawNumberOfThreadsValue() {
+	public static final int getCrawNumberOfThreadsValue() {
 		return crawNumberOfThreadsValue;
 	}
 
"
867bd3ba1aeee3bba9e7f4dc24edce44c97a59d7,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 43f0b9a..fba7426 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -3,6 +3,7 @@
  */
 package com.crawljax.util;
 
+import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.regex.Matcher;
@@ -35,14 +36,16 @@
 
 	private static String genFilepath = ""generated.pages.filepath"";
 	private static String siteUrl = ""site.url"";
+	private static String siteIndexablePath = ""site.indexable.path"";
 	private static String baseUrl = ""site.base.url"";
 	private static String crawlDepth = ""crawl.depth"";
 	private static String crawlMaxStates = ""crawl.max.states"";
 	private static String crawlMaxTime = ""crawl.max.runtime"";
+	private static String crawlThrehold = ""crawl.threshold"";
+	private static String robotEvents = ""robot.events"";
 	private static String crawlTags = ""crawl.tags"";
 	private static String crawlExludeTags = ""crawl.tags.exclude"";
 	private static String crawlFilterAttributes = ""crawl.filter.attributes"";
-	/* TODO: all, There is no implementation for this? */
 	private static String crawlNumberOfThreads = ""crawl.numberOfThreads"";
 
 	private static String hibernateProperties = ""hibernate.properties"";
@@ -79,14 +82,25 @@
 	private static String detectEventHandlers = ""eventHandlers.detect"";
 	private static int detectEventHandlersValue = 1;
 
+	private static String supportDomEvents = ""eventHandlers.supportDomEvents"";
+	private static int supportDomEventsValue = 1;
+	private static String supportAddEvents = ""eventHandlers.supportAddEvents"";
+	private static int supportAddEventsValue = 1;
+	private static String supportJQuery = ""eventHandlers.supportJQuery"";
+	private static int supportJQueryValue = 1;
+
 	private static String siteUrlValue;
+	private static String genFilepathValue = ""target/generated-sources/"";
+	private static String siteIndexablePathValue;
 	private static String baseUrlValue;
 	private static int crawlDepthValue;
+	private static double crawlThreholdValue;
 	private static List<String> robotEventsValues;
 	private static List<String> crawlTagsValues;
 	private static List<String> crawlFilterAttributesValues;
 	private static List<TagElement> crawlTagElements = new ArrayList<TagElement>();
 	private static List<TagElement> crawlExcludeTagElements = new ArrayList<TagElement>();
+	private static List<String> atusaPluginsValues;
 	private static int crawlMaxStatesValue = 0;
 	private static int crawlMaxTimeValue = 0;
 
@@ -98,6 +112,14 @@
 
 	private static int crawNumberOfThreadsValue = 1;
 
+	private static String seleniumTestsuitePath = ""selenium.testsuite.path"";
+
+	private static String seleniumTestsuitePathValue;
+
+	private static String maxHistorySizeText = ""history.maxsize"";
+
+	private static int maxHistorySize;
+
 	private static String propertiesFileName;
 
 	/**
@@ -151,10 +173,13 @@
 		projectRelativePathValue = getProperty(projectRelativePath);
 
 		siteUrlValue = getProperty(siteUrl);
+		genFilepathValue = getProperty(genFilepath);
+		siteIndexablePathValue = getProperty(siteIndexablePath);
 		baseUrlValue = getProperty(baseUrl);
 		crawlDepthValue = getPropertyAsInt(crawlDepth);
 		crawNumberOfThreadsValue = getPropertyAsInt(crawlNumberOfThreads);
-
+		// crawlThreholdValue = getPropertyAsDouble(crawlThrehold);
+		robotEventsValues = getPropertyAsList(robotEvents);
 		crawlTagsValues = getPropertyAsList(crawlTags);
 		crawlFilterAttributesValues = getPropertyAsList(crawlFilterAttributes);
 		browserValue = getProperty(browser);
@@ -185,6 +210,13 @@
 			proxyEnabledValue = getPropertyAsInt(proxyEnabled);
 		}
 
+		if (config.containsKey(seleniumTestsuitePath)) {
+			seleniumTestsuitePathValue = getProperty(seleniumTestsuitePath);
+		}
+		if (config.containsKey(maxHistorySizeText)) {
+			maxHistorySize = getPropertyAsInt(maxHistorySizeText);
+		}
+
 		hibernateSchemaValue = getProperty(hibernateSchema);
 
 		if (!checkProperties()) {
@@ -267,12 +299,32 @@
 			return false;
 		}
 
+		try {
+			if (genFilepathValue != null && !genFilepathValue.equals("""")) {
+				Helper.directoryCheck(genFilepathValue);
+			}
+		} catch (IOException e) {
+			LOGGER.error(e.getMessage(), e);
+
+			return false;
+		}
+
 		if (isEmpty(hibernateSchemaValue)) {
 			LOGGER.error(""Property "" + hibernateSchema + "" is not set."");
 
 			return false;
 		}
 
+		try {
+			// make sure the report is written to an existing path
+			if (seleniumTestsuitePathValue != null) {
+				Helper.directoryCheck(seleniumTestsuitePathValue);
+			}
+		} catch (IOException e) {
+			LOGGER.error(e.getMessage(), e);
+			return false;
+		}
+
 		return true;
 	}
 
@@ -354,6 +406,13 @@
 	}
 
 	/**
+	 * @return the siteIndexablePath
+	 */
+	public static String getSiteIndexablePath() {
+		return siteIndexablePath;
+	}
+
+	/**
 	 * @return the baseUrl
 	 */
 	public static String getBaseUrl() {
@@ -368,6 +427,20 @@
 	}
 
 	/**
+	 * @return the crawlThrehold
+	 */
+	public static String getCrawlThrehold() {
+		return crawlThrehold;
+	}
+
+	/**
+	 * @return the robotEvents
+	 */
+	public static String getRobotEvents() {
+		return robotEvents;
+	}
+
+	/**
 	 * @return the crawlTags
 	 */
 	public static String getCrawlTags() {
@@ -396,6 +469,20 @@
 	}
 
 	/**
+	 * @return the genFilepathValue
+	 */
+	public static String getGenFilepathValue() {
+		return genFilepathValue;
+	}
+
+	/**
+	 * @return the siteIndexablePathValue
+	 */
+	public static String getSiteIndexablePathValue() {
+		return siteIndexablePathValue;
+	}
+
+	/**
 	 * @return the baseUrlValue
 	 */
 	public static String getBaseUrlValue() {
@@ -410,6 +497,13 @@
 	}
 
 	/**
+	 * @return the crawlThreholdValue
+	 */
+	public static double getCrawlThreholdValue() {
+		return crawlThreholdValue;
+	}
+
+	/**
 	 * @return the robotEventsValues
 	 */
 	public static List<String> getRobotEventsValues() {
@@ -626,6 +720,13 @@
 	}
 
 	/**
+	 * @return TODO: DOCUMENT ME!
+	 */
+	public static List<String> getAtusaPluginsValues() {
+		return atusaPluginsValues;
+	}
+
+	/**
 	 * @return Whether to use the proxy.
 	 */
 	public static boolean getProxyEnabledValue() {
@@ -646,6 +747,25 @@
 		return domTidyValue == 1;
 	}
 
+	// selenium
+	/**
+	 * Return the path in which the Selenium report should be created.
+	 * 
+	 * @return the genFilepathValue
+	 */
+	public static String getSeleniumTestsuitePathValue() {
+		return seleniumTestsuitePathValue;
+	}
+
+	/**
+	 * Return the max history size.
+	 * 
+	 * @return Maximum history size.
+	 */
+	public static int getMaxHistorySize() {
+		return maxHistorySize;
+	}
+
 	/**
 	 * Returns the hibernate schema name.
 	 * 
@@ -684,6 +804,48 @@
 	}
 
 	/**
+	 * @return the supportDomEvents
+	 */
+	public static String getSupportDomEvents() {
+		return supportDomEvents;
+	}
+
+	/**
+	 * @return the supportDomEventsValue
+	 */
+	public static boolean getSupportDomEventsValue() {
+		return supportDomEventsValue == 1;
+	}
+
+	/**
+	 * @return the supportAddEvents
+	 */
+	public static String getSupportAddEvents() {
+		return supportAddEvents;
+	}
+
+	/**
+	 * @return the supportAddEventsValue
+	 */
+	public static boolean getSupportAddEventsValue() {
+		return supportAddEventsValue == 1;
+	}
+
+	/**
+	 * @return the supportJQuery
+	 */
+	public static String getSupportJQuery() {
+		return supportJQuery;
+	}
+
+	/**
+	 * @return the supportJQueryValue
+	 */
+	public static boolean getSupportJQueryValue() {
+		return supportJQueryValue == 1;
+	}
+
+	/**
 	 * Get filename of the properties file in use.
 	 * 
 	 * @return Filename.
@@ -695,7 +857,7 @@
 	/**
 	 * @return the crawNumberOfThreadsValue
 	 */
-	public static int getCrawNumberOfThreadsValue() {
+	public static final int getCrawNumberOfThreadsValue() {
 		return crawNumberOfThreadsValue;
 	}
 
"
37cbd61d213b6675395f1996f07f7d4a6e0ba625,Frank Groeneveld,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index fba7426..22b50af 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -3,7 +3,6 @@
  */
 package com.crawljax.util;
 
-import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.regex.Matcher;
@@ -34,9 +33,7 @@
 	private static String outputFolderName = ""output.path"";
 	private static String outputFolder = """";
 
-	private static String genFilepath = ""generated.pages.filepath"";
 	private static String siteUrl = ""site.url"";
-	private static String siteIndexablePath = ""site.indexable.path"";
 	private static String baseUrl = ""site.base.url"";
 	private static String crawlDepth = ""crawl.depth"";
 	private static String crawlMaxStates = ""crawl.max.states"";
@@ -51,7 +48,6 @@
 	private static String hibernateProperties = ""hibernate.properties"";
 	private static String hibernatePropertiesValue = ""hibernate.properties"";
 
-	private static String crawlManualEnterForm = ""crawl.forms.manual"";
 	private static String crawlFormRandomInput = ""crawl.forms.randominput"";
 	private static int crawlFormRandomInputValue = 1;
 
@@ -75,26 +71,13 @@
 
 	private static int testInvariantsWhileCrawlingValue = 1;
 
-	private static String debugVariables = ""reportbuilder.debugvariables"";
-	private static List<String> debugVariablesValues;
-
 	/* event handlers */
 	private static String detectEventHandlers = ""eventHandlers.detect"";
 	private static int detectEventHandlersValue = 1;
 
-	private static String supportDomEvents = ""eventHandlers.supportDomEvents"";
-	private static int supportDomEventsValue = 1;
-	private static String supportAddEvents = ""eventHandlers.supportAddEvents"";
-	private static int supportAddEventsValue = 1;
-	private static String supportJQuery = ""eventHandlers.supportJQuery"";
-	private static int supportJQueryValue = 1;
-
 	private static String siteUrlValue;
-	private static String genFilepathValue = ""target/generated-sources/"";
-	private static String siteIndexablePathValue;
 	private static String baseUrlValue;
 	private static int crawlDepthValue;
-	private static double crawlThreholdValue;
 	private static List<String> robotEventsValues;
 	private static List<String> crawlTagsValues;
 	private static List<String> crawlFilterAttributesValues;
@@ -112,10 +95,6 @@
 
 	private static int crawNumberOfThreadsValue = 1;
 
-	private static String seleniumTestsuitePath = ""selenium.testsuite.path"";
-
-	private static String seleniumTestsuitePathValue;
-
 	private static String maxHistorySizeText = ""history.maxsize"";
 
 	private static int maxHistorySize;
@@ -173,8 +152,6 @@
 		projectRelativePathValue = getProperty(projectRelativePath);
 
 		siteUrlValue = getProperty(siteUrl);
-		genFilepathValue = getProperty(genFilepath);
-		siteIndexablePathValue = getProperty(siteIndexablePath);
 		baseUrlValue = getProperty(baseUrl);
 		crawlDepthValue = getPropertyAsInt(crawlDepth);
 		crawNumberOfThreadsValue = getPropertyAsInt(crawlNumberOfThreads);
@@ -201,8 +178,6 @@
 			clickOnceValue = getPropertyAsInt(clickOnce);
 		}
 
-		debugVariablesValues = getPropertyAsList(debugVariables);
-
 		setTagElements();
 		setTagExcludeElements();
 
@@ -210,9 +185,6 @@
 			proxyEnabledValue = getPropertyAsInt(proxyEnabled);
 		}
 
-		if (config.containsKey(seleniumTestsuitePath)) {
-			seleniumTestsuitePathValue = getProperty(seleniumTestsuitePath);
-		}
 		if (config.containsKey(maxHistorySizeText)) {
 			maxHistorySize = getPropertyAsInt(maxHistorySizeText);
 		}
@@ -299,32 +271,12 @@
 			return false;
 		}
 
-		try {
-			if (genFilepathValue != null && !genFilepathValue.equals("""")) {
-				Helper.directoryCheck(genFilepathValue);
-			}
-		} catch (IOException e) {
-			LOGGER.error(e.getMessage(), e);
-
-			return false;
-		}
-
 		if (isEmpty(hibernateSchemaValue)) {
 			LOGGER.error(""Property "" + hibernateSchema + "" is not set."");
 
 			return false;
 		}
 
-		try {
-			// make sure the report is written to an existing path
-			if (seleniumTestsuitePathValue != null) {
-				Helper.directoryCheck(seleniumTestsuitePathValue);
-			}
-		} catch (IOException e) {
-			LOGGER.error(e.getMessage(), e);
-			return false;
-		}
-
 		return true;
 	}
 
@@ -392,13 +344,6 @@
 	}
 
 	/**
-	 * @return the genFilepath.
-	 */
-	public static String getGenFilepath() {
-		return genFilepath;
-	}
-
-	/**
 	 * @return the siteUrl
 	 */
 	public static String getSiteUrl() {
@@ -406,13 +351,6 @@
 	}
 
 	/**
-	 * @return the siteIndexablePath
-	 */
-	public static String getSiteIndexablePath() {
-		return siteIndexablePath;
-	}
-
-	/**
 	 * @return the baseUrl
 	 */
 	public static String getBaseUrl() {
@@ -434,13 +372,6 @@
 	}
 
 	/**
-	 * @return the robotEvents
-	 */
-	public static String getRobotEvents() {
-		return robotEvents;
-	}
-
-	/**
 	 * @return the crawlTags
 	 */
 	public static String getCrawlTags() {
@@ -469,20 +400,6 @@
 	}
 
 	/**
-	 * @return the genFilepathValue
-	 */
-	public static String getGenFilepathValue() {
-		return genFilepathValue;
-	}
-
-	/**
-	 * @return the siteIndexablePathValue
-	 */
-	public static String getSiteIndexablePathValue() {
-		return siteIndexablePathValue;
-	}
-
-	/**
 	 * @return the baseUrlValue
 	 */
 	public static String getBaseUrlValue() {
@@ -497,13 +414,6 @@
 	}
 
 	/**
-	 * @return the crawlThreholdValue
-	 */
-	public static double getCrawlThreholdValue() {
-		return crawlThreholdValue;
-	}
-
-	/**
 	 * @return the robotEventsValues
 	 */
 	public static List<String> getRobotEventsValues() {
@@ -692,13 +602,6 @@
 	}
 
 	/**
-	 * @return the crawlManualEnterForm
-	 */
-	public static String getCrawlManualEnterForm() {
-		return crawlManualEnterForm;
-	}
-
-	/**
 	 * @return the crawlManualEnterFormValue
 	 */
 	public static boolean getCrawlManualEnterFormValue() {
@@ -747,16 +650,6 @@
 		return domTidyValue == 1;
 	}
 
-	// selenium
-	/**
-	 * Return the path in which the Selenium report should be created.
-	 * 
-	 * @return the genFilepathValue
-	 */
-	public static String getSeleniumTestsuitePathValue() {
-		return seleniumTestsuitePathValue;
-	}
-
 	/**
 	 * Return the max history size.
 	 * 
@@ -783,13 +676,6 @@
 	}
 
 	/**
-	 * @return the debugVariablesValues
-	 */
-	public static List<String> getDebugVariablesValues() {
-		return debugVariablesValues;
-	}
-
-	/**
 	 * @return the detectEventHandlers
 	 */
 	public static String getDetectEventHandlers() {
@@ -804,48 +690,6 @@
 	}
 
 	/**
-	 * @return the supportDomEvents
-	 */
-	public static String getSupportDomEvents() {
-		return supportDomEvents;
-	}
-
-	/**
-	 * @return the supportDomEventsValue
-	 */
-	public static boolean getSupportDomEventsValue() {
-		return supportDomEventsValue == 1;
-	}
-
-	/**
-	 * @return the supportAddEvents
-	 */
-	public static String getSupportAddEvents() {
-		return supportAddEvents;
-	}
-
-	/**
-	 * @return the supportAddEventsValue
-	 */
-	public static boolean getSupportAddEventsValue() {
-		return supportAddEventsValue == 1;
-	}
-
-	/**
-	 * @return the supportJQuery
-	 */
-	public static String getSupportJQuery() {
-		return supportJQuery;
-	}
-
-	/**
-	 * @return the supportJQueryValue
-	 */
-	public static boolean getSupportJQueryValue() {
-		return supportJQueryValue == 1;
-	}
-
-	/**
 	 * Get filename of the properties file in use.
 	 * 
 	 * @return Filename.
@@ -857,7 +701,7 @@
 	/**
 	 * @return the crawNumberOfThreadsValue
 	 */
-	public static final int getCrawNumberOfThreadsValue() {
+	public static int getCrawNumberOfThreadsValue() {
 		return crawNumberOfThreadsValue;
 	}
 
"
4b7bb3562c8370251db64a586749555856bbea7e,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index fba7426..22b50af 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -3,7 +3,6 @@
  */
 package com.crawljax.util;
 
-import java.io.IOException;
 import java.util.ArrayList;
 import java.util.List;
 import java.util.regex.Matcher;
@@ -34,9 +33,7 @@
 	private static String outputFolderName = ""output.path"";
 	private static String outputFolder = """";
 
-	private static String genFilepath = ""generated.pages.filepath"";
 	private static String siteUrl = ""site.url"";
-	private static String siteIndexablePath = ""site.indexable.path"";
 	private static String baseUrl = ""site.base.url"";
 	private static String crawlDepth = ""crawl.depth"";
 	private static String crawlMaxStates = ""crawl.max.states"";
@@ -51,7 +48,6 @@
 	private static String hibernateProperties = ""hibernate.properties"";
 	private static String hibernatePropertiesValue = ""hibernate.properties"";
 
-	private static String crawlManualEnterForm = ""crawl.forms.manual"";
 	private static String crawlFormRandomInput = ""crawl.forms.randominput"";
 	private static int crawlFormRandomInputValue = 1;
 
@@ -75,26 +71,13 @@
 
 	private static int testInvariantsWhileCrawlingValue = 1;
 
-	private static String debugVariables = ""reportbuilder.debugvariables"";
-	private static List<String> debugVariablesValues;
-
 	/* event handlers */
 	private static String detectEventHandlers = ""eventHandlers.detect"";
 	private static int detectEventHandlersValue = 1;
 
-	private static String supportDomEvents = ""eventHandlers.supportDomEvents"";
-	private static int supportDomEventsValue = 1;
-	private static String supportAddEvents = ""eventHandlers.supportAddEvents"";
-	private static int supportAddEventsValue = 1;
-	private static String supportJQuery = ""eventHandlers.supportJQuery"";
-	private static int supportJQueryValue = 1;
-
 	private static String siteUrlValue;
-	private static String genFilepathValue = ""target/generated-sources/"";
-	private static String siteIndexablePathValue;
 	private static String baseUrlValue;
 	private static int crawlDepthValue;
-	private static double crawlThreholdValue;
 	private static List<String> robotEventsValues;
 	private static List<String> crawlTagsValues;
 	private static List<String> crawlFilterAttributesValues;
@@ -112,10 +95,6 @@
 
 	private static int crawNumberOfThreadsValue = 1;
 
-	private static String seleniumTestsuitePath = ""selenium.testsuite.path"";
-
-	private static String seleniumTestsuitePathValue;
-
 	private static String maxHistorySizeText = ""history.maxsize"";
 
 	private static int maxHistorySize;
@@ -173,8 +152,6 @@
 		projectRelativePathValue = getProperty(projectRelativePath);
 
 		siteUrlValue = getProperty(siteUrl);
-		genFilepathValue = getProperty(genFilepath);
-		siteIndexablePathValue = getProperty(siteIndexablePath);
 		baseUrlValue = getProperty(baseUrl);
 		crawlDepthValue = getPropertyAsInt(crawlDepth);
 		crawNumberOfThreadsValue = getPropertyAsInt(crawlNumberOfThreads);
@@ -201,8 +178,6 @@
 			clickOnceValue = getPropertyAsInt(clickOnce);
 		}
 
-		debugVariablesValues = getPropertyAsList(debugVariables);
-
 		setTagElements();
 		setTagExcludeElements();
 
@@ -210,9 +185,6 @@
 			proxyEnabledValue = getPropertyAsInt(proxyEnabled);
 		}
 
-		if (config.containsKey(seleniumTestsuitePath)) {
-			seleniumTestsuitePathValue = getProperty(seleniumTestsuitePath);
-		}
 		if (config.containsKey(maxHistorySizeText)) {
 			maxHistorySize = getPropertyAsInt(maxHistorySizeText);
 		}
@@ -299,32 +271,12 @@
 			return false;
 		}
 
-		try {
-			if (genFilepathValue != null && !genFilepathValue.equals("""")) {
-				Helper.directoryCheck(genFilepathValue);
-			}
-		} catch (IOException e) {
-			LOGGER.error(e.getMessage(), e);
-
-			return false;
-		}
-
 		if (isEmpty(hibernateSchemaValue)) {
 			LOGGER.error(""Property "" + hibernateSchema + "" is not set."");
 
 			return false;
 		}
 
-		try {
-			// make sure the report is written to an existing path
-			if (seleniumTestsuitePathValue != null) {
-				Helper.directoryCheck(seleniumTestsuitePathValue);
-			}
-		} catch (IOException e) {
-			LOGGER.error(e.getMessage(), e);
-			return false;
-		}
-
 		return true;
 	}
 
@@ -392,13 +344,6 @@
 	}
 
 	/**
-	 * @return the genFilepath.
-	 */
-	public static String getGenFilepath() {
-		return genFilepath;
-	}
-
-	/**
 	 * @return the siteUrl
 	 */
 	public static String getSiteUrl() {
@@ -406,13 +351,6 @@
 	}
 
 	/**
-	 * @return the siteIndexablePath
-	 */
-	public static String getSiteIndexablePath() {
-		return siteIndexablePath;
-	}
-
-	/**
 	 * @return the baseUrl
 	 */
 	public static String getBaseUrl() {
@@ -434,13 +372,6 @@
 	}
 
 	/**
-	 * @return the robotEvents
-	 */
-	public static String getRobotEvents() {
-		return robotEvents;
-	}
-
-	/**
 	 * @return the crawlTags
 	 */
 	public static String getCrawlTags() {
@@ -469,20 +400,6 @@
 	}
 
 	/**
-	 * @return the genFilepathValue
-	 */
-	public static String getGenFilepathValue() {
-		return genFilepathValue;
-	}
-
-	/**
-	 * @return the siteIndexablePathValue
-	 */
-	public static String getSiteIndexablePathValue() {
-		return siteIndexablePathValue;
-	}
-
-	/**
 	 * @return the baseUrlValue
 	 */
 	public static String getBaseUrlValue() {
@@ -497,13 +414,6 @@
 	}
 
 	/**
-	 * @return the crawlThreholdValue
-	 */
-	public static double getCrawlThreholdValue() {
-		return crawlThreholdValue;
-	}
-
-	/**
 	 * @return the robotEventsValues
 	 */
 	public static List<String> getRobotEventsValues() {
@@ -692,13 +602,6 @@
 	}
 
 	/**
-	 * @return the crawlManualEnterForm
-	 */
-	public static String getCrawlManualEnterForm() {
-		return crawlManualEnterForm;
-	}
-
-	/**
 	 * @return the crawlManualEnterFormValue
 	 */
 	public static boolean getCrawlManualEnterFormValue() {
@@ -747,16 +650,6 @@
 		return domTidyValue == 1;
 	}
 
-	// selenium
-	/**
-	 * Return the path in which the Selenium report should be created.
-	 * 
-	 * @return the genFilepathValue
-	 */
-	public static String getSeleniumTestsuitePathValue() {
-		return seleniumTestsuitePathValue;
-	}
-
 	/**
 	 * Return the max history size.
 	 * 
@@ -783,13 +676,6 @@
 	}
 
 	/**
-	 * @return the debugVariablesValues
-	 */
-	public static List<String> getDebugVariablesValues() {
-		return debugVariablesValues;
-	}
-
-	/**
 	 * @return the detectEventHandlers
 	 */
 	public static String getDetectEventHandlers() {
@@ -804,48 +690,6 @@
 	}
 
 	/**
-	 * @return the supportDomEvents
-	 */
-	public static String getSupportDomEvents() {
-		return supportDomEvents;
-	}
-
-	/**
-	 * @return the supportDomEventsValue
-	 */
-	public static boolean getSupportDomEventsValue() {
-		return supportDomEventsValue == 1;
-	}
-
-	/**
-	 * @return the supportAddEvents
-	 */
-	public static String getSupportAddEvents() {
-		return supportAddEvents;
-	}
-
-	/**
-	 * @return the supportAddEventsValue
-	 */
-	public static boolean getSupportAddEventsValue() {
-		return supportAddEventsValue == 1;
-	}
-
-	/**
-	 * @return the supportJQuery
-	 */
-	public static String getSupportJQuery() {
-		return supportJQuery;
-	}
-
-	/**
-	 * @return the supportJQueryValue
-	 */
-	public static boolean getSupportJQueryValue() {
-		return supportJQueryValue == 1;
-	}
-
-	/**
 	 * Get filename of the properties file in use.
 	 * 
 	 * @return Filename.
@@ -857,7 +701,7 @@
 	/**
 	 * @return the crawNumberOfThreadsValue
 	 */
-	public static final int getCrawNumberOfThreadsValue() {
+	public static int getCrawNumberOfThreadsValue() {
 		return crawNumberOfThreadsValue;
 	}
 
"
67ec5cea0622928edf412b53e804f4afbd19f7d5,Frank Groeneveld,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 22b50af..22964c2 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -38,7 +38,7 @@
 	private static String crawlDepth = ""crawl.depth"";
 	private static String crawlMaxStates = ""crawl.max.states"";
 	private static String crawlMaxTime = ""crawl.max.runtime"";
-	private static String crawlThrehold = ""crawl.threshold"";
+
 	private static String robotEvents = ""robot.events"";
 	private static String crawlTags = ""crawl.tags"";
 	private static String crawlExludeTags = ""crawl.tags.exclude"";
@@ -365,13 +365,6 @@
 	}
 
 	/**
-	 * @return the crawlThrehold
-	 */
-	public static String getCrawlThrehold() {
-		return crawlThrehold;
-	}
-
-	/**
 	 * @return the crawlTags
 	 */
 	public static String getCrawlTags() {
"
211628b1f8a7e46abcf1938fa38ed2f2f6fbbd7a,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 22b50af..22964c2 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -38,7 +38,7 @@
 	private static String crawlDepth = ""crawl.depth"";
 	private static String crawlMaxStates = ""crawl.max.states"";
 	private static String crawlMaxTime = ""crawl.max.runtime"";
-	private static String crawlThrehold = ""crawl.threshold"";
+
 	private static String robotEvents = ""robot.events"";
 	private static String crawlTags = ""crawl.tags"";
 	private static String crawlExludeTags = ""crawl.tags.exclude"";
@@ -365,13 +365,6 @@
 	}
 
 	/**
-	 * @return the crawlThrehold
-	 */
-	public static String getCrawlThrehold() {
-		return crawlThrehold;
-	}
-
-	/**
 	 * @return the crawlTags
 	 */
 	public static String getCrawlTags() {
"
23f1722487c52a42092f9f2486348c5a3c9f56d4,Stefan Lenselink,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/src/main/java/com/crawljax/core/CrawlQueue.java b/src/main/java/com/crawljax/core/CrawlQueue.java
index 820a85c..5f1dabb 100644
--- a/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -8,6 +8,8 @@
 import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.TimeUnit;
 
+import net.jcip.annotations.GuardedBy;
+
 /**
  * This class implements a BlockingQueue with Runnable as its Generic type and extends Stack with
  * also Runnable as generic type. This class is used in the ThreadPoolExecutor and its used to store
@@ -25,14 +27,24 @@
 
 	@Override
 	public int drainTo(Collection<? super Runnable> c) {
-		// Is never used, TODO Stefan a implementation whould be nice
-		return 0;
+		return drainTo(c, Integer.MAX_VALUE);
 	}
 
 	@Override
-	public int drainTo(Collection<? super Runnable> c, int maxRunnablelements) {
-		// Is never used, TODO Stefan a implementation whould be nice
-		return 0;
+	public synchronized int drainTo(Collection<? super Runnable> c, int maxRunnablelements) {
+		int counter = 0;
+		for (Runnable object : this) {
+			counter++;
+			if (counter < maxRunnablelements) {
+				c.add(object);
+			} else {
+				break;
+			}
+		}
+		for (Object object : c) {
+			this.remove(object);
+		}
+		return counter;
 	}
 
 	@Override
@@ -67,7 +79,8 @@
 	}
 
 	@Override
-	public Runnable element() {
+	@GuardedBy(""this"")
+	public synchronized Runnable element() {
 		return this.get(this.size() - 1);
 	}
 
@@ -77,7 +90,8 @@
 	}
 
 	@Override
-	public Runnable remove() {
+	@GuardedBy(""this"")
+	public synchronized Runnable remove() {
 		if (this.size() <= 0) {
 			return null;
 		}
"
23f1722487c52a42092f9f2486348c5a3c9f56d4,Stefan Lenselink,CrawljaxController.java,MODIFY,"updateStateMachine -> [StateVertix currentHold, Eventable event, StateVertix newState, Crawler crawler] | [StateVertix currentHold, Eventable event, StateVertix newState, EmbeddedBrowser browser]","diff --git a/src/main/java/com/crawljax/core/CrawljaxController.java b/src/main/java/com/crawljax/core/CrawljaxController.java
index b4d7789..ac32a7c 100644
--- a/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -1,11 +1,14 @@
 package com.crawljax.core;
 
 import java.util.ArrayList;
-import java.util.LinkedHashSet;
+import java.util.Collection;
 import java.util.List;
-import java.util.Set;
+import java.util.Map;
+import java.util.concurrent.ConcurrentHashMap;
+import java.util.concurrent.ConcurrentLinkedQueue;
 import java.util.concurrent.ThreadPoolExecutor;
 import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
 
 import net.jcip.annotations.GuardedBy;
 
@@ -40,7 +43,6 @@
 public class CrawljaxController {
 	private static final Logger LOGGER = Logger.getLogger(CrawljaxController.class.getName());
 
-	private int stateCounter = 1;
 	private StateVertix indexState;
 	private EmbeddedBrowser browser;
 	private StateMachine stateMachine;
@@ -63,13 +65,29 @@
 
 	private final List<OracleComparator> oracleComparator;
 
-	private final Set<String> checkedElements = new LinkedHashSet<String>();
-
 	private final ThreadPoolExecutor workQueue;
 
-	private boolean foundNewState;
+	/**
+	 * Use AtomicInteger to denote the stateCounter, in doing so its thread-safe
+	 */
+	private final AtomicInteger stateCounter = new AtomicInteger(1);
 
-	private int numberofExaminedElements;
+	/**
+	 * Use the ConcurrentHashMap to make sure the foundNewStateMap is thread-safe
+	 */
+	private final Map<Thread, Boolean> foundNewStateMap =
+	        new ConcurrentHashMap<Thread, Boolean>();
+
+	/**
+	 * Use the AtomicInteger to prevent Problems when increasing
+	 */
+	private final AtomicInteger numberofExaminedElements = new AtomicInteger();
+
+	/**
+	 * Use the ConcurrentLinkedQueue to prevent Thread problems when checking and storing
+	 * checkedElements
+	 */
+	private final Collection<String> checkedElements = new ConcurrentLinkedQueue<String>();
 
 	/**
 	 * The constructor.
@@ -235,7 +253,7 @@
 		                TimeUnit.MILLISECONDS.toSeconds(timeCrawlCalc)
 		                        - TimeUnit.MINUTES.toSeconds(TimeUnit.MILLISECONDS
 		                                .toMinutes(timeCrawlCalc))));
-		LOGGER.info(""EXAMINED ELEMENTS: "" + numberofExaminedElements);
+		LOGGER.info(""EXAMINED ELEMENTS: "" + numberofExaminedElements.get());
 		LOGGER.info(""CLICKABLES: "" + stateMachine.getStateFlowGraph().getAllEdges().size());
 		LOGGER.info(""STATES: "" + stateMachine.getStateFlowGraph().getAllStates().size());
 		LOGGER.info(""Dom average size (byte): ""
@@ -249,11 +267,11 @@
 	}
 
 	/**
-	 * Checks the state and time constraints. This function is ThreadSafe
+	 * Checks the state and time constraints. This function is nearly Thread-safe
 	 * 
 	 * @return true if all conditions are met.
 	 */
-	@GuardedBy(""stateMachine"")
+	@GuardedBy(""stateMachine.getStateFlowGraph()"")
 	public boolean checkConstraints() {
 		long timePassed = System.currentTimeMillis() - startCrawl;
 
@@ -267,7 +285,7 @@
 			return false;
 		}
 
-		synchronized (stateMachine) {
+		synchronized (stateMachine.getStateFlowGraph()) {
 			if ((PropertyHelper.getCrawlMaxStatesValue() != 0)
 			        && (stateMachine.getStateFlowGraph().getAllStates().size() >= PropertyHelper
 			                .getCrawlMaxStatesValue())) {
@@ -286,6 +304,8 @@
 	}
 
 	/**
+	 * TODO Stefan move the synchronized
+	 * 
 	 * @param currentHold
 	 *            the placeholder for the current stateVertix.
 	 * @param event
@@ -297,12 +317,12 @@
 	 * @return true if the new state is not found in the state machine.
 	 * @NotThreadSafe
 	 */
-	public boolean updateStateMachine(final StateVertix currentHold, final Eventable event,
-	        StateVertix newState, Crawler crawler) {
+	public synchronized boolean updateStateMachine(final StateVertix currentHold,
+	        final Eventable event, StateVertix newState, EmbeddedBrowser browser) {
 		StateVertix cloneState = stateMachine.addStateToCurrentState(newState, event);
-		foundNewState = true;
+		foundNewStateMap.put(Thread.currentThread(), true);
 		if (cloneState != null) {
-			foundNewState = false;
+			foundNewStateMap.put(Thread.currentThread(), false);
 			newState = cloneState.clone();
 		}
 
@@ -311,7 +331,7 @@
 		        + stateMachine.getCurrentState().getName() + "" FROM "" + currentHold.getName());
 
 		if (PropertyHelper.getTestInvariantsWhileCrawlingValue()) {
-			checkInvariants(crawler);
+			checkInvariants(browser);
 		}
 
 		synchronized (session) {
@@ -334,8 +354,7 @@
 
 	/**
 	 * Test to see if the (new) dom is changed with regards to the old dom. This method is Thread
-	 * safe, at least as the equals call of StateVertix is Thread safe and the stateBefor and
-	 * stateAfter do not change on interleaving.
+	 * safe.
 	 * 
 	 * @param stateBefore
 	 *            the state before the event.
@@ -361,16 +380,17 @@
 	}
 
 	/**
-	 * Return the name of the (new)State.
+	 * Return the name of the (new)State. By using the AtomicInteger the stateCounter is thread-safe
 	 * 
 	 * @return State name the name of the state
 	 */
-	@GuardedBy(""this"")
-	public synchronized String getStateName() {
-		if (foundNewState) {
-			stateCounter++;
+	public final String getStateName() {
+		Thread thread = Thread.currentThread();
+		Boolean value = foundNewStateMap.get(thread);
+		if (value != null && value) {
+			stateCounter.getAndIncrement();
 		}
-		String state = ""state"" + stateCounter;
+		String state = ""state"" + stateCounter.get();
 		return state;
 	}
 
@@ -378,8 +398,8 @@
 	 * @param crawler
 	 *            the Crawler to execute the invariants from
 	 */
-	private void checkInvariants(Crawler crawler) {
-		if (!invariantChecker.check(crawler.getBrowser())) {
+	private void checkInvariants(EmbeddedBrowser browser) {
+		if (!invariantChecker.check(browser)) {
 			final List<Invariant> failedInvariants = invariantChecker.getFailedInvariants();
 			for (Invariant failedInvariant : failedInvariants) {
 				CrawljaxPluginsUtil.runOnInvriantViolationPlugins(failedInvariant, session);
@@ -406,7 +426,9 @@
 	}
 
 	/**
-	 * @NotThreadSafe
+	 * Retrieve the current session, there is only one session active at a time. So this method by
+	 * it self is Thread-Safe but actions on the session are NOT!
+	 * 
 	 * @return the session
 	 */
 	public final CrawlSession getSession() {
@@ -414,11 +436,13 @@
 	}
 
 	/**
+	 * TODO Stefan move the synchronized
+	 * 
 	 * @NotThreadSafe
 	 * @param state
 	 *            the state to change the state machines pointer to.
 	 */
-	public void changeStateMachineState(StateVertix state) {
+	public synchronized void changeStateMachineState(StateVertix state) {
 		synchronized (stateMachine) {
 			LOGGER.debug(""AFTER: sm.current: "" + stateMachine.getCurrentState().getName()
 			        + "" hold.current: "" + state.getName());
@@ -429,9 +453,11 @@
 	}
 
 	/**
+	 * TODO Stefan move the synchronized
+	 * 
 	 * @NotThreadSafe
 	 */
-	public void rewindStateMachine() {
+	public synchronized void rewindStateMachine() {
 		/**
 		 * TODO Stefan There is some performance loss using this technique The state machine can
 		 * also be hard forced into the new 'start' state...
@@ -440,7 +466,7 @@
 	}
 
 	/**
-	 * Add work (Crawler) to the Queue of work that need to be done.
+	 * Add work (Crawler) to the Queue of work that need to be done. The class is thread-safe.
 	 * 
 	 * @param work
 	 *            the work (Crawler) to add to the Queue
@@ -453,44 +479,41 @@
 	}
 
 	/**
-	 * Check if a given element is already checked, preventing duplicate work.
+	 * Check if a given element is already checked, preventing duplicate work. This is implemented
+	 * in a ConcurrentLinkedQueue to support thread-safety
 	 * 
 	 * @param element
 	 *            the to search for if its already checked
 	 * @return true if the element is already checked
 	 */
-	@GuardedBy(""checkedElements"")
-	public boolean elementIsAlreadyChecked(String element) {
-		synchronized (checkedElements) {
-			return this.checkedElements.contains(element);
-		}
+	public final boolean elementIsAlreadyChecked(String element) {
+		return this.checkedElements.contains(element);
 	}
 
 	/**
-	 * Mark a given element as checked to prevent duplicate work.
+	 * Mark a given element as checked to prevent duplicate work. This is implemented in a
+	 * ConcurrentLinkedQueue to support thread-safety
 	 * 
 	 * @param element
 	 *            the elements that is checked
 	 */
-	@GuardedBy(""checkedElements"")
-	public void markElementAsChecked(String element) {
-		synchronized (checkedElements) {
-			this.checkedElements.add(element);
-		}
+	public final void markElementAsChecked(String element) {
+		this.checkedElements.add(element);
 	}
 
 	/**
-	 * Wait for a given condition.
+	 * Wait for a given condition. This call is thread safe as the underlying object is thread-safe.
 	 * 
 	 * @param browser
 	 *            the browser which requires a wait condition
 	 */
-	public void doBrowserWait(EmbeddedBrowser browser) {
+	public final void doBrowserWait(EmbeddedBrowser browser) {
 		this.waitConditionChecker.wait(browser);
 	}
 
 	/**
-	 * Retrieve the index state.
+	 * Retrieve the index state. This class is supposed to be thread safe, but be care full that no
+	 * one changes the indexState...
 	 * 
 	 * @return the indexState of the current crawl
 	 */
@@ -499,7 +522,8 @@
 	}
 
 	/**
-	 * Return the Checker of the CrawlConditions.
+	 * Return the Checker of the CrawlConditions. This call itself is thread-safe but the
+	 * crawlconditionCheck is nearly thread-safe, the failedCrawlConditions could cause trouble.
 	 * 
 	 * @return the crawlConditionChecker
 	 */
@@ -509,15 +533,18 @@
 
 	/**
 	 * increase the number of checked elements, as a statistics measure to know how many elements
-	 * were actually examined.
+	 * were actually examined. Its thread safe by using the AtomicInteger
+	 * 
+	 * @see java.util.concurrent.atomic.AtomicInteger
 	 */
-	@GuardedBy(""this"")
-	public synchronized void increaseNumberExaminedElements() {
-		numberofExaminedElements++;
+	public final void increaseNumberExaminedElements() {
+		numberofExaminedElements.getAndIncrement();
 	}
 
 	/**
-	 * TODO Check thread safety.
+	 * get the stripped version of the dom currently in the browser. This call is nearly thread
+	 * safe, maybe there is a corner case in the StateComparator with the private static field
+	 * lastUsedOraclePreConditions which is never read nevertheless.
 	 * 
 	 * @param browser
 	 *            the browser instance.
@@ -533,4 +560,43 @@
 	public final Crawler getCrawler() {
 		return crawler;
 	}
+
+	private String formatRunningTime() {
+		long timeCrawlCalc = System.currentTimeMillis() - startCrawl;
+		return String.format(""%d min, %d sec"", TimeUnit.MILLISECONDS.toMinutes(timeCrawlCalc),
+		        TimeUnit.MILLISECONDS.toSeconds(timeCrawlCalc)
+		                - TimeUnit.MINUTES.toSeconds(TimeUnit.MILLISECONDS
+		                        .toMinutes(timeCrawlCalc)));
+	}
+
+	/**
+	 * Terminate the crawling, Stop all threads this will cause the controller which is sleeping to
+	 * reactive and do the final work....
+	 */
+	@GuardedBy(""this"")
+	public final synchronized void terminate() {
+		LOGGER.warn(""After "" + this.formatRunningTime()
+		        + "" the crawling process was requested to terminate @ "" + Thread.currentThread());
+		LOGGER.info(""Trying to stop all the threads"");
+		// TODO Stefan do the actual termination of all the threads. Also test if it works!
+		LOGGER.info(""There are "" + workQueue.getActiveCount() + "" threads active"");
+		workQueue.shutdownNow();
+
+		if (workQueue.isShutdown()) {
+			LOGGER.info(""ThreadPoolExecuter is shutdown"");
+		} else {
+			LOGGER.warn(""ThreadPoolExecuter is not shutdown"");
+		}
+		if (workQueue.isTerminated()) {
+			LOGGER.info(""All threads are terminated"");
+		} else {
+			LOGGER.warn(""Not All threads are terminated, there still are ""
+			        + workQueue.getActiveCount() + "" threads active"");
+		}
+		LOGGER.info(""Trying to close all browsers"");
+		/**
+		 * Needs some more testing when Threads are not finished, the browser gets locked...
+		 */
+		BrowserFactory.close();
+	}
 }
"
da0f1715697f54c708f966e88051573a974fde16,Ali Mesbah,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/src/main/java/com/crawljax/core/CrawlQueue.java b/src/main/java/com/crawljax/core/CrawlQueue.java
index 820a85c..5f1dabb 100644
--- a/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -8,6 +8,8 @@
 import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.TimeUnit;
 
+import net.jcip.annotations.GuardedBy;
+
 /**
  * This class implements a BlockingQueue with Runnable as its Generic type and extends Stack with
  * also Runnable as generic type. This class is used in the ThreadPoolExecutor and its used to store
@@ -25,14 +27,24 @@
 
 	@Override
 	public int drainTo(Collection<? super Runnable> c) {
-		// Is never used, TODO Stefan a implementation whould be nice
-		return 0;
+		return drainTo(c, Integer.MAX_VALUE);
 	}
 
 	@Override
-	public int drainTo(Collection<? super Runnable> c, int maxRunnablelements) {
-		// Is never used, TODO Stefan a implementation whould be nice
-		return 0;
+	public synchronized int drainTo(Collection<? super Runnable> c, int maxRunnablelements) {
+		int counter = 0;
+		for (Runnable object : this) {
+			counter++;
+			if (counter < maxRunnablelements) {
+				c.add(object);
+			} else {
+				break;
+			}
+		}
+		for (Object object : c) {
+			this.remove(object);
+		}
+		return counter;
 	}
 
 	@Override
@@ -67,7 +79,8 @@
 	}
 
 	@Override
-	public Runnable element() {
+	@GuardedBy(""this"")
+	public synchronized Runnable element() {
 		return this.get(this.size() - 1);
 	}
 
@@ -77,7 +90,8 @@
 	}
 
 	@Override
-	public Runnable remove() {
+	@GuardedBy(""this"")
+	public synchronized Runnable remove() {
 		if (this.size() <= 0) {
 			return null;
 		}
"
34c0e7634485582accc16bed1c3e4a1d85589827,Ali Mesbah,Crawler.java,MODIFY,"clickTag -> [CandidateElement candidateElement, String eventType, boolean handleInputElements, StateVertix currentHold] | [Eventable eventable, boolean handleInputElements, StateVertix currentHold]","diff --git a/src/main/java/com/crawljax/core/Crawler.java b/src/main/java/com/crawljax/core/Crawler.java
index 241cdd9..fc2f44e 100644
--- a/src/main/java/com/crawljax/core/Crawler.java
+++ b/src/main/java/com/crawljax/core/Crawler.java
@@ -31,7 +31,7 @@
 
 	private static final Logger LOGGER = Logger.getLogger(Crawler.class.getName());
 
-	private static final AtomicInteger totalThreadIdCounter = new AtomicInteger();
+	private static final AtomicInteger TOTAL_THREAD_ID_COUNT = new AtomicInteger();
 
 	private final int threadId;
 	/**
@@ -140,7 +140,7 @@
 	private Crawler(CrawljaxController mother, boolean loadIndex) {
 		this.controller = mother;
 		this.candidateExtractor = new CandidateElementExtractor(this);
-		this.threadId = totalThreadIdCounter.incrementAndGet();
+		this.threadId = TOTAL_THREAD_ID_COUNT.incrementAndGet();
 		if (loadIndex) {
 			/**
 			 * The index page is requested to load so load a browser and reloads the initialURL
@@ -254,6 +254,7 @@
 	 */
 	public void handleInputElements(Eventable eventable) {
 		List<FormInput> formInputs = eventable.getRelatedFormInputs();
+
 		FormHandler formHandler = new FormHandler(browser);
 		for (FormInput formInput : formHandler.getFormInputs()) {
 			if (!formInputs.contains(formInput)) {
@@ -262,6 +263,7 @@
 		}
 		eventable.setRelatedFormInputs(formInputs);
 		formHandler.handleFormElements(formInputs);
+
 	}
 
 	/**
@@ -318,15 +320,19 @@
 	}
 
 	/**
-	 * @param elements
-	 *            the list of candidate elements.
+	 * @param eventable
+	 *            the element to execute an action on.
+	 * @param handleInputElements
+	 *            if inputs should be handled.
+	 * @param currentHold
+	 *            the current state kept for comparison.
+	 * @return 1 If Dom Changed and the new state is not found in the state machine. 0 If Dom
+	 *         Changed and new state is a Clone. -1 If Dom is Not Changed at all.
 	 * @throws CrawljaxException
 	 *             an exception.
 	 */
-	public int clickTag(final CandidateElement candidateElement, String eventType,
-	        boolean handleInputElements, StateVertix currentHold) throws CrawljaxException {
-
-		Eventable eventable = new Eventable(candidateElement, eventType);
+	public int clickTag(final Eventable eventable, boolean handleInputElements,
+	        StateVertix currentHold) throws CrawljaxException {
 
 		// load input element values
 		if (handleInputElements) {
@@ -382,7 +388,6 @@
 	 */
 	private boolean crawl() throws CrawljaxException {
 		if (!this.controller.checkConstraints()) {
-			/* stop crawling */
 			return false;
 		}
 		if (depth >= PropertyHelper.getCrawlDepthValue()
@@ -433,8 +438,8 @@
 					 * Not Changed
 					 */
 					int clickResult =
-					        clickTag(candidateElement, eventType, handleInputElements,
-					                currentHold);
+					        clickTag(new Eventable(candidateElement, eventType),
+					                handleInputElements, currentHold);
 					if (clickResult >= 0) {
 
 						if (clickResult == 0) {
"
634fe0c49677fa990e348d3ce52bb5bd9a44a33c,Stefan Lenselink,CrawljaxConfiguration.java,MODIFY,setBrowser -> [WebDriver driver] | [EmbeddedBrowser browser],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index bdf7904..a047fac 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -7,9 +7,9 @@
 import org.apache.commons.configuration.PropertiesConfiguration;
 import org.openqa.selenium.WebDriver;
 
-import com.crawljax.browser.AbstractWebDriver;
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.browser.WebDriverFirefox;
+import com.crawljax.browser.WebDriverOther;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.util.Helper;
@@ -245,11 +245,16 @@
 	}
 
 	/**
+	 * Deprecated function to specify the browser used. Replaced by
+	 * {@link CrawljaxConfiguration#setBrowser(EmbeddedBrowser)}.
+	 * 
+	 * @see #setBrowser(EmbeddedBrowser)
 	 * @param driver
 	 *            The Webdriver driver used to crawl. By default {@link WebDriverFirefox} is used.
 	 */
+	@Deprecated
 	public void setBrowser(WebDriver driver) {
-		this.browser = new AbstractWebDriver(driver);
+		this.browser = new WebDriverOther(driver);
 	}
 
 	/**
"
8452b90c332cb30c9030dc33c2b6b15f5cfc08af,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setBrowser -> [WebDriver driver] | [EmbeddedBrowser browser],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index bdf7904..a047fac 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -7,9 +7,9 @@
 import org.apache.commons.configuration.PropertiesConfiguration;
 import org.openqa.selenium.WebDriver;
 
-import com.crawljax.browser.AbstractWebDriver;
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.browser.WebDriverFirefox;
+import com.crawljax.browser.WebDriverOther;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.util.Helper;
@@ -245,11 +245,16 @@
 	}
 
 	/**
+	 * Deprecated function to specify the browser used. Replaced by
+	 * {@link CrawljaxConfiguration#setBrowser(EmbeddedBrowser)}.
+	 * 
+	 * @see #setBrowser(EmbeddedBrowser)
 	 * @param driver
 	 *            The Webdriver driver used to crawl. By default {@link WebDriverFirefox} is used.
 	 */
+	@Deprecated
 	public void setBrowser(WebDriver driver) {
-		this.browser = new AbstractWebDriver(driver);
+		this.browser = new WebDriverOther(driver);
 	}
 
 	/**
"
6b18dfc9dc61a6359b715ec4016ae0a57c853165,Stefan Lenselink,StateFlowGraph.java,MODIFY,"addEdge -> [StateVertix sourceVertex, StateVertix targetVertex, Eventable clickable] | [StateVertix sourceVert, StateVertix targetVert, Eventable clickable]","diff --git a/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index bdb6a1b..349a6aa 100644
--- a/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -4,6 +4,9 @@
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
+import java.util.concurrent.Semaphore;
+
+import net.jcip.annotations.GuardedBy;
 
 import org.apache.commons.math.stat.descriptive.moment.Mean;
 import org.apache.log4j.Logger;
@@ -24,6 +27,8 @@
 
 	private final DirectedGraph<StateVertix, Eventable> sfg;
 
+	private final Semaphore stateFlowGraphMutex = new Semaphore(1);
+
 	/**
 	 * The constructor.
 	 */
@@ -44,7 +49,12 @@
 	 * @return true if this graph did not already contain the specified vertex.
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
+	@GuardedBy(""stateFlowGraphMutex"")
 	public boolean addState(StateVertix stateVertix) {
+		if (stateFlowGraphMutex.availablePermits() != 0) {
+			LOGGER.warn(""possible code executing without required permit!"", new Throwable(
+			        ""possible code executing without required permit!"").fillInStackTrace());
+		}
 		return sfg.addVertex(stateVertix);
 	}
 
@@ -58,22 +68,27 @@
 	 * returns true. The source and target vertices must already be contained in this graph. If they
 	 * are not found in graph IllegalArgumentException is thrown.
 	 * 
-	 * @param sourceVertex
+	 * @param sourceVert
 	 *            source vertex of the edge.
-	 * @param targetVertex
+	 * @param targetVert
 	 *            target vertex of the edge.
 	 * @param clickable
 	 *            the clickable edge to be added to this graph.
 	 * @return true if this graph did not already contain the specified edge.
 	 * @see org.jgrapht.Graph#addEdge(Object, Object, Object)
 	 */
-	public boolean addEdge(StateVertix sourceVertex, StateVertix targetVertex, Eventable clickable) {
-		if (sfg.containsEdge(sourceVertex, targetVertex)
-		        && sfg.getAllEdges(sourceVertex, targetVertex).contains(clickable)) {
+	@GuardedBy(""stateFlowGraphMutex"")
+	public boolean addEdge(StateVertix sourceVert, StateVertix targetVert, Eventable clickable) {
+		if (stateFlowGraphMutex.availablePermits() != 0) {
+			LOGGER.warn(""possible code executing without required permit!"", new Throwable(
+			        ""possible code executing without required permit!"").fillInStackTrace());
+		}
+		if (sfg.containsEdge(sourceVert, targetVert)
+		        && sfg.getAllEdges(sourceVert, targetVert).contains(clickable)) {
 			return false;
 		}
 
-		return sfg.addEdge(sourceVertex, targetVertex, clickable);
+		return sfg.addEdge(sourceVert, targetVert, clickable);
 	}
 
 	/**
@@ -146,7 +161,12 @@
 	 *            the target state.
 	 * @return true if it is possible (edge exists in graph) to go from source to target.
 	 */
+	@GuardedBy(""stateFlowGraphMutex"")
 	public boolean canGoTo(StateVertix source, StateVertix target) {
+		if (stateFlowGraphMutex.availablePermits() != 0) {
+			LOGGER.warn(""possible code executing without required permit!"", new Throwable(
+			        ""possible code executing without required permit!"").fillInStackTrace());
+		}
 		return sfg.containsEdge(source, target) || sfg.containsEdge(target, source);
 	}
 
@@ -188,7 +208,12 @@
 	 *            TODO: DOCUMENT ME!
 	 * @return TODO: DOCUMENT ME!
 	 */
+	@GuardedBy(""stateFlowGraphMutex"")
 	public StateVertix getStateInGraph(StateVertix state) {
+		if (stateFlowGraphMutex.availablePermits() != 0) {
+			LOGGER.warn(""possible code executing without required permit!"", new Throwable(
+			        ""possible code executing without required permit!"").fillInStackTrace());
+		}
 		Set<StateVertix> states = getAllStates();
 
 		for (StateVertix st : states) {
@@ -207,7 +232,12 @@
 	 *            TODO: DOCUMENT ME!
 	 * @return TODO: DOCUMENT ME!
 	 */
+	@GuardedBy(""stateFlowGraphMutex"")
 	public boolean containsVertex(StateVertix state) {
+		if (stateFlowGraphMutex.availablePermits() != 0) {
+			LOGGER.warn(""possible code executing without required permit!"", new Throwable(
+			        ""possible code executing without required permit!"").fillInStackTrace());
+		}
 		return sfg.containsVertex(state);
 	}
 
@@ -315,4 +345,25 @@
 		return results;
 	}
 
+	/**
+	 * Request a lock on the stateFlowGraph datastructure. Becarefull a requested lock MUST be
+	 * returned by hand! using the {@link #releaseExaminedElementsMutex()}
+	 * 
+	 * @see StateFlowGraph#releaseExaminedElementsMutex()
+	 */
+	public void requestStateFlowGraphMutex() {
+		try {
+			stateFlowGraphMutex.acquire();
+		} catch (InterruptedException e) {
+			LOGGER.error(""The acquire of the stateFlowGraphMutex was interrupted"", e);
+		}
+	}
+
+	/**
+	 * Release the lock for the stateFlowGraph datastructure.
+	 */
+	public void releaseStateFlowGraphMutex() {
+		stateFlowGraphMutex.release();
+	}
+
 }
"
a40542f0e93bf79549e013f7ccbfb25b992a36bb,Ali Mesbah,Crawler.java,MODIFY,getCurrentExactPaths -> [] | [boolean removeLastElement],"diff --git a/src/main/java/com/crawljax/core/Crawler.java b/src/main/java/com/crawljax/core/Crawler.java
index 6fc676c..106652e 100644
--- a/src/main/java/com/crawljax/core/Crawler.java
+++ b/src/main/java/com/crawljax/core/Crawler.java
@@ -83,6 +83,8 @@
 
 	private String name = ""automatic"";
 
+	private boolean goBackExact = true;
+
 	private StateMachine stateMachine;
 
 	private String stateName;
@@ -112,12 +114,15 @@
 	 *            the event path up till this moment.
 	 * @param reload
 	 *            if true the browser first will be reloaded.
+	 * @param goBackExact
+	 *            true if the crawler should relaod to get to a previous state.
 	 * @param name
 	 *            a name for this crawler (default is automatic).
 	 */
 	public Crawler(CrawljaxController mother, List<Eventable> exactEventPath, boolean reload,
-	        String name) {
+	        String name, boolean goBackExact) {
 		this(mother, reload);
+		this.goBackExact = goBackExact;
 		this.exactEventPath = exactEventPath;
 		this.name = name;
 		LOGGER.info(getName() + "" ExactPaths: "" + exactEventPath.size());
@@ -128,7 +133,7 @@
 
 	private String getName() {
 
-		return ""CRAWLER-NAME: "" + this.name + "" "";
+		return this.name + "": "";
 	}
 
 	/**
@@ -204,45 +209,55 @@
 	 *            the eventable to fire
 	 * @return true iff the event is fired
 	 */
-	public boolean fireEvent(final Eventable eventable) {
+	public boolean fireEvent(Eventable eventable) {
 		try {
-			/**
-			 * The path in the page to the 'clickable' (link, div, span, etc)
-			 */
-			String xpath = eventable.getIdentification().getValue();
 
-			/**
-			 * The type of event to execute on the 'clickable' like onClick, mouseOver, hover, etc
-			 */
-			String eventType = eventable.getEventType();
+			if (eventable.getEventType().equals(""onclick"")) {
 
-			/**
-			 * Try to find a 'better' / 'quicker' xpath
-			 */
-			String newXPath = new ElementResolver(eventable, browser).resolve();
-			if (newXPath != null) {
-				if (!xpath.equals(newXPath)) {
-					LOGGER.info(getName() + ""XPath changed from "" + xpath + "" to "" + newXPath);
-				}
-				if (browser.fireEvent(new Eventable(new Identification(""xpath"", newXPath),
-				        eventType))) {
+				/**
+				 * The path in the page to the 'clickable' (link, div, span, etc)
+				 */
+				String xpath = eventable.getIdentification().getValue();
 
-					/**
-					 * Let the controller execute its specified wait operation on the browser Thread
-					 * safe
-					 */
-					controller.doBrowserWait(browser);
+				/**
+				 * The type of event to execute on the 'clickable' like onClick, mouseOver, hover,
+				 * etc
+				 */
+				String eventType = eventable.getEventType();
 
-					/**
-					 * Close opened windows
-					 */
-					browser.closeOtherWindows();
-
-					return true;
-				} else {
-					return false;
+				/**
+				 * Try to find a 'better' / 'quicker' xpath
+				 */
+				String newXPath = new ElementResolver(eventable, browser).resolve();
+				if (newXPath != null) {
+					if (!xpath.equals(newXPath)) {
+						LOGGER
+						        .info(getName() + ""XPath changed from "" + xpath + "" to ""
+						                + newXPath);
+						eventable =
+						        new Eventable(new Identification(""xpath"", newXPath), eventType);
+					}
 				}
 			}
+
+			if (browser.fireEvent(eventable)) {
+
+				/**
+				 * Let the controller execute its specified wait operation on the browser Thread
+				 * safe
+				 */
+				controller.doBrowserWait(browser);
+
+				/**
+				 * Close opened windows
+				 */
+				browser.closeOtherWindows();
+
+				return true;
+			} else {
+				return false;
+			}
+
 		} catch (Exception e) {
 			LOGGER.error(e.getMessage(), e);
 		}
@@ -292,7 +307,7 @@
 					return;
 				}
 
-				LOGGER.info(getName() + ""Backtracking by firing "" + clickable.getEventType()
+				LOGGER.info(getName() + ""Backtracking by executing "" + clickable.getEventType()
 				        + "" on element: "" + clickable);
 
 				stateMachine.changeState(clickable.getTargetStateVertix());
@@ -302,6 +317,7 @@
 				crawlPath.add(clickable);
 
 				this.handleInputElements(clickable);
+
 				if (this.fireEvent(clickable)) {
 
 					// TODO ali, do not increase depth if eventable is from guidedcrawling
@@ -317,6 +333,7 @@
 				if (!controller.getCrawlConditionChecker().check(browser)) {
 					return;
 				}
+
 			}
 		}
 	}
@@ -341,14 +358,14 @@
 			this.handleInputElements(eventable);
 		}
 
-		LOGGER.info(getName() + ""Firing "" + eventable.getEventType() + "" on element: ""
+		LOGGER.info(getName() + ""Executing "" + eventable.getEventType() + "" on element: ""
 		        + eventable + ""; State: "" + currentHold.getName());
 
 		if (this.fireEvent(eventable)) {
 			// String dom = new String(browser.getDom());
 			StateVertix newState =
-			        new StateVertix(browser.getCurrentUrl(), stateName, browser.getDom(),
-			                this.controller.getStripedDom(browser));
+			        new StateVertix(browser.getCurrentUrl(), controller.getNewStateName(),
+			                browser.getDom(), this.controller.getStripedDom(browser));
 
 			if (controller.isDomChanged(currentHold, newState)) {
 				crawlPath.add(eventable);
@@ -358,8 +375,9 @@
 					// No Clone
 
 					// Fix the name of the new StateVertix
-					this.stateName = controller.getNewStateName();
-					stateMachine.getCurrentState().setName(stateName);
+					// TODO Ali: why is this not done in the state machine itself?
+					// this.stateName = controller.getNewStateName();
+					// stateMachine.getCurrentState().setName(stateName);
 
 					exactEventPath.add(eventable);
 
@@ -405,7 +423,7 @@
 			return true;
 		}
 
-		checkCandidates();
+		getCandidates();
 
 		boolean resetTypes = true;
 		if (this.eventTypes == null || this.eventTypes.size() == 0) {
@@ -444,9 +462,17 @@
 					 * clickResult: 1 = Dom Changed & No Clone. 0 = Dom Changed & Clone. -1 = Dom
 					 * Not Changed
 					 */
-					int clickResult =
-					        clickTag(new Eventable(candidateElement, eventType),
-					                handleInputElements, currentHold);
+					int clickResult;
+
+					if (candidateElement.getEventType().endsWith(""switchto.iframe"")) {
+						clickResult =
+						        clickTag(new Eventable(candidateElement, candidateElement
+						                .getEventType()), handleInputElements, currentHold);
+					} else {
+						clickResult =
+						        clickTag(new Eventable(candidateElement, eventType),
+						                handleInputElements, currentHold);
+					}
 					if (clickResult >= 0) {
 
 						if (clickResult == 0) {
@@ -512,13 +538,13 @@
 			}
 		}
 		if (reStoreCandidates) {
-			ArrayList<Eventable> path = getCurrentExactPaths();
-
 			/**
 			 * Make clone of everything that might be reused
 			 */
-			Crawler c = new Crawler(this.controller, path, reThreadElements, reThreadEventTypes);
-			controller.addWorkToQueue(c);
+
+			controller.addWorkToQueue(new Crawler(this.controller, getCurrentExactPaths(true),
+			        reThreadElements, reThreadEventTypes));
+			// this.currentState = currentHold;
 		}
 		if (recursion) {
 			/**
@@ -543,7 +569,7 @@
 		return true;
 	}
 
-	private ArrayList<Eventable> getCurrentExactPaths() {
+	private ArrayList<Eventable> getCurrentExactPaths(boolean removeLastElement) {
 		ArrayList<Eventable> path = new ArrayList<Eventable>();
 		for (Eventable eventable : this.exactEventPath) {
 			Eventable e = eventable.clone();
@@ -554,13 +580,14 @@
 		// into the original state where the last change (last in list)
 		// was made
 
-		if (path.size() > 0) {
+		if (removeLastElement && path.size() > 0) {
 			path.remove(path.size() - 1);
 		}
+
 		return path;
 	}
 
-	private void checkCandidates() throws CrawljaxException {
+	private void getCandidates() throws CrawljaxException {
 		if (this.candidates == null) {
 			if (controller.getCrawlConditionChecker().check(browser)) {
 				LOGGER.info(getName() + ""Looking in state: ""
@@ -590,14 +617,13 @@
 	@Override
 	public void run() {
 
-		LOGGER.info(getName());
-
 		/**
 		 * If the browser is null place a request for a browser from the BrowserFactory
 		 */
 		if (this.browser == null) {
 			this.browser = BrowserFactory.requestBrowser();
-			LOGGER.info(getName() + ""Reloading Page for navigating back."");
+			LOGGER.info(getName()
+			        + ""Reloading Page for navigating back since browser is not initialized."");
 			try {
 				this.goToInitialURL();
 			} catch (Exception e) {
@@ -611,7 +637,7 @@
 		/**
 		 * Do we need to go back into a previous state?
 		 */
-		if (exactEventPath.size() > 0) {
+		if (exactEventPath.size() > 0 && this.goBackExact) {
 			try {
 				this.goBackExact();
 			} catch (Exception e) {
"
59629cfaafe2d9be077d8a5364e068c5b9891531,Ali Mesbah,AbstractWebDriver.java,MODIFY,toUniformDOM -> [String html] | [Document doc],"diff --git a/src/main/java/com/crawljax/browser/AbstractWebDriver.java b/src/main/java/com/crawljax/browser/AbstractWebDriver.java
index d4702c1..3d8edf1 100644
--- a/src/main/java/com/crawljax/browser/AbstractWebDriver.java
+++ b/src/main/java/com/crawljax/browser/AbstractWebDriver.java
@@ -1,6 +1,7 @@
 package com.crawljax.browser;
 
 import java.io.File;
+import java.io.IOException;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
@@ -13,7 +14,11 @@
 import org.openqa.selenium.WebDriver;
 import org.openqa.selenium.WebElement;
 import org.openqa.selenium.firefox.FirefoxDriver;
+import org.w3c.dom.Attr;
 import org.w3c.dom.Document;
+import org.w3c.dom.Element;
+import org.w3c.dom.NodeList;
+import org.xml.sax.SAXException;
 
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.state.Eventable;
@@ -136,7 +141,7 @@
 	 */
 	public String getDom() throws CrawljaxException {
 		try {
-			return toUniformDOM(browser.getPageSource());
+			return toUniformDOM(getDomTreeWithFrames());
 		} catch (Exception e) {
 			throw new CrawljaxException(e.getMessage(), e);
 		}
@@ -149,7 +154,10 @@
 	 * @throws Exception
 	 *             On error.
 	 */
-	private static String toUniformDOM(final String html) throws Exception {
+	private static String toUniformDOM(Document doc) throws Exception {
+
+		String html = Helper.getDocumentToString(doc);
+
 		Pattern p =
 		        Pattern.compile(""<SCRIPT(.*?)</SCRIPT>"", Pattern.DOTALL
 		                | Pattern.CASE_INSENSITIVE);
@@ -162,7 +170,7 @@
 
 		// html = html.replace(""<?xml:namespace prefix = gwt >"", """");
 
-		Document doc = Helper.getDocument(htmlFormatted);
+		doc = Helper.getDocument(htmlFormatted);
 		htmlFormatted = Helper.getDocumentToString(doc);
 		htmlFormatted = Helper.filterAttributes(htmlFormatted);
 		return htmlFormatted;
@@ -216,18 +224,15 @@
 	public synchronized boolean fireEvent(Eventable eventable) throws CrawljaxException {
 		try {
 
-			if (eventable.getEventType().equals(""onclick"")) {
-				WebElement webElement =
-				        browser.findElement(eventable.getIdentification().getWebDriverBy());
-
-				if (webElement != null) {
-					return fireEventWait(webElement, eventable);
-				}
+			if (eventable.getRelatedFrame() != null && !eventable.getRelatedFrame().equals("""")) {
+				browser.switchTo().frame(eventable.getRelatedFrame());
 			}
 
-			if (eventable.getEventType().equals(""switchto.iframe"")) {
-				browser.switchTo().frame(eventable.getIdentification().getValue());
-				return true;
+			WebElement webElement =
+			        browser.findElement(eventable.getIdentification().getWebDriverBy());
+
+			if (webElement != null) {
+				return fireEventWait(webElement, eventable);
 			}
 
 			return false;
@@ -332,7 +337,75 @@
 		}
 	}
 
+	private String getFrameIdentification(Element frame, int index) {
+
+		Attr attr = (Attr) frame.getAttributeNode(""name"");
+		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
+			return attr.getNodeValue();
+		}
+
+		attr = (Attr) frame.getAttributeNode(""id"");
+		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
+			return attr.getNodeValue();
+		}
+
+		return """" + index;
+	}
+
 	@Override
 	public abstract EmbeddedBrowser clone();
 
+	/**
+	 * @return a Document object containing the contents of iframes as well.
+	 * @throws CrawljaxException
+	 *             if an exception is thrown.
+	 */
+	private Document getDomTreeWithFrames() throws CrawljaxException {
+
+		Document document;
+		try {
+			document = Helper.getDocument(browser.getPageSource());
+			appendFrameContent(browser.getWindowHandle(), document.getDocumentElement(),
+			        document, """");
+		} catch (SAXException e) {
+			throw new CrawljaxException(e.getMessage(), e);
+		} catch (IOException e) {
+			throw new CrawljaxException(e.getMessage(), e);
+		}
+
+		return document;
+	}
+
+	private void appendFrameContent(String windowHandle, Element orig, Document document,
+	        String topFrame) throws SAXException, IOException {
+
+		NodeList frameNodes = orig.getElementsByTagName(""IFRAME"");
+
+		int nodes = frameNodes.getLength();
+		browser.switchTo().window(windowHandle);
+
+		for (int i = 0; i < nodes; i++) {
+			String frameIdentification = """";
+
+			if (topFrame != null && !topFrame.equals("""")) {
+				frameIdentification += topFrame + ""."";
+			}
+
+			Element frameElement = (Element) frameNodes.item(i);
+			frameIdentification += getFrameIdentification(frameElement, i);
+
+			logger.info(""frame-identification: "" + frameIdentification);
+
+			String toAppend = browser.switchTo().frame(frameIdentification).getPageSource();
+
+			Element toAppendElement = Helper.getDocument(toAppend).getDocumentElement();
+			toAppendElement = (Element) document.importNode(toAppendElement, true);
+			frameElement.appendChild(toAppendElement);
+
+			appendFrameContent(windowHandle, toAppendElement, document, frameIdentification);
+
+			browser.switchTo().window(windowHandle);
+		}
+
+	}
 }
\ No newline at end of file
"
799be7833dbf6fa9a4b866c8a3f24de4c38f810c,Ali Mesbah,AbstractWebDriver.java,MODIFY,toUniformDOM -> [Document doc] | [String html],"diff --git a/src/main/java/com/crawljax/browser/AbstractWebDriver.java b/src/main/java/com/crawljax/browser/AbstractWebDriver.java
index 3d8edf1..ec024a3 100644
--- a/src/main/java/com/crawljax/browser/AbstractWebDriver.java
+++ b/src/main/java/com/crawljax/browser/AbstractWebDriver.java
@@ -141,7 +141,7 @@
 	 */
 	public String getDom() throws CrawljaxException {
 		try {
-			return toUniformDOM(getDomTreeWithFrames());
+			return toUniformDOM(Helper.getDocumentToString(getDomTreeWithFrames()));
 		} catch (Exception e) {
 			throw new CrawljaxException(e.getMessage(), e);
 		}
@@ -154,9 +154,7 @@
 	 * @throws Exception
 	 *             On error.
 	 */
-	private static String toUniformDOM(Document doc) throws Exception {
-
-		String html = Helper.getDocumentToString(doc);
+	private static String toUniformDOM(String html) throws Exception {
 
 		Pattern p =
 		        Pattern.compile(""<SCRIPT(.*?)</SCRIPT>"", Pattern.DOTALL
@@ -170,7 +168,7 @@
 
 		// html = html.replace(""<?xml:namespace prefix = gwt >"", """");
 
-		doc = Helper.getDocument(htmlFormatted);
+		Document doc = Helper.getDocument(htmlFormatted);
 		htmlFormatted = Helper.getDocumentToString(doc);
 		htmlFormatted = Helper.filterAttributes(htmlFormatted);
 		return htmlFormatted;
@@ -408,4 +406,20 @@
 		}
 
 	}
+
+	/**
+	 * @return the dom without the iframe contents.
+	 * @throws CrawljaxException
+	 *             if it fails.
+	 * @see com.crawljax.browser.EmbeddedBrowser#getDomWithoutIframeContent().
+	 */
+	public String getDomWithoutIframeContent() throws CrawljaxException {
+
+		try {
+			return toUniformDOM(browser.getPageSource());
+		} catch (Exception e) {
+			throw new CrawljaxException(e.getMessage(), e);
+		}
+
+	}
 }
\ No newline at end of file
"
b30f640849d6b304b878f11ce0d10a25bf2abab5,Stefan Lenselink,CandidateElementExtractor.java,MODIFY,"extract -> [List crawlTagElements, List crawlExcludeTagElements, boolean clickOnce] | [List crawlTagElements, List crawlExcludeTagElements, boolean clickOnce, StateVertix currentState]","diff --git a/src/main/java/com/crawljax/core/CandidateElementExtractor.java b/src/main/java/com/crawljax/core/CandidateElementExtractor.java
index 852ab43..4993fed 100644
--- a/src/main/java/com/crawljax/core/CandidateElementExtractor.java
+++ b/src/main/java/com/crawljax/core/CandidateElementExtractor.java
@@ -19,10 +19,12 @@
 import org.xml.sax.SAXException;
 
 import com.crawljax.browser.AbstractWebDriver;
+import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.condition.eventablecondition.EventableConditionChecker;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.Identification;
+import com.crawljax.core.state.StateVertix;
 import com.crawljax.forms.FormInputValueHelper;
 import com.crawljax.util.Helper;
 import com.crawljax.util.XPathHelper;
@@ -39,14 +41,21 @@
 	private static final Logger LOGGER =
 	        Logger.getLogger(CandidateElementExtractor.class.getName());
 
-	private final Crawler crawler;
+	private final ExtractorManager checkedElements;
+	private final EmbeddedBrowser browser;
 
 	/**
-	 * @param c
-	 *            the Crawler which uses this Extractor
+	 * Create a new CandidateElementExtractor.
+	 * 
+	 * @param checker
+	 *            the ExtractorManager to use for marking handled elements and retrieve the
+	 *            EventableConditionChecker
+	 * @param browser
+	 *            the current browser instance used in the Crawler
 	 */
-	public CandidateElementExtractor(Crawler c) {
-		this.crawler = c;
+	public CandidateElementExtractor(ExtractorManager checker, EmbeddedBrowser browser) {
+		checkedElements = checker;
+		this.browser = browser;
 	}
 
 	/**
@@ -59,18 +68,27 @@
 	 *            a list of TagElements to exclude.
 	 * @param clickOnce
 	 *            true if each candidate elements should be included only once.
+	 * @param currentState
+	 *            the state in which this extract method is requested.
 	 * @return a list of candidate elements that are not excluded.
 	 * @throws CrawljaxException
 	 *             if the method fails.
 	 */
 	public List<CandidateElement> extract(List<TagElement> crawlTagElements,
-	        List<TagElement> crawlExcludeTagElements, boolean clickOnce) throws CrawljaxException {
+	        List<TagElement> crawlExcludeTagElements, boolean clickOnce, StateVertix currentState)
+	        throws CrawljaxException {
 		List<CandidateElement> results = new ArrayList<CandidateElement>();
 
-		crawler.requestExaminedElementsMutex();
+		if (!checkedElements.checkCrawlCondition(browser)) {
+			LOGGER.info(""State "" + currentState.getName()
+			        + "" dit not satisfy the CrawlConditions."");
+			return results;
+		}
+		LOGGER.info(""Looking in state: "" + currentState.getName()
+		        + "" for candidate elements with "");
 
 		try {
-			Document dom = Helper.getDocument(crawler.getBrowser().getDomWithoutIframeContent());
+			Document dom = Helper.getDocument(browser.getDomWithoutIframeContent());
 			extractElements(dom, crawlTagElements, crawlExcludeTagElements, clickOnce, results,
 			        """");
 		} catch (SAXException e) {
@@ -81,8 +99,6 @@
 			throw new CrawljaxException(e.getMessage(), e);
 		}
 
-		crawler.releaseExaminedElementsMutex();
-
 		LOGGER.info(""Found "" + results.size() + "" new candidate elements to analyze!"");
 		return results;
 	}
@@ -99,7 +115,7 @@
 			try {
 
 				foundElements =
-				        getNodeListForTagElement(dom, tag, this.crawler
+				        getNodeListForTagElement(dom, tag, checkedElements
 				                .getEventableConditionChecker(), crawlExcludeTagElements);
 
 				getFramesCandidates(dom, crawlTagElements, crawlExcludeTagElements, clickOnce,
@@ -111,7 +127,7 @@
 
 			for (Element sourceElement : foundElements) {
 				EventableCondition eventableCondition =
-				        this.crawler.getEventableConditionChecker().getEventableCondition(
+				        checkedElements.getEventableConditionChecker().getEventableCondition(
 				                tag.getId());
 				String xpath = XPathHelper.getXpathExpression(sourceElement);
 				// get multiple candidate elements when there are input
@@ -124,8 +140,8 @@
 					// add multiple candidate elements, for every input
 					// value combination
 					candidateElements =
-					        FormInputValueHelper.getCandidateElementsForInputs(this.crawler
-					                .getBrowser(), sourceElement, eventableCondition);
+					        FormInputValueHelper.getCandidateElementsForInputs(browser,
+					                sourceElement, eventableCondition);
 				} else {
 					// just add default element
 					candidateElements.add(new CandidateElement(sourceElement, new Identification(
@@ -133,8 +149,7 @@
 				}
 
 				for (CandidateElement candidateElement : candidateElements) {
-					String elementUniqueString = candidateElement.getUniqueString();
-					if (!clickOnce || !crawler.elementIsAlreadyChecked(elementUniqueString)) {
+					if (!clickOnce || checkedElements.markChecked(candidateElement)) {
 						LOGGER.info(""Found new candidate element: ""
 						        + candidateElement.getUniqueString());
 
@@ -142,14 +157,11 @@
 							candidateElement.setEventableCondition(eventableCondition);
 						}
 						results.add(candidateElement);
-						// TODO add element to checkedElements after the
-						// event is fired!
-						crawler.markElementAsChecked(elementUniqueString);
-						// also add string without 'atusa' attribute to
-						// make sure an
-						// form action element is only clicked for its
-						// defined values
-						crawler.markElementAsChecked(candidateElement.getGeneralString());
+						/**
+						 * TODO add element to checkedElements after the event is fired! also add
+						 * string without 'atusa' attribute to make sure an form action element is
+						 * only clicked for its defined values
+						 */
 					}
 				}
 			}
@@ -160,8 +172,8 @@
 	        List<TagElement> crawlExcludeTagElements, boolean clickOnce,
 	        List<CandidateElement> results, String relatedFrame) throws CrawljaxException {
 
-		if (crawler.getBrowser() instanceof AbstractWebDriver) {
-			WebDriver driver = ((AbstractWebDriver) crawler.getBrowser()).getDriver();
+		if (browser instanceof AbstractWebDriver) {
+			WebDriver driver = ((AbstractWebDriver) browser).getDriver();
 
 			String handle = driver.getWindowHandle();
 
@@ -202,12 +214,12 @@
 
 	private String getFrameIdentification(Element frame, int index) {
 
-		Attr attr = (Attr) frame.getAttributeNode(""name"");
+		Attr attr = frame.getAttributeNode(""name"");
 		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
 			return attr.getNodeValue();
 		}
 
-		attr = (Attr) frame.getAttributeNode(""id"");
+		attr = frame.getAttributeNode(""id"");
 		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
 			return attr.getNodeValue();
 		}
@@ -252,27 +264,27 @@
 					// element
 				}
 			}
+
+			// TODO Stefan This is a possible Thread-Interleaving problem, as isChecked can return
+			// false and when needed to add it can return true.
 			// check if element is a candidate
 			if (matchesXpath
-			        && !crawler.elementIsAlreadyChecked(element.getNodeName() + "": ""
+			        && !checkedElements.isChecked(element.getNodeName() + "": ""
 			                + Helper.getAllElementAttributes(element))
 			        && isElementVisible(dom, element) && !filterElement(attributes, element)) {
 				if (""A"".equalsIgnoreCase(tagElement.getName())) {
 					String href = element.getAttribute(""href"");
-					boolean isExternal =
-					        Helper
-					                .isLinkExternal(this.crawler.getBrowser().getCurrentUrl(),
-					                        href);
+					boolean isExternal = Helper.isLinkExternal(browser.getCurrentUrl(), href);
 					boolean isEmail = isEmail(href);
 					LOGGER.debug(""HREF: "" + href + ""isExternal= "" + isExternal);
 
 					if (!(isExternal || isEmail || isPDForPS(href))) {
 						result.add(element);
-						crawler.increaseNumberExaminedElements();
+						checkedElements.increaseElementsCounter();
 					}
 				} else {
 					result.add(element);
-					crawler.increaseNumberExaminedElements();
+					checkedElements.increaseElementsCounter();
 				}
 			}
 		}
"
b30f640849d6b304b878f11ce0d10a25bf2abab5,Stefan Lenselink,Crawler.java,MODIFY,"clickTag -> [Eventable eventable, boolean handleInputElements, StateVertix currentHold] | [Eventable eventable, boolean handleInputElements]","diff --git a/src/main/java/com/crawljax/core/Crawler.java b/src/main/java/com/crawljax/core/Crawler.java
index 667877f..0b763c0 100644
--- a/src/main/java/com/crawljax/core/Crawler.java
+++ b/src/main/java/com/crawljax/core/Crawler.java
@@ -2,14 +2,11 @@
 
 import java.util.ArrayList;
 import java.util.List;
-import java.util.concurrent.atomic.AtomicInteger;
 
 import org.apache.log4j.Logger;
 
 import com.crawljax.browser.BrowserFactory;
 import com.crawljax.browser.EmbeddedBrowser;
-import com.crawljax.condition.eventablecondition.EventableCondition;
-import com.crawljax.condition.eventablecondition.EventableConditionChecker;
 import com.crawljax.core.plugin.CrawljaxPluginsUtil;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.Identification;
@@ -32,12 +29,9 @@
 
 	private static final Logger LOGGER = Logger.getLogger(Crawler.class.getName());
 
-	private static final AtomicInteger TOTAL_THREAD_ID_COUNT = new AtomicInteger();
-
-	private final int threadId;
 	/**
-	 * The main browser window 1 to 1 relation; Every Thread (instance of Crawljax) will get on
-	 * browser assigned in the run function.
+	 * The main browser window 1 to 1 relation; Every Thread will get on browser assigned in the run
+	 * function.
 	 */
 	private EmbeddedBrowser browser;
 
@@ -62,32 +56,50 @@
 	 * TODO Stefan why is there two times the same variable? What is the difference and could it be
 	 * merged? The path followed from the index to the current state.
 	 */
-	private List<Eventable> crawlPath = new ArrayList<Eventable>();
-
-	/**
-	 * Restart from these candidates.
-	 */
-	private List<CandidateElement> candidates;
-
-	/**
-	 * Restart with this list of eventTypes.
-	 */
-	private List<String> eventTypes;
+	private final List<Eventable> crawlPath = new ArrayList<Eventable>();
 
 	/**
 	 * The utility which is used to extract the candidate clickables.
 	 */
-	private final CandidateElementExtractor candidateExtractor;
+	private CandidateElementExtractor candidateExtractor;
 
 	private boolean fired = false;
 
-	private String name = ""automatic"";
+	/**
+	 * The name of this Crawler when not default (automatic) this will be added to the Thread name
+	 * in the {@link CrawlThreadFactory} as (name). In the
+	 * {@link CrawlThreadFactory#newThread(Runnable)} the name is retrieved using the
+	 * {@link #toString()} function.
+	 * 
+	 * @see Crawler#toString()
+	 * @see CrawlThreadFactory#newThread(Runnable)
+	 */
+	private String name = """";
 
+	/**
+	 * TODO Ali; describe this variable.
+	 */
 	private boolean goBackExact = true;
 
+	/**
+	 * The sateMachine for this Crawler, keeping track of the path crawled by this Crawler. TODO
+	 * Stefan its better to have this final...
+	 */
 	private StateMachine stateMachine;
 
-	private String stateName;
+	// TODO Stefan delete or use!
+	@SuppressWarnings(""unused"")
+	private final String stateName;
+
+	/**
+	 * Enum for describing what has happened after a {@link Crawler#clickTag(Eventable, boolean)}
+	 * has been performed.
+	 * 
+	 * @see Crawler#clickTag(Eventable, boolean)
+	 */
+	private enum ClickResult {
+		cloneDetected, newState, domUnChanged
+	}
 
 	/**
 	 * Crawler constructor for a new 'starting from scratch(index)' crawler.
@@ -96,14 +108,22 @@
 	 *            the main CrawljaxController
 	 */
 	public Crawler(CrawljaxController mother) {
-		this(mother, false);
+		this(mother, new ArrayList<Eventable>());
 		if (this.browser == null) {
 			/**
 			 * The Crawler is created with only a controller so probably its requested from the
-			 * CrawljaxController Create a new Browser to prevent null pointers :)
+			 * CrawljaxController Create a new Browser to prevent null pointers :). Creating a
+			 * browser here would result in NOT loading the initial page in the run operation! This
+			 * MUST be done by hand!
 			 */
 			browser = BrowserFactory.requestBrowser();
 		}
+		/**
+		 * Reset the state machine to null, dropping the existing state machine, as this call is
+		 * from the CrawljaxController the initial State is not known yet and causes trouble. The
+		 * CrawljaxController must create & set the first stateMachine using the setStateMachine
+		 * which on his case checks is the stateMachine is not set for safety reasons.
+		 */
 		stateMachine = null;
 	}
 
@@ -112,77 +132,37 @@
 	 *            the main CrawljaxController
 	 * @param exactEventPath
 	 *            the event path up till this moment.
-	 * @param reload
-	 *            if true the browser first will be reloaded.
-	 * @param goBackExact
-	 *            true if the crawler should relaod to get to a previous state.
 	 * @param name
-	 *            a name for this crawler (default is automatic).
+	 *            a name for this crawler (default is empty).
+	 * @param goBackExact
+	 *            true if the crawler should reload to get to a previous state.
 	 */
-	public Crawler(CrawljaxController mother, List<Eventable> exactEventPath, boolean reload,
-	        String name, boolean goBackExact) {
-		this(mother, reload);
+	public Crawler(CrawljaxController mother, List<Eventable> exactEventPath, String name,
+	        boolean goBackExact) {
+		this(mother, exactEventPath);
 		this.goBackExact = goBackExact;
-		this.exactEventPath = exactEventPath;
 		this.name = name;
-		LOGGER.info(getName() + "" ExactPaths: "" + exactEventPath.size());
+		LOGGER.info(""ExactPaths: "" + exactEventPath.size());
 		for (Eventable e : exactEventPath) {
 			LOGGER.info(""Eventable: "" + e);
 		}
 	}
 
-	private String getName() {
-
-		return this.name + "": "";
-	}
-
-	/**
-	 * Private crawler constructor for a new crawler. only used from internal
-	 * 
-	 * @param mother
-	 *            the main CrawljaxController
-	 * @param loadIndex
-	 *            true if the index need to be loaded
-	 */
-	private Crawler(CrawljaxController mother, boolean loadIndex) {
-		this.controller = mother;
-		this.candidateExtractor = new CandidateElementExtractor(this);
-		this.threadId = TOTAL_THREAD_ID_COUNT.incrementAndGet();
-		stateMachine =
-		        new StateMachine(controller.getStateFlowGraph(), controller.getIndexState());
-		stateName = controller.getLastStateName();
-		if (loadIndex) {
-			/**
-			 * The index page is requested to load so load a browser and reloads the initialURL
-			 */
-			browser = BrowserFactory.requestBrowser();
-			try {
-				goToInitialURL();
-			} catch (Exception e) {
-				LOGGER.fatal(""Failed to load the site: "" + e.getMessage(), e);
-				System.exit(0);
-			}
-		}
-	}
-
 	/**
 	 * Private Crawler constructor for a 'reload' crawler. only used from internal
 	 * 
 	 * @param mother
 	 *            the main CrawljaxController
-	 * @param currentState
-	 *            the state the Crawler would go to to start
 	 * @param returnPath
-	 *            the path used to return to this eventable
-	 * @param reThreadEventTypes
-	 * @param reThreadElements
+	 *            the path used to return to the last state, this can be a empty list
 	 */
-	private Crawler(CrawljaxController mother, ArrayList<Eventable> returnPath,
-	        List<CandidateElement> reThreadElements, List<String> reThreadEventTypes) {
-		this(mother, false);
+	private Crawler(CrawljaxController mother, List<Eventable> returnPath) {
 		this.exactEventPath = returnPath;
-		this.candidates = reThreadElements;
-		this.eventTypes = reThreadEventTypes;
+		this.controller = mother;
+		stateMachine =
+		        new StateMachine(controller.getStateFlowGraph(), controller.getIndexState());
+		// TODO Stefan what to do with this?
+		stateName = controller.getLastStateName();
 	}
 
 	/**
@@ -192,7 +172,7 @@
 	 *             an exception when the index page can not be loaded
 	 */
 	public void goToInitialURL() throws CrawljaxException {
-		LOGGER.info(getName() + ""Loading Page "" + PropertyHelper.getSiteUrlValue());
+		LOGGER.info(""Loading Page "" + PropertyHelper.getSiteUrlValue());
 		browser.goToUrl(PropertyHelper.getSiteUrlValue());
 		/**
 		 * Thread safe
@@ -232,7 +212,7 @@
 				String newXPath = new ElementResolver(eventable, browser).resolve();
 				if (newXPath != null) {
 					if (!xpath.equals(newXPath)) {
-						LOGGER.info(getName() + ""XPath changed from "" + xpath + "" to "" + newXPath
+						LOGGER.info(""XPath changed from "" + xpath + "" to "" + newXPath
 						        + "" relatedFrame:"" + eventable.getRelatedFrame());
 						eventable =
 						        new Eventable(new Identification(""xpath"", newXPath), eventType);
@@ -253,15 +233,15 @@
 				 */
 				browser.closeOtherWindows();
 
-				return true;
+				return true; // A event fired
 			} else {
-				return false;
+				return false; // no event fired
 			}
 
 		} catch (Exception e) {
 			LOGGER.error(e.getMessage(), e);
 		}
-		return false;
+		return false; // As we are here there was a error... so definitely there is no event fired.
 	}
 
 	/**
@@ -307,7 +287,7 @@
 					return;
 				}
 
-				LOGGER.info(getName() + ""Backtracking by executing "" + clickable.getEventType()
+				LOGGER.info(""Backtracking by executing "" + clickable.getEventType()
 				        + "" on element: "" + clickable);
 
 				stateMachine.changeState(clickable.getTargetStateVertix());
@@ -324,7 +304,7 @@
 					depth++;
 
 					/**
-					 * Run the onRevisitStateValidator(s) TODO Stefan check for thread safty
+					 * Run the onRevisitStateValidator(s) TODO Stefan check for thread safety
 					 */
 					CrawljaxPluginsUtil.runOnRevisitStatePlugins(this.controller.getSession(),
 					        curState);
@@ -342,24 +322,21 @@
 	 * @param eventable
 	 *            the element to execute an action on.
 	 * @param handleInputElements
-	 *            if inputs should be handled.
-	 * @param currentHold
-	 *            the current state kept for comparison.
-	 * @return 1 If Dom Changed and the new state is not found in the state machine. 0 If Dom
-	 *         Changed and new state is a Clone. -1 If Dom is Not Changed at all.
+	 *            if inputs should be handled..
+	 * @return the result of the click operation
 	 * @throws CrawljaxException
 	 *             an exception.
 	 */
-	public int clickTag(final Eventable eventable, boolean handleInputElements,
-	        StateVertix currentHold) throws CrawljaxException {
+	private ClickResult clickTag(final Eventable eventable, boolean handleInputElements)
+	        throws CrawljaxException {
 
 		// load input element values
 		if (handleInputElements) {
 			this.handleInputElements(eventable);
 		}
 
-		LOGGER.info(getName() + ""Executing "" + eventable.getEventType() + "" on element: ""
-		        + eventable + ""; State: "" + currentHold.getName());
+		LOGGER.info(""Executing "" + eventable.getEventType() + "" on element: "" + eventable
+		        + ""; State: "" + stateMachine.getCurrentState().getName());
 
 		if (this.fireEvent(eventable)) {
 			// String dom = new String(browser.getDom());
@@ -367,10 +344,9 @@
 			        new StateVertix(browser.getCurrentUrl(), controller.getNewStateName(),
 			                browser.getDom(), this.controller.getStripedDom(browser));
 
-			if (controller.isDomChanged(currentHold, newState)) {
+			if (controller.isDomChanged(stateMachine.getCurrentState(), newState)) {
 				crawlPath.add(eventable);
-				if (stateMachine.update(currentHold, eventable, newState, this.getBrowser(),
-				        this.controller)) {
+				if (stateMachine.update(eventable, newState, this.getBrowser(), this.controller)) {
 					// Dom changed
 					// No Clone
 
@@ -383,17 +359,17 @@
 
 					CrawljaxPluginsUtil.runGuidedCrawlingPlugins(controller, controller
 					        .getSession(), getExacteventpath());
-					return 1;
+
+					return ClickResult.newState;
 				} else {
-					// Dom changed
-					// Clone
-					return 0;
+					// Dom changed; Clone
+					return ClickResult.cloneDetected;
 				}
 			}
 		}
 		// Event not fired or
 		// Dom not changed
-		return -1;
+		return ClickResult.domUnChanged;
 	}
 
 	/**
@@ -406,162 +382,123 @@
 	}
 
 	/**
+	 * Have we reached the depth limit?
+	 * 
+	 * @param depth
+	 *            the current depth. Added as argument so this call can be moved out if desired.
+	 * @return true if the limit has been reached
+	 */
+	private boolean depthLimitReached(int depth) {
+		if (depth >= PropertyHelper.getCrawlDepthValue()
+		        && PropertyHelper.getCrawlDepthValue() != 0) {
+			LOGGER.info(""DEPTH "" + depth + "" reached returning from rec call. Given depth: ""
+			        + PropertyHelper.getCrawlDepthValue());
+			return true;
+		} else {
+			return false;
+		}
+	}
+
+	/**
 	 * Crawl through the clickables.
 	 * 
 	 * @throws CrawljaxException
 	 *             if an exception is thrown.
 	 */
 	private boolean crawl() throws CrawljaxException {
-		if (!this.controller.checkConstraints()) {
-			return false;
-		}
-		if (depth >= PropertyHelper.getCrawlDepthValue()
-		        && PropertyHelper.getCrawlDepthValue() != 0) {
-			LOGGER.info(getName() + ""DEPTH "" + depth
-			        + "" reached returning from rec call. Given depth: ""
-			        + PropertyHelper.getCrawlDepthValue());
+		if (depthLimitReached(depth)) {
 			return true;
 		}
 
-		getCandidates();
-
-		boolean resetTypes = true;
-		if (this.eventTypes == null || this.eventTypes.size() == 0) {
-			resetTypes = false;
-			this.eventTypes = PropertyHelper.getRobotEventsValues();
+		if (!this.controller.checkConstraints()) {
+			return false;
 		}
 
-		StateVertix currentHold = stateMachine.getCurrentState().clone();
+		// Store the currentState to be able to 'back-track' later.
+		StateVertix orrigionalState = stateMachine.getCurrentState();
+		orrigionalState.searchForCandidateElements(candidateExtractor);
 
-		LOGGER.info(getName() + ""Starting preStateCrawlingPlugins..."");
-		CrawljaxPluginsUtil.runPreStateCrawlingPlugins(controller.getSession(), candidates);
+		LOGGER.info(""Starting preStateCrawlingPlugins..."");
+
+		CrawljaxPluginsUtil.runPreStateCrawlingPlugins(controller.getSession(), orrigionalState
+		        .getUnprocessedCandidateElements());
 
 		boolean handleInputElements = true;
-		boolean reStoreCandidates = false;
-		boolean reStoreEvents = false;
-		boolean recursion = false;
-		List<CandidateElement> reThreadElements = new ArrayList<CandidateElement>();
-		List<String> reThreadEventTypes = new ArrayList<String>();
-		for (CandidateElement candidateElement : candidates) {
-			if (reStoreCandidates) {
-				reThreadElements.add(candidateElement);
-				continue;
-			}
-			EventableCondition eventableCondition = candidateElement.getEventableCondition();
-			boolean conditionsSatisifed = true;
-			if (eventableCondition != null) {
-				conditionsSatisifed = eventableCondition.checkAllConditionsSatisfied(browser);
-			}
-			if (conditionsSatisifed) {
-				for (String eventType : eventTypes) {
-					if (reStoreEvents) {
-						reThreadEventTypes.add(eventType);
-						continue;
-					}
-					/**
-					 * clickResult: 1 = Dom Changed & No Clone. 0 = Dom Changed & Clone. -1 = Dom
-					 * Not Changed
-					 */
-					int clickResult =
-					        clickTag(new Eventable(candidateElement, eventType),
-					                handleInputElements, currentHold);
 
-					if (clickResult >= 0) {
+		for (CandidateCrawlAction action : orrigionalState) {
+			CandidateElement candidateElement = action.getCandidateElement();
+			String eventType = action.getEventType();
 
-						if (clickResult == 0) {
-							fired = false;
-							// TODO Sometimes its possible to skip the reload....
-							this.controller.getSession().addCrawlPath(crawlPath);
-
-							// GO Back
-							LOGGER.info(getName() + ""Reloading Page for navigating back."");
-							try {
-								this.goToInitialURL();
-							} catch (Exception e) {
-								LOGGER.error(""Could not reload the inital page after a CLONE"", e);
-							}
-
-							/**
-							 * Always do a state machine rewind because we are about to begin form
-							 * scratch.
-							 */
-							depth = 0;
-							stateMachine.rewind();
-							this.crawlPath = new ArrayList<Eventable>();
-							this.goBackExact();
-							recursion = false;
-						} else {
-							fired = true;
-
-							recursion = true;
-							boolean lastCandidate =
-							        candidateElement
-							                .equals(candidates.get(candidates.size() - 1));
-							boolean lastEventType =
-							        eventType.equals(eventTypes.get(eventTypes.size() - 1));
-							if (lastCandidate && lastEventType) {
-								LOGGER.info(getName() + ""No more items to process""
-								        + "" for this depth so not forking..."");
-							} else {
-								if (!lastEventType) {
-									// We were not at the last possible
-									// eventType
-									reStoreEvents = true;
-									reThreadElements.add(candidateElement);
-								}
-								reStoreCandidates = true;
-							}
+			if (candidateElement.allConditionsSatisfied(browser)) {
+				ClickResult clickResult =
+				        clickTag(new Eventable(candidateElement, eventType), handleInputElements);
+				switch (clickResult) {
+					case cloneDetected:
+						fired = false;
+						// TODO A optimisation could be to check the new state (== clone) to see
+						// if there is unfinished work and continue with that so reload can be
+						// Postponed and 1 reload can be saved.
+						this.controller.getSession().addCrawlPath(crawlPath);
+						if (orrigionalState.hasMoreToExplore()) {
+							controller.addWorkToQueue(new Crawler(this.controller,
+							        getCurrentExactPaths(false)));
 						}
-					} else {
-						// Dom not yet updated
-						// continue with the next
+						return true;
+					case newState:
+						fired = true;
+						// Recurse because new state found
+						if (orrigionalState.hasMoreToExplore()) {
+							controller.addWorkToQueue(new Crawler(this.controller,
+							        getCurrentExactPaths(true)));
+						}
+						return newStateDetected(orrigionalState);
+					case domUnChanged:
+						// Dom not updated, continue with the next
 						handleInputElements = false;
-					}
+						break;
+					default:
+						break;
 				}
-				reStoreEvents = false;
 			} else {
 				Eventable eventable = new Eventable(candidateElement, """");
-				LOGGER.info(getName() + ""Conditions not satisfied for element: "" + eventable
-				        + ""; State: "" + stateMachine.getCurrentState().getName());
-			}
-
-			if (resetTypes) {
-				resetTypes = false;
-				this.eventTypes = PropertyHelper.getRobotEventsValues();
+				LOGGER.info(""Conditions not satisfied for element: "" + eventable + ""; State: ""
+				        + stateMachine.getCurrentState().getName());
 			}
 		}
-		if (reStoreCandidates) {
-			/**
-			 * Make clone of everything that might be reused
-			 */
-
-			controller.addWorkToQueue(new Crawler(this.controller, getCurrentExactPaths(true),
-			        reThreadElements, reThreadEventTypes));
-			// this.currentState = currentHold;
-		}
-		if (recursion) {
-			/**
-			 * Reset the 'restart' data
-			 */
-			this.candidates = null;
-			this.eventTypes = null;
-
-			/**
-			 * An event has been fired so we are one level deeper
-			 */
-			depth++;
-			LOGGER.info(getName() + ""RECURSIVE Call crawl; Current DEPTH= "" + depth);
-			if (!this.crawl()) {
-				// Crawling has stopped
-				controller.terminate();
-				return false;
-			}
-			stateMachine.changeState(currentHold);
-		}
-
 		return true;
 	}
 
+	/**
+	 * A new state has been found!
+	 * 
+	 * @param orrigionalState
+	 *            the current state
+	 * @return true if crawling must continue false otherwise.
+	 * @throws CrawljaxException
+	 */
+	private boolean newStateDetected(StateVertix orrigionalState) throws CrawljaxException {
+
+		/**
+		 * An event has been fired so we are one level deeper
+		 */
+		depth++;
+		LOGGER.info(""RECURSIVE Call crawl; Current DEPTH= "" + depth);
+		if (!this.crawl()) {
+			// Crawling has stopped
+			controller.terminate();
+			return false;
+		}
+		stateMachine.changeState(orrigionalState);
+		return true;
+	}
+
+	/**
+	 * Return the exactEventPath to be used in creating a new Crawler.
+	 * 
+	 * @param removeLastElement
+	 *            if set to true the last element will not be in the crawlPath.
+	 * @return the crawlPath leading to the current state.
+	 */
 	private ArrayList<Eventable> getCurrentExactPaths(boolean removeLastElement) {
 		ArrayList<Eventable> path = new ArrayList<Eventable>();
 		for (Eventable eventable : this.exactEventPath) {
@@ -580,24 +517,6 @@
 		return path;
 	}
 
-	private void getCandidates() throws CrawljaxException {
-		if (this.candidates == null) {
-			if (controller.getCrawlConditionChecker().check(browser)) {
-				LOGGER.info(getName() + ""Looking in state: ""
-				        + stateMachine.getCurrentState().getName()
-				        + "" for candidate elements with "");
-				this.candidates =
-				        this.candidateExtractor.extract(PropertyHelper.getCrawlTagElements(),
-				                PropertyHelper.getCrawlExcludeTagElements(), PropertyHelper
-				                        .getClickOnceValue());
-			} else {
-				LOGGER.info(getName() + ""State "" + stateMachine.getCurrentState().getName()
-				        + "" dit not satisfy the CrawlConditions."");
-				this.candidates = new ArrayList<CandidateElement>();
-			}
-		}
-	}
-
 	/**
 	 * The main function stated by the ExecutorService. Crawlers add themselves to the list by
 	 * calling {@link CrawljaxController#addWorkToQueue(Crawler)}. When the ExecutorService finds a
@@ -615,8 +534,7 @@
 		 */
 		if (this.browser == null) {
 			this.browser = BrowserFactory.requestBrowser();
-			LOGGER.info(getName()
-			        + ""Reloading Page for navigating back since browser is not initialized."");
+			LOGGER.info(""Reloading Page for navigating back since browser is not initialized."");
 			try {
 				this.goToInitialURL();
 			} catch (Exception e) {
@@ -625,6 +543,10 @@
 			}
 		}
 
+		// TODO Stefan ideally this should be placed in the constructor
+		this.candidateExtractor =
+		        new CandidateElementExtractor(controller.getElementChecker(), this.getBrowser());
+
 		stateMachine.rewind();
 
 		/**
@@ -634,7 +556,7 @@
 			try {
 				this.goBackExact();
 			} catch (Exception e) {
-				LOGGER.error(getName() + ""Failed to backtrack"", e);
+				LOGGER.error(""Failed to backtrack"", e);
 			}
 		}
 
@@ -649,12 +571,12 @@
 			/**
 			 * Crawling is done; so the crawlPath of the current branch is known
 			 */
-			// TODO
+			// TODO Stefan Delete the fired variable if possible?
 			if (fired) {
 				controller.getSession().addCrawlPath(crawlPath);
 			}
 		} catch (Exception e) {
-			LOGGER.error(getName() + ""Crawl failed!"", e);
+			LOGGER.error(""Crawl failed!"", e);
 		} finally {
 			/**
 			 * At last failure or non release the browser
@@ -672,57 +594,17 @@
 		return browser;
 	}
 
-	/**
-	 * @return the eventable condition checker.
-	 */
-	public EventableConditionChecker getEventableConditionChecker() {
-		return this.controller.getEventableConditionChecker();
-	}
-
-	/**
-	 * increase the number of checked elements, as a statistics measure to know how many elements
-	 * were actually examined.
-	 */
-	public void increaseNumberExaminedElements() {
-		this.controller.increaseNumberExaminedElements();
-	}
-
-	/**
-	 * Check if a given element is already checked, preventing duplicate work. Passing the request
-	 * to the CrawljaxController.
-	 * 
-	 * @see CrawljaxController#elementIsAlreadyChecked(String)
-	 * @param element
-	 *            the to search for if its already checked
-	 * @return true if the element is already checked
-	 */
-	public boolean elementIsAlreadyChecked(String element) {
-		return this.controller.elementIsAlreadyChecked(element);
-	}
-
-	/**
-	 * Mark a given element as checked to prevent duplicate work. Passing the operation to
-	 * Controller.
-	 * 
-	 * @see CrawljaxController#markElementAsChecked(String)
-	 * @param element
-	 *            the elements that is checked
-	 */
-	public void markElementAsChecked(String element) {
-		controller.markElementAsChecked(element);
-	}
-
 	@Override
 	public String toString() {
-		return ""Crawler Thread "" + this.threadId + "": "" + this.getName();
+		return this.name;
 	}
 
 	/**
-	 * Set the stateMachine that must be used, becarefull! This must only be called during the init
+	 * Set the stateMachine that must be used, be careful! This must only be called during the init
 	 * of the CrawljaxController.
 	 * 
 	 * @throws CrawljaxException
-	 *             will be thrown when the stateMachine is allready set!
+	 *             will be thrown when the stateMachine is already set!
 	 * @param machine
 	 *            the stateMachine to set.
 	 */
@@ -735,23 +617,6 @@
 	}
 
 	/**
-	 * Request a lock on the examinedElements datastructure. Becarefull a requested lock MUST be
-	 * returned by hand! using the {@link #releaseExaminedElementsMutex()}
-	 * 
-	 * @see Crawler#releaseExaminedElementsMutex()
-	 */
-	public void requestExaminedElementsMutex() {
-		controller.requestExaminedElementsMutex();
-	}
-
-	/**
-	 * Release the lock for the examinedElements datastructure.
-	 */
-	public void releaseExaminedElementsMutex() {
-		controller.releaseExaminedElementsMutex();
-	}
-
-	/**
 	 * @return the state machine.
 	 */
 	public StateMachine getStateMachine() {
"
b30f640849d6b304b878f11ce0d10a25bf2abab5,Stefan Lenselink,StateMachine.java,MODIFY,"update -> [StateVertix currentHold, Eventable event, StateVertix newState, EmbeddedBrowser browser, CrawljaxController controller] | [Eventable event, StateVertix newState, EmbeddedBrowser browser, CrawljaxController controller]","diff --git a/src/main/java/com/crawljax/core/state/StateMachine.java b/src/main/java/com/crawljax/core/state/StateMachine.java
index d561427..745214d 100644
--- a/src/main/java/com/crawljax/core/state/StateMachine.java
+++ b/src/main/java/com/crawljax/core/state/StateMachine.java
@@ -20,26 +20,19 @@
 public class StateMachine {
 	private static final Logger LOGGER = Logger.getLogger(StateMachine.class.getName());
 	/**
-	 * One-to-one releation with the StateFlowGraph, the stateFlowGraph variable is never changed.
+	 * One-to-one relation with the StateFlowGraph, the stateFlowGraph variable is never changed.
 	 */
 	private final StateFlowGraph stateFlowGraph;
 
 	/**
-	 * One-to-one releation with the initalState, the initalState is never changed.
+	 * One-to-one relation with the initalState, the initalState is never changed.
 	 */
 	private StateVertix initialState;
 
-	/**
-	 * TODO Stefan Current and previous state often changes; thus given problems.
-	 */
 	private StateVertix currentState;
 
-	@SuppressWarnings(""unused"")
-	@Deprecated
 	private StateVertix previousState;
 
-	private boolean haveLock = false;
-
 	/**
 	 * Create a new StateMachine.
 	 * 
@@ -65,24 +58,19 @@
 	public boolean changeState(StateVertix nextState) {
 		LOGGER.debug(""AFTER: sm.current: "" + currentState.getName() + "" hold.current: ""
 		        + nextState.getName());
-		if (!haveLock) {
-			stateFlowGraph.requestStateFlowGraphMutex();
-		}
+
 		if (stateFlowGraph.canGoTo(currentState, nextState)) {
-			if (!haveLock) {
-				stateFlowGraph.releaseStateFlowGraphMutex();
-			}
+
 			LOGGER.debug(""Changed To state: "" + nextState.getName() + "" From: ""
 			        + currentState.getName());
+
 			this.previousState = this.currentState;
 			currentState = nextState;
+
 			LOGGER.info(""StateMachine's Pointer changed to: "" + currentState);
 
 			return true;
 		} else {
-			if (!haveLock) {
-				stateFlowGraph.releaseStateFlowGraphMutex();
-			}
 			LOGGER.info(""Cannot change To state: "" + nextState.getName() + "" From: ""
 			        + currentState.getName());
 			return false;
@@ -102,26 +90,25 @@
 	private StateVertix addStateToCurrentState(StateVertix newState, Eventable eventable) {
 		LOGGER.debug(""currentState: "" + currentState.getName());
 		LOGGER.debug(""newState: "" + newState.getName());
-		currentState = stateFlowGraph.getStateInGraph(currentState);
-		StateVertix cloneState = null;
-		if (stateFlowGraph.containsVertex(newState)) {
-			String name = newState.getName();
-			newState = stateFlowGraph.getStateInGraph(newState);
-			LOGGER.info(""CLONE State detected: "" + name + "" and "" + newState.getName()
-			        + "" are the same."");
+
+		// Add the state to the stateFlowGraph. Store the result
+		StateVertix cloneState = stateFlowGraph.addState(newState);
+
+		// Is there a clone detected?
+		if (cloneState != null) {
+			LOGGER.info(""CLONE State detected: "" + newState.getName() + "" and ""
+			        + cloneState.getName() + "" are the same."");
 			LOGGER.debug(""CLONE CURRENTSTATE: "" + currentState.getName());
-			LOGGER.debug(""CLONE STATE: "" + newState.getName());
+			LOGGER.debug(""CLONE STATE: "" + cloneState.getName());
 			LOGGER.debug(""CLONE CLICKABLE: "" + eventable);
-			cloneState = newState;
 		} else {
-			stateFlowGraph.addState(newState);
 			LOGGER.info(""State "" + newState.getName() + "" added to the StateMachine."");
 		}
 
-		// eventable.setSourceStateVertix(currentState);
-		// eventable.setTargetStateVertix(newState);
+		// Store in DB
 		HibernateUtil.insert(eventable);
 
+		// Add the Edge
 		stateFlowGraph.addEdge(currentState, newState, eventable);
 
 		return cloneState;
@@ -145,8 +132,8 @@
 	}
 
 	/**
-	 * @param currentHold
-	 *            the placeholder for the current stateVertix.
+	 * TODO Stefan Remove the controller argument.
+	 * 
 	 * @param event
 	 *            the event edge.
 	 * @param newState
@@ -157,21 +144,19 @@
 	 *            the CrawljaxController to inquire for the checkInvariants
 	 * @return true if the new state is not found in the state machine.
 	 */
-	public boolean update(final StateVertix currentHold, final Eventable event,
-	        StateVertix newState, EmbeddedBrowser browser, CrawljaxController controller) {
-		stateFlowGraph.requestStateFlowGraphMutex();
-		haveLock = true;
+	public boolean update(final Eventable event, StateVertix newState, EmbeddedBrowser browser,
+	        CrawljaxController controller) {
 		StateVertix cloneState = this.addStateToCurrentState(newState, event);
 
 		if (cloneState != null) {
-			newState = cloneState.clone();
+			// Why cloning?
+			newState = cloneState;
 		}
 
 		this.changeState(newState);
-		stateFlowGraph.releaseStateFlowGraphMutex();
-		haveLock = false;
+
 		LOGGER.info(""StateMachine's Pointer changed to: "" + this.currentState.getName()
-		        + "" FROM "" + currentHold.getName());
+		        + "" FROM "" + previousState.getName());
 
 		if (PropertyHelper.getTestInvariantsWhileCrawlingValue()) {
 			controller.checkInvariants(browser);
@@ -183,7 +168,7 @@
 		synchronized (controller.getSession()) {
 			/**
 			 * Only one thread at the time may set the currentState in the session and expose it to
-			 * the OnNewStatePlugins. Garranty it will not be interleaved
+			 * the OnNewStatePlugins. Guaranty it will not be interleaved
 			 */
 			controller.getSession().setCurrentState(newState);
 
"
d7d55e3d487d572e69b91acaa3be64bc58237e69,Ali Mesbah,CrawljaxPluginsUtil.java,MODIFY,"runGuidedCrawlingPlugins -> [CrawljaxController controller, CrawlSession session, List exactEventPaths] | [CrawljaxController controller, CrawlSession session, List exactEventPaths, StateMachine stateMachine]","diff --git a/src/main/java/com/crawljax/core/plugin/CrawljaxPluginsUtil.java b/src/main/java/com/crawljax/core/plugin/CrawljaxPluginsUtil.java
index f6ba547..71c3271 100644
--- a/src/main/java/com/crawljax/core/plugin/CrawljaxPluginsUtil.java
+++ b/src/main/java/com/crawljax/core/plugin/CrawljaxPluginsUtil.java
@@ -12,6 +12,7 @@
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.ProxyConfiguration;
 import com.crawljax.core.state.Eventable;
+import com.crawljax.core.state.StateMachine;
 import com.crawljax.core.state.StateVertix;
 import com.crawljax.util.PropertyHelper;
 
@@ -234,14 +235,18 @@
 	 * @param exactEventPaths
 	 *            the exact crawled event paths. Used to bring the browser back to the state the
 	 *            crawler was before guided crawling.
+	 * @param stateMachine
+	 *            the state machine.
 	 */
 	public static void runGuidedCrawlingPlugins(CrawljaxController controller,
-	        CrawlSession session, final List<Eventable> exactEventPaths) {
+	        CrawlSession session, final List<Eventable> exactEventPaths,
+	        final StateMachine stateMachine) {
 		if (PropertyHelper.getCrawljaxConfiguration() != null) {
+			StateVertix currentState = session.getCurrentState();
 			for (Plugin plugin : PropertyHelper.getCrawljaxConfiguration().getPlugins()) {
 				if (plugin instanceof GuidedCrawlingPlugin) {
-					((GuidedCrawlingPlugin) plugin).guidedCrawling(controller, session,
-					        exactEventPaths);
+					((GuidedCrawlingPlugin) plugin).guidedCrawling(currentState, controller,
+					        session, exactEventPaths, stateMachine);
 				}
 			}
 		}
"
d7d55e3d487d572e69b91acaa3be64bc58237e69,Ali Mesbah,GuidedCrawlingPlugin.java,MODIFY,"guidedCrawling -> [CrawljaxController controler, CrawlSession session, List exactEventPaths] | [StateVertix currentState, CrawljaxController controler, CrawlSession session, List exactEventPaths, StateMachine stateMachine]","diff --git a/src/main/java/com/crawljax/core/plugin/GuidedCrawlingPlugin.java b/src/main/java/com/crawljax/core/plugin/GuidedCrawlingPlugin.java
index 15ca264..c761ca1 100644
--- a/src/main/java/com/crawljax/core/plugin/GuidedCrawlingPlugin.java
+++ b/src/main/java/com/crawljax/core/plugin/GuidedCrawlingPlugin.java
@@ -5,6 +5,8 @@
 import com.crawljax.core.CrawlSession;
 import com.crawljax.core.CrawljaxController;
 import com.crawljax.core.state.Eventable;
+import com.crawljax.core.state.StateMachine;
+import com.crawljax.core.state.StateVertix;
 
 /**
  * Plugin type that is called when the crawling control needs to be given to a plugin. After the
@@ -16,6 +18,8 @@
 public interface GuidedCrawlingPlugin extends Plugin {
 
 	/**
+	 * @param currentState
+	 *            a copy of the currentState.
 	 * @param controler
 	 *            the crawljax controller instance.
 	 * @param session
@@ -23,8 +27,10 @@
 	 * @param exactEventPaths
 	 *            the exact crawled event paths. Used to bring the browser back to the state the
 	 *            crawler was before guided crawling.
+	 * @param stateMachine
+	 *            the state machine.
 	 */
-	void guidedCrawling(CrawljaxController controler, CrawlSession session,
-	        List<Eventable> exactEventPaths);
+	void guidedCrawling(StateVertix currentState, CrawljaxController controler,
+	        CrawlSession session, List<Eventable> exactEventPaths, StateMachine stateMachine);
 
 }
"
c9ebfe349cea13dc583ad63ffa8e8c370c4133e4,Stefan Lenselink,StateMachine.java,MODIFY,"update -> [Eventable event, StateVertix newState, EmbeddedBrowser browser, CrawljaxController controller] | [Eventable event, StateVertix newState, EmbeddedBrowser browser, CrawlSession session]","diff --git a/src/main/java/com/crawljax/core/state/StateMachine.java b/src/main/java/com/crawljax/core/state/StateMachine.java
index 745214d..0331caa 100644
--- a/src/main/java/com/crawljax/core/state/StateMachine.java
+++ b/src/main/java/com/crawljax/core/state/StateMachine.java
@@ -3,10 +3,15 @@
  */
 package com.crawljax.core.state;
 
+import java.util.ArrayList;
+import java.util.List;
+
 import org.apache.log4j.Logger;
 
 import com.crawljax.browser.EmbeddedBrowser;
-import com.crawljax.core.CrawljaxController;
+import com.crawljax.condition.invariant.Invariant;
+import com.crawljax.condition.invariant.InvariantChecker;
+import com.crawljax.core.CrawlSession;
 import com.crawljax.core.plugin.CrawljaxPluginsUtil;
 import com.crawljax.util.PropertyHelper;
 import com.crawljax.util.database.HibernateUtil;
@@ -27,24 +32,44 @@
 	/**
 	 * One-to-one relation with the initalState, the initalState is never changed.
 	 */
-	private StateVertix initialState;
+	private final StateVertix initialState;
 
 	private StateVertix currentState;
 
 	private StateVertix previousState;
 
 	/**
+	 * The invariantChecker to use when updating the state machine.
+	 */
+	private final InvariantChecker invariantChecker;
+
+	/**
+	 * Create a new StateMachine with a empty Invariant list in the {@link InvariantChecker}.
+	 * 
+	 * @param sfg
+	 *            the state flow graph that is shared.
+	 * @param indexState
+	 *            the state representing the Index vertix
+	 */
+	public StateMachine(StateFlowGraph sfg, StateVertix indexState) {
+		this(sfg, indexState, new ArrayList<Invariant>());
+	}
+
+	/**
 	 * Create a new StateMachine.
 	 * 
 	 * @param sfg
 	 *            the state flow graph that is shared.
 	 * @param indexState
 	 *            the state representing the Index vertix
+	 * @param invariantList
+	 *            the invariants to use in the InvariantChecker.
 	 */
-	public StateMachine(StateFlowGraph sfg, StateVertix indexState) {
+	public StateMachine(StateFlowGraph sfg, StateVertix indexState, List<Invariant> invariantList) {
 		stateFlowGraph = sfg;
 		this.initialState = indexState;
 		currentState = initialState;
+		invariantChecker = new InvariantChecker(invariantList);
 	}
 
 	/**
@@ -140,16 +165,15 @@
 	 *            the new state.
 	 * @param browser
 	 *            used to feet to checkInvariants
-	 * @param controller
-	 *            the CrawljaxController to inquire for the checkInvariants
+	 * @param session
+	 *            the current Session
 	 * @return true if the new state is not found in the state machine.
 	 */
 	public boolean update(final Eventable event, StateVertix newState, EmbeddedBrowser browser,
-	        CrawljaxController controller) {
+	        CrawlSession session) {
 		StateVertix cloneState = this.addStateToCurrentState(newState, event);
 
 		if (cloneState != null) {
-			// Why cloning?
 			newState = cloneState;
 		}
 
@@ -159,21 +183,21 @@
 		        + "" FROM "" + previousState.getName());
 
 		if (PropertyHelper.getTestInvariantsWhileCrawlingValue()) {
-			controller.checkInvariants(browser);
+			checkInvariants(browser, session);
 		}
 
 		/**
 		 * TODO Stefan FIX this getSession stuff...
 		 */
-		synchronized (controller.getSession()) {
+		synchronized (session) {
 			/**
 			 * Only one thread at the time may set the currentState in the session and expose it to
 			 * the OnNewStatePlugins. Guaranty it will not be interleaved
 			 */
-			controller.getSession().setCurrentState(newState);
+			session.setCurrentState(newState);
 
 			if (cloneState == null) {
-				CrawljaxPluginsUtil.runOnNewStatePlugins(controller.getSession());
+				CrawljaxPluginsUtil.runOnNewStatePlugins(session);
 				// recurse
 				return true;
 			} else {
@@ -184,20 +208,18 @@
 	}
 
 	/**
-	 * @param initialState
-	 *            the initialState to set
-	 */
-	public final void setInitialState(StateVertix initialState) {
-		this.initialState = initialState;
-		this.currentState = initialState;
-	}
-
-	/**
-	 * Return the number of states in the StateFlowGraph.
+	 * Check the invariants. This call is nearly thread safe only calls to set/get affected nodes in
+	 * a Invariant may produce wrong output.
 	 * 
-	 * @return the number of states in the StateFlowGraph
+	 * @param browser
+	 *            the browser to feed to the invariants
 	 */
-	public int getNumberOfStates() {
-		return this.stateFlowGraph.getAllStates().size();
+	private void checkInvariants(EmbeddedBrowser browser, CrawlSession session) {
+		if (!invariantChecker.check(browser)) {
+			final List<Invariant> failedInvariants = invariantChecker.getFailedInvariants();
+			for (Invariant failedInvariant : failedInvariants) {
+				CrawljaxPluginsUtil.runOnInvriantViolationPlugins(failedInvariant, session);
+			}
+		}
 	}
 }
"
37605744113d7e81423a5bcdda5d2208e7fd8277,Frank Groeneveld,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 3ae76cc..96d5065 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -159,8 +159,7 @@
 		}
 		if (nodeList.getLength() > 0) {
 			if (nodeList.getLength() > 1) {
-				LOGGER.info(""WARNING: Expression "" + xpathExpression
-				        + "" returned more than one element."");
+				LOGGER.warn(""Expression "" + xpathExpression + "" returned more than one element."");
 			}
 			return getXpathExpression(nodeList.item(0));
 		}
"
37605744113d7e81423a5bcdda5d2208e7fd8277,Frank Groeneveld,HibernateUtil.java,MODIFY,initialize -> [String hbm2ddlAuto] | [],"diff --git a/src/main/java/com/crawljax/util/database/HibernateUtil.java b/src/main/java/com/crawljax/util/database/HibernateUtil.java
index 6dcd3af..185f6fe 100644
--- a/src/main/java/com/crawljax/util/database/HibernateUtil.java
+++ b/src/main/java/com/crawljax/util/database/HibernateUtil.java
@@ -146,7 +146,7 @@
 			transaction.commit();
 			session.flush();
 		} catch (Exception e) {
-			LOGGER.info(""Warning: "" + e.getMessage());
+			LOGGER.warn(e.getMessage());
 			// no unqiue object exception. Do we really care?
 		} finally {
 			closeSession();
"
ba893adcf1fe12af1aae6ec2150cd9e8e8d022a2,Ali Mesbah,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 3ae76cc..96d5065 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -159,8 +159,7 @@
 		}
 		if (nodeList.getLength() > 0) {
 			if (nodeList.getLength() > 1) {
-				LOGGER.info(""WARNING: Expression "" + xpathExpression
-				        + "" returned more than one element."");
+				LOGGER.warn(""Expression "" + xpathExpression + "" returned more than one element."");
 			}
 			return getXpathExpression(nodeList.item(0));
 		}
"
ba893adcf1fe12af1aae6ec2150cd9e8e8d022a2,Ali Mesbah,HibernateUtil.java,MODIFY,initialize -> [String hbm2ddlAuto] | [],"diff --git a/src/main/java/com/crawljax/util/database/HibernateUtil.java b/src/main/java/com/crawljax/util/database/HibernateUtil.java
index 6dcd3af..185f6fe 100644
--- a/src/main/java/com/crawljax/util/database/HibernateUtil.java
+++ b/src/main/java/com/crawljax/util/database/HibernateUtil.java
@@ -146,7 +146,7 @@
 			transaction.commit();
 			session.flush();
 		} catch (Exception e) {
-			LOGGER.info(""Warning: "" + e.getMessage());
+			LOGGER.warn(e.getMessage());
 			// no unqiue object exception. Do we really care?
 		} finally {
 			closeSession();
"
03e66f5bcfbcc1819bbf793aa6a38fc9f42805e3,Ali Mesbah,Helper.java,MODIFY,"writeDocumentToFile -> [Document document, String filePathname] | [Document document, String filePathname, String method, int indent]","diff --git a/src/main/java/com/crawljax/util/Helper.java b/src/main/java/com/crawljax/util/Helper.java
index 9122588..1257336 100644
--- a/src/main/java/com/crawljax/util/Helper.java
+++ b/src/main/java/com/crawljax/util/Helper.java
@@ -7,7 +7,6 @@
 import java.io.ByteArrayOutputStream;
 import java.io.File;
 import java.io.FileInputStream;
-import java.io.FileNotFoundException;
 import java.io.FileOutputStream;
 import java.io.FileReader;
 import java.io.FileWriter;
@@ -213,32 +212,6 @@
 	}
 
 	/**
-	 * @param document
-	 *            The Document object.
-	 * @param filePathname
-	 *            the filename to write the document to.
-	 */
-	public static void writeDocumentToFile(Document document, String filePathname) {
-		try {
-			TransformerFactory tFactory = TransformerFactory.newInstance();
-			Transformer transformer = tFactory.newTransformer();
-			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
-			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
-			transformer.setOutputProperty(OutputKeys.METHOD, ""text"");
-
-			DOMSource source = new DOMSource(document);
-			Result result = new StreamResult(new FileOutputStream(filePathname));
-			transformer.transform(source, result);
-		} catch (TransformerConfigurationException e) {
-			LOGGER.error(e.getMessage(), e);
-		} catch (TransformerException e) {
-			LOGGER.error(e.getMessage(), e);
-		} catch (FileNotFoundException e) {
-			LOGGER.error(e.getMessage(), e);
-		}
-	}
-
-	/**
 	 * @param dom
 	 *            the DOM document.
 	 * @param xpath
@@ -721,27 +694,37 @@
 	}
 
 	/**
+	 * Write the document object to a file.
+	 * 
 	 * @param document
 	 *            the document object.
 	 * @param filePathname
 	 *            the path name of the file to be written to.
+	 * @param method
+	 *            the output method: for instance html, xml, text
+	 * @param indent
+	 *            amount of indentation. -1 to use the default.
+	 * @throws TransformerException
+	 *             if an exception occurs.
+	 * @throws IOException
+	 *             if an IO exception occurs.
 	 */
-	public static void writeDocumentToHTMLFile(Document document, String filePathname) {
-		try {
-			Transformer transformer = TransformerFactory.newInstance().newTransformer();
-			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
-			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
-			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
+	public static void writeDocumentToFile(Document document, String filePathname, String method,
+	        int indent) throws TransformerException, IOException {
 
-			Result result = new StreamResult(new FileOutputStream(filePathname));
-			transformer.transform(new DOMSource(document), result);
-		} catch (TransformerConfigurationException e) {
-			LOGGER.error(e.getMessage(), e);
-		} catch (TransformerException e) {
-			LOGGER.error(e.getMessage(), e);
-		} catch (FileNotFoundException e) {
-			LOGGER.error(e.getMessage(), e);
+		checkFolderForFile(filePathname);
+		Transformer transformer = TransformerFactory.newInstance().newTransformer();
+		transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
+		transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
+		transformer.setOutputProperty(OutputKeys.METHOD, method);
+
+		if (indent > -1) {
+			transformer.setOutputProperty(
+			        org.apache.xml.serializer.OutputPropertiesFactory.S_KEY_INDENT_AMOUNT,
+			        Integer.toString(indent));
 		}
+		transformer.transform(new DOMSource(document), new StreamResult(new FileOutputStream(
+		        filePathname)));
 	}
 
 }
"
131dd15185bfd5dc1c7d74094fcd6107353de2c0,Ali Mesbah,Identification.java,MODIFY,setHow -> [String how] | [How how],"diff --git a/src/main/java/com/crawljax/core/state/Identification.java b/src/main/java/com/crawljax/core/state/Identification.java
index 8f5a071..48e28ce 100644
--- a/src/main/java/com/crawljax/core/state/Identification.java
+++ b/src/main/java/com/crawljax/core/state/Identification.java
@@ -2,6 +2,8 @@
 
 import java.io.Serializable;
 
+import org.apache.commons.lang.builder.EqualsBuilder;
+import org.apache.commons.lang.builder.HashCodeBuilder;
 import org.openqa.selenium.By;
 
 /**
@@ -13,8 +15,13 @@
  */
 public class Identification implements Serializable, Cloneable {
 	private static final long serialVersionUID = -1608879189549535808L;
+
+	public enum How {
+		xpath, name, id, tag, text, partialText
+	}
+
 	private long id;
-	private String how;
+	private How how;
 	private String value;
 
 	/**
@@ -32,7 +39,7 @@
 	 * @param value
 	 *            the value of the identification method.
 	 */
-	public Identification(String how, String value) {
+	public Identification(How how, String value) {
 		this.how = how;
 		this.value = value;
 	}
@@ -40,7 +47,7 @@
 	/**
 	 * @return the how
 	 */
-	public String getHow() {
+	public How getHow() {
 		return how;
 	}
 
@@ -48,7 +55,7 @@
 	 * @param how
 	 *            the how to set
 	 */
-	public void setHow(String how) {
+	public void setHow(How how) {
 		this.how = how;
 	}
 
@@ -98,23 +105,31 @@
 	 * @return the correct By specification of the current Identification.
 	 */
 	public By getWebDriverBy() {
-		if (how.equals(""name"")) {
-			return By.name(this.value);
+
+		switch (how) {
+			case name:
+				return By.name(this.value);
+
+			case xpath:
+				return By.xpath(this.value);
+
+			case id:
+				return By.id(this.value);
+
+			case tag:
+				return By.tagName(this.value);
+
+			case text:
+				return By.linkText(this.value);
+
+			case partialText:
+				return By.partialLinkText(this.value);
+
+			default:
+				return null;
+
 		}
 
-		if (how.equals(""xpath"")) {
-			return By.xpath(this.value);
-		}
-
-		if (how.equals(""id"")) {
-			return By.id(this.value);
-		}
-
-		if (how.equals(""tag"")) {
-			return By.tagName(this.value);
-		}
-
-		return null;
 	}
 
 	/**
@@ -128,4 +143,24 @@
 		id.setValue(this.value);
 		return id;
 	}
+
+	@Override
+	public boolean equals(Object obj) {
+		if (!(obj instanceof Identification)) {
+			return false;
+		}
+
+		if (this == obj) {
+			return true;
+		}
+		final Identification rhs = (Identification) obj;
+
+		return new EqualsBuilder().append(this.how, rhs.getHow()).append(this.value,
+		        rhs.getValue()).isEquals();
+	}
+
+	@Override
+	public int hashCode() {
+		return new HashCodeBuilder().append(this.how).append(this.value).toHashCode();
+	}
 }
"
131dd15185bfd5dc1c7d74094fcd6107353de2c0,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index ba90bb7..e557faa 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -56,7 +56,7 @@
 	 */
 	private void setInputElementValue(Node element, FormInput input) {
 
-		LOGGER.debug(""INPUTFIELD: "" + input.getName() + "" ("" + input.getType() + "")"");
+		LOGGER.debug(""INPUTFIELD: "" + input.getIdentification() + "" ("" + input.getType() + "")"");
 		if (element == null) {
 			return;
 		}
"
131dd15185bfd5dc1c7d74094fcd6107353de2c0,Ali Mesbah,FormInput.java,MODIFY,"containsInput -> [Set inputs, String name] | [Set inputs, Identification identification]","diff --git a/src/main/java/com/crawljax/forms/FormInput.java b/src/main/java/com/crawljax/forms/FormInput.java
index 50b74f7..0d4962e 100644
--- a/src/main/java/com/crawljax/forms/FormInput.java
+++ b/src/main/java/com/crawljax/forms/FormInput.java
@@ -6,10 +6,13 @@
 import java.util.HashSet;
 import java.util.Set;
 
+import org.apache.commons.lang.builder.EqualsBuilder;
+import org.apache.commons.lang.builder.HashCodeBuilder;
 import org.apache.commons.lang.builder.ToStringBuilder;
 import org.apache.commons.lang.builder.ToStringStyle;
 
 import com.crawljax.core.state.Eventable;
+import com.crawljax.core.state.Identification;
 
 /**
  * @author mesbah
@@ -19,7 +22,9 @@
 
 	private long id;
 	private String type = ""text"";
-	private String name;
+
+	private Identification identification;
+
 	private Set<InputValue> inputValues = new HashSet<InputValue>();
 	private Eventable eventable;
 	// public int index;
@@ -36,19 +41,19 @@
 	/**
 	 * @param type
 	 *            the type of the input elements (e.g. text, checkbox)
-	 * @param name
-	 *            the id or name of the elements
+	 * @param identification
+	 *            the identification.
 	 * @param value
 	 *            the value of the elements. 1 for checked
 	 */
-	public FormInput(String type, String name, String value) {
+	public FormInput(String type, Identification identification, String value) {
 		this.type = type;
-		this.name = name;
+		this.identification = identification;
 		inputValues.add(new InputValue(value, value.equals(""1"")));
 	}
 
 	/**
-	 * @return TODO: DOCUMENT ME!
+	 * @return the id.
 	 */
 	public long getId() {
 		return id;
@@ -56,14 +61,14 @@
 
 	/**
 	 * @param id
-	 *            TODO: DOCUMENT ME!
+	 *            the id.
 	 */
 	public void setId(long id) {
 		this.id = id;
 	}
 
 	/**
-	 * @return TODO: DOCUMENT ME!
+	 * @return the input type.
 	 */
 	public String getType() {
 		return type;
@@ -71,7 +76,7 @@
 
 	/**
 	 * @param type
-	 *            TODO: DOCUMENT ME!
+	 *            the input type.
 	 */
 	public void setType(String type) {
 		if (!"""".equals(type)) {
@@ -79,33 +84,24 @@
 		}
 	}
 
-	/**
-	 * @return DOCUMENT ME!
-	 */
-	public String getName() {
-		return name;
-	}
-
-	/**
-	 * @param name
-	 *            DOCUMENT ME!
-	 */
-	public void setName(String name) {
-		this.name = name;
-	}
-
 	@Override
 	public boolean equals(Object obj) {
-		if (obj == null || getType() == null || getName() == null) {
+		if (!(obj instanceof FormInput)) {
 			return false;
 		}
-		FormInput formInput = (FormInput) obj;
-		return getName().equals(formInput.getName()) && getType().equals(formInput.getType());
+
+		if (this == obj) {
+			return true;
+		}
+		final FormInput rhs = (FormInput) obj;
+
+		return new EqualsBuilder().append(this.identification, rhs.getIdentification()).append(
+		        this.type, rhs.getType()).isEquals();
 	}
 
 	@Override
 	public int hashCode() {
-		return getName().hashCode() + getType().hashCode();
+		return new HashCodeBuilder().append(this.identification).append(this.type).toHashCode();
 	}
 
 	/**
@@ -130,14 +126,14 @@
 
 	/**
 	 * @param inputs
-	 *            DOCUMENT ME!
-	 * @param name
-	 *            DOCUMENT ME!
-	 * @return DOCUMENT ME!
+	 *            form input set.
+	 * @param identification
+	 *            the identification to check.
+	 * @return true if set contains a FormInput that has the same identification.
 	 */
-	public static boolean containsInput(Set<FormInput> inputs, String name) {
+	public static boolean containsInput(Set<FormInput> inputs, Identification identification) {
 		for (FormInput input : inputs) {
-			if (input.getName().equalsIgnoreCase(name)) {
+			if (input.getIdentification().equals(identification)) {
 				return true;
 			}
 		}
@@ -147,14 +143,14 @@
 
 	/**
 	 * @param inputs
-	 *            DOCUMENT ME!
-	 * @param name
-	 *            DOCUMENT ME!
-	 * @return DOCUMENT ME!
+	 *            form input set.
+	 * @param identification
+	 *            the identification to check.
+	 * @return a FormInput object that has the same identification.
 	 */
-	public static FormInput getInput(Set<FormInput> inputs, String name) {
+	public static FormInput getInput(Set<FormInput> inputs, Identification identification) {
 		for (FormInput input : inputs) {
-			if (input.getName().equalsIgnoreCase(name)) {
+			if (input.getIdentification().equals(identification)) {
 				return input;
 			}
 		}
@@ -207,9 +203,24 @@
 		}
 		fi.setId(this.id);
 		fi.setMultiple(this.multiple);
-		fi.setName(this.name);
+		fi.setIdentification(this.identification);
 		fi.setType(this.type);
 		fi.setInputValues(iv);
 		return fi;
 	}
+
+	/**
+	 * @return the identification
+	 */
+	public Identification getIdentification() {
+		return identification;
+	}
+
+	/**
+	 * @param identification
+	 *            the identification to set
+	 */
+	public void setIdentification(Identification identification) {
+		this.identification = identification;
+	}
 }
"
537421452a7e586d658d0c14a809be1c0964ef9a,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index ba90bb7..e557faa 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -56,7 +56,7 @@
 	 */
 	private void setInputElementValue(Node element, FormInput input) {
 
-		LOGGER.debug(""INPUTFIELD: "" + input.getName() + "" ("" + input.getType() + "")"");
+		LOGGER.debug(""INPUTFIELD: "" + input.getIdentification() + "" ("" + input.getType() + "")"");
 		if (element == null) {
 			return;
 		}
"
e7a3d99f6af98e729b322ff35c84a0271697343c,Ali Mesbah,StateFlowGraph.java,MODIFY,"makeStateName -> [int id] | [int id, boolean guided]","diff --git a/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index 8dbd69f..295e85a 100644
--- a/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -71,7 +71,8 @@
 				 */
 				// the -1 is for the ""index"" state.
 				int totalNumberOfStates = this.getAllStates().size() - 1;
-				String correctName = makeStateName(totalNumberOfStates);
+				String correctName =
+				        makeStateName(totalNumberOfStates, stateVertix.isGuidedCrawling());
 				if (!stateVertix.getName().equals(""index"")
 				        && !stateVertix.getName().equals(correctName)) {
 					LOGGER.info(""Correcting state name from  "" + stateVertix.getName() + "" to ""
@@ -369,7 +370,7 @@
 	 */
 	public String getNewStateName() {
 		stateCounter.getAndIncrement();
-		String state = makeStateName(stateCounter.get());
+		String state = makeStateName(stateCounter.get(), false);
 		return state;
 	}
 
@@ -381,7 +382,12 @@
 	 *            the id where this name needs to be for.
 	 * @return the String containing the new name.
 	 */
-	private String makeStateName(int id) {
+	private String makeStateName(int id, boolean guided) {
+
+		if (guided) {
+			return ""guided"" + id;
+		}
+
 		return ""state"" + id;
 	}
 }
"
0873adfe592913e89c81e6cd0a744e74679f8c15,Ali Mesbah,PropertiesFile.java,MODIFY,"parseTagElement -> [String text, CrawlSpecification crawler] | [String text, CrawlSpecification crawlSpec]","diff --git a/src/main/java/com/crawljax/core/configuration/PropertiesFile.java b/src/main/java/com/crawljax/core/configuration/PropertiesFile.java
index e636c2a..c694ffb 100644
--- a/src/main/java/com/crawljax/core/configuration/PropertiesFile.java
+++ b/src/main/java/com/crawljax/core/configuration/PropertiesFile.java
@@ -136,8 +136,10 @@
 	 * 
 	 * @param text
 	 *            The string containing the tag elements.
+	 * @param crawlSpec
+	 *            the crawlSpecification.
 	 */
-	public void parseTagElement(String text, CrawlSpecification crawler) {
+	public void parseTagElement(String text, CrawlSpecification crawlSpec) {
 		if (text.equals("""")) {
 			return;
 		}
@@ -188,7 +190,7 @@
 
 		}
 
-		CrawlElement element = crawler.click(tagElement.getName());
+		CrawlElement element = crawlSpec.click(tagElement.getName());
 		for (TagAttribute attrib : tagElement.getAttributes()) {
 			element.withAttribute(attrib.getName(), attrib.getValue());
 		}
"
245d0fc46cc3426b09fc1f7c8f2e6f82e8fa5f90,Ali Mesbah,AbstractWebDriver.java,MODIFY,isVisible -> [By locater] | [Identification identification],"diff --git a/src/main/java/com/crawljax/browser/AbstractWebDriver.java b/src/main/java/com/crawljax/browser/AbstractWebDriver.java
index bf751d1..5757a37 100644
--- a/src/main/java/com/crawljax/browser/AbstractWebDriver.java
+++ b/src/main/java/com/crawljax/browser/AbstractWebDriver.java
@@ -9,7 +9,6 @@
 import java.util.regex.Pattern;
 
 import org.apache.log4j.Logger;
-import org.openqa.selenium.By;
 import org.openqa.selenium.ElementNotVisibleException;
 import org.openqa.selenium.JavascriptExecutor;
 import org.openqa.selenium.NoSuchElementException;
@@ -247,16 +246,20 @@
 	}
 
 	/**
-	 * Determines whether locater is visible.
+	 * Determines whether the corresponding element is visible.
 	 * 
-	 * @param locater
+	 * @param identification
 	 *            The element to search for.
-	 * @return Whether it is visible.
+	 * @return true if the element is visible
 	 */
-	public boolean isVisible(By locater) {
+	public boolean isVisible(Identification identification) {
 		try {
-			WebElement el = browser.findElement(locater);
-			return ((RenderedWebElement) el).isDisplayed();
+			WebElement el = browser.findElement(identification.getWebDriverBy());
+			if (el != null) {
+				return ((RenderedWebElement) el).isDisplayed();
+			}
+
+			return false;
 		} catch (Exception e) {
 			return false;
 		}
"
245d0fc46cc3426b09fc1f7c8f2e6f82e8fa5f90,Ali Mesbah,EmbeddedBrowser.java,MODIFY,isVisible -> [By locater] | [Identification identification],"diff --git a/src/main/java/com/crawljax/browser/EmbeddedBrowser.java b/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
index 19d8d95..e9a8b32 100644
--- a/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
@@ -3,8 +3,6 @@
  */
 package com.crawljax.browser;
 
-import org.openqa.selenium.By;
-
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.Identification;
@@ -89,13 +87,13 @@
 	Object executeJavaScript(String script) throws CrawljaxException;
 
 	/**
-	 * Checks if an element is visible. TODO: replace By by Identification
+	 * Checks if an element is visible.
 	 * 
-	 * @param locater
-	 *            Locater to use.
-	 * @return Whether it is visible.
+	 * @param identification
+	 *            identification to use.
+	 * @return true if the element is visible.
 	 */
-	boolean isVisible(By locater);
+	boolean isVisible(Identification identification);
 
 	/**
 	 * @return The current browser url.
"
fb91abf5383dc275a2f1dfab723019ab850a3bed,Ali Mesbah,DummyBrowser.java,MODIFY,isVisible -> [By locater] | [Identification locater],"diff --git a/src/test/java/com/crawljax/browser/DummyBrowser.java b/src/test/java/com/crawljax/browser/DummyBrowser.java
index 06aedc3..e010311 100644
--- a/src/test/java/com/crawljax/browser/DummyBrowser.java
+++ b/src/test/java/com/crawljax/browser/DummyBrowser.java
@@ -1,7 +1,5 @@
 package com.crawljax.browser;
 
-import org.openqa.selenium.By;
-
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.Identification;
@@ -64,7 +62,7 @@
 	}
 
 	@Override
-	public boolean isVisible(By locater) {
+	public boolean isVisible(Identification locater) {
 		return false;
 	}
 
"
81280c31fed8c11593a44ddc940f250f1885f1f5,Ali Mesbah,Eventable.java,MODIFY,setEventType -> [String eventType] | [EventType eventType],"diff --git a/src/main/java/com/crawljax/core/state/Eventable.java b/src/main/java/com/crawljax/core/state/Eventable.java
index 3d7dce0..c8d8ebe 100644
--- a/src/main/java/com/crawljax/core/state/Eventable.java
+++ b/src/main/java/com/crawljax/core/state/Eventable.java
@@ -32,13 +32,20 @@
 	private static final long serialVersionUID = 3229708706467350994L;
 	private static final Logger LOGGER = Logger.getLogger(Eventable.class.getName());
 	private long id;
-	private String eventType;
+	private EventType eventType;
 	private Identification identification;
 	private Element element;
 	private List<FormInput> relatedFormInputs = new ArrayList<FormInput>();
 	private String relatedFrame = """";
 
 	/**
+	 * The event type.
+	 */
+	public enum EventType {
+		click, hover
+	}
+
+	/**
 	 * Default constructor to support saving instances of this class as an XML.
 	 */
 	public Eventable() {
@@ -51,9 +58,9 @@
 	 * @param identification
 	 *            the identification object.
 	 * @param eventType
-	 *            the event.
+	 *            the event type.
 	 */
-	public Eventable(Identification identification, String eventType) {
+	public Eventable(Identification identification, EventType eventType) {
 		this.identification = identification;
 		this.eventType = eventType;
 	}
@@ -68,7 +75,7 @@
 	 * @param relatedFrame
 	 *            the frame containing this element.
 	 */
-	public Eventable(Identification identification, String eventType, String relatedFrame) {
+	public Eventable(Identification identification, EventType eventType, String relatedFrame) {
 		this(identification, eventType);
 		this.relatedFrame = relatedFrame;
 	}
@@ -81,7 +88,7 @@
 	 * @param eventType
 	 *            the event type.
 	 */
-	public Eventable(Node node, String eventType) {
+	public Eventable(Node node, EventType eventType) {
 		this(new Identification(Identification.How.xpath, XPathHelper.getXpathExpression(node)),
 		        eventType);
 		this.element = new Element(node);
@@ -95,7 +102,7 @@
 	 * @param eventType
 	 *            the event type. TODO ali remove
 	 */
-	public Eventable(CandidateElement candidateElement, String eventType) {
+	public Eventable(CandidateElement candidateElement, EventType eventType) {
 		this(candidateElement.getIdentification(), eventType);
 		if (candidateElement.getElement() != null) {
 			this.element = new Element(candidateElement.getElement());
@@ -155,7 +162,7 @@
 	/**
 	 * @return the eventType.
 	 */
-	public String getEventType() {
+	public EventType getEventType() {
 		return eventType;
 	}
 
@@ -193,7 +200,7 @@
 	 * @param eventType
 	 *            the eventType to set
 	 */
-	public void setEventType(String eventType) {
+	public void setEventType(EventType eventType) {
 		this.eventType = eventType;
 	}
 
@@ -269,15 +276,19 @@
 
 	/**
 	 * @return the source state.
+	 * @throws CrawljaxException
+	 *             if the source cannot be found.
 	 */
-	public StateVertix getSourceStateVertix() {
+	public StateVertix getSourceStateVertix() throws CrawljaxException {
 		return getSuperField(""source"");
 	}
 
 	/**
 	 * @return the target state.
+	 * @throws CrawljaxException
+	 *             if the target cannot be found.
 	 */
-	public StateVertix getTargetStateVertix() {
+	public StateVertix getTargetStateVertix() throws CrawljaxException {
 		return getSuperField(""target"");
 	}
 
@@ -299,17 +310,15 @@
 		setSuperField(""target"", vertix);
 	}
 
-	private StateVertix getSuperField(String name) {
+	private StateVertix getSuperField(String name) throws CrawljaxException {
 		try {
 			return (StateVertix) searchSuperField(name).get(this);
 		} catch (IllegalArgumentException e) {
-			// TODO Log
-			e.printStackTrace();
+			throw new CrawljaxException(e.getMessage(), e);
 		} catch (IllegalAccessException e) {
-			// TODO Log
-			e.printStackTrace();
+			throw new CrawljaxException(e.getMessage(), e);
 		}
-		return null;
+
 	}
 
 	private Field searchSuperField(String name) {
"
2817cf3150c8be546d909d5a09e62e9e28027a9a,Ali Mesbah,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 9242130..b657bbd 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -8,6 +8,7 @@
 import com.crawljax.condition.browserwaiter.WaitCondition;
 import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.invariant.Invariant;
+import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.oraclecomparator.Comparator;
 import com.crawljax.oraclecomparator.OracleComparator;
 
@@ -30,13 +31,13 @@
  * EXAMPLE:<br />
  * CrawlSpecification crawler = new CrawlSpecification(""http://www.google.com"");<br />
  * //click these elements<br />
- * crawler.click(""a"");<br />
- * crawler.click(""input"").withAttribute(""type"", ""submit"");<br />
+ * crawler.lookFor(""a"");<br />
+ * crawler.lookFor(""input"").withAttribute(""type"", ""submit"");<br />
  * onLoginPageCondition = new UrlCondition(""#login"");<br />
  * crawler.when(onLoginPageCondition).click(""a"").withText(""Login"");<br />
  * //but don't click these<br />
- * crawler.dontClick(""a"").underXpath(""//DIV[@id='guser']"");
- * crawler.dontClick(""a"").withText(""Language Tools""); <br />
+ * crawler.ignore(""a"").underXpath(""//DIV[@id='guser']"");
+ * crawler.ignore(""a"").withText(""Language Tools""); <br />
  * //restrict the scope of the crawling<br />
  * crawler.setCrawlMaximumStates(15);<br />
  * crawler.setCrawlDepth(2);
@@ -52,7 +53,8 @@
 
 	private final String url;
 
-	private final List<String> crawlEvents = new ArrayList<String>();
+	private List<EventType> crawlEvents = new ArrayList<EventType>();
+
 	private int depth = 0;
 	private int maximumStates = 0;
 	private int maximumRuntime = DEFAULT_MAXIMUMRUNTIME; // in seconds
@@ -77,7 +79,7 @@
 	 *            the site to crawl
 	 */
 	public CrawlSpecification(String url) {
-		this.crawlEvents.add(""onclick"");
+		this.crawlEvents.add(EventType.click);
 		this.url = url;
 	}
 
@@ -86,26 +88,26 @@
 	 * anchor tags All buttons
 	 */
 	public void clickDefaultElements() {
-		crawlActions.click(""a"");
-		crawlActions.click(""button"");
-		crawlActions.click(""input"").withAttribute(""type"", ""submit"");
-		crawlActions.click(""input"").withAttribute(""type"", ""button"");
+		crawlActions.lookFor(""a"");
+		crawlActions.lookFor(""button"");
+		crawlActions.lookFor(""input"").withAttribute(""type"", ""submit"");
+		crawlActions.lookFor(""input"").withAttribute(""type"", ""button"");
 	}
 
 	/**
 	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
-	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}.
+	 * click(""a"") will only include 1 This set can be restricted by {@link #ignore(String)}.
 	 * 
 	 * @param tagName
 	 *            the tag name of the elements to be included
 	 * @return this CrawlElement
 	 */
-	public CrawlElement click(String tagName) {
-		return crawlActions.click(tagName);
+	public CrawlElement lookFor(String tagName) {
+		return crawlActions.lookFor(tagName);
 	}
 
 	/**
-	 * Set of HTML elements Crawljax will NOT click during crawling When an HTML is present in the
+	 * Set of HTML elements Crawljax will NOT examine during crawling When an HTML is present in the
 	 * click and dontClick sets, then the element will not be clicked. For example: 1) <a
 	 * href=""#"">Some text</a> 2) <a class=""foo"" .../> 3) <div class=""foo"" .../> click(""a"")
 	 * dontClick(""a"").withAttribute(""class"", ""foo""); Will include only include HTML element 2
@@ -114,7 +116,7 @@
 	 *            the tag name of the elements to be excluded
 	 * @return this CrawlElement
 	 */
-	public CrawlElement dontClick(String tagName) {
+	public CrawlElement ignore(String tagName) {
 		return crawlActions.dontClick(tagName);
 	}
 
@@ -239,7 +241,7 @@
 	/**
 	 * @return the events that should be fired (e.g. onclick)
 	 */
-	protected List<String> getCrawlEvents() {
+	protected List<EventType> getCrawlEvents() {
 		return crawlEvents;
 	}
 
@@ -434,4 +436,12 @@
 		this.clicklOnce = clickOnce;
 	}
 
+	/**
+	 * @param crawlEvents
+	 *            the crawlEvents to set
+	 */
+	public void setCrawlEvents(List<EventType> crawlEvents) {
+		this.crawlEvents = crawlEvents;
+	}
+
 }
"
57ee99a4e540c4654572b8b8ad9b31d92c3a51af,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setBrowser -> [WebDriver driver] | [EmbeddedBrowser browser],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index a047fac..675719c 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -38,8 +38,6 @@
  */
 public final class CrawljaxConfiguration {
 
-	private static final int ONE_SECOND = 1000;
-
 	private EmbeddedBrowser browser;
 
 	private String outputFolder = """";
@@ -125,8 +123,7 @@
 		        .getWaitTimeAfterReloadUrl());
 		config.addProperty(""crawl.wait.event"", getCrawlSpecification().getWaitTimeAfterEvent());
 		config.addProperty(""crawl.max.states"", getCrawlSpecification().getMaximumStates());
-		config.addProperty(""crawl.max.runtime"", getCrawlSpecification().getMaximumRuntime()
-		        * ONE_SECOND);
+		config.addProperty(""crawl.max.runtime"", getCrawlSpecification().getMaximumRuntime());
 		config.addProperty(""crawl.forms.randominput"", ConfigurationHelper
 		        .booleanToInt(getCrawlSpecification().getRandomInputInForms()));
 		config.addProperty(""crawl.numberOfThreads"", getCrawlSpecification().getNumberOfThreads());
@@ -198,6 +195,7 @@
 				eventableConditions.add(eventableCondition);
 			}
 		}
+
 		return eventableConditions;
 	}
 
"
57ee99a4e540c4654572b8b8ad9b31d92c3a51af,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 22964c2..e3d2177 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -451,20 +451,6 @@
 	/**
 	 * @return TODO: DOCUMENT ME!
 	 */
-	public static String getCrawlMaxStates() {
-		return crawlMaxStates;
-	}
-
-	/**
-	 * @return TODO: DOCUMENT ME!
-	 */
-	public static String getCrawlMaxTime() {
-		return crawlMaxTime;
-	}
-
-	/**
-	 * @return TODO: DOCUMENT ME!
-	 */
 	public static int getCrawlMaxStatesValue() {
 		return crawlMaxStatesValue;
 	}
"
e2762a3963efb28ae6c00541924e2f68f7c69662,Frank Groeneveld,CrawljaxConfiguration.java,MODIFY,setBrowser -> [WebDriver driver] | [EmbeddedBrowser browser],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index a047fac..675719c 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -38,8 +38,6 @@
  */
 public final class CrawljaxConfiguration {
 
-	private static final int ONE_SECOND = 1000;
-
 	private EmbeddedBrowser browser;
 
 	private String outputFolder = """";
@@ -125,8 +123,7 @@
 		        .getWaitTimeAfterReloadUrl());
 		config.addProperty(""crawl.wait.event"", getCrawlSpecification().getWaitTimeAfterEvent());
 		config.addProperty(""crawl.max.states"", getCrawlSpecification().getMaximumStates());
-		config.addProperty(""crawl.max.runtime"", getCrawlSpecification().getMaximumRuntime()
-		        * ONE_SECOND);
+		config.addProperty(""crawl.max.runtime"", getCrawlSpecification().getMaximumRuntime());
 		config.addProperty(""crawl.forms.randominput"", ConfigurationHelper
 		        .booleanToInt(getCrawlSpecification().getRandomInputInForms()));
 		config.addProperty(""crawl.numberOfThreads"", getCrawlSpecification().getNumberOfThreads());
@@ -198,6 +195,7 @@
 				eventableConditions.add(eventableCondition);
 			}
 		}
+
 		return eventableConditions;
 	}
 
"
e2762a3963efb28ae6c00541924e2f68f7c69662,Frank Groeneveld,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 22964c2..e3d2177 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -451,20 +451,6 @@
 	/**
 	 * @return TODO: DOCUMENT ME!
 	 */
-	public static String getCrawlMaxStates() {
-		return crawlMaxStates;
-	}
-
-	/**
-	 * @return TODO: DOCUMENT ME!
-	 */
-	public static String getCrawlMaxTime() {
-		return crawlMaxTime;
-	}
-
-	/**
-	 * @return TODO: DOCUMENT ME!
-	 */
 	public static int getCrawlMaxStatesValue() {
 		return crawlMaxStatesValue;
 	}
"
69820bb23fa6f809d667b455c7443739318ac2bd,Frank Groeneveld,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index b657bbd..2a5dd8e 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -87,7 +87,7 @@
 	 * Specifies that Crawljax should click all the default clickable elements. These include: All
 	 * anchor tags All buttons
 	 */
-	public void clickDefaultElements() {
+	public void lookForDefaultElements() {
 		crawlActions.lookFor(""a"");
 		crawlActions.lookFor(""button"");
 		crawlActions.lookFor(""input"").withAttribute(""type"", ""submit"");
"
a6e8fb96c74f8e99b2b77152a1872d1e4ff53774,Ali Mesbah,StateVertix.java,MODIFY,"searchForCandidateElements -> [CandidateElementExtractor candidateExtractor] | [CandidateElementExtractor candidateExtractor, List crawlTagElements, List crawlExcludeTagElements, boolean clickOnce, List eventTypes]","diff --git a/src/main/java/com/crawljax/core/state/StateVertix.java b/src/main/java/com/crawljax/core/state/StateVertix.java
index 2efc2f0..1a1bf12 100644
--- a/src/main/java/com/crawljax/core/state/StateVertix.java
+++ b/src/main/java/com/crawljax/core/state/StateVertix.java
@@ -15,9 +15,9 @@
 import com.crawljax.core.CandidateElement;
 import com.crawljax.core.CandidateElementExtractor;
 import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.TagElement;
 import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.util.Helper;
-import com.crawljax.util.PropertyHelper;
 import com.crawljax.util.database.HibernateUtil;
 
 /**
@@ -237,16 +237,24 @@
 	 * 
 	 * @param candidateExtractor
 	 *            the CandidateElementExtractor to use.
+	 * @param crawlTagElements
+	 *            the tag elements to examine.
+	 * @param crawlExcludeTagElements
+	 *            the elements to exclude.
+	 * @param clickOnce
+	 *            if true examine each element once.
+	 * @param eventTypes
+	 *            the event types.
 	 */
-	public void searchForCandidateElements(CandidateElementExtractor candidateExtractor) {
+	public void searchForCandidateElements(CandidateElementExtractor candidateExtractor,
+	        List<TagElement> crawlTagElements, List<TagElement> crawlExcludeTagElements,
+	        boolean clickOnce, List<String> eventTypes) {
 		if (candidateActions == null) {
 			candidateActions = new ArrayList<CandidateCrawlAction>();
 			try {
 				List<CandidateElement> candidateList =
-				        candidateExtractor.extract(PropertyHelper.getCrawlTagElements(),
-				                PropertyHelper.getCrawlExcludeTagElements(), PropertyHelper
-				                        .getClickOnceValue(), this);
-				List<String> eventTypes = PropertyHelper.getRobotEventsValues();
+				        candidateExtractor.extract(crawlTagElements, crawlExcludeTagElements,
+				                clickOnce, this);
 
 				for (CandidateElement candidateElement : candidateList) {
 					for (String eventType : eventTypes) {
"
cf3b527c1caf55b3c25829b2f57d0af15ed30584,Ali Mesbah,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/src/main/java/com/crawljax/core/configuration/InputField.java b/src/main/java/com/crawljax/core/configuration/InputField.java
index b333e2d..6bd301d 100644
--- a/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -120,7 +120,7 @@
 	 * @param field
 	 *            the field to add to the fieldValues
 	 */
-	protected void addFieldValue(String field) {
+	public void addFieldValue(String field) {
 		this.fieldValues.add(field);
 	}
 
"
cf3b527c1caf55b3c25829b2f57d0af15ed30584,Ali Mesbah,PropertiesFile.java,MODIFY,"parseTagElement -> [String text, CrawlSpecification crawlSpec] | [String text]","diff --git a/src/main/java/com/crawljax/core/configuration/PropertiesFile.java b/src/main/java/com/crawljax/core/configuration/PropertiesFile.java
index c642025..8fd110a 100644
--- a/src/main/java/com/crawljax/core/configuration/PropertiesFile.java
+++ b/src/main/java/com/crawljax/core/configuration/PropertiesFile.java
@@ -1,7 +1,9 @@
 package com.crawljax.core.configuration;
 
 import java.io.File;
+import java.util.HashSet;
 import java.util.List;
+import java.util.Set;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
@@ -140,7 +142,7 @@
 		/* walk through all elements */
 		for (String tag : tags) {
 			/* call the correct api stuff on the crawler for tag */
-			tagElement = parseTagElement(tag, crawler);
+			tagElement = parseTagElement(tag);
 
 			CrawlElement element = crawler.lookFor(tagElement.getName());
 			for (TagAttribute attrib : tagElement.getAttributes()) {
@@ -154,7 +156,7 @@
 		/* walk through all elements */
 		for (String tag : tags) {
 			/* call the correct api stuff on the crawler for tag */
-			tagElement = parseTagElement(tag, crawler);
+			tagElement = parseTagElement(tag);
 
 			CrawlElement element = crawler.ignore(tagElement.getName());
 			for (TagAttribute attrib : tagElement.getAttributes()) {
@@ -168,15 +170,16 @@
 	 * 
 	 * @param text
 	 *            The string containing the tag elements.
-	 * @param crawlSpec
-	 *            the crawlSpecification.
 	 * @return the TagElement;
 	 */
-	public TagElement parseTagElement(String text, CrawlSpecification crawlSpec) {
+	public TagElement parseTagElement(String text) {
 		if (text.equals("""")) {
 			return null;
 		}
-		TagElement tagElement = new TagElement();
+		String name = null;
+		Set<TagAttribute> attributes = new HashSet<TagAttribute>();
+		String id = null;
+
 		Pattern pattern =
 		        Pattern.compile(""\\w+:\\{(\\w+=?(\\-*\\s*[\\w%]\\s*)+\\;?\\s?)*}""
 		                + ""(\\[\\w+\\])?"");
@@ -196,34 +199,38 @@
 			matcher = patternTagName.matcher(substring);
 
 			if (matcher.find()) {
-				tagElement.setName(matcher.group().trim());
+				name = matcher.group().trim();
 			}
 
 			matcher = patternAttributes.matcher(substring);
 
 			// attributes
 			if (matcher.find()) {
-				String attributes = (matcher.group());
+				String tmp = matcher.group();
 				// parse attributes
-				matcher = patternAttribute.matcher(attributes);
+				matcher = patternAttribute.matcher(tmp);
 
 				while (matcher.find()) {
-					String name = matcher.group(1).trim();
+					String attrName = matcher.group(1).trim();
 					String value = matcher.group(2).trim();
-					tagElement.getAttributes().add(new TagAttribute(name, value));
+					attributes.add(new TagAttribute(attrName, value));
 				}
 			}
 
 			// id
 			matcher = patternId.matcher(substring);
 			if (matcher.find()) {
-				String id = matcher.group(2);
-				tagElement.setId(id);
+				id = matcher.group(2);
 			}
 
+			TagElement el = new TagElement(attributes, name);
+			if (id != null) {
+				el.setId(id);
+			}
+			return el;
 		}
 
-		return tagElement;
+		return null;
 	}
 
 	/**
"
cf3b527c1caf55b3c25829b2f57d0af15ed30584,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index e3d2177..51ff159 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -4,7 +4,9 @@
 package com.crawljax.util;
 
 import java.util.ArrayList;
+import java.util.HashSet;
 import java.util.List;
+import java.util.Set;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
@@ -199,7 +201,7 @@
 
 	private static void setTagElements() {
 		for (String text : getPropertyAsList(crawlTags)) {
-			TagElement tagElement = parseTagElements(text);
+			TagElement tagElement = parseTagElement(text);
 
 			if (tagElement != null) {
 				crawlTagElements.add(tagElement);
@@ -209,7 +211,7 @@
 
 	private static void setTagExcludeElements() {
 		for (String text : getPropertyAsList(crawlExludeTags)) {
-			TagElement tagElement = parseTagElements(text);
+			TagElement tagElement = parseTagElement(text);
 
 			if (tagElement != null) {
 				crawlExcludeTagElements.add(tagElement);
@@ -365,13 +367,6 @@
 	}
 
 	/**
-	 * @return the crawlTags
-	 */
-	public static String getCrawlTags() {
-		return crawlTags;
-	}
-
-	/**
 	 * @return the browser
 	 */
 	public static String getBrowser() {
@@ -414,13 +409,6 @@
 	}
 
 	/**
-	 * @return the crawlTagsValues
-	 */
-	public static List<String> getCrawlTagsValues() {
-		return crawlTagsValues;
-	}
-
-	/**
 	 * @return the crawlFilterAttributesValues
 	 */
 	public static List<String> getCrawlFilterAttributesValues() {
@@ -469,11 +457,14 @@
 	 *            The string containing the tag elements.
 	 * @return The tag element.
 	 */
-	public static TagElement parseTagElements(String text) {
+	public static TagElement parseTagElement(String text) {
 		if (text.equals("""")) {
 			return null;
 		}
-		TagElement tagElement = new TagElement();
+		String name = null;
+		Set<TagAttribute> attributes = new HashSet<TagAttribute>();
+		String id = null;
+
 		Pattern pattern =
 		        Pattern.compile(""\\w+:\\{(\\w+=?(\\-*\\s*[\\w%]\\s*)+\\;?\\s?)*}""
 		                + ""(\\[\\w+\\])?"");
@@ -493,70 +484,38 @@
 			matcher = patternTagName.matcher(substring);
 
 			if (matcher.find()) {
-				tagElement.setName(matcher.group().trim());
+				name = matcher.group().trim();
 			}
 
 			matcher = patternAttributes.matcher(substring);
 
 			// attributes
 			if (matcher.find()) {
-				String attributes = (matcher.group());
+				String tmp = matcher.group();
 				// parse attributes
-				matcher = patternAttribute.matcher(attributes);
+				matcher = patternAttribute.matcher(tmp);
 
 				while (matcher.find()) {
-					String name = matcher.group(1).trim();
+					String attrName = matcher.group(1).trim();
 					String value = matcher.group(2).trim();
-					tagElement.getAttributes().add(new TagAttribute(name, value));
+					attributes.add(new TagAttribute(attrName, value));
 				}
 			}
 
 			// id
 			matcher = patternId.matcher(substring);
 			if (matcher.find()) {
-				String id = matcher.group(2);
-				tagElement.setId(id);
+				id = matcher.group(2);
 			}
 
-		}
-		return tagElement;
-	}
-
-	/**
-	 * @param args
-	 *            TODO: DOCUMENT ME!
-	 */
-	public static void main(String[] args) {
-		String text = ""div:{class=expandable-hitarea}"";
-
-		TagElement tagElement = parseTagElements(text);
-		System.out.println(""tagname: "" + tagElement.getName());
-
-		for (TagAttribute attr : tagElement.getAttributes()) {
-			System.out.println(""attrName: "" + attr.getName() + "" value: "" + attr.getValue());
+			TagElement el = new TagElement(attributes, name);
+			if (id != null) {
+				el.setId(id);
+			}
+			return el;
 		}
 
-		/*
-		 * String text =
-		 * ""a:{attr=value}, div:{class=aha; id=room}, span:{}, div:{class=expandable-hitarea}"" ; try
-		 * { PropertyHelper.init(""src/test/resources/testcrawljax.properties""); } catch
-		 * (ConfigurationException e) { System.out.println(e.getMessage()); } List<String> tList =
-		 * getPropertyAsList(crawlTags); for (String e : tList) { System.out.println(e); TagElement
-		 * tagElement = parseTagElements(e); System.out.println(""tagname: "" + tagElement.getName());
-		 * for (TagAttribute attr : tagElement.getAttributes()) { System.out.println(""attrName: "" +
-		 * attr.getName() + "" value: "" + attr.getValue()); } }
-		 */
-
-		/*
-		 * for (String t : getPropertyAsList(crawlTags)) { TagElement tagElement =
-		 * parseTagElements(t); if (tagElement != null) { crawlTagElements.add(tagElement); } }
-		 */
-
-		/*
-		 * TagElement tagElement = parseTagElements(text); System.out.println(""tagname: "" +
-		 * tagElement.getName()); for (TagAttribute attr : tagElement.getAttributes()) {
-		 * System.out.println( ""attrName: "" + attr.getName() + "" value: "" + attr.getValue()); }
-		 */
+		return null;
 	}
 
 	/**
@@ -602,13 +561,6 @@
 	}
 
 	/**
-	 * @return TODO: DOCUMENT ME!
-	 */
-	public static List<String> getAtusaPluginsValues() {
-		return atusaPluginsValues;
-	}
-
-	/**
 	 * @return Whether to use the proxy.
 	 */
 	public static boolean getProxyEnabledValue() {
"
b611fdc56d0e42c64b82aaa9ea7039852f5c94f0,Frank Groeneveld,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/src/main/java/com/crawljax/core/configuration/InputField.java b/src/main/java/com/crawljax/core/configuration/InputField.java
index b333e2d..6bd301d 100644
--- a/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -120,7 +120,7 @@
 	 * @param field
 	 *            the field to add to the fieldValues
 	 */
-	protected void addFieldValue(String field) {
+	public void addFieldValue(String field) {
 		this.fieldValues.add(field);
 	}
 
"
b611fdc56d0e42c64b82aaa9ea7039852f5c94f0,Frank Groeneveld,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index e3d2177..51ff159 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -4,7 +4,9 @@
 package com.crawljax.util;
 
 import java.util.ArrayList;
+import java.util.HashSet;
 import java.util.List;
+import java.util.Set;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
@@ -199,7 +201,7 @@
 
 	private static void setTagElements() {
 		for (String text : getPropertyAsList(crawlTags)) {
-			TagElement tagElement = parseTagElements(text);
+			TagElement tagElement = parseTagElement(text);
 
 			if (tagElement != null) {
 				crawlTagElements.add(tagElement);
@@ -209,7 +211,7 @@
 
 	private static void setTagExcludeElements() {
 		for (String text : getPropertyAsList(crawlExludeTags)) {
-			TagElement tagElement = parseTagElements(text);
+			TagElement tagElement = parseTagElement(text);
 
 			if (tagElement != null) {
 				crawlExcludeTagElements.add(tagElement);
@@ -365,13 +367,6 @@
 	}
 
 	/**
-	 * @return the crawlTags
-	 */
-	public static String getCrawlTags() {
-		return crawlTags;
-	}
-
-	/**
 	 * @return the browser
 	 */
 	public static String getBrowser() {
@@ -414,13 +409,6 @@
 	}
 
 	/**
-	 * @return the crawlTagsValues
-	 */
-	public static List<String> getCrawlTagsValues() {
-		return crawlTagsValues;
-	}
-
-	/**
 	 * @return the crawlFilterAttributesValues
 	 */
 	public static List<String> getCrawlFilterAttributesValues() {
@@ -469,11 +457,14 @@
 	 *            The string containing the tag elements.
 	 * @return The tag element.
 	 */
-	public static TagElement parseTagElements(String text) {
+	public static TagElement parseTagElement(String text) {
 		if (text.equals("""")) {
 			return null;
 		}
-		TagElement tagElement = new TagElement();
+		String name = null;
+		Set<TagAttribute> attributes = new HashSet<TagAttribute>();
+		String id = null;
+
 		Pattern pattern =
 		        Pattern.compile(""\\w+:\\{(\\w+=?(\\-*\\s*[\\w%]\\s*)+\\;?\\s?)*}""
 		                + ""(\\[\\w+\\])?"");
@@ -493,70 +484,38 @@
 			matcher = patternTagName.matcher(substring);
 
 			if (matcher.find()) {
-				tagElement.setName(matcher.group().trim());
+				name = matcher.group().trim();
 			}
 
 			matcher = patternAttributes.matcher(substring);
 
 			// attributes
 			if (matcher.find()) {
-				String attributes = (matcher.group());
+				String tmp = matcher.group();
 				// parse attributes
-				matcher = patternAttribute.matcher(attributes);
+				matcher = patternAttribute.matcher(tmp);
 
 				while (matcher.find()) {
-					String name = matcher.group(1).trim();
+					String attrName = matcher.group(1).trim();
 					String value = matcher.group(2).trim();
-					tagElement.getAttributes().add(new TagAttribute(name, value));
+					attributes.add(new TagAttribute(attrName, value));
 				}
 			}
 
 			// id
 			matcher = patternId.matcher(substring);
 			if (matcher.find()) {
-				String id = matcher.group(2);
-				tagElement.setId(id);
+				id = matcher.group(2);
 			}
 
-		}
-		return tagElement;
-	}
-
-	/**
-	 * @param args
-	 *            TODO: DOCUMENT ME!
-	 */
-	public static void main(String[] args) {
-		String text = ""div:{class=expandable-hitarea}"";
-
-		TagElement tagElement = parseTagElements(text);
-		System.out.println(""tagname: "" + tagElement.getName());
-
-		for (TagAttribute attr : tagElement.getAttributes()) {
-			System.out.println(""attrName: "" + attr.getName() + "" value: "" + attr.getValue());
+			TagElement el = new TagElement(attributes, name);
+			if (id != null) {
+				el.setId(id);
+			}
+			return el;
 		}
 
-		/*
-		 * String text =
-		 * ""a:{attr=value}, div:{class=aha; id=room}, span:{}, div:{class=expandable-hitarea}"" ; try
-		 * { PropertyHelper.init(""src/test/resources/testcrawljax.properties""); } catch
-		 * (ConfigurationException e) { System.out.println(e.getMessage()); } List<String> tList =
-		 * getPropertyAsList(crawlTags); for (String e : tList) { System.out.println(e); TagElement
-		 * tagElement = parseTagElements(e); System.out.println(""tagname: "" + tagElement.getName());
-		 * for (TagAttribute attr : tagElement.getAttributes()) { System.out.println(""attrName: "" +
-		 * attr.getName() + "" value: "" + attr.getValue()); } }
-		 */
-
-		/*
-		 * for (String t : getPropertyAsList(crawlTags)) { TagElement tagElement =
-		 * parseTagElements(t); if (tagElement != null) { crawlTagElements.add(tagElement); } }
-		 */
-
-		/*
-		 * TagElement tagElement = parseTagElements(text); System.out.println(""tagname: "" +
-		 * tagElement.getName()); for (TagAttribute attr : tagElement.getAttributes()) {
-		 * System.out.println( ""attrName: "" + attr.getName() + "" value: "" + attr.getValue()); }
-		 */
+		return null;
 	}
 
 	/**
@@ -602,13 +561,6 @@
 	}
 
 	/**
-	 * @return TODO: DOCUMENT ME!
-	 */
-	public static List<String> getAtusaPluginsValues() {
-		return atusaPluginsValues;
-	}
-
-	/**
 	 * @return Whether to use the proxy.
 	 */
 	public static boolean getProxyEnabledValue() {
"
636940ebdb710b2493895f7e929201e0b3adabd2,Ali Mesbah,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/src/main/java/com/crawljax/core/configuration/InputField.java b/src/main/java/com/crawljax/core/configuration/InputField.java
index 6bd301d..b333e2d 100644
--- a/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -120,7 +120,7 @@
 	 * @param field
 	 *            the field to add to the fieldValues
 	 */
-	public void addFieldValue(String field) {
+	protected void addFieldValue(String field) {
 		this.fieldValues.add(field);
 	}
 
"
9feb5b6049e67b7ee986ea24b0e9a7827889f4a0,Frank Groeneveld,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/src/main/java/com/crawljax/core/configuration/InputField.java b/src/main/java/com/crawljax/core/configuration/InputField.java
index 6bd301d..b333e2d 100644
--- a/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -120,7 +120,7 @@
 	 * @param field
 	 *            the field to add to the fieldValues
 	 */
-	public void addFieldValue(String field) {
+	protected void addFieldValue(String field) {
 		this.fieldValues.add(field);
 	}
 
"
e6f3adf7381e1d8eebdcb0efc1d94aee7eb46fd7,Ali Mesbah,FormInputField.java,MODIFY,setValues -> [boolean values] | [String values],"diff --git a/src/main/java/com/crawljax/core/configuration/FormInputField.java b/src/main/java/com/crawljax/core/configuration/FormInputField.java
index 4f97ad4..c2fd585 100644
--- a/src/main/java/com/crawljax/core/configuration/FormInputField.java
+++ b/src/main/java/com/crawljax/core/configuration/FormInputField.java
@@ -28,7 +28,7 @@
 	 */
 	public FormInputField setValues(String... values) {
 		for (String value : values) {
-			this.addFieldValue(value);
+			this.setValue(value);
 		}
 		return this;
 	}
@@ -43,9 +43,9 @@
 	public FormInputField setValues(boolean... values) {
 		for (boolean value : values) {
 			if (value) {
-				this.addFieldValue(""1"");
+				this.setValue(""1"");
 			} else {
-				this.addFieldValue(""0"");
+				this.setValue(""0"");
 			}
 		}
 		return this;
"
e6f3adf7381e1d8eebdcb0efc1d94aee7eb46fd7,Ali Mesbah,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/src/main/java/com/crawljax/core/configuration/InputField.java b/src/main/java/com/crawljax/core/configuration/InputField.java
index b333e2d..474d562 100644
--- a/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -113,15 +113,4 @@
 	protected List<String> getFieldValues() {
 		return fieldValues;
 	}
-
-	/**
-	 * Add a field to the field values.
-	 * 
-	 * @param field
-	 *            the field to add to the fieldValues
-	 */
-	protected void addFieldValue(String field) {
-		this.fieldValues.add(field);
-	}
-
 }
"
d8b736aacea5b83de7c641dc6a48853391012928,Frank Groeneveld,FormInputField.java,MODIFY,setValues -> [boolean values] | [String values],"diff --git a/src/main/java/com/crawljax/core/configuration/FormInputField.java b/src/main/java/com/crawljax/core/configuration/FormInputField.java
index 4f97ad4..c2fd585 100644
--- a/src/main/java/com/crawljax/core/configuration/FormInputField.java
+++ b/src/main/java/com/crawljax/core/configuration/FormInputField.java
@@ -28,7 +28,7 @@
 	 */
 	public FormInputField setValues(String... values) {
 		for (String value : values) {
-			this.addFieldValue(value);
+			this.setValue(value);
 		}
 		return this;
 	}
@@ -43,9 +43,9 @@
 	public FormInputField setValues(boolean... values) {
 		for (boolean value : values) {
 			if (value) {
-				this.addFieldValue(""1"");
+				this.setValue(""1"");
 			} else {
-				this.addFieldValue(""0"");
+				this.setValue(""0"");
 			}
 		}
 		return this;
"
d8b736aacea5b83de7c641dc6a48853391012928,Frank Groeneveld,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/src/main/java/com/crawljax/core/configuration/InputField.java b/src/main/java/com/crawljax/core/configuration/InputField.java
index b333e2d..474d562 100644
--- a/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -113,15 +113,4 @@
 	protected List<String> getFieldValues() {
 		return fieldValues;
 	}
-
-	/**
-	 * Add a field to the field values.
-	 * 
-	 * @param field
-	 *            the field to add to the fieldValues
-	 */
-	protected void addFieldValue(String field) {
-		this.fieldValues.add(field);
-	}
-
 }
"
5601de4989fd5bed9914569fe1a1f7867d8a2be5,Ali Mesbah,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 2a5dd8e..9f6ac43 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -88,10 +88,10 @@
 	 * anchor tags All buttons
 	 */
 	public void lookForDefaultElements() {
-		crawlActions.lookFor(""a"");
-		crawlActions.lookFor(""button"");
-		crawlActions.lookFor(""input"").withAttribute(""type"", ""submit"");
-		crawlActions.lookFor(""input"").withAttribute(""type"", ""button"");
+		crawlActions.click(""a"");
+		crawlActions.click(""button"");
+		crawlActions.click(""input"").withAttribute(""type"", ""submit"");
+		crawlActions.click(""input"").withAttribute(""type"", ""button"");
 	}
 
 	/**
@@ -103,7 +103,7 @@
 	 * @return this CrawlElement
 	 */
 	public CrawlElement lookFor(String tagName) {
-		return crawlActions.lookFor(tagName);
+		return crawlActions.click(tagName);
 	}
 
 	/**
"
5601de4989fd5bed9914569fe1a1f7867d8a2be5,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setBrowser -> [WebDriver driver] | [BrowserType browser],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 675719c..72b92b0 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -5,15 +5,11 @@
 
 import org.apache.commons.configuration.Configuration;
 import org.apache.commons.configuration.PropertiesConfiguration;
-import org.openqa.selenium.WebDriver;
 
-import com.crawljax.browser.EmbeddedBrowser;
-import com.crawljax.browser.WebDriverFirefox;
-import com.crawljax.browser.WebDriverOther;
+import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.util.Helper;
-import com.crawljax.util.PropertyHelper;
 
 /**
  * Specifies the settings Crawljax. The methods in this class fall into two categories:Oz
@@ -28,7 +24,7 @@
  * {@link CrawljaxConfiguration#setHibernateConfiguration(HibernateConfiguration)} See also
  * {@link HibernateConfiguration}
  * <p/>
- * DEFAULT VAlUES: Browser: WebDriverFirefox Project Full Path: empty Project Relative Path: empty
+ * DEFAULT VAlUES: Browser: webdriver firefox Project Full Path: empty Project Relative Path: empty
  * Filter attributes: closure_hashcode_(\\w)*, jquery[0-9]+ Test invariants while crawling: true
  * EXAMPLE: CrawljaxConfiguration crawljaxConfig = new CrawljaxConfiguration(); CrawlSpecification
  * crawler = new CrawlSpecification(""http://www.google.com""); crawler.click(""a"");
@@ -38,7 +34,7 @@
  */
 public final class CrawljaxConfiguration {
 
-	private EmbeddedBrowser browser;
+	private BrowserType browser = BrowserType.firefox;
 
 	private String outputFolder = """";
 	private String projectRelativePath = """";
@@ -216,46 +212,21 @@
 	}
 
 	/**
-	 * @return The browser used to crawl. See {@link EmbeddedBrowser}. By default
-	 *         {@link WebDriverFirefox} is used.
+	 * @return The browser used to crawl. By default firefox is used.
 	 */
-	protected EmbeddedBrowser getBrowser() {
-		if (browser == null) {
-			if (PropertyHelper.getCrawljaxConfiguration() != null
-			        && PropertyHelper.getCrawljaxConfiguration().getProxyConfiguration() != null) {
-				browser =
-				        new WebDriverFirefox(PropertyHelper.getCrawljaxConfiguration()
-				                .getProxyConfiguration());
-			} else {
-				browser = new WebDriverFirefox();
-			}
-		}
+	protected BrowserType getBrowser() {
 		return browser;
 	}
 
 	/**
 	 * @param browser
-	 *            The browser used to crawl. See {@link EmbeddedBrowser}. By default
-	 *            {@link WebDriverFirefox} is used.
+	 *            The browser used to crawl.
 	 */
-	public void setBrowser(EmbeddedBrowser browser) {
+	public void setBrowser(BrowserType browser) {
 		this.browser = browser;
 	}
 
 	/**
-	 * Deprecated function to specify the browser used. Replaced by
-	 * {@link CrawljaxConfiguration#setBrowser(EmbeddedBrowser)}.
-	 * 
-	 * @see #setBrowser(EmbeddedBrowser)
-	 * @param driver
-	 *            The Webdriver driver used to crawl. By default {@link WebDriverFirefox} is used.
-	 */
-	@Deprecated
-	public void setBrowser(WebDriver driver) {
-		this.browser = new WebDriverOther(driver);
-	}
-
-	/**
 	 * @return The path of the outputFolder with a trailing slash.
 	 */
 	protected String getOutputFolder() {
"
5601de4989fd5bed9914569fe1a1f7867d8a2be5,Ali Mesbah,CrawljaxPluginsUtil.java,MODIFY,loadPlugins -> [] | [List plugins],"diff --git a/src/main/java/com/crawljax/core/plugin/CrawljaxPluginsUtil.java b/src/main/java/com/crawljax/core/plugin/CrawljaxPluginsUtil.java
index a0c7a1b..db184b3 100644
--- a/src/main/java/com/crawljax/core/plugin/CrawljaxPluginsUtil.java
+++ b/src/main/java/com/crawljax/core/plugin/CrawljaxPluginsUtil.java
@@ -14,7 +14,6 @@
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateMachine;
 import com.crawljax.core.state.StateVertix;
-import com.crawljax.util.PropertyHelper;
 
 /**
  * Class for invoking the plugin. The methods in this class are invoked from the Crawljax Core.
@@ -30,6 +29,7 @@
 	 * Make a new Log4j object used to do the logging.
 	 */
 	private static final Logger LOGGER = Logger.getLogger(CrawljaxPluginsUtil.class.getName());
+	private static List<Plugin> plugins;
 
 	/**
 	 * Non instanceable constructor; does nothing never used, this constructor prevents the
@@ -46,15 +46,18 @@
 	}
 
 	/**
-	 * Load the Plugins.
+	 * Set the Plugins.
+	 * 
+	 * @param plugins
+	 *            the list of plugins.
 	 */
-	public static void loadPlugins() {
-		if (PropertyHelper.getCrawljaxConfiguration() == null
-		        || PropertyHelper.getCrawljaxConfiguration().getPlugins().size() == 0) {
+	public static void loadPlugins(List<Plugin> plugins) {
+		if (plugins == null || plugins.size() == 0) {
 			LOGGER.warn(""No plugins loaded because CrawljaxConfiguration is empty"");
 			return;
 		}
-		for (Plugin plugin : PropertyHelper.getCrawljaxConfiguration().getPlugins()) {
+		CrawljaxPluginsUtil.plugins = plugins;
+		for (Plugin plugin : CrawljaxPluginsUtil.plugins) {
 			/**
 			 * Log the name of the plugin loaded
 			 */
@@ -75,8 +78,8 @@
 	 *            the browser instance to load to the plugin.
 	 */
 	public static void runPreCrawlingPlugins(EmbeddedBrowser browser) {
-		if (PropertyHelper.getCrawljaxConfiguration() != null) {
-			for (Plugin plugin : PropertyHelper.getCrawljaxConfiguration().getPlugins()) {
+		if (CrawljaxPluginsUtil.plugins != null) {
+			for (Plugin plugin : CrawljaxPluginsUtil.plugins) {
 				if (plugin instanceof PreCrawlingPlugin) {
 					LOGGER.debug(""Running preCrawlingPlugin "" + plugin.getClass().getName());
 					((PreCrawlingPlugin) plugin).preCrawling(browser);
@@ -95,8 +98,8 @@
 	 *            the embedded browser instance to load in the plugin.
 	 */
 	public static void runOnUrlLoadPlugins(EmbeddedBrowser browser) {
-		if (PropertyHelper.getCrawljaxConfiguration() != null) {
-			for (Plugin plugin : PropertyHelper.getCrawljaxConfiguration().getPlugins()) {
+		if (CrawljaxPluginsUtil.plugins != null) {
+			for (Plugin plugin : CrawljaxPluginsUtil.plugins) {
 				if (plugin instanceof OnUrlLoadPlugin) {
 					((OnUrlLoadPlugin) plugin).onUrlLoad(browser);
 				}
@@ -113,8 +116,8 @@
 	 *            the session to load in the plugin
 	 */
 	public static void runOnNewStatePlugins(CrawlSession session) {
-		if (PropertyHelper.getCrawljaxConfiguration() != null) {
-			for (Plugin plugin : PropertyHelper.getCrawljaxConfiguration().getPlugins()) {
+		if (CrawljaxPluginsUtil.plugins != null) {
+			for (Plugin plugin : CrawljaxPluginsUtil.plugins) {
 				if (plugin instanceof OnNewStatePlugin) {
 					((OnNewStatePlugin) plugin).onNewState(session);
 				}
@@ -134,8 +137,8 @@
 	 *            the session to load in the plugin
 	 */
 	public static void runOnInvriantViolationPlugins(Invariant invariant, CrawlSession session) {
-		if (PropertyHelper.getCrawljaxConfiguration() != null) {
-			for (Plugin plugin : PropertyHelper.getCrawljaxConfiguration().getPlugins()) {
+		if (CrawljaxPluginsUtil.plugins != null) {
+			for (Plugin plugin : CrawljaxPluginsUtil.plugins) {
 				if (plugin instanceof OnInvariantViolationPlugin) {
 					((OnInvariantViolationPlugin) plugin)
 					        .onInvariantViolation(invariant, session);
@@ -153,8 +156,8 @@
 	 *            the session to load in the plugin
 	 */
 	public static void runPostCrawlingPlugins(CrawlSession session) {
-		if (PropertyHelper.getCrawljaxConfiguration() != null) {
-			for (Plugin plugin : PropertyHelper.getCrawljaxConfiguration().getPlugins()) {
+		if (CrawljaxPluginsUtil.plugins != null) {
+			for (Plugin plugin : CrawljaxPluginsUtil.plugins) {
 				if (plugin instanceof PostCrawlingPlugin) {
 					((PostCrawlingPlugin) plugin).postCrawling(session);
 				}
@@ -173,8 +176,8 @@
 	 *            the state the 'back tracking' operation is currently in
 	 */
 	public static void runOnRevisitStatePlugins(CrawlSession session, StateVertix currentState) {
-		if (PropertyHelper.getCrawljaxConfiguration() != null) {
-			for (Plugin plugin : PropertyHelper.getCrawljaxConfiguration().getPlugins()) {
+		if (CrawljaxPluginsUtil.plugins != null) {
+			for (Plugin plugin : CrawljaxPluginsUtil.plugins) {
 				if (plugin instanceof OnRevisitStatePlugin) {
 					((OnRevisitStatePlugin) plugin).onRevisitState(session, currentState);
 				}
@@ -195,8 +198,8 @@
 	 */
 	public static void runPreStateCrawlingPlugins(CrawlSession session,
 	        List<CandidateElement> candidateElements) {
-		if (PropertyHelper.getCrawljaxConfiguration() != null) {
-			for (Plugin plugin : PropertyHelper.getCrawljaxConfiguration().getPlugins()) {
+		if (CrawljaxPluginsUtil.plugins != null) {
+			for (Plugin plugin : CrawljaxPluginsUtil.plugins) {
 				if (plugin instanceof PreStateCrawlingPlugin) {
 					((PreStateCrawlingPlugin) plugin)
 					        .preStateCrawling(session, candidateElements);
@@ -215,8 +218,8 @@
 	 *            The ProxyConfiguration to use.
 	 */
 	public static void runProxyServerPlugins(ProxyConfiguration config) {
-		if (PropertyHelper.getCrawljaxConfiguration() != null) {
-			for (Plugin plugin : PropertyHelper.getCrawljaxConfiguration().getPlugins()) {
+		if (CrawljaxPluginsUtil.plugins != null) {
+			for (Plugin plugin : CrawljaxPluginsUtil.plugins) {
 				if (plugin instanceof ProxyServerPlugin) {
 					((ProxyServerPlugin) plugin).proxyServer(config);
 				}
@@ -241,9 +244,9 @@
 	public static void runGuidedCrawlingPlugins(CrawljaxController controller,
 	        CrawlSession session, final List<Eventable> exactEventPaths,
 	        final StateMachine stateMachine) {
-		if (PropertyHelper.getCrawljaxConfiguration() != null) {
+		if (CrawljaxPluginsUtil.plugins != null) {
 			StateVertix currentState = session.getCurrentState();
-			for (Plugin plugin : PropertyHelper.getCrawljaxConfiguration().getPlugins()) {
+			for (Plugin plugin : CrawljaxPluginsUtil.plugins) {
 				if (plugin instanceof GuidedCrawlingPlugin) {
 					((GuidedCrawlingPlugin) plugin).guidedCrawling(currentState, controller,
 					        session, exactEventPaths, stateMachine);
@@ -262,8 +265,8 @@
 	 *            the path TO this eventable.
 	 */
 	public static void runOnFireEventFailedPlugins(Eventable eventable, List<Eventable> path) {
-		if (PropertyHelper.getCrawljaxConfiguration() != null) {
-			for (Plugin plugin : PropertyHelper.getCrawljaxConfiguration().getPlugins()) {
+		if (CrawljaxPluginsUtil.plugins != null) {
+			for (Plugin plugin : CrawljaxPluginsUtil.plugins) {
 				if (plugin instanceof OnFireEventFailedPlugin) {
 					((OnFireEventFailedPlugin) plugin).onFireEventFaild(eventable, path);
 				}
"
5601de4989fd5bed9914569fe1a1f7867d8a2be5,Ali Mesbah,StateVertix.java,MODIFY,"searchForCandidateElements -> [CandidateElementExtractor candidateExtractor, List crawlTagElements, List crawlExcludeTagElements, boolean clickOnce, List eventTypes] | [CandidateElementExtractor candidateExtractor, List crawlTagElements, List crawlExcludeTagElements, boolean clickOnce]","diff --git a/src/main/java/com/crawljax/core/state/StateVertix.java b/src/main/java/com/crawljax/core/state/StateVertix.java
index 1a1bf12..2f8431c 100644
--- a/src/main/java/com/crawljax/core/state/StateVertix.java
+++ b/src/main/java/com/crawljax/core/state/StateVertix.java
@@ -243,12 +243,15 @@
 	 *            the elements to exclude.
 	 * @param clickOnce
 	 *            if true examine each element once.
-	 * @param eventTypes
-	 *            the event types.
 	 */
 	public void searchForCandidateElements(CandidateElementExtractor candidateExtractor,
 	        List<TagElement> crawlTagElements, List<TagElement> crawlExcludeTagElements,
-	        boolean clickOnce, List<String> eventTypes) {
+	        boolean clickOnce) {
+
+		// TODO read the eventtypes from the crawl elements instead
+		List<String> eventTypes = new ArrayList<String>();
+		eventTypes.add(EventType.click.toString());
+
 		if (candidateActions == null) {
 			candidateActions = new ArrayList<CandidateCrawlAction>();
 			try {
"
5601de4989fd5bed9914569fe1a1f7867d8a2be5,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index e557faa..6cc5d51 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -11,10 +11,14 @@
 
 import org.apache.log4j.Logger;
 import org.w3c.dom.Document;
+import org.w3c.dom.Element;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
 
 import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.condition.eventablecondition.EventableCondition;
+import com.crawljax.core.CandidateElement;
+import com.crawljax.core.configuration.InputSpecification;
 import com.crawljax.util.Helper;
 import com.crawljax.util.XPathHelper;
 
@@ -31,16 +35,26 @@
 	private boolean randomFieldValue = false;
 	private final EmbeddedBrowser browser;
 
+	public static final int RANDOM_STRING_LENGTH = 8;
+
 	private static final double HALF = 0.5;
 
+	private FormInputValueHelper formInputValueHelper;
+
 	/**
 	 * Public constructor.
 	 * 
 	 * @param browser
 	 *            the embedded browser.
+	 * @param inputSpecification
+	 *            the input specification.
+	 * @param randomInput
+	 *            if random data should be generated on the input fields.
 	 */
-	public FormHandler(EmbeddedBrowser browser) {
+	public FormHandler(EmbeddedBrowser browser, InputSpecification inputSpecification,
+	        boolean randomInput) {
 		this.browser = browser;
+		this.formInputValueHelper = new FormInputValueHelper(inputSpecification, randomInput);
 	}
 
 	private static final String[] ALLOWED_INPUT_TYPES =
@@ -183,7 +197,7 @@
 			List<Node> nodes = getInputElements(dom);
 			for (Node node : nodes) {
 				FormInput formInput =
-				        FormInputValueHelper.getFormInputWithDefaultValue(browser, node);
+				        formInputValueHelper.getFormInputWithDefaultValue(browser, node);
 				if (formInput != null) {
 					formInputs.add(formInput);
 				}
@@ -216,11 +230,25 @@
 			dom = Helper.getDocument(browser.getDom());
 			for (FormInput input : formInputs) {
 				LOGGER.debug(""Filling in: "" + input);
-				setInputElementValue(FormInputValueHelper.getBelongingNode(input, dom), input);
+				setInputElementValue(formInputValueHelper.getBelongingNode(input, dom), input);
 			}
 		} catch (Exception e) {
 			LOGGER.warn(""Could not handle form elements"");
 		}
 	}
 
+	/**
+	 * @param sourceElement
+	 *            the form element
+	 * @param eventableCondition
+	 *            the belonging eventable condition for sourceElement
+	 * @return a list with Candidate elements for the inputs.
+	 */
+	public List<CandidateElement> getCandidateElementsForInputs(Element sourceElement,
+	        EventableCondition eventableCondition) {
+
+		return formInputValueHelper.getCandidateElementsForInputs(browser, sourceElement,
+		        eventableCondition);
+	}
+
 }
"
bcc548a97d5e9e0fb8803a5f1740e5d06d817106,Ali Mesbah,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 2a5dd8e..9f6ac43 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -88,10 +88,10 @@
 	 * anchor tags All buttons
 	 */
 	public void lookForDefaultElements() {
-		crawlActions.lookFor(""a"");
-		crawlActions.lookFor(""button"");
-		crawlActions.lookFor(""input"").withAttribute(""type"", ""submit"");
-		crawlActions.lookFor(""input"").withAttribute(""type"", ""button"");
+		crawlActions.click(""a"");
+		crawlActions.click(""button"");
+		crawlActions.click(""input"").withAttribute(""type"", ""submit"");
+		crawlActions.click(""input"").withAttribute(""type"", ""button"");
 	}
 
 	/**
@@ -103,7 +103,7 @@
 	 * @return this CrawlElement
 	 */
 	public CrawlElement lookFor(String tagName) {
-		return crawlActions.lookFor(tagName);
+		return crawlActions.click(tagName);
 	}
 
 	/**
"
bcc548a97d5e9e0fb8803a5f1740e5d06d817106,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 675719c..72b92b0 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -5,15 +5,11 @@
 
 import org.apache.commons.configuration.Configuration;
 import org.apache.commons.configuration.PropertiesConfiguration;
-import org.openqa.selenium.WebDriver;
 
-import com.crawljax.browser.EmbeddedBrowser;
-import com.crawljax.browser.WebDriverFirefox;
-import com.crawljax.browser.WebDriverOther;
+import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.util.Helper;
-import com.crawljax.util.PropertyHelper;
 
 /**
  * Specifies the settings Crawljax. The methods in this class fall into two categories:Oz
@@ -28,7 +24,7 @@
  * {@link CrawljaxConfiguration#setHibernateConfiguration(HibernateConfiguration)} See also
  * {@link HibernateConfiguration}
  * <p/>
- * DEFAULT VAlUES: Browser: WebDriverFirefox Project Full Path: empty Project Relative Path: empty
+ * DEFAULT VAlUES: Browser: webdriver firefox Project Full Path: empty Project Relative Path: empty
  * Filter attributes: closure_hashcode_(\\w)*, jquery[0-9]+ Test invariants while crawling: true
  * EXAMPLE: CrawljaxConfiguration crawljaxConfig = new CrawljaxConfiguration(); CrawlSpecification
  * crawler = new CrawlSpecification(""http://www.google.com""); crawler.click(""a"");
@@ -38,7 +34,7 @@
  */
 public final class CrawljaxConfiguration {
 
-	private EmbeddedBrowser browser;
+	private BrowserType browser = BrowserType.firefox;
 
 	private String outputFolder = """";
 	private String projectRelativePath = """";
@@ -216,46 +212,21 @@
 	}
 
 	/**
-	 * @return The browser used to crawl. See {@link EmbeddedBrowser}. By default
-	 *         {@link WebDriverFirefox} is used.
+	 * @return The browser used to crawl. By default firefox is used.
 	 */
-	protected EmbeddedBrowser getBrowser() {
-		if (browser == null) {
-			if (PropertyHelper.getCrawljaxConfiguration() != null
-			        && PropertyHelper.getCrawljaxConfiguration().getProxyConfiguration() != null) {
-				browser =
-				        new WebDriverFirefox(PropertyHelper.getCrawljaxConfiguration()
-				                .getProxyConfiguration());
-			} else {
-				browser = new WebDriverFirefox();
-			}
-		}
+	protected BrowserType getBrowser() {
 		return browser;
 	}
 
 	/**
 	 * @param browser
-	 *            The browser used to crawl. See {@link EmbeddedBrowser}. By default
-	 *            {@link WebDriverFirefox} is used.
+	 *            The browser used to crawl.
 	 */
-	public void setBrowser(EmbeddedBrowser browser) {
+	public void setBrowser(BrowserType browser) {
 		this.browser = browser;
 	}
 
 	/**
-	 * Deprecated function to specify the browser used. Replaced by
-	 * {@link CrawljaxConfiguration#setBrowser(EmbeddedBrowser)}.
-	 * 
-	 * @see #setBrowser(EmbeddedBrowser)
-	 * @param driver
-	 *            The Webdriver driver used to crawl. By default {@link WebDriverFirefox} is used.
-	 */
-	@Deprecated
-	public void setBrowser(WebDriver driver) {
-		this.browser = new WebDriverOther(driver);
-	}
-
-	/**
 	 * @return The path of the outputFolder with a trailing slash.
 	 */
 	protected String getOutputFolder() {
"
bcc548a97d5e9e0fb8803a5f1740e5d06d817106,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index e557faa..6cc5d51 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -11,10 +11,14 @@
 
 import org.apache.log4j.Logger;
 import org.w3c.dom.Document;
+import org.w3c.dom.Element;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
 
 import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.condition.eventablecondition.EventableCondition;
+import com.crawljax.core.CandidateElement;
+import com.crawljax.core.configuration.InputSpecification;
 import com.crawljax.util.Helper;
 import com.crawljax.util.XPathHelper;
 
@@ -31,16 +35,26 @@
 	private boolean randomFieldValue = false;
 	private final EmbeddedBrowser browser;
 
+	public static final int RANDOM_STRING_LENGTH = 8;
+
 	private static final double HALF = 0.5;
 
+	private FormInputValueHelper formInputValueHelper;
+
 	/**
 	 * Public constructor.
 	 * 
 	 * @param browser
 	 *            the embedded browser.
+	 * @param inputSpecification
+	 *            the input specification.
+	 * @param randomInput
+	 *            if random data should be generated on the input fields.
 	 */
-	public FormHandler(EmbeddedBrowser browser) {
+	public FormHandler(EmbeddedBrowser browser, InputSpecification inputSpecification,
+	        boolean randomInput) {
 		this.browser = browser;
+		this.formInputValueHelper = new FormInputValueHelper(inputSpecification, randomInput);
 	}
 
 	private static final String[] ALLOWED_INPUT_TYPES =
@@ -183,7 +197,7 @@
 			List<Node> nodes = getInputElements(dom);
 			for (Node node : nodes) {
 				FormInput formInput =
-				        FormInputValueHelper.getFormInputWithDefaultValue(browser, node);
+				        formInputValueHelper.getFormInputWithDefaultValue(browser, node);
 				if (formInput != null) {
 					formInputs.add(formInput);
 				}
@@ -216,11 +230,25 @@
 			dom = Helper.getDocument(browser.getDom());
 			for (FormInput input : formInputs) {
 				LOGGER.debug(""Filling in: "" + input);
-				setInputElementValue(FormInputValueHelper.getBelongingNode(input, dom), input);
+				setInputElementValue(formInputValueHelper.getBelongingNode(input, dom), input);
 			}
 		} catch (Exception e) {
 			LOGGER.warn(""Could not handle form elements"");
 		}
 	}
 
+	/**
+	 * @param sourceElement
+	 *            the form element
+	 * @param eventableCondition
+	 *            the belonging eventable condition for sourceElement
+	 * @return a list with Candidate elements for the inputs.
+	 */
+	public List<CandidateElement> getCandidateElementsForInputs(Element sourceElement,
+	        EventableCondition eventableCondition) {
+
+		return formInputValueHelper.getCandidateElementsForInputs(browser, sourceElement,
+		        eventableCondition);
+	}
+
 }
"
7885b8071fad1500fa5cd9a937e3756589cf7733,Ali Mesbah,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 9f6ac43..b6f75a5 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -31,13 +31,13 @@
  * EXAMPLE:<br />
  * CrawlSpecification crawler = new CrawlSpecification(""http://www.google.com"");<br />
  * //click these elements<br />
- * crawler.lookFor(""a"");<br />
- * crawler.lookFor(""input"").withAttribute(""type"", ""submit"");<br />
+ * crawler.click(""a"");<br />
+ * crawler.click(""input"").withAttribute(""type"", ""submit"");<br />
  * onLoginPageCondition = new UrlCondition(""#login"");<br />
  * crawler.when(onLoginPageCondition).click(""a"").withText(""Login"");<br />
  * //but don't click these<br />
- * crawler.ignore(""a"").underXpath(""//DIV[@id='guser']"");
- * crawler.ignore(""a"").withText(""Language Tools""); <br />
+ * crawler.dontClick(""a"").underXpath(""//DIV[@id='guser']"");
+ * crawler.dontClick(""a"").withText(""Language Tools""); <br />
  * //restrict the scope of the crawling<br />
  * crawler.setCrawlMaximumStates(15);<br />
  * crawler.setCrawlDepth(2);
@@ -87,7 +87,7 @@
 	 * Specifies that Crawljax should click all the default clickable elements. These include: All
 	 * anchor tags All buttons
 	 */
-	public void lookForDefaultElements() {
+	public void clickDefaultElements() {
 		crawlActions.click(""a"");
 		crawlActions.click(""button"");
 		crawlActions.click(""input"").withAttribute(""type"", ""submit"");
@@ -96,13 +96,13 @@
 
 	/**
 	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
-	 * click(""a"") will only include 1 This set can be restricted by {@link #ignore(String)}.
+	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}.
 	 * 
 	 * @param tagName
 	 *            the tag name of the elements to be included
 	 * @return this CrawlElement
 	 */
-	public CrawlElement lookFor(String tagName) {
+	public CrawlElement click(String tagName) {
 		return crawlActions.click(tagName);
 	}
 
@@ -116,7 +116,7 @@
 	 *            the tag name of the elements to be excluded
 	 * @return this CrawlElement
 	 */
-	public CrawlElement ignore(String tagName) {
+	public CrawlElement dontClick(String tagName) {
 		return crawlActions.dontClick(tagName);
 	}
 
"
92611a9fbc62dd201759cf5ac46bcb59a1b0bdff,Ali Mesbah,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index b6f75a5..57aecc0 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -60,7 +60,6 @@
 	private int maximumRuntime = DEFAULT_MAXIMUMRUNTIME; // in seconds
 	private int waitTimeAfterReloadUrl = DEFAULT_WAITTIMEAFTERRELOADURL; // in milliseconds
 	private int waitTimeAfterEvent = DEFAULT_WAITTIMEAFTEREVENT; // in milliseconds
-	private int numberOfThreads = 1;
 	private final CrawlActions crawlActions = new CrawlActions();
 
 	private boolean randomInputInForms = true;
@@ -261,21 +260,6 @@
 	}
 
 	/**
-	 * @param numberOfThreads
-	 *            the numberOfThreads to set
-	 */
-	public void setNumberOfThreads(int numberOfThreads) {
-		this.numberOfThreads = numberOfThreads;
-	}
-
-	/**
-	 * @return the numberOfThreads
-	 */
-	public int getNumberOfThreads() {
-		return numberOfThreads;
-	}
-
-	/**
 	 * @return the different crawl actions.
 	 */
 	protected CrawlActions crawlActions() {
"
8398f64ee37467984428d3a8826eff187176b362,Stefan Lenselink,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index b6f75a5..57aecc0 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -60,7 +60,6 @@
 	private int maximumRuntime = DEFAULT_MAXIMUMRUNTIME; // in seconds
 	private int waitTimeAfterReloadUrl = DEFAULT_WAITTIMEAFTERRELOADURL; // in milliseconds
 	private int waitTimeAfterEvent = DEFAULT_WAITTIMEAFTEREVENT; // in milliseconds
-	private int numberOfThreads = 1;
 	private final CrawlActions crawlActions = new CrawlActions();
 
 	private boolean randomInputInForms = true;
@@ -261,21 +260,6 @@
 	}
 
 	/**
-	 * @param numberOfThreads
-	 *            the numberOfThreads to set
-	 */
-	public void setNumberOfThreads(int numberOfThreads) {
-		this.numberOfThreads = numberOfThreads;
-	}
-
-	/**
-	 * @return the numberOfThreads
-	 */
-	public int getNumberOfThreads() {
-		return numberOfThreads;
-	}
-
-	/**
 	 * @return the different crawl actions.
 	 */
 	protected CrawlActions crawlActions() {
"
8398f64ee37467984428d3a8826eff187176b362,Stefan Lenselink,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 72b92b0..24c9ca9 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -48,6 +48,7 @@
 	private CrawlSpecification crawlSpecification = new CrawlSpecification("""");
 	private HibernateConfiguration hibernateConfiguration = new HibernateConfiguration();
 	private ProxyConfiguration proxyConfiguration = null;
+	private ThreadConfiguration threadConfiguration = new ThreadConfiguration();
 
 	/**
 	 * Constructor.
@@ -122,7 +123,7 @@
 		config.addProperty(""crawl.max.runtime"", getCrawlSpecification().getMaximumRuntime());
 		config.addProperty(""crawl.forms.randominput"", ConfigurationHelper
 		        .booleanToInt(getCrawlSpecification().getRandomInputInForms()));
-		config.addProperty(""crawl.numberOfThreads"", getCrawlSpecification().getNumberOfThreads());
+		config.addProperty(""crawl.numberOfThreads"", getThreadConfiguration().getNumberThreads());
 
 		if (getProxyConfiguration() != null) {
 			config.addProperty(""proxy.enabled"", 1);
@@ -150,6 +151,21 @@
 	}
 
 	/**
+	 * @param threadConfiguration
+	 *            the threadConfiguration to set
+	 */
+	public void setThreadConfiguration(ThreadConfiguration threadConfiguration) {
+		this.threadConfiguration = threadConfiguration;
+	}
+
+	/**
+	 * @return the threadConfiguration
+	 */
+	protected ThreadConfiguration getThreadConfiguration() {
+		return threadConfiguration;
+	}
+
+	/**
 	 * @return All the included crawlTags.
 	 */
 	protected List<CrawlElement> getAllIncludedCrawlElements() {
"
9476a68face19f6ffbc954bd99ffdb6237cb2108,Ali Mesbah,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 96d5065..1502464 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -347,15 +347,18 @@
 	 *         text()
 	 */
 	public static String stripXPathToElement(String xpath) {
-		if (xpath.toLowerCase().indexOf(""/text()"") != -1) {
-			xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/text()""));
+		if (xpath != null && !xpath.equals("""")) {
+			if (xpath.toLowerCase().indexOf(""/text()"") != -1) {
+				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/text()""));
+			}
+			if (xpath.toLowerCase().indexOf(""/comment()"") != -1) {
+				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/comment()""));
+			}
+			if (xpath.indexOf(""@"") != -1) {
+				xpath = xpath.substring(0, xpath.indexOf(""@"") - 1);
+			}
 		}
-		if (xpath.toLowerCase().indexOf(""/comment()"") != -1) {
-			xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/comment()""));
-		}
-		if (xpath.indexOf(""@"") != -1) {
-			xpath = xpath.substring(0, xpath.indexOf(""@"") - 1);
-		}
+
 		return xpath;
 	}
 
"
61ca40c9fe3fab98e1319fa591fcdc9f840763ab,Ali Mesbah,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 96d5065..1502464 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -347,15 +347,18 @@
 	 *         text()
 	 */
 	public static String stripXPathToElement(String xpath) {
-		if (xpath.toLowerCase().indexOf(""/text()"") != -1) {
-			xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/text()""));
+		if (xpath != null && !xpath.equals("""")) {
+			if (xpath.toLowerCase().indexOf(""/text()"") != -1) {
+				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/text()""));
+			}
+			if (xpath.toLowerCase().indexOf(""/comment()"") != -1) {
+				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/comment()""));
+			}
+			if (xpath.indexOf(""@"") != -1) {
+				xpath = xpath.substring(0, xpath.indexOf(""@"") - 1);
+			}
 		}
-		if (xpath.toLowerCase().indexOf(""/comment()"") != -1) {
-			xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/comment()""));
-		}
-		if (xpath.indexOf(""@"") != -1) {
-			xpath = xpath.substring(0, xpath.indexOf(""@"") - 1);
-		}
+
 		return xpath;
 	}
 
"
d25f42a0416fcd8af6f067752750a05538d4720b,Ali Mesbah,StateFlowGraph.java,MODIFY,"addState -> [StateVertix stateVertix] | [StateVertix stateVertix, boolean correctName]","diff --git a/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index c8fdee2..1e4e852 100644
--- a/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -57,15 +57,36 @@
 	 * u.equals(v). If this graph already contains such vertex, the call leaves this graph unchanged
 	 * and returns false. In combination with the restriction on constructors, this ensures that
 	 * graphs never contain duplicate vertices. Throws java.lang.NullPointerException - if the
-	 * specified vertex is null.
+	 * specified vertex is null. This method automatically updates the state name to reflect the
+	 * internal state counter.
 	 * 
 	 * @param stateVertix
 	 *            the state to be added.
 	 * @return the clone if one is detected null otherwise.
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
-	@GuardedBy(""sfg"")
 	public StateVertix addState(StateVertix stateVertix) {
+		return addState(stateVertix, true);
+	}
+
+	/**
+	 * Adds a state (as a vertix) to the State-Flow Graph if not already present. More formally,
+	 * adds the specified vertex, v, to this graph if this graph contains no vertex u such that
+	 * u.equals(v). If this graph already contains such vertex, the call leaves this graph unchanged
+	 * and returns false. In combination with the restriction on constructors, this ensures that
+	 * graphs never contain duplicate vertices. Throws java.lang.NullPointerException - if the
+	 * specified vertex is null.
+	 * 
+	 * @param stateVertix
+	 *            the state to be added.
+	 * @param correctName
+	 *            if true the name of the state will be corrected according to the internal state
+	 *            counter.
+	 * @return the clone if one is detected null otherwise.
+	 * @see org.jgrapht.Graph#addVertex(Object)
+	 */
+	@GuardedBy(""sfg"")
+	public StateVertix addState(StateVertix stateVertix, boolean correctName) {
 		synchronized (sfg) {
 			if (!sfg.addVertex(stateVertix)) {
 				// Graph already contained the vertix
@@ -76,15 +97,17 @@
 				 * is the only place states can be added and we are now locked so getAllStates.size
 				 * works correctly.
 				 */
-				// the -1 is for the ""index"" state.
-				int totalNumberOfStates = this.getAllStates().size() - 1;
-				String correctName =
-				        makeStateName(totalNumberOfStates, stateVertix.isGuidedCrawling());
-				if (!stateVertix.getName().equals(""index"")
-				        && !stateVertix.getName().equals(correctName)) {
-					LOGGER.info(""Correcting state name from  "" + stateVertix.getName() + "" to ""
-					        + correctName);
-					stateVertix.setName(correctName);
+				if (correctName) {
+					// the -1 is for the ""index"" state.
+					int totalNumberOfStates = this.getAllStates().size() - 1;
+					String correctedName =
+					        makeStateName(totalNumberOfStates, stateVertix.isGuidedCrawling());
+					if (!stateVertix.getName().equals(""index"")
+					        && !stateVertix.getName().equals(correctedName)) {
+						LOGGER.info(""Correcting state name from  "" + stateVertix.getName()
+						        + "" to "" + correctedName);
+						stateVertix.setName(correctedName);
+					}
 				}
 			}
 			stateCounter.set(this.getAllStates().size() - 1);
"
8dcca8b91af59bb84758eddb801f96fe2b89c5fc,Ali Mesbah,StateFlowGraph.java,MODIFY,"addState -> [StateVertix stateVertix, boolean correctName] | [StateVertix stateVertix]","diff --git a/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index c8fdee2..1e4e852 100644
--- a/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -57,15 +57,36 @@
 	 * u.equals(v). If this graph already contains such vertex, the call leaves this graph unchanged
 	 * and returns false. In combination with the restriction on constructors, this ensures that
 	 * graphs never contain duplicate vertices. Throws java.lang.NullPointerException - if the
-	 * specified vertex is null.
+	 * specified vertex is null. This method automatically updates the state name to reflect the
+	 * internal state counter.
 	 * 
 	 * @param stateVertix
 	 *            the state to be added.
 	 * @return the clone if one is detected null otherwise.
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
-	@GuardedBy(""sfg"")
 	public StateVertix addState(StateVertix stateVertix) {
+		return addState(stateVertix, true);
+	}
+
+	/**
+	 * Adds a state (as a vertix) to the State-Flow Graph if not already present. More formally,
+	 * adds the specified vertex, v, to this graph if this graph contains no vertex u such that
+	 * u.equals(v). If this graph already contains such vertex, the call leaves this graph unchanged
+	 * and returns false. In combination with the restriction on constructors, this ensures that
+	 * graphs never contain duplicate vertices. Throws java.lang.NullPointerException - if the
+	 * specified vertex is null.
+	 * 
+	 * @param stateVertix
+	 *            the state to be added.
+	 * @param correctName
+	 *            if true the name of the state will be corrected according to the internal state
+	 *            counter.
+	 * @return the clone if one is detected null otherwise.
+	 * @see org.jgrapht.Graph#addVertex(Object)
+	 */
+	@GuardedBy(""sfg"")
+	public StateVertix addState(StateVertix stateVertix, boolean correctName) {
 		synchronized (sfg) {
 			if (!sfg.addVertex(stateVertix)) {
 				// Graph already contained the vertix
@@ -76,15 +97,17 @@
 				 * is the only place states can be added and we are now locked so getAllStates.size
 				 * works correctly.
 				 */
-				// the -1 is for the ""index"" state.
-				int totalNumberOfStates = this.getAllStates().size() - 1;
-				String correctName =
-				        makeStateName(totalNumberOfStates, stateVertix.isGuidedCrawling());
-				if (!stateVertix.getName().equals(""index"")
-				        && !stateVertix.getName().equals(correctName)) {
-					LOGGER.info(""Correcting state name from  "" + stateVertix.getName() + "" to ""
-					        + correctName);
-					stateVertix.setName(correctName);
+				if (correctName) {
+					// the -1 is for the ""index"" state.
+					int totalNumberOfStates = this.getAllStates().size() - 1;
+					String correctedName =
+					        makeStateName(totalNumberOfStates, stateVertix.isGuidedCrawling());
+					if (!stateVertix.getName().equals(""index"")
+					        && !stateVertix.getName().equals(correctedName)) {
+						LOGGER.info(""Correcting state name from  "" + stateVertix.getName()
+						        + "" to "" + correctedName);
+						stateVertix.setName(correctedName);
+					}
 				}
 			}
 			stateCounter.set(this.getAllStates().size() - 1);
"
ad564521c754176f685e99e008565c17cb574486,Ali Mesbah,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 51ff159..862e882 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -81,11 +81,9 @@
 	private static String baseUrlValue;
 	private static int crawlDepthValue;
 	private static List<String> robotEventsValues;
-	private static List<String> crawlTagsValues;
 	private static List<String> crawlFilterAttributesValues;
 	private static List<TagElement> crawlTagElements = new ArrayList<TagElement>();
 	private static List<TagElement> crawlExcludeTagElements = new ArrayList<TagElement>();
-	private static List<String> atusaPluginsValues;
 	private static int crawlMaxStatesValue = 0;
 	private static int crawlMaxTimeValue = 0;
 
@@ -159,7 +157,6 @@
 		crawNumberOfThreadsValue = getPropertyAsInt(crawlNumberOfThreads);
 		// crawlThreholdValue = getPropertyAsDouble(crawlThrehold);
 		robotEventsValues = getPropertyAsList(robotEvents);
-		crawlTagsValues = getPropertyAsList(crawlTags);
 		crawlFilterAttributesValues = getPropertyAsList(crawlFilterAttributes);
 		browserValue = getProperty(browser);
 		crawlWaitReloadValue = getPropertyAsInt(crawlWaitReload);
"
b06f5f15bf0a0c4a84bb51dcd23e77e5af202410,Frank Groeneveld,PropertyHelper.java,MODIFY,init -> [Configuration configuration] | [String propertiesFile],"diff --git a/src/main/java/com/crawljax/util/PropertyHelper.java b/src/main/java/com/crawljax/util/PropertyHelper.java
index 51ff159..862e882 100644
--- a/src/main/java/com/crawljax/util/PropertyHelper.java
+++ b/src/main/java/com/crawljax/util/PropertyHelper.java
@@ -81,11 +81,9 @@
 	private static String baseUrlValue;
 	private static int crawlDepthValue;
 	private static List<String> robotEventsValues;
-	private static List<String> crawlTagsValues;
 	private static List<String> crawlFilterAttributesValues;
 	private static List<TagElement> crawlTagElements = new ArrayList<TagElement>();
 	private static List<TagElement> crawlExcludeTagElements = new ArrayList<TagElement>();
-	private static List<String> atusaPluginsValues;
 	private static int crawlMaxStatesValue = 0;
 	private static int crawlMaxTimeValue = 0;
 
@@ -159,7 +157,6 @@
 		crawNumberOfThreadsValue = getPropertyAsInt(crawlNumberOfThreads);
 		// crawlThreholdValue = getPropertyAsDouble(crawlThrehold);
 		robotEventsValues = getPropertyAsList(robotEvents);
-		crawlTagsValues = getPropertyAsList(crawlTags);
 		crawlFilterAttributesValues = getPropertyAsList(crawlFilterAttributes);
 		browserValue = getProperty(browser);
 		crawlWaitReloadValue = getPropertyAsInt(crawlWaitReload);
"
5762ed3db757e1f9eec24e89a9513d140fd11a4b,Ali Mesbah,EmbeddedBrowser.java,MODIFY,"input -> [Eventable eventable, String text] | [Identification identification, String text]","diff --git a/src/main/java/com/crawljax/browser/EmbeddedBrowser.java b/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
index 29ce235..6339305 100644
--- a/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
@@ -78,15 +78,15 @@
 	void goBack();
 
 	/**
-	 * @param eventable
-	 *            the event.
+	 * @param identification
+	 *            the identification.
 	 * @param text
 	 *            the text.
 	 * @return true if succeeded.
 	 * @throws CrawljaxException
 	 *             if fails.
 	 */
-	boolean input(Eventable eventable, String text) throws CrawljaxException;
+	boolean input(Identification identification, String text) throws CrawljaxException;
 
 	/**
 	 * Execute JavaScript in the browser.
"
e66e4136ca73c875b41232d455934c756af9c971,Ali Mesbah,AbstractWebDriver.java,MODIFY,"input -> [Eventable clickable, String text] | [Identification identification, String text]","diff --git a/src/main/java/com/crawljax/browser/AbstractWebDriver.java b/src/main/java/com/crawljax/browser/AbstractWebDriver.java
index 8911639..f2e5e65 100644
--- a/src/main/java/com/crawljax/browser/AbstractWebDriver.java
+++ b/src/main/java/com/crawljax/browser/AbstractWebDriver.java
@@ -220,8 +220,8 @@
 	 *            The input.
 	 * @return true if succeeds.
 	 */
-	public boolean input(Eventable clickable, String text) {
-		WebElement field = browser.findElement(clickable.getIdentification().getWebDriverBy());
+	public boolean input(Identification identification, String text) {
+		WebElement field = browser.findElement(identification.getWebDriverBy());
 
 		if (field != null) {
 			field.sendKeys(text);
@@ -244,12 +244,12 @@
 	 */
 	public synchronized boolean fireEvent(Eventable eventable) throws CrawljaxException {
 		try {
-			String handle = browser.getWindowHandle();
 
 			boolean handleChanged = false;
 			boolean result = false;
 
 			if (eventable.getRelatedFrame() != null && !eventable.getRelatedFrame().equals("""")) {
+				logger.debug(""switching to frame: "" + eventable.getRelatedFrame());
 				browser.switchTo().frame(eventable.getRelatedFrame());
 				handleChanged = true;
 			}
@@ -262,7 +262,7 @@
 			}
 
 			if (handleChanged) {
-				browser.switchTo().window(handle);
+				browser.switchTo().defaultContent();
 			}
 
 			return result;
@@ -319,12 +319,14 @@
 
 	@Override
 	public void closeOtherWindows() {
+		String current = browser.getWindowHandle();
 		for (String handle : browser.getWindowHandles()) {
 			if (!handle.equals(browser.getWindowHandle())) {
-				String current = browser.getWindowHandle();
+
 				browser.switchTo().window(handle);
 				logger.info(""Closing other window with title \"""" + browser.getTitle() + ""\"""");
 				browser.close();
+				// browser.switchTo().defaultContent();
 				browser.switchTo().window(current);
 			}
 		}
@@ -343,8 +345,7 @@
 		Document document;
 		try {
 			document = Helper.getDocument(browser.getPageSource());
-			appendFrameContent(browser.getWindowHandle(), document.getDocumentElement(),
-			        document, """");
+			appendFrameContent(document.getDocumentElement(), document, """");
 		} catch (SAXException e) {
 			throw new CrawljaxException(e.getMessage(), e);
 		} catch (IOException e) {
@@ -354,13 +355,11 @@
 		return document;
 	}
 
-	private void appendFrameContent(String windowHandle, Element orig, Document document,
-	        String topFrame) throws SAXException, IOException {
+	private void appendFrameContent(Element orig, Document document, String topFrame)
+	        throws SAXException, IOException {
 
 		NodeList frameNodes = orig.getElementsByTagName(""IFRAME"");
 
-		browser.switchTo().window(windowHandle);
-
 		List<Element> nodeList = new ArrayList<Element>();
 
 		for (int i = 0; i < frameNodes.getLength(); i++) {
@@ -382,15 +381,25 @@
 			if (nameId != null) {
 				frameIdentification += nameId;
 
-				logger.debug(""frame-identification: "" + frameIdentification);
+				String handle = new String(browser.getWindowHandle());
 
-				String toAppend = browser.switchTo().frame(frameIdentification).getPageSource();
+				logger.debug(""The current H: "" + handle);
+
+				logger.debug(""switching to frame: "" + frameIdentification);
+				browser.switchTo().frame(frameIdentification);
+				String toAppend = new String(browser.getPageSource());
+
+				logger.debug(""frame dom: "" + toAppend);
+
+				browser.switchTo().defaultContent();
+
+				logger.debug(""default handle window source: "" + browser.getPageSource());
 
 				Element toAppendElement = Helper.getDocument(toAppend).getDocumentElement();
 				Element importedElement = (Element) document.importNode(toAppendElement, true);
 				frameElement.appendChild(importedElement);
 
-				appendFrameContent(windowHandle, importedElement, document, frameIdentification);
+				appendFrameContent(importedElement, document, frameIdentification);
 			}
 		}
 
@@ -405,7 +414,11 @@
 	public String getDomWithoutIframeContent() throws CrawljaxException {
 
 		try {
-			return toUniformDOM(browser.getPageSource());
+			String dom = browser.getPageSource();
+			// logger.debug(""driver.source: "" + dom);
+			String result = toUniformDOM(dom);
+			// logger.debug(""driver.source toUniformDom: "" + result);
+			return result;
 		} catch (Exception e) {
 			throw new CrawljaxException(e.getMessage(), e);
 		}
@@ -468,14 +481,14 @@
 
 	@Override
 	public String getFrameDom(String iframeIdentification) {
-		String handle = browser.getWindowHandle();
 
+		logger.debug(""switching to frame: "" + iframeIdentification);
 		browser.switchTo().frame(iframeIdentification);
 
 		// make a copy of the dom before changing into the top page
 		String frameDom = new String(browser.getPageSource());
 
-		browser.switchTo().window(handle);
+		browser.switchTo().defaultContent();
 
 		return frameDom;
 	}
"
298415dc89c125183c879563e33576cf09c140d2,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 6cc5d51..5db2134 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -227,7 +227,7 @@
 	public void handleFormElements(List<FormInput> formInputs) {
 		Document dom;
 		try {
-			dom = Helper.getDocument(browser.getDom());
+			dom = Helper.getDocument(browser.getDomWithoutIframeContent());
 			for (FormInput input : formInputs) {
 				LOGGER.debug(""Filling in: "" + input);
 				setInputElementValue(formInputValueHelper.getBelongingNode(input, dom), input);
"
aee035325b20c81ad57caf0731f75c820687106d,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 6cc5d51..5db2134 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -227,7 +227,7 @@
 	public void handleFormElements(List<FormInput> formInputs) {
 		Document dom;
 		try {
-			dom = Helper.getDocument(browser.getDom());
+			dom = Helper.getDocument(browser.getDomWithoutIframeContent());
 			for (FormInput input : formInputs) {
 				LOGGER.debug(""Filling in: "" + input);
 				setInputElementValue(formInputValueHelper.getBelongingNode(input, dom), input);
"
8a275901de20563a207b2002ef9178c598632d80,Ali Mesbah,DummyBrowser.java,MODIFY,"input -> [Eventable eventable, String text] | [Identification eventable, String text]","diff --git a/src/test/java/com/crawljax/browser/DummyBrowser.java b/src/test/java/com/crawljax/browser/DummyBrowser.java
index 60d6893..b870738 100644
--- a/src/test/java/com/crawljax/browser/DummyBrowser.java
+++ b/src/test/java/com/crawljax/browser/DummyBrowser.java
@@ -63,7 +63,7 @@
 	}
 
 	@Override
-	public boolean input(Eventable eventable, String text) throws CrawljaxException {
+	public boolean input(Identification eventable, String text) throws CrawljaxException {
 		return false;
 	}
 
"
cd2cd0a52bd16f305cce7520970d54ed7faf6f00,Ali Mesbah,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 1502464..a691a17 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -71,13 +71,13 @@
 	}
 
 	/**
-	 * TODO: DOCUMENT ME!
+	 * Get siblings of the same type as element from parent
 	 * 
 	 * @param parent
 	 *            parent node.
 	 * @param element
 	 *            element.
-	 * @return
+	 * @return List of sibling (from element) under parent
 	 */
 	private static List<Node> getSiblings(Node parent, Node element) {
 		List<Node> result = new ArrayList<Node>();
@@ -190,11 +190,6 @@
 		return formatted;
 	}
 
-	// public static void main(String[] args) {
-	// System.out.println(formatXPath(""//DIV[@class='foo']""));
-	// System.out.println(formatXPath(""/jeee/JEUJ/fooo/div[@KWAAK=\""false\""]""));
-	// }
-
 	/**
 	 * @param xpath
 	 *            The xpath expression to find the last element of.
"
c3f83cc25b3acab94d44c3b4b0606377e6b49362,Frank Groeneveld,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 1502464..a691a17 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -71,13 +71,13 @@
 	}
 
 	/**
-	 * TODO: DOCUMENT ME!
+	 * Get siblings of the same type as element from parent
 	 * 
 	 * @param parent
 	 *            parent node.
 	 * @param element
 	 *            element.
-	 * @return
+	 * @return List of sibling (from element) under parent
 	 */
 	private static List<Node> getSiblings(Node parent, Node element) {
 		List<Node> result = new ArrayList<Node>();
@@ -190,11 +190,6 @@
 		return formatted;
 	}
 
-	// public static void main(String[] args) {
-	// System.out.println(formatXPath(""//DIV[@class='foo']""));
-	// System.out.println(formatXPath(""/jeee/JEUJ/fooo/div[@KWAAK=\""false\""]""));
-	// }
-
 	/**
 	 * @param xpath
 	 *            The xpath expression to find the last element of.
"
7cb077f316b0e4433eb218f228287d5610631f40,Frank Groeneveld,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index a691a17..7c742f9 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -17,6 +17,7 @@
 
 import org.apache.log4j.Logger;
 import org.w3c.dom.Document;
+import org.w3c.dom.NamedNodeMap;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
 
@@ -71,6 +72,75 @@
 	}
 
 	/**
+	 * Reverse Engineers an XPath Expression of a given Node in the DOM. This method is more
+	 * specific than getXpathExpression because it also adds the attributes of the nodes to the
+	 * expression.
+	 * 
+	 * @param node
+	 *            the given node.
+	 * @return string xpath expression (e.g.,
+	 *         ""/html[1]/body[1][@class=""content""]/div[3][@class=""sidebar""]"").
+	 */
+	public static String getSpecificXpathExpression(Node node) {
+		Node parent = node.getParentNode();
+
+		if ((parent == null) || parent.getNodeName().contains(""#document"")) {
+			return ""/"" + getXPathNameStep(node) + ""[1]"";
+		}
+
+		StringBuffer buffer = new StringBuffer();
+
+		if (parent != node) {
+			buffer.append(getSpecificXpathExpression(parent));
+			buffer.append(""/"");
+		}
+
+		buffer.append(getXPathNameStep(node));
+
+		List<Node> mySiblings = getSiblings(parent, node);
+
+		for (int i = 0; i < mySiblings.size(); i++) {
+			Node el = mySiblings.get(i);
+
+			if (el.equals(node)) {
+				buffer.append(""["");
+				buffer.append(Integer.toString(i + 1));
+				buffer.append(""]"");
+				NamedNodeMap attribs = node.getAttributes();
+				if (attribs.getLength() != 0) {
+					StringBuilder attrBuffer = new StringBuilder();
+
+					for (int j = 0; j < attribs.getLength(); j++) {
+						Node attrib = attribs.item(i);
+
+						if (attrib == null) {
+							continue;
+						}
+
+						if (j != 0) {
+							attrBuffer.append("" and "");
+						}
+
+						attrBuffer.append(""@"" + attrib.getNodeName() + ""=\"""");
+						attrBuffer.append(attrib.getNodeValue() + ""\"""");
+					}
+
+					/*
+					 * only append [ ... ] if there really were attributes (ie, the list of attribs
+					 * might not be empty, but there can be NULL's in there
+					 */
+					if (attrBuffer.length() != 0) {
+						buffer.append(""["");
+						buffer.append(attrBuffer);
+						buffer.append(""]"");
+					}
+				}
+			}
+		}
+		return buffer.toString();
+	}
+
+	/**
 	 * Get siblings of the same type as element from parent
 	 * 
 	 * @param parent
"
a5a81869d07a5d887873913de57a128a476c265d,Ali Mesbah,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 7c742f9..24baf19 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -107,33 +107,23 @@
 				buffer.append(Integer.toString(i + 1));
 				buffer.append(""]"");
 				NamedNodeMap attribs = node.getAttributes();
-				if (attribs.getLength() != 0) {
-					StringBuilder attrBuffer = new StringBuilder();
-
+				if (attribs.getLength() > 0) {
+					buffer.append(""["");
 					for (int j = 0; j < attribs.getLength(); j++) {
-						Node attrib = attribs.item(i);
+						Node attrib = attribs.item(j);
 
 						if (attrib == null) {
 							continue;
 						}
 
 						if (j != 0) {
-							attrBuffer.append("" and "");
+							buffer.append("" and "");
 						}
 
-						attrBuffer.append(""@"" + attrib.getNodeName() + ""=\"""");
-						attrBuffer.append(attrib.getNodeValue() + ""\"""");
+						buffer.append(""@"" + attrib.getNodeName() + ""=\"""");
+						buffer.append(attrib.getNodeValue() + ""\"""");
 					}
-
-					/*
-					 * only append [ ... ] if there really were attributes (ie, the list of attribs
-					 * might not be empty, but there can be NULL's in there
-					 */
-					if (attrBuffer.length() != 0) {
-						buffer.append(""["");
-						buffer.append(attrBuffer);
-						buffer.append(""]"");
-					}
+					buffer.append(""]"");
 				}
 			}
 		}
"
15c2b06c941a148ed730de400e2e019b259190e4,Frank Groeneveld,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 7c742f9..24baf19 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -107,33 +107,23 @@
 				buffer.append(Integer.toString(i + 1));
 				buffer.append(""]"");
 				NamedNodeMap attribs = node.getAttributes();
-				if (attribs.getLength() != 0) {
-					StringBuilder attrBuffer = new StringBuilder();
-
+				if (attribs.getLength() > 0) {
+					buffer.append(""["");
 					for (int j = 0; j < attribs.getLength(); j++) {
-						Node attrib = attribs.item(i);
+						Node attrib = attribs.item(j);
 
 						if (attrib == null) {
 							continue;
 						}
 
 						if (j != 0) {
-							attrBuffer.append("" and "");
+							buffer.append("" and "");
 						}
 
-						attrBuffer.append(""@"" + attrib.getNodeName() + ""=\"""");
-						attrBuffer.append(attrib.getNodeValue() + ""\"""");
+						buffer.append(""@"" + attrib.getNodeName() + ""=\"""");
+						buffer.append(attrib.getNodeValue() + ""\"""");
 					}
-
-					/*
-					 * only append [ ... ] if there really were attributes (ie, the list of attribs
-					 * might not be empty, but there can be NULL's in there
-					 */
-					if (attrBuffer.length() != 0) {
-						buffer.append(""["");
-						buffer.append(attrBuffer);
-						buffer.append(""]"");
-					}
+					buffer.append(""]"");
 				}
 			}
 		}
"
4c6575f33789f114cae3ee31fc22216248be793f,Ali Mesbah,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 24baf19..0a19952 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -17,7 +17,6 @@
 
 import org.apache.log4j.Logger;
 import org.w3c.dom.Document;
-import org.w3c.dom.NamedNodeMap;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
 
@@ -45,7 +44,7 @@
 		Node parent = node.getParentNode();
 
 		if ((parent == null) || parent.getNodeName().contains(""#document"")) {
-			return ""/"" + getXPathNameStep(node) + ""[1]"";
+			return ""/"" + node.getNodeName() + ""[1]"";
 		}
 
 		StringBuffer buffer = new StringBuffer();
@@ -55,7 +54,7 @@
 			buffer.append(""/"");
 		}
 
-		buffer.append(getXPathNameStep(node));
+		buffer.append(node.getNodeName());
 
 		List<Node> mySiblings = getSiblings(parent, node);
 
@@ -72,65 +71,6 @@
 	}
 
 	/**
-	 * Reverse Engineers an XPath Expression of a given Node in the DOM. This method is more
-	 * specific than getXpathExpression because it also adds the attributes of the nodes to the
-	 * expression.
-	 * 
-	 * @param node
-	 *            the given node.
-	 * @return string xpath expression (e.g.,
-	 *         ""/html[1]/body[1][@class=""content""]/div[3][@class=""sidebar""]"").
-	 */
-	public static String getSpecificXpathExpression(Node node) {
-		Node parent = node.getParentNode();
-
-		if ((parent == null) || parent.getNodeName().contains(""#document"")) {
-			return ""/"" + getXPathNameStep(node) + ""[1]"";
-		}
-
-		StringBuffer buffer = new StringBuffer();
-
-		if (parent != node) {
-			buffer.append(getSpecificXpathExpression(parent));
-			buffer.append(""/"");
-		}
-
-		buffer.append(getXPathNameStep(node));
-
-		List<Node> mySiblings = getSiblings(parent, node);
-
-		for (int i = 0; i < mySiblings.size(); i++) {
-			Node el = mySiblings.get(i);
-
-			if (el.equals(node)) {
-				buffer.append(""["");
-				buffer.append(Integer.toString(i + 1));
-				buffer.append(""]"");
-				NamedNodeMap attribs = node.getAttributes();
-				if (attribs.getLength() > 0) {
-					buffer.append(""["");
-					for (int j = 0; j < attribs.getLength(); j++) {
-						Node attrib = attribs.item(j);
-
-						if (attrib == null) {
-							continue;
-						}
-
-						if (j != 0) {
-							buffer.append("" and "");
-						}
-
-						buffer.append(""@"" + attrib.getNodeName() + ""=\"""");
-						buffer.append(attrib.getNodeValue() + ""\"""");
-					}
-					buffer.append(""]"");
-				}
-			}
-		}
-		return buffer.toString();
-	}
-
-	/**
 	 * Get siblings of the same type as element from parent
 	 * 
 	 * @param parent
@@ -139,7 +79,7 @@
 	 *            element.
 	 * @return List of sibling (from element) under parent
 	 */
-	private static List<Node> getSiblings(Node parent, Node element) {
+	public static List<Node> getSiblings(Node parent, Node element) {
 		List<Node> result = new ArrayList<Node>();
 		NodeList list = parent.getChildNodes();
 
@@ -154,10 +94,6 @@
 		return result;
 	}
 
-	private static String getXPathNameStep(Node element) {
-		return element.getNodeName();
-	}
-
 	/**
 	 * Returns the list of nodes which match the expression xpathExpr in the String domStr.
 	 * 
"
06ef82b008b07b99cb6a0f23b309f3b5bb8ee981,Frank Groeneveld,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 24baf19..0a19952 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -17,7 +17,6 @@
 
 import org.apache.log4j.Logger;
 import org.w3c.dom.Document;
-import org.w3c.dom.NamedNodeMap;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
 
@@ -45,7 +44,7 @@
 		Node parent = node.getParentNode();
 
 		if ((parent == null) || parent.getNodeName().contains(""#document"")) {
-			return ""/"" + getXPathNameStep(node) + ""[1]"";
+			return ""/"" + node.getNodeName() + ""[1]"";
 		}
 
 		StringBuffer buffer = new StringBuffer();
@@ -55,7 +54,7 @@
 			buffer.append(""/"");
 		}
 
-		buffer.append(getXPathNameStep(node));
+		buffer.append(node.getNodeName());
 
 		List<Node> mySiblings = getSiblings(parent, node);
 
@@ -72,65 +71,6 @@
 	}
 
 	/**
-	 * Reverse Engineers an XPath Expression of a given Node in the DOM. This method is more
-	 * specific than getXpathExpression because it also adds the attributes of the nodes to the
-	 * expression.
-	 * 
-	 * @param node
-	 *            the given node.
-	 * @return string xpath expression (e.g.,
-	 *         ""/html[1]/body[1][@class=""content""]/div[3][@class=""sidebar""]"").
-	 */
-	public static String getSpecificXpathExpression(Node node) {
-		Node parent = node.getParentNode();
-
-		if ((parent == null) || parent.getNodeName().contains(""#document"")) {
-			return ""/"" + getXPathNameStep(node) + ""[1]"";
-		}
-
-		StringBuffer buffer = new StringBuffer();
-
-		if (parent != node) {
-			buffer.append(getSpecificXpathExpression(parent));
-			buffer.append(""/"");
-		}
-
-		buffer.append(getXPathNameStep(node));
-
-		List<Node> mySiblings = getSiblings(parent, node);
-
-		for (int i = 0; i < mySiblings.size(); i++) {
-			Node el = mySiblings.get(i);
-
-			if (el.equals(node)) {
-				buffer.append(""["");
-				buffer.append(Integer.toString(i + 1));
-				buffer.append(""]"");
-				NamedNodeMap attribs = node.getAttributes();
-				if (attribs.getLength() > 0) {
-					buffer.append(""["");
-					for (int j = 0; j < attribs.getLength(); j++) {
-						Node attrib = attribs.item(j);
-
-						if (attrib == null) {
-							continue;
-						}
-
-						if (j != 0) {
-							buffer.append("" and "");
-						}
-
-						buffer.append(""@"" + attrib.getNodeName() + ""=\"""");
-						buffer.append(attrib.getNodeValue() + ""\"""");
-					}
-					buffer.append(""]"");
-				}
-			}
-		}
-		return buffer.toString();
-	}
-
-	/**
 	 * Get siblings of the same type as element from parent
 	 * 
 	 * @param parent
@@ -139,7 +79,7 @@
 	 *            element.
 	 * @return List of sibling (from element) under parent
 	 */
-	private static List<Node> getSiblings(Node parent, Node element) {
+	public static List<Node> getSiblings(Node parent, Node element) {
 		List<Node> result = new ArrayList<Node>();
 		NodeList list = parent.getChildNodes();
 
@@ -154,10 +94,6 @@
 		return result;
 	}
 
-	private static String getXPathNameStep(Node element) {
-		return element.getNodeName();
-	}
-
 	/**
 	 * Returns the list of nodes which match the expression xpathExpr in the String domStr.
 	 * 
"
79ab668b0bc423a8585bbd25b37fb8fc5141824e,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 24c9ca9..0a27152 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -46,7 +46,7 @@
 	private List<Plugin> plugins = new ArrayList<Plugin>();
 
 	private CrawlSpecification crawlSpecification = new CrawlSpecification("""");
-	private HibernateConfiguration hibernateConfiguration = new HibernateConfiguration();
+	private HibernateConfiguration hibernateConfiguration = null;
 	private ProxyConfiguration proxyConfiguration = null;
 	private ThreadConfiguration threadConfiguration = new ThreadConfiguration();
 
"
79ab668b0bc423a8585bbd25b37fb8fc5141824e,Ali Mesbah,HibernateUtil.java,MODIFY,initialize -> [String hbm2ddlAuto] | [],"diff --git a/src/main/java/com/crawljax/util/database/HibernateUtil.java b/src/main/java/com/crawljax/util/database/HibernateUtil.java
index 185f6fe..9187dbb 100644
--- a/src/main/java/com/crawljax/util/database/HibernateUtil.java
+++ b/src/main/java/com/crawljax/util/database/HibernateUtil.java
@@ -1,6 +1,5 @@
 package com.crawljax.util.database;
 
-import java.io.FileInputStream;
 import java.util.Properties;
 
 import org.apache.log4j.Logger;
@@ -10,8 +9,8 @@
 import org.hibernate.Transaction;
 import org.hibernate.cfg.Configuration;
 
+import com.crawljax.core.configuration.HibernateConfiguration;
 import com.crawljax.core.state.Eventable;
-import com.crawljax.util.PropertyHelper;
 
 /**
  * Hibernate Utility class.
@@ -21,6 +20,8 @@
  */
 public final class HibernateUtil {
 
+	private static HibernateConfiguration hibernateConfig;
+
 	private HibernateUtil() {
 
 	}
@@ -33,12 +34,7 @@
 	 * @return Whether to use the database.
 	 */
 	public static boolean useDatabase() {
-		if (PropertyHelper.getCrawljaxConfiguration() == null) {
-			return PropertyHelper.useDatabase();
-		}
-
-		return PropertyHelper.getCrawljaxConfiguration().getUseDatabase();
-
+		return hibernateConfig != null;
 	}
 
 	/**
@@ -54,33 +50,23 @@
 	 * @param hbm2ddlAuto
 	 *            Whether to create, update, drop the tables first.
 	 */
-	public static void initialize(String hbm2ddlAuto) {
+	public static void initialize(HibernateConfiguration hibConfig) {
+		hibernateConfig = hibConfig;
+
 		if (!useDatabase()) {
 			return;
 		}
+
 		try {
 			Configuration config = new Configuration();
 			Properties p = new Properties();
-			if (PropertyHelper.getCrawljaxConfiguration() == null) {
-				// load from file
-				LOGGER.info(""Loading Hibernate config from: ""
-				        + PropertyHelper.getHibernatePropertiesValue());
-				p.load(new FileInputStream(PropertyHelper.getHibernatePropertiesValue()));
-			} else {
-				// load from config
-				LOGGER.info(""Loading Hibernate config from CrawljaxConfiguration"");
-				p.load(PropertyHelper.getCrawljaxConfiguration().getHibernateConfiguration()
-				        .getConfiguration());
 
-			}
+			// load from config
+			LOGGER.info(""Loading Hibernate config from CrawljaxConfiguration"");
+			p.load(hibConfig.getConfiguration());
+
 			config.setProperties(p);
 
-			if (hbm2ddlAuto != null && !"""".equals(hbm2ddlAuto)) {
-				config.setProperty(""hibernate.hbm2ddl.auto"", hbm2ddlAuto);
-			} else {
-				config.setProperty(""hibernate.hbm2ddl.auto"", PropertyHelper
-				        .getHibernateSchemaValue());
-			}
 			sessionFactory = config.configure().buildSessionFactory();
 		} catch (Throwable ex) {
 			LOGGER.fatal(""Initial SessionFactory creation failed."" + ex);
"
0ecdc3425d02894268cb495f0a49aaabdd3330b1,Frank Groeneveld,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 24c9ca9..0a27152 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -46,7 +46,7 @@
 	private List<Plugin> plugins = new ArrayList<Plugin>();
 
 	private CrawlSpecification crawlSpecification = new CrawlSpecification("""");
-	private HibernateConfiguration hibernateConfiguration = new HibernateConfiguration();
+	private HibernateConfiguration hibernateConfiguration = null;
 	private ProxyConfiguration proxyConfiguration = null;
 	private ThreadConfiguration threadConfiguration = new ThreadConfiguration();
 
"
0ecdc3425d02894268cb495f0a49aaabdd3330b1,Frank Groeneveld,HibernateUtil.java,MODIFY,initialize -> [HibernateConfiguration hibConfig] | [],"diff --git a/src/main/java/com/crawljax/util/database/HibernateUtil.java b/src/main/java/com/crawljax/util/database/HibernateUtil.java
index 185f6fe..9187dbb 100644
--- a/src/main/java/com/crawljax/util/database/HibernateUtil.java
+++ b/src/main/java/com/crawljax/util/database/HibernateUtil.java
@@ -1,6 +1,5 @@
 package com.crawljax.util.database;
 
-import java.io.FileInputStream;
 import java.util.Properties;
 
 import org.apache.log4j.Logger;
@@ -10,8 +9,8 @@
 import org.hibernate.Transaction;
 import org.hibernate.cfg.Configuration;
 
+import com.crawljax.core.configuration.HibernateConfiguration;
 import com.crawljax.core.state.Eventable;
-import com.crawljax.util.PropertyHelper;
 
 /**
  * Hibernate Utility class.
@@ -21,6 +20,8 @@
  */
 public final class HibernateUtil {
 
+	private static HibernateConfiguration hibernateConfig;
+
 	private HibernateUtil() {
 
 	}
@@ -33,12 +34,7 @@
 	 * @return Whether to use the database.
 	 */
 	public static boolean useDatabase() {
-		if (PropertyHelper.getCrawljaxConfiguration() == null) {
-			return PropertyHelper.useDatabase();
-		}
-
-		return PropertyHelper.getCrawljaxConfiguration().getUseDatabase();
-
+		return hibernateConfig != null;
 	}
 
 	/**
@@ -54,33 +50,23 @@
 	 * @param hbm2ddlAuto
 	 *            Whether to create, update, drop the tables first.
 	 */
-	public static void initialize(String hbm2ddlAuto) {
+	public static void initialize(HibernateConfiguration hibConfig) {
+		hibernateConfig = hibConfig;
+
 		if (!useDatabase()) {
 			return;
 		}
+
 		try {
 			Configuration config = new Configuration();
 			Properties p = new Properties();
-			if (PropertyHelper.getCrawljaxConfiguration() == null) {
-				// load from file
-				LOGGER.info(""Loading Hibernate config from: ""
-				        + PropertyHelper.getHibernatePropertiesValue());
-				p.load(new FileInputStream(PropertyHelper.getHibernatePropertiesValue()));
-			} else {
-				// load from config
-				LOGGER.info(""Loading Hibernate config from CrawljaxConfiguration"");
-				p.load(PropertyHelper.getCrawljaxConfiguration().getHibernateConfiguration()
-				        .getConfiguration());
 
-			}
+			// load from config
+			LOGGER.info(""Loading Hibernate config from CrawljaxConfiguration"");
+			p.load(hibConfig.getConfiguration());
+
 			config.setProperties(p);
 
-			if (hbm2ddlAuto != null && !"""".equals(hbm2ddlAuto)) {
-				config.setProperty(""hibernate.hbm2ddl.auto"", hbm2ddlAuto);
-			} else {
-				config.setProperty(""hibernate.hbm2ddl.auto"", PropertyHelper
-				        .getHibernateSchemaValue());
-			}
 			sessionFactory = config.configure().buildSessionFactory();
 		} catch (Throwable ex) {
 			LOGGER.fatal(""Initial SessionFactory creation failed."" + ex);
"
79fbd6d47d6a99053b773ec1f8e69219ef04073d,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 0a27152..dd0e97d 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -3,9 +3,6 @@
 import java.util.ArrayList;
 import java.util.List;
 
-import org.apache.commons.configuration.Configuration;
-import org.apache.commons.configuration.PropertiesConfiguration;
-
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.plugin.Plugin;
@@ -85,55 +82,6 @@
 	}
 
 	/**
-	 * @return A PropertiesConfiguration. For use by PropertyHelper only!
-	 */
-	protected Configuration getConfiguration() {
-		if (getCrawlSpecification() == null) {
-			return null;
-		}
-		Configuration config = new PropertiesConfiguration();
-		config.addProperty(""output.path"", getOutputFolder());
-		config.addProperty(""project.path.relative"", getProjectRelativePath());
-
-		config.addProperty(""hibernate.hbm2ddl.auto"", getHibernateConfiguration()
-		        .getDatabaseScheme());
-		config.addProperty(""invariantcontroller.testcrawling"", ConfigurationHelper
-		        .booleanToInt(getCrawlSpecification().getTestInvariantsWhileCrawling()));
-
-		// CrawlSpecification
-		config.addProperty(""site.url"", getCrawlSpecification().getUrl());
-		config.addProperty(""database.use"", getUseDatabaseAsInt());
-
-		config.addProperty(""click.once"", ConfigurationHelper.booleanToInt(getCrawlSpecification()
-		        .getClickOnce()));
-
-		config.addProperty(""robot.events"", ConfigurationHelper
-		        .listToString(getCrawlSpecification().getCrawlEvents()));
-		config.addProperty(""crawl.tags"", ConfigurationHelper
-		        .listToString(getAllIncludedCrawlElements()));
-		config.addProperty(""crawl.tags.exclude"", ConfigurationHelper
-		        .listToString(getCrawlSpecification().crawlActions().getCrawlElementsExcluded()));
-		config.addProperty(""crawl.filter.attributes"", ConfigurationHelper
-		        .listToString(getFilterAttributeNames()));
-		config.addProperty(""crawl.depth"", getCrawlSpecification().getDepth());
-		config.addProperty(""crawl.wait.reload"", getCrawlSpecification()
-		        .getWaitTimeAfterReloadUrl());
-		config.addProperty(""crawl.wait.event"", getCrawlSpecification().getWaitTimeAfterEvent());
-		config.addProperty(""crawl.max.states"", getCrawlSpecification().getMaximumStates());
-		config.addProperty(""crawl.max.runtime"", getCrawlSpecification().getMaximumRuntime());
-		config.addProperty(""crawl.forms.randominput"", ConfigurationHelper
-		        .booleanToInt(getCrawlSpecification().getRandomInputInForms()));
-		config.addProperty(""crawl.numberOfThreads"", getThreadConfiguration().getNumberThreads());
-
-		if (getProxyConfiguration() != null) {
-			config.addProperty(""proxy.enabled"", 1);
-			config.addProperty(""proxy.port"", getProxyConfiguration().getPort());
-		}
-
-		return config;
-	}
-
-	/**
 	 * Enable the crawljax proxy extension.
 	 * 
 	 * @param proxyConfiguration
"
5cae8d330d58e69f6d4c2826aaae7e1a48a7d868,Frank Groeneveld,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 0a27152..dd0e97d 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -3,9 +3,6 @@
 import java.util.ArrayList;
 import java.util.List;
 
-import org.apache.commons.configuration.Configuration;
-import org.apache.commons.configuration.PropertiesConfiguration;
-
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.plugin.Plugin;
@@ -85,55 +82,6 @@
 	}
 
 	/**
-	 * @return A PropertiesConfiguration. For use by PropertyHelper only!
-	 */
-	protected Configuration getConfiguration() {
-		if (getCrawlSpecification() == null) {
-			return null;
-		}
-		Configuration config = new PropertiesConfiguration();
-		config.addProperty(""output.path"", getOutputFolder());
-		config.addProperty(""project.path.relative"", getProjectRelativePath());
-
-		config.addProperty(""hibernate.hbm2ddl.auto"", getHibernateConfiguration()
-		        .getDatabaseScheme());
-		config.addProperty(""invariantcontroller.testcrawling"", ConfigurationHelper
-		        .booleanToInt(getCrawlSpecification().getTestInvariantsWhileCrawling()));
-
-		// CrawlSpecification
-		config.addProperty(""site.url"", getCrawlSpecification().getUrl());
-		config.addProperty(""database.use"", getUseDatabaseAsInt());
-
-		config.addProperty(""click.once"", ConfigurationHelper.booleanToInt(getCrawlSpecification()
-		        .getClickOnce()));
-
-		config.addProperty(""robot.events"", ConfigurationHelper
-		        .listToString(getCrawlSpecification().getCrawlEvents()));
-		config.addProperty(""crawl.tags"", ConfigurationHelper
-		        .listToString(getAllIncludedCrawlElements()));
-		config.addProperty(""crawl.tags.exclude"", ConfigurationHelper
-		        .listToString(getCrawlSpecification().crawlActions().getCrawlElementsExcluded()));
-		config.addProperty(""crawl.filter.attributes"", ConfigurationHelper
-		        .listToString(getFilterAttributeNames()));
-		config.addProperty(""crawl.depth"", getCrawlSpecification().getDepth());
-		config.addProperty(""crawl.wait.reload"", getCrawlSpecification()
-		        .getWaitTimeAfterReloadUrl());
-		config.addProperty(""crawl.wait.event"", getCrawlSpecification().getWaitTimeAfterEvent());
-		config.addProperty(""crawl.max.states"", getCrawlSpecification().getMaximumStates());
-		config.addProperty(""crawl.max.runtime"", getCrawlSpecification().getMaximumRuntime());
-		config.addProperty(""crawl.forms.randominput"", ConfigurationHelper
-		        .booleanToInt(getCrawlSpecification().getRandomInputInForms()));
-		config.addProperty(""crawl.numberOfThreads"", getThreadConfiguration().getNumberThreads());
-
-		if (getProxyConfiguration() != null) {
-			config.addProperty(""proxy.enabled"", 1);
-			config.addProperty(""proxy.port"", getProxyConfiguration().getPort());
-		}
-
-		return config;
-	}
-
-	/**
 	 * Enable the crawljax proxy extension.
 	 * 
 	 * @param proxyConfiguration
"
dc59f5484a53ec3793f4005ba3c15906236861cf,Ali Mesbah,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 0a19952..a902470 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -21,7 +21,8 @@
 import org.w3c.dom.NodeList;
 
 /**
- * TODO: DOCUMENT ME!
+ * Utility class that contains methods used by Crawljax and some plugin to deal with XPath
+ * resolving, constructing etc.
  * 
  * @author mesbah
  * @version $Id$
"
c6a7939d7b5869e207f17bd1d92dbd28f250d0d5,Frank Groeneveld,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 0a19952..a902470 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -21,7 +21,8 @@
 import org.w3c.dom.NodeList;
 
 /**
- * TODO: DOCUMENT ME!
+ * Utility class that contains methods used by Crawljax and some plugin to deal with XPath
+ * resolving, constructing etc.
  * 
  * @author mesbah
  * @version $Id$
"
e8cde194924479c3106405ab885fe1de1f43e2d6,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index dd0e97d..791039a 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -43,7 +43,6 @@
 	private List<Plugin> plugins = new ArrayList<Plugin>();
 
 	private CrawlSpecification crawlSpecification = new CrawlSpecification("""");
-	private HibernateConfiguration hibernateConfiguration = null;
 	private ProxyConfiguration proxyConfiguration = null;
 	private ThreadConfiguration threadConfiguration = new ThreadConfiguration();
 
@@ -160,22 +159,6 @@
 	}
 
 	/**
-	 * @return The HibernateConfiguration which contains the Hibernate Database settings.
-	 */
-	protected HibernateConfiguration getHibernateConfiguration() {
-		return hibernateConfiguration;
-	}
-
-	/**
-	 * @param hibernateConfiguration
-	 *            Which contains the Hibernate Database settings.
-	 */
-	public void setHibernateConfiguration(HibernateConfiguration hibernateConfiguration) {
-		this.useDatabase = true;
-		this.hibernateConfiguration = hibernateConfiguration;
-	}
-
-	/**
 	 * @return The browser used to crawl. By default firefox is used.
 	 */
 	protected BrowserType getBrowser() {
"
ab805fcc1eeaad2d30edfc50bb605f3ee652806a,Frank Groeneveld,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index dd0e97d..791039a 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -43,7 +43,6 @@
 	private List<Plugin> plugins = new ArrayList<Plugin>();
 
 	private CrawlSpecification crawlSpecification = new CrawlSpecification("""");
-	private HibernateConfiguration hibernateConfiguration = null;
 	private ProxyConfiguration proxyConfiguration = null;
 	private ThreadConfiguration threadConfiguration = new ThreadConfiguration();
 
@@ -160,22 +159,6 @@
 	}
 
 	/**
-	 * @return The HibernateConfiguration which contains the Hibernate Database settings.
-	 */
-	protected HibernateConfiguration getHibernateConfiguration() {
-		return hibernateConfiguration;
-	}
-
-	/**
-	 * @param hibernateConfiguration
-	 *            Which contains the Hibernate Database settings.
-	 */
-	public void setHibernateConfiguration(HibernateConfiguration hibernateConfiguration) {
-		this.useDatabase = true;
-		this.hibernateConfiguration = hibernateConfiguration;
-	}
-
-	/**
 	 * @return The browser used to crawl. By default firefox is used.
 	 */
 	protected BrowserType getBrowser() {
"
a49e7aa1f5ed1f83e92eb915ca63e0ffb3b74eed,Ali Mesbah,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index a902470..eef0353 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -72,7 +72,7 @@
 	}
 
 	/**
-	 * Get siblings of the same type as element from parent
+	 * Get siblings of the same type as element from parent.
 	 * 
 	 * @param parent
 	 *            parent node.
"
8f9b15673da346eb404bfcbc59bf38693ec966a2,Ali Mesbah,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index a902470..eef0353 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -72,7 +72,7 @@
 	}
 
 	/**
-	 * Get siblings of the same type as element from parent
+	 * Get siblings of the same type as element from parent.
 	 * 
 	 * @param parent
 	 *            parent node.
"
584f207b04a2bf1e4de0324e68073e69a29ef0b0,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 5db2134..e88ed25 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -85,7 +85,7 @@
 					if (text.equals("""")) {
 						return;
 					}
-					String js = Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
+					String js = Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
 					js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
 					browser.executeJavaScript(js);
 				}
@@ -94,7 +94,7 @@
 				if (input.getType().equals(""checkbox"")) {
 					for (InputValue inputValue : input.getInputValues()) {
 						String js =
-						        Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
+						        Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
 						boolean check;
 						if (!randomFieldValue) {
 							check = inputValue.isChecked();
@@ -120,7 +120,7 @@
 						if (inputValue.isChecked()) {
 							String js =
 							        Helper.getJSGetElement(XPathHelper
-							                .getXpathExpression(element));
+							                .getXPathExpression(element));
 							js += ""try{ATUSA_element.checked=true;}catch(e){}"";
 							browser.executeJavaScript(js);
 						}
@@ -132,7 +132,7 @@
 					for (InputValue inputValue : input.getInputValues()) {
 						// if(browser.getDriver()==null){
 						String js =
-						        Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
+						        Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
 						js +=
 						        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
 						                + ""if(ATUSA_element.options[i].value=='""
@@ -158,7 +158,7 @@
 	private List<Node> getInputElements(Document dom) {
 		List<Node> nodes = new ArrayList<Node>();
 		try {
-			NodeList nodeList = Helper.getElementsByXpath(dom, ""//INPUT"");
+			NodeList nodeList = XPathHelper.evaluateXpathExpression(dom, ""//INPUT"");
 			List<String> allowedTypes = new ArrayList<String>(Arrays.asList(ALLOWED_INPUT_TYPES));
 
 			for (int i = 0; i < nodeList.getLength(); i++) {
@@ -170,11 +170,11 @@
 					nodes.add(nodeList.item(i));
 				}
 			}
-			nodeList = Helper.getElementsByXpath(dom, ""//TEXTAREA"");
+			nodeList = XPathHelper.evaluateXpathExpression(dom, ""//TEXTAREA"");
 			for (int i = 0; i < nodeList.getLength(); i++) {
 				nodes.add(nodeList.item(i));
 			}
-			nodeList = Helper.getElementsByXpath(dom, ""//SELECT"");
+			nodeList = XPathHelper.evaluateXpathExpression(dom, ""//SELECT"");
 			for (int i = 0; i < nodeList.getLength(); i++) {
 				nodes.add(nodeList.item(i));
 			}
"
584f207b04a2bf1e4de0324e68073e69a29ef0b0,Ali Mesbah,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/src/main/java/com/crawljax/util/ElementResolver.java b/src/main/java/com/crawljax/util/ElementResolver.java
index c3734ff..80302af 100644
--- a/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/src/main/java/com/crawljax/util/ElementResolver.java
@@ -75,7 +75,7 @@
 				LOGGER.info(""Search other candidate elements"");
 			}
 			NodeList candidateElements =
-			        Helper.getElementsByXpath(dom, ""//""
+			        XPathHelper.evaluateXpathExpression(dom, ""//""
 			                + eventable.getElement().getTag().toUpperCase());
 			if (logging) {
 				LOGGER.info(""Candidates: "" + candidateElements.getLength());
@@ -83,7 +83,7 @@
 			for (int i = 0; i < candidateElements.getLength(); i++) {
 				Element candidateElement = new Element(candidateElements.item(i));
 				if (equivalent(candidateElement, logging)) {
-					return XPathHelper.getXpathExpression(candidateElements.item(i));
+					return XPathHelper.getXPathExpression(candidateElements.item(i));
 				}
 			}
 
"
5b3b1c183ea7c418bf1ce54b85b6b671b130352d,Frank Groeneveld,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 5db2134..e88ed25 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -85,7 +85,7 @@
 					if (text.equals("""")) {
 						return;
 					}
-					String js = Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
+					String js = Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
 					js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
 					browser.executeJavaScript(js);
 				}
@@ -94,7 +94,7 @@
 				if (input.getType().equals(""checkbox"")) {
 					for (InputValue inputValue : input.getInputValues()) {
 						String js =
-						        Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
+						        Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
 						boolean check;
 						if (!randomFieldValue) {
 							check = inputValue.isChecked();
@@ -120,7 +120,7 @@
 						if (inputValue.isChecked()) {
 							String js =
 							        Helper.getJSGetElement(XPathHelper
-							                .getXpathExpression(element));
+							                .getXPathExpression(element));
 							js += ""try{ATUSA_element.checked=true;}catch(e){}"";
 							browser.executeJavaScript(js);
 						}
@@ -132,7 +132,7 @@
 					for (InputValue inputValue : input.getInputValues()) {
 						// if(browser.getDriver()==null){
 						String js =
-						        Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
+						        Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
 						js +=
 						        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
 						                + ""if(ATUSA_element.options[i].value=='""
@@ -158,7 +158,7 @@
 	private List<Node> getInputElements(Document dom) {
 		List<Node> nodes = new ArrayList<Node>();
 		try {
-			NodeList nodeList = Helper.getElementsByXpath(dom, ""//INPUT"");
+			NodeList nodeList = XPathHelper.evaluateXpathExpression(dom, ""//INPUT"");
 			List<String> allowedTypes = new ArrayList<String>(Arrays.asList(ALLOWED_INPUT_TYPES));
 
 			for (int i = 0; i < nodeList.getLength(); i++) {
@@ -170,11 +170,11 @@
 					nodes.add(nodeList.item(i));
 				}
 			}
-			nodeList = Helper.getElementsByXpath(dom, ""//TEXTAREA"");
+			nodeList = XPathHelper.evaluateXpathExpression(dom, ""//TEXTAREA"");
 			for (int i = 0; i < nodeList.getLength(); i++) {
 				nodes.add(nodeList.item(i));
 			}
-			nodeList = Helper.getElementsByXpath(dom, ""//SELECT"");
+			nodeList = XPathHelper.evaluateXpathExpression(dom, ""//SELECT"");
 			for (int i = 0; i < nodeList.getLength(); i++) {
 				nodes.add(nodeList.item(i));
 			}
"
5b3b1c183ea7c418bf1ce54b85b6b671b130352d,Frank Groeneveld,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/src/main/java/com/crawljax/util/ElementResolver.java b/src/main/java/com/crawljax/util/ElementResolver.java
index c3734ff..80302af 100644
--- a/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/src/main/java/com/crawljax/util/ElementResolver.java
@@ -75,7 +75,7 @@
 				LOGGER.info(""Search other candidate elements"");
 			}
 			NodeList candidateElements =
-			        Helper.getElementsByXpath(dom, ""//""
+			        XPathHelper.evaluateXpathExpression(dom, ""//""
 			                + eventable.getElement().getTag().toUpperCase());
 			if (logging) {
 				LOGGER.info(""Candidates: "" + candidateElements.getLength());
@@ -83,7 +83,7 @@
 			for (int i = 0; i < candidateElements.getLength(); i++) {
 				Element candidateElement = new Element(candidateElements.item(i));
 				if (equivalent(candidateElement, logging)) {
-					return XPathHelper.getXpathExpression(candidateElements.item(i));
+					return XPathHelper.getXPathExpression(candidateElements.item(i));
 				}
 			}
 
"
5b3b1c183ea7c418bf1ce54b85b6b671b130352d,Frank Groeneveld,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index eef0353..ffa6107 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -41,7 +41,7 @@
 	 *            the given node.
 	 * @return string xpath expression (e.g., ""/html[1]/body[1]/div[3]"").
 	 */
-	public static String getXpathExpression(Node node) {
+	public static String getXPathExpression(Node node) {
 		Node parent = node.getParentNode();
 
 		if ((parent == null) || parent.getNodeName().contains(""#document"")) {
@@ -51,7 +51,7 @@
 		StringBuffer buffer = new StringBuffer();
 
 		if (parent != node) {
-			buffer.append(getXpathExpression(parent));
+			buffer.append(getXPathExpression(parent));
 			buffer.append(""/"");
 		}
 
@@ -138,29 +138,30 @@
 	}
 
 	/**
-	 * Returns the xpath of the first node retrieved by xpathExpression. Example: //DIV[@id='foo']
+	 * Returns the XPaths of all nodes retrieved by xpathExpression. Example: //DIV[@id='foo']
 	 * returns /HTM[1]/BODY[1]/DIV[2]
 	 * 
 	 * @param dom
 	 *            The dom.
 	 * @param xpathExpression
 	 *            The expression to find the element.
-	 * @return the xpath of the first node retrieved by xpathExpression.
+	 * @return list of XPaths retrieved by xpathExpression.
 	 */
-	public static String getXpathForXPathExpression(Document dom, String xpathExpression) {
+	public static List<String> getXpathForXPathExpressions(Document dom, String xpathExpression) {
 		NodeList nodeList;
 		try {
-			nodeList = Helper.getElementsByXpath(dom, xpathExpression);
+			nodeList = XPathHelper.evaluateXpathExpression(dom, xpathExpression);
 		} catch (XPathExpressionException e) {
 			return null;
 		}
+		List<String> result = new ArrayList<String>();
 		if (nodeList.getLength() > 0) {
-			if (nodeList.getLength() > 1) {
-				LOGGER.warn(""Expression "" + xpathExpression + "" returned more than one element."");
+			for (int i = 0; i < nodeList.getLength(); i++) {
+				Node n = nodeList.item(i);
+				result.add(getXPathExpression(n));
 			}
-			return getXpathExpression(nodeList.item(0));
 		}
-		return null;
+		return result;
 	}
 
 	/**
"
60c563d57aebf241f13b5c1415ce486b71be181a,Ali Mesbah,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 9242130..57aecc0 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -8,6 +8,7 @@
 import com.crawljax.condition.browserwaiter.WaitCondition;
 import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.invariant.Invariant;
+import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.oraclecomparator.Comparator;
 import com.crawljax.oraclecomparator.OracleComparator;
 
@@ -52,13 +53,13 @@
 
 	private final String url;
 
-	private final List<String> crawlEvents = new ArrayList<String>();
+	private List<EventType> crawlEvents = new ArrayList<EventType>();
+
 	private int depth = 0;
 	private int maximumStates = 0;
 	private int maximumRuntime = DEFAULT_MAXIMUMRUNTIME; // in seconds
 	private int waitTimeAfterReloadUrl = DEFAULT_WAITTIMEAFTERRELOADURL; // in milliseconds
 	private int waitTimeAfterEvent = DEFAULT_WAITTIMEAFTEREVENT; // in milliseconds
-	private int numberOfThreads = 1;
 	private final CrawlActions crawlActions = new CrawlActions();
 
 	private boolean randomInputInForms = true;
@@ -77,7 +78,7 @@
 	 *            the site to crawl
 	 */
 	public CrawlSpecification(String url) {
-		this.crawlEvents.add(""onclick"");
+		this.crawlEvents.add(EventType.click);
 		this.url = url;
 	}
 
@@ -105,7 +106,7 @@
 	}
 
 	/**
-	 * Set of HTML elements Crawljax will NOT click during crawling When an HTML is present in the
+	 * Set of HTML elements Crawljax will NOT examine during crawling When an HTML is present in the
 	 * click and dontClick sets, then the element will not be clicked. For example: 1) <a
 	 * href=""#"">Some text</a> 2) <a class=""foo"" .../> 3) <div class=""foo"" .../> click(""a"")
 	 * dontClick(""a"").withAttribute(""class"", ""foo""); Will include only include HTML element 2
@@ -239,7 +240,7 @@
 	/**
 	 * @return the events that should be fired (e.g. onclick)
 	 */
-	protected List<String> getCrawlEvents() {
+	protected List<EventType> getCrawlEvents() {
 		return crawlEvents;
 	}
 
@@ -259,21 +260,6 @@
 	}
 
 	/**
-	 * @param numberOfThreads
-	 *            the numberOfThreads to set
-	 */
-	public void setNumberOfThreads(int numberOfThreads) {
-		this.numberOfThreads = numberOfThreads;
-	}
-
-	/**
-	 * @return the numberOfThreads
-	 */
-	public int getNumberOfThreads() {
-		return numberOfThreads;
-	}
-
-	/**
 	 * @return the different crawl actions.
 	 */
 	protected CrawlActions crawlActions() {
@@ -434,4 +420,12 @@
 		this.clicklOnce = clickOnce;
 	}
 
+	/**
+	 * @param crawlEvents
+	 *            the crawlEvents to set
+	 */
+	public void setCrawlEvents(List<EventType> crawlEvents) {
+		this.crawlEvents = crawlEvents;
+	}
+
 }
"
60c563d57aebf241f13b5c1415ce486b71be181a,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index a047fac..791039a 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -3,17 +3,10 @@
 import java.util.ArrayList;
 import java.util.List;
 
-import org.apache.commons.configuration.Configuration;
-import org.apache.commons.configuration.PropertiesConfiguration;
-import org.openqa.selenium.WebDriver;
-
-import com.crawljax.browser.EmbeddedBrowser;
-import com.crawljax.browser.WebDriverFirefox;
-import com.crawljax.browser.WebDriverOther;
+import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.util.Helper;
-import com.crawljax.util.PropertyHelper;
 
 /**
  * Specifies the settings Crawljax. The methods in this class fall into two categories:Oz
@@ -28,7 +21,7 @@
  * {@link CrawljaxConfiguration#setHibernateConfiguration(HibernateConfiguration)} See also
  * {@link HibernateConfiguration}
  * <p/>
- * DEFAULT VAlUES: Browser: WebDriverFirefox Project Full Path: empty Project Relative Path: empty
+ * DEFAULT VAlUES: Browser: webdriver firefox Project Full Path: empty Project Relative Path: empty
  * Filter attributes: closure_hashcode_(\\w)*, jquery[0-9]+ Test invariants while crawling: true
  * EXAMPLE: CrawljaxConfiguration crawljaxConfig = new CrawljaxConfiguration(); CrawlSpecification
  * crawler = new CrawlSpecification(""http://www.google.com""); crawler.click(""a"");
@@ -38,9 +31,7 @@
  */
 public final class CrawljaxConfiguration {
 
-	private static final int ONE_SECOND = 1000;
-
-	private EmbeddedBrowser browser;
+	private BrowserType browser = BrowserType.firefox;
 
 	private String outputFolder = """";
 	private String projectRelativePath = """";
@@ -52,8 +43,8 @@
 	private List<Plugin> plugins = new ArrayList<Plugin>();
 
 	private CrawlSpecification crawlSpecification = new CrawlSpecification("""");
-	private HibernateConfiguration hibernateConfiguration = new HibernateConfiguration();
 	private ProxyConfiguration proxyConfiguration = null;
+	private ThreadConfiguration threadConfiguration = new ThreadConfiguration();
 
 	/**
 	 * Constructor.
@@ -90,56 +81,6 @@
 	}
 
 	/**
-	 * @return A PropertiesConfiguration. For use by PropertyHelper only!
-	 */
-	protected Configuration getConfiguration() {
-		if (getCrawlSpecification() == null) {
-			return null;
-		}
-		Configuration config = new PropertiesConfiguration();
-		config.addProperty(""output.path"", getOutputFolder());
-		config.addProperty(""project.path.relative"", getProjectRelativePath());
-
-		config.addProperty(""hibernate.hbm2ddl.auto"", getHibernateConfiguration()
-		        .getDatabaseScheme());
-		config.addProperty(""invariantcontroller.testcrawling"", ConfigurationHelper
-		        .booleanToInt(getCrawlSpecification().getTestInvariantsWhileCrawling()));
-
-		// CrawlSpecification
-		config.addProperty(""site.url"", getCrawlSpecification().getUrl());
-		config.addProperty(""database.use"", getUseDatabaseAsInt());
-
-		config.addProperty(""click.once"", ConfigurationHelper.booleanToInt(getCrawlSpecification()
-		        .getClickOnce()));
-
-		config.addProperty(""robot.events"", ConfigurationHelper
-		        .listToString(getCrawlSpecification().getCrawlEvents()));
-		config.addProperty(""crawl.tags"", ConfigurationHelper
-		        .listToString(getAllIncludedCrawlElements()));
-		config.addProperty(""crawl.tags.exclude"", ConfigurationHelper
-		        .listToString(getCrawlSpecification().crawlActions().getCrawlElementsExcluded()));
-		config.addProperty(""crawl.filter.attributes"", ConfigurationHelper
-		        .listToString(getFilterAttributeNames()));
-		config.addProperty(""crawl.depth"", getCrawlSpecification().getDepth());
-		config.addProperty(""crawl.wait.reload"", getCrawlSpecification()
-		        .getWaitTimeAfterReloadUrl());
-		config.addProperty(""crawl.wait.event"", getCrawlSpecification().getWaitTimeAfterEvent());
-		config.addProperty(""crawl.max.states"", getCrawlSpecification().getMaximumStates());
-		config.addProperty(""crawl.max.runtime"", getCrawlSpecification().getMaximumRuntime()
-		        * ONE_SECOND);
-		config.addProperty(""crawl.forms.randominput"", ConfigurationHelper
-		        .booleanToInt(getCrawlSpecification().getRandomInputInForms()));
-		config.addProperty(""crawl.numberOfThreads"", getCrawlSpecification().getNumberOfThreads());
-
-		if (getProxyConfiguration() != null) {
-			config.addProperty(""proxy.enabled"", 1);
-			config.addProperty(""proxy.port"", getProxyConfiguration().getPort());
-		}
-
-		return config;
-	}
-
-	/**
 	 * Enable the crawljax proxy extension.
 	 * 
 	 * @param proxyConfiguration
@@ -157,6 +98,21 @@
 	}
 
 	/**
+	 * @param threadConfiguration
+	 *            the threadConfiguration to set
+	 */
+	public void setThreadConfiguration(ThreadConfiguration threadConfiguration) {
+		this.threadConfiguration = threadConfiguration;
+	}
+
+	/**
+	 * @return the threadConfiguration
+	 */
+	protected ThreadConfiguration getThreadConfiguration() {
+		return threadConfiguration;
+	}
+
+	/**
 	 * @return All the included crawlTags.
 	 */
 	protected List<CrawlElement> getAllIncludedCrawlElements() {
@@ -198,66 +154,26 @@
 				eventableConditions.add(eventableCondition);
 			}
 		}
+
 		return eventableConditions;
 	}
 
 	/**
-	 * @return The HibernateConfiguration which contains the Hibernate Database settings.
+	 * @return The browser used to crawl. By default firefox is used.
 	 */
-	protected HibernateConfiguration getHibernateConfiguration() {
-		return hibernateConfiguration;
-	}
-
-	/**
-	 * @param hibernateConfiguration
-	 *            Which contains the Hibernate Database settings.
-	 */
-	public void setHibernateConfiguration(HibernateConfiguration hibernateConfiguration) {
-		this.useDatabase = true;
-		this.hibernateConfiguration = hibernateConfiguration;
-	}
-
-	/**
-	 * @return The browser used to crawl. See {@link EmbeddedBrowser}. By default
-	 *         {@link WebDriverFirefox} is used.
-	 */
-	protected EmbeddedBrowser getBrowser() {
-		if (browser == null) {
-			if (PropertyHelper.getCrawljaxConfiguration() != null
-			        && PropertyHelper.getCrawljaxConfiguration().getProxyConfiguration() != null) {
-				browser =
-				        new WebDriverFirefox(PropertyHelper.getCrawljaxConfiguration()
-				                .getProxyConfiguration());
-			} else {
-				browser = new WebDriverFirefox();
-			}
-		}
+	protected BrowserType getBrowser() {
 		return browser;
 	}
 
 	/**
 	 * @param browser
-	 *            The browser used to crawl. See {@link EmbeddedBrowser}. By default
-	 *            {@link WebDriverFirefox} is used.
+	 *            The browser used to crawl.
 	 */
-	public void setBrowser(EmbeddedBrowser browser) {
+	public void setBrowser(BrowserType browser) {
 		this.browser = browser;
 	}
 
 	/**
-	 * Deprecated function to specify the browser used. Replaced by
-	 * {@link CrawljaxConfiguration#setBrowser(EmbeddedBrowser)}.
-	 * 
-	 * @see #setBrowser(EmbeddedBrowser)
-	 * @param driver
-	 *            The Webdriver driver used to crawl. By default {@link WebDriverFirefox} is used.
-	 */
-	@Deprecated
-	public void setBrowser(WebDriver driver) {
-		this.browser = new WebDriverOther(driver);
-	}
-
-	/**
 	 * @return The path of the outputFolder with a trailing slash.
 	 */
 	protected String getOutputFolder() {
"
60c563d57aebf241f13b5c1415ce486b71be181a,Ali Mesbah,FormInputField.java,MODIFY,setValues -> [boolean values] | [String values],"diff --git a/src/main/java/com/crawljax/core/configuration/FormInputField.java b/src/main/java/com/crawljax/core/configuration/FormInputField.java
index 4f97ad4..c2fd585 100644
--- a/src/main/java/com/crawljax/core/configuration/FormInputField.java
+++ b/src/main/java/com/crawljax/core/configuration/FormInputField.java
@@ -28,7 +28,7 @@
 	 */
 	public FormInputField setValues(String... values) {
 		for (String value : values) {
-			this.addFieldValue(value);
+			this.setValue(value);
 		}
 		return this;
 	}
@@ -43,9 +43,9 @@
 	public FormInputField setValues(boolean... values) {
 		for (boolean value : values) {
 			if (value) {
-				this.addFieldValue(""1"");
+				this.setValue(""1"");
 			} else {
-				this.addFieldValue(""0"");
+				this.setValue(""0"");
 			}
 		}
 		return this;
"
60c563d57aebf241f13b5c1415ce486b71be181a,Ali Mesbah,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/src/main/java/com/crawljax/core/configuration/InputField.java b/src/main/java/com/crawljax/core/configuration/InputField.java
index b333e2d..474d562 100644
--- a/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -113,15 +113,4 @@
 	protected List<String> getFieldValues() {
 		return fieldValues;
 	}
-
-	/**
-	 * Add a field to the field values.
-	 * 
-	 * @param field
-	 *            the field to add to the fieldValues
-	 */
-	protected void addFieldValue(String field) {
-		this.fieldValues.add(field);
-	}
-
 }
"
60c563d57aebf241f13b5c1415ce486b71be181a,Ali Mesbah,StateFlowGraph.java,MODIFY,"addState -> [StateVertix stateVertix, boolean correctName] | [StateVertix stateVertix]","diff --git a/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index 8dbd69f..1e4e852 100644
--- a/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -34,13 +34,20 @@
 	private final AtomicInteger stateCounter = new AtomicInteger(1);
 
 	/**
+	 * Empty constructor.
+	 */
+	public StateFlowGraph() {
+		sfg = new DirectedMultigraph<StateVertix, Eventable>(Eventable.class);
+	}
+
+	/**
 	 * The constructor.
 	 * 
 	 * @param initialState
 	 *            the state to start from.
 	 */
 	public StateFlowGraph(StateVertix initialState) {
-		sfg = new DirectedMultigraph<StateVertix, Eventable>(Eventable.class);
+		this();
 		sfg.addVertex(initialState);
 	}
 
@@ -50,15 +57,36 @@
 	 * u.equals(v). If this graph already contains such vertex, the call leaves this graph unchanged
 	 * and returns false. In combination with the restriction on constructors, this ensures that
 	 * graphs never contain duplicate vertices. Throws java.lang.NullPointerException - if the
+	 * specified vertex is null. This method automatically updates the state name to reflect the
+	 * internal state counter.
+	 * 
+	 * @param stateVertix
+	 *            the state to be added.
+	 * @return the clone if one is detected null otherwise.
+	 * @see org.jgrapht.Graph#addVertex(Object)
+	 */
+	public StateVertix addState(StateVertix stateVertix) {
+		return addState(stateVertix, true);
+	}
+
+	/**
+	 * Adds a state (as a vertix) to the State-Flow Graph if not already present. More formally,
+	 * adds the specified vertex, v, to this graph if this graph contains no vertex u such that
+	 * u.equals(v). If this graph already contains such vertex, the call leaves this graph unchanged
+	 * and returns false. In combination with the restriction on constructors, this ensures that
+	 * graphs never contain duplicate vertices. Throws java.lang.NullPointerException - if the
 	 * specified vertex is null.
 	 * 
 	 * @param stateVertix
 	 *            the state to be added.
+	 * @param correctName
+	 *            if true the name of the state will be corrected according to the internal state
+	 *            counter.
 	 * @return the clone if one is detected null otherwise.
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
 	@GuardedBy(""sfg"")
-	public StateVertix addState(StateVertix stateVertix) {
+	public StateVertix addState(StateVertix stateVertix, boolean correctName) {
 		synchronized (sfg) {
 			if (!sfg.addVertex(stateVertix)) {
 				// Graph already contained the vertix
@@ -69,14 +97,17 @@
 				 * is the only place states can be added and we are now locked so getAllStates.size
 				 * works correctly.
 				 */
-				// the -1 is for the ""index"" state.
-				int totalNumberOfStates = this.getAllStates().size() - 1;
-				String correctName = makeStateName(totalNumberOfStates);
-				if (!stateVertix.getName().equals(""index"")
-				        && !stateVertix.getName().equals(correctName)) {
-					LOGGER.info(""Correcting state name from  "" + stateVertix.getName() + "" to ""
-					        + correctName);
-					stateVertix.setName(correctName);
+				if (correctName) {
+					// the -1 is for the ""index"" state.
+					int totalNumberOfStates = this.getAllStates().size() - 1;
+					String correctedName =
+					        makeStateName(totalNumberOfStates, stateVertix.isGuidedCrawling());
+					if (!stateVertix.getName().equals(""index"")
+					        && !stateVertix.getName().equals(correctedName)) {
+						LOGGER.info(""Correcting state name from  "" + stateVertix.getName()
+						        + "" to "" + correctedName);
+						stateVertix.setName(correctedName);
+					}
 				}
 			}
 			stateCounter.set(this.getAllStates().size() - 1);
@@ -168,11 +199,9 @@
 	}
 
 	/**
-	 * TODO: DOCUMENT ME!
-	 * 
 	 * @param clickable
-	 *            TODO: DOCUMENT ME!
-	 * @return TODO: DOCUMENT ME!
+	 *            the edge.
+	 * @return the target state of this edge.
 	 */
 	public StateVertix getTargetState(Eventable clickable) {
 		return sfg.getEdgeTarget(clickable);
@@ -246,24 +275,8 @@
 	}
 
 	/**
-	 * Checks to see if a certain StateVertix already exists in the StateFlowGraph. Depreciated
-	 * because its never used anywhere?
-	 * 
-	 * @param state
-	 *            the state to check of existence
-	 * @return true if the StateFlowGraph contains the given StateVertix
+	 * @return Dom string average size (byte).
 	 */
-	@Deprecated
-	public boolean containsVertex(StateVertix state) {
-		return sfg.containsVertex(state);
-	}
-
-	/**
-	 * TODO: DOCUMENT ME!
-	 * 
-	 * @return TODO: DOCUMENT ME!
-	 */
-
 	public int getMeanStateStringSize() {
 		Mean mean = new Mean();
 		List<Integer> list = new ArrayList<Integer>();
@@ -280,7 +293,7 @@
 	}
 
 	/**
-	 * @return the sfg
+	 * @return the state-flow graph.
 	 */
 	public DirectedGraph<StateVertix, Eventable> getSfg() {
 		return sfg;
@@ -334,9 +347,11 @@
 	}
 
 	/**
+	 * This method returns all possible paths from the index state using the Kshortest paths.
+	 * 
 	 * @param index
-	 *            TODO: DOCUMENT ME!
-	 * @return TODO: DOCUMENT ME!
+	 *            the initial state.
+	 * @return a list of GraphPath lists.
 	 */
 	public List<List<GraphPath<StateVertix, Eventable>>> getAllPossiblePaths(StateVertix index) {
 		final List<List<GraphPath<StateVertix, Eventable>>> results =
@@ -369,19 +384,24 @@
 	 */
 	public String getNewStateName() {
 		stateCounter.getAndIncrement();
-		String state = makeStateName(stateCounter.get());
+		String state = makeStateName(stateCounter.get(), false);
 		return state;
 	}
 
 	/**
-	 * Make a new state name given its id. Separated to get a central point when changeing the names
-	 * of states.
+	 * Make a new state name given its id. Separated to get a central point when changing the names
+	 * of states. The automatic state names start with ""state"" and guided ones with ""guide"".
 	 * 
 	 * @param id
 	 *            the id where this name needs to be for.
 	 * @return the String containing the new name.
 	 */
-	private String makeStateName(int id) {
+	private String makeStateName(int id, boolean guided) {
+
+		if (guided) {
+			return ""guided"" + id;
+		}
+
 		return ""state"" + id;
 	}
 }
"
60c563d57aebf241f13b5c1415ce486b71be181a,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index ba90bb7..e88ed25 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -11,10 +11,14 @@
 
 import org.apache.log4j.Logger;
 import org.w3c.dom.Document;
+import org.w3c.dom.Element;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
 
 import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.condition.eventablecondition.EventableCondition;
+import com.crawljax.core.CandidateElement;
+import com.crawljax.core.configuration.InputSpecification;
 import com.crawljax.util.Helper;
 import com.crawljax.util.XPathHelper;
 
@@ -31,16 +35,26 @@
 	private boolean randomFieldValue = false;
 	private final EmbeddedBrowser browser;
 
+	public static final int RANDOM_STRING_LENGTH = 8;
+
 	private static final double HALF = 0.5;
 
+	private FormInputValueHelper formInputValueHelper;
+
 	/**
 	 * Public constructor.
 	 * 
 	 * @param browser
 	 *            the embedded browser.
+	 * @param inputSpecification
+	 *            the input specification.
+	 * @param randomInput
+	 *            if random data should be generated on the input fields.
 	 */
-	public FormHandler(EmbeddedBrowser browser) {
+	public FormHandler(EmbeddedBrowser browser, InputSpecification inputSpecification,
+	        boolean randomInput) {
 		this.browser = browser;
+		this.formInputValueHelper = new FormInputValueHelper(inputSpecification, randomInput);
 	}
 
 	private static final String[] ALLOWED_INPUT_TYPES =
@@ -56,7 +70,7 @@
 	 */
 	private void setInputElementValue(Node element, FormInput input) {
 
-		LOGGER.debug(""INPUTFIELD: "" + input.getName() + "" ("" + input.getType() + "")"");
+		LOGGER.debug(""INPUTFIELD: "" + input.getIdentification() + "" ("" + input.getType() + "")"");
 		if (element == null) {
 			return;
 		}
@@ -71,7 +85,7 @@
 					if (text.equals("""")) {
 						return;
 					}
-					String js = Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
+					String js = Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
 					js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
 					browser.executeJavaScript(js);
 				}
@@ -80,7 +94,7 @@
 				if (input.getType().equals(""checkbox"")) {
 					for (InputValue inputValue : input.getInputValues()) {
 						String js =
-						        Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
+						        Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
 						boolean check;
 						if (!randomFieldValue) {
 							check = inputValue.isChecked();
@@ -106,7 +120,7 @@
 						if (inputValue.isChecked()) {
 							String js =
 							        Helper.getJSGetElement(XPathHelper
-							                .getXpathExpression(element));
+							                .getXPathExpression(element));
 							js += ""try{ATUSA_element.checked=true;}catch(e){}"";
 							browser.executeJavaScript(js);
 						}
@@ -118,7 +132,7 @@
 					for (InputValue inputValue : input.getInputValues()) {
 						// if(browser.getDriver()==null){
 						String js =
-						        Helper.getJSGetElement(XPathHelper.getXpathExpression(element));
+						        Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
 						js +=
 						        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
 						                + ""if(ATUSA_element.options[i].value=='""
@@ -144,7 +158,7 @@
 	private List<Node> getInputElements(Document dom) {
 		List<Node> nodes = new ArrayList<Node>();
 		try {
-			NodeList nodeList = Helper.getElementsByXpath(dom, ""//INPUT"");
+			NodeList nodeList = XPathHelper.evaluateXpathExpression(dom, ""//INPUT"");
 			List<String> allowedTypes = new ArrayList<String>(Arrays.asList(ALLOWED_INPUT_TYPES));
 
 			for (int i = 0; i < nodeList.getLength(); i++) {
@@ -156,11 +170,11 @@
 					nodes.add(nodeList.item(i));
 				}
 			}
-			nodeList = Helper.getElementsByXpath(dom, ""//TEXTAREA"");
+			nodeList = XPathHelper.evaluateXpathExpression(dom, ""//TEXTAREA"");
 			for (int i = 0; i < nodeList.getLength(); i++) {
 				nodes.add(nodeList.item(i));
 			}
-			nodeList = Helper.getElementsByXpath(dom, ""//SELECT"");
+			nodeList = XPathHelper.evaluateXpathExpression(dom, ""//SELECT"");
 			for (int i = 0; i < nodeList.getLength(); i++) {
 				nodes.add(nodeList.item(i));
 			}
@@ -183,7 +197,7 @@
 			List<Node> nodes = getInputElements(dom);
 			for (Node node : nodes) {
 				FormInput formInput =
-				        FormInputValueHelper.getFormInputWithDefaultValue(browser, node);
+				        formInputValueHelper.getFormInputWithDefaultValue(browser, node);
 				if (formInput != null) {
 					formInputs.add(formInput);
 				}
@@ -213,14 +227,28 @@
 	public void handleFormElements(List<FormInput> formInputs) {
 		Document dom;
 		try {
-			dom = Helper.getDocument(browser.getDom());
+			dom = Helper.getDocument(browser.getDomWithoutIframeContent());
 			for (FormInput input : formInputs) {
 				LOGGER.debug(""Filling in: "" + input);
-				setInputElementValue(FormInputValueHelper.getBelongingNode(input, dom), input);
+				setInputElementValue(formInputValueHelper.getBelongingNode(input, dom), input);
 			}
 		} catch (Exception e) {
 			LOGGER.warn(""Could not handle form elements"");
 		}
 	}
 
+	/**
+	 * @param sourceElement
+	 *            the form element
+	 * @param eventableCondition
+	 *            the belonging eventable condition for sourceElement
+	 * @return a list with Candidate elements for the inputs.
+	 */
+	public List<CandidateElement> getCandidateElementsForInputs(Element sourceElement,
+	        EventableCondition eventableCondition) {
+
+		return formInputValueHelper.getCandidateElementsForInputs(browser, sourceElement,
+		        eventableCondition);
+	}
+
 }
"
60c563d57aebf241f13b5c1415ce486b71be181a,Ali Mesbah,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/src/main/java/com/crawljax/util/ElementResolver.java b/src/main/java/com/crawljax/util/ElementResolver.java
index c3734ff..80302af 100644
--- a/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/src/main/java/com/crawljax/util/ElementResolver.java
@@ -75,7 +75,7 @@
 				LOGGER.info(""Search other candidate elements"");
 			}
 			NodeList candidateElements =
-			        Helper.getElementsByXpath(dom, ""//""
+			        XPathHelper.evaluateXpathExpression(dom, ""//""
 			                + eventable.getElement().getTag().toUpperCase());
 			if (logging) {
 				LOGGER.info(""Candidates: "" + candidateElements.getLength());
@@ -83,7 +83,7 @@
 			for (int i = 0; i < candidateElements.getLength(); i++) {
 				Element candidateElement = new Element(candidateElements.item(i));
 				if (equivalent(candidateElement, logging)) {
-					return XPathHelper.getXpathExpression(candidateElements.item(i));
+					return XPathHelper.getXPathExpression(candidateElements.item(i));
 				}
 			}
 
"
60c563d57aebf241f13b5c1415ce486b71be181a,Ali Mesbah,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 96d5065..ffa6107 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -21,7 +21,8 @@
 import org.w3c.dom.NodeList;
 
 /**
- * TODO: DOCUMENT ME!
+ * Utility class that contains methods used by Crawljax and some plugin to deal with XPath
+ * resolving, constructing etc.
  * 
  * @author mesbah
  * @version $Id$
@@ -40,21 +41,21 @@
 	 *            the given node.
 	 * @return string xpath expression (e.g., ""/html[1]/body[1]/div[3]"").
 	 */
-	public static String getXpathExpression(Node node) {
+	public static String getXPathExpression(Node node) {
 		Node parent = node.getParentNode();
 
 		if ((parent == null) || parent.getNodeName().contains(""#document"")) {
-			return ""/"" + getXPathNameStep(node) + ""[1]"";
+			return ""/"" + node.getNodeName() + ""[1]"";
 		}
 
 		StringBuffer buffer = new StringBuffer();
 
 		if (parent != node) {
-			buffer.append(getXpathExpression(parent));
+			buffer.append(getXPathExpression(parent));
 			buffer.append(""/"");
 		}
 
-		buffer.append(getXPathNameStep(node));
+		buffer.append(node.getNodeName());
 
 		List<Node> mySiblings = getSiblings(parent, node);
 
@@ -71,15 +72,15 @@
 	}
 
 	/**
-	 * TODO: DOCUMENT ME!
+	 * Get siblings of the same type as element from parent.
 	 * 
 	 * @param parent
 	 *            parent node.
 	 * @param element
 	 *            element.
-	 * @return
+	 * @return List of sibling (from element) under parent
 	 */
-	private static List<Node> getSiblings(Node parent, Node element) {
+	public static List<Node> getSiblings(Node parent, Node element) {
 		List<Node> result = new ArrayList<Node>();
 		NodeList list = parent.getChildNodes();
 
@@ -94,10 +95,6 @@
 		return result;
 	}
 
-	private static String getXPathNameStep(Node element) {
-		return element.getNodeName();
-	}
-
 	/**
 	 * Returns the list of nodes which match the expression xpathExpr in the String domStr.
 	 * 
@@ -141,29 +138,30 @@
 	}
 
 	/**
-	 * Returns the xpath of the first node retrieved by xpathExpression. Example: //DIV[@id='foo']
+	 * Returns the XPaths of all nodes retrieved by xpathExpression. Example: //DIV[@id='foo']
 	 * returns /HTM[1]/BODY[1]/DIV[2]
 	 * 
 	 * @param dom
 	 *            The dom.
 	 * @param xpathExpression
 	 *            The expression to find the element.
-	 * @return the xpath of the first node retrieved by xpathExpression.
+	 * @return list of XPaths retrieved by xpathExpression.
 	 */
-	public static String getXpathForXPathExpression(Document dom, String xpathExpression) {
+	public static List<String> getXpathForXPathExpressions(Document dom, String xpathExpression) {
 		NodeList nodeList;
 		try {
-			nodeList = Helper.getElementsByXpath(dom, xpathExpression);
+			nodeList = XPathHelper.evaluateXpathExpression(dom, xpathExpression);
 		} catch (XPathExpressionException e) {
 			return null;
 		}
+		List<String> result = new ArrayList<String>();
 		if (nodeList.getLength() > 0) {
-			if (nodeList.getLength() > 1) {
-				LOGGER.warn(""Expression "" + xpathExpression + "" returned more than one element."");
+			for (int i = 0; i < nodeList.getLength(); i++) {
+				Node n = nodeList.item(i);
+				result.add(getXPathExpression(n));
 			}
-			return getXpathExpression(nodeList.item(0));
 		}
-		return null;
+		return result;
 	}
 
 	/**
@@ -190,11 +188,6 @@
 		return formatted;
 	}
 
-	// public static void main(String[] args) {
-	// System.out.println(formatXPath(""//DIV[@class='foo']""));
-	// System.out.println(formatXPath(""/jeee/JEUJ/fooo/div[@KWAAK=\""false\""]""));
-	// }
-
 	/**
 	 * @param xpath
 	 *            The xpath expression to find the last element of.
@@ -347,15 +340,18 @@
 	 *         text()
 	 */
 	public static String stripXPathToElement(String xpath) {
-		if (xpath.toLowerCase().indexOf(""/text()"") != -1) {
-			xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/text()""));
+		if (xpath != null && !xpath.equals("""")) {
+			if (xpath.toLowerCase().indexOf(""/text()"") != -1) {
+				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/text()""));
+			}
+			if (xpath.toLowerCase().indexOf(""/comment()"") != -1) {
+				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/comment()""));
+			}
+			if (xpath.indexOf(""@"") != -1) {
+				xpath = xpath.substring(0, xpath.indexOf(""@"") - 1);
+			}
 		}
-		if (xpath.toLowerCase().indexOf(""/comment()"") != -1) {
-			xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/comment()""));
-		}
-		if (xpath.indexOf(""@"") != -1) {
-			xpath = xpath.substring(0, xpath.indexOf(""@"") - 1);
-		}
+
 		return xpath;
 	}
 
"
ec6e7a494ad58eb671b048b715b7f4137669499a,Stefan Lenselink,Crawler.java,MODIFY,"clickTag -> [Eventable eventable, boolean handleInputElements] | [Eventable eventable]","diff --git a/src/main/java/com/crawljax/core/Crawler.java b/src/main/java/com/crawljax/core/Crawler.java
index 0552216..bbbf02c 100644
--- a/src/main/java/com/crawljax/core/Crawler.java
+++ b/src/main/java/com/crawljax/core/Crawler.java
@@ -3,8 +3,6 @@
 import java.util.ArrayList;
 import java.util.List;
 
-import net.jcip.annotations.GuardedBy;
-
 import org.apache.log4j.Logger;
 
 import com.crawljax.browser.EmbeddedBrowser;
@@ -55,7 +53,7 @@
 	/**
 	 * The path followed from the index to the current state.
 	 */
-	private List<Eventable> exactEventPath = new ArrayList<Eventable>();
+	private final List<Eventable> exactEventPath = new ArrayList<Eventable>();
 
 	/**
 	 * TODO Stefan why is there two times the same variable? What is the difference and could it be
@@ -84,16 +82,20 @@
 	private String name = """";
 
 	/**
-	 * The sateMachine for this Crawler, keeping track of the path crawled by this Crawler. TODO
-	 * Stefan its better to have this final...
+	 * The sateMachine for this Crawler, keeping track of the path crawled by this Crawler.
 	 */
-	private StateMachine stateMachine;
+	private final StateMachine stateMachine;
 
 	private final CrawljaxConfigurationReader configurationReader;
 
 	private FormHandler formHandler;
 
 	/**
+	 * The object to places calls to add new Crawlers or to remove one.
+	 */
+	private final CrawlQueueManager crawlQueueManager;
+
+	/**
 	 * Enum for describing what has happened after a {@link Crawler#clickTag(Eventable, boolean)}
 	 * has been performed.
 	 * 
@@ -104,36 +106,6 @@
 	}
 
 	/**
-	 * Crawler constructor for a new 'starting from scratch(index)' crawler.
-	 * 
-	 * @param mother
-	 *            the main CrawljaxController
-	 */
-	public Crawler(CrawljaxController mother) {
-		this(mother, new ArrayList<Eventable>());
-		if (this.browser == null) {
-			/**
-			 * The Crawler is created with only a controller so probably its requested from the
-			 * CrawljaxController Create a new Browser to prevent null pointers :). Creating a
-			 * browser here would result in NOT loading the initial page in the run operation! This
-			 * MUST be done by hand!
-			 */
-			try {
-				browser = mother.getBrowserFactory().requestBrowser();
-			} catch (InterruptedException e) {
-				LOGGER.error(""The request for a browser was interuped"", e);
-			}
-		}
-		/**
-		 * Reset the state machine to null, dropping the existing state machine, as this call is
-		 * from the CrawljaxController the initial State is not known yet and causes trouble. The
-		 * CrawljaxController must create & set the first stateMachine using the setStateMachine
-		 * which on his case checks is the stateMachine is not set for safety reasons.
-		 */
-		stateMachine = null;
-	}
-
-	/**
 	 * @param mother
 	 *            the main CrawljaxController
 	 * @param exactEventPath
@@ -154,11 +126,22 @@
 	 * @param returnPath
 	 *            the path used to return to the last state, this can be a empty list
 	 */
-	private Crawler(CrawljaxController mother, List<Eventable> returnPath) {
-		this.exactEventPath = returnPath;
+	protected Crawler(CrawljaxController mother, List<Eventable> returnPath) {
+		this.exactEventPath.addAll(returnPath);
 		this.controller = mother;
-		stateMachine = controller.buildNewStateMachine();
 		this.configurationReader = controller.getConfigurationReader();
+		this.crawlQueueManager = mother.getCrawlQueueManager();
+		if (controller.getSession() != null) {
+			this.stateMachine =
+			        new StateMachine(controller.getSession().getStateFlowGraph(), controller
+			                .getSession().getInitialState(), controller.getInvariantList());
+		} else {
+			/**
+			 * Reset the state machine to null, because there is no session where to load the
+			 * stateFlowGraph from.
+			 */
+			this.stateMachine = null;
+		}
 	}
 
 	/**
@@ -170,12 +153,12 @@
 	public void goToInitialURL() throws CrawljaxException {
 		LOGGER.info(""Loading Page ""
 		        + configurationReader.getCrawlSpecificationReader().getSiteUrl());
-		browser.goToUrl(configurationReader.getCrawlSpecificationReader().getSiteUrl());
+		getBrowser().goToUrl(configurationReader.getCrawlSpecificationReader().getSiteUrl());
 		/**
 		 * Thread safe
 		 */
-		controller.doBrowserWait(browser);
-		CrawljaxPluginsUtil.runOnUrlLoadPlugins(browser);
+		controller.doBrowserWait(getBrowser());
+		CrawljaxPluginsUtil.runOnUrlLoadPlugins(getBrowser());
 	}
 
 	/**
@@ -188,6 +171,9 @@
 	private boolean fireEvent(Eventable eventable) {
 		try {
 
+			// TODO Stefan; FindBugs found this bug, not yet solved
+			// Should be changed with:
+			// eventable.getIdentification().getHow().toString().equals(""xpath"")
 			if (eventable.getIdentification().getHow().equals(""xpath"")
 			        && eventable.getRelatedFrame().equals("""")) {
 
@@ -205,7 +191,7 @@
 				/**
 				 * Try to find a 'better' / 'quicker' xpath
 				 */
-				String newXPath = new ElementResolver(eventable, browser).resolve();
+				String newXPath = new ElementResolver(eventable, getBrowser()).resolve();
 				if (newXPath != null) {
 					if (!xpath.equals(newXPath)) {
 						LOGGER.info(""XPath changed from "" + xpath + "" to "" + newXPath
@@ -217,18 +203,18 @@
 				}
 			}
 
-			if (browser.fireEvent(eventable)) {
+			if (getBrowser().fireEvent(eventable)) {
 
 				/**
 				 * Let the controller execute its specified wait operation on the browser Thread
 				 * safe
 				 */
-				controller.doBrowserWait(browser);
+				controller.doBrowserWait(getBrowser());
 
 				/**
 				 * Close opened windows
 				 */
-				browser.closeOtherWindows();
+				getBrowser().closeOtherWindows();
 
 				return true; // A event fired
 			} else {
@@ -268,7 +254,6 @@
 		}
 		eventable.setRelatedFormInputs(formInputs);
 		formHandler.handleFormElements(formInputs);
-
 	}
 
 	/**
@@ -278,47 +263,42 @@
 	 *             if the crawler encounters an error.
 	 */
 	private void goBackExact() throws CrawljaxException {
-
 		/**
 		 * Thread safe
 		 */
 		StateVertix curState = controller.getSession().getInitialState();
 
-		// remove the currentEvent from the list
-		if (exactEventPath.size() > 0) {
-			for (Eventable clickable : exactEventPath) {
+		for (Eventable clickable : exactEventPath) {
 
-				if (!controller.getElementChecker().checkCrawlCondition(browser)) {
-					return;
-				}
+			if (!controller.getElementChecker().checkCrawlCondition(getBrowser())) {
+				return;
+			}
 
-				LOGGER.info(""Backtracking by executing "" + clickable.getEventType()
-				        + "" on element: "" + clickable);
+			LOGGER.info(""Backtracking by executing "" + clickable.getEventType() + "" on element: ""
+			        + clickable);
 
-				stateMachine.changeState(clickable.getTargetStateVertix());
+			this.getStateMachine().changeState(clickable.getTargetStateVertix());
 
-				curState = clickable.getTargetStateVertix();
+			curState = clickable.getTargetStateVertix();
 
-				crawlPath.add(clickable);
+			crawlPath.add(clickable);
 
-				this.handleInputElements(clickable);
+			this.handleInputElements(clickable);
 
-				if (this.fireEvent(clickable)) {
+			if (this.fireEvent(clickable)) {
 
-					// TODO ali, do not increase depth if eventable is from guidedcrawling
-					depth++;
+				// TODO ali, do not increase depth if eventable is from guidedcrawling
+				depth++;
 
-					/**
-					 * Run the onRevisitStateValidator(s) TODO Stefan check for thread safety
-					 */
-					CrawljaxPluginsUtil.runOnRevisitStatePlugins(this.controller.getSession(),
-					        curState);
-				}
+				/**
+				 * Run the onRevisitStateValidator(s)
+				 */
+				CrawljaxPluginsUtil.runOnRevisitStatePlugins(this.controller.getSession(),
+				        curState);
+			}
 
-				if (!controller.getElementChecker().checkCrawlCondition(browser)) {
-					return;
-				}
-
+			if (!controller.getElementChecker().checkCrawlCondition(getBrowser())) {
+				return;
 			}
 		}
 	}
@@ -332,36 +312,31 @@
 	 * @throws CrawljaxException
 	 *             an exception.
 	 */
-	private ClickResult clickTag(final Eventable eventable, boolean handleInputElements)
-	        throws CrawljaxException {
-
+	private ClickResult clickTag(final Eventable eventable) throws CrawljaxException {
 		// load input element values
-		if (handleInputElements) {
-			this.handleInputElements(eventable);
-		}
+		this.handleInputElements(eventable);
 
 		LOGGER.info(""Executing "" + eventable.getEventType() + "" on element: "" + eventable
-		        + ""; State: "" + stateMachine.getCurrentState().getName());
-
+		        + ""; State: "" + this.getStateMachine().getCurrentState().getName());
 		if (this.fireEvent(eventable)) {
-			// String dom = new String(browser.getDom());
 			StateVertix newState =
-			        new StateVertix(browser.getCurrentUrl(), controller.getSession()
-			                .getStateFlowGraph().getNewStateName(), browser.getDom(),
-			                this.controller.getStrippedDom(browser));
+			        new StateVertix(getBrowser().getCurrentUrl(), controller.getSession()
+			                .getStateFlowGraph().getNewStateName(), getBrowser().getDom(),
+			                this.controller.getStrippedDom(getBrowser()));
 
-			if (isDomChanged(stateMachine.getCurrentState(), newState)) {
+			if (isDomChanged(this.getStateMachine().getCurrentState(), newState)) {
+				// Dom is changed, so data might need be filled in again
 				crawlPath.add(eventable);
+				// TODO Stefan; Fix this behaviour, this causes trouble + performance...
 				this.controller.getSession().setExactEventPath(getExacteventpath());
-				if (stateMachine.update(eventable, newState, this.getBrowser(), this.controller
-				        .getSession())) {
+				if (this.getStateMachine().update(eventable, newState, this.getBrowser(),
+				        this.controller.getSession())) {
 					// Dom changed
 					// No Clone
-
 					exactEventPath.add(eventable);
 
 					CrawljaxPluginsUtil.runGuidedCrawlingPlugins(controller, controller
-					        .getSession(), getExacteventpath(), this.stateMachine);
+					        .getSession(), getExacteventpath(), this.getStateMachine());
 
 					return ClickResult.newState;
 				} else {
@@ -370,8 +345,7 @@
 				}
 			}
 		}
-		// Event not fired or
-		// Dom not changed
+		// Event not fired or, Dom not changed
 		return ClickResult.domUnChanged;
 	}
 
@@ -403,6 +377,52 @@
 		}
 	}
 
+	private void spawnThreads(StateVertix state, boolean removeLastStateFromEventPath) {
+		Crawler c = null;
+		do {
+			if (c != null) {
+				this.crawlQueueManager.addWorkToQueue(c);
+			}
+			c = new Crawler(this.controller, getCurrentExactPaths(removeLastStateFromEventPath));
+		} while (state.registerCrawler(c));
+	}
+
+	private ClickResult crawlAction(CandidateCrawlAction action) throws CrawljaxException {
+		CandidateElement candidateElement = action.getCandidateElement();
+		EventType eventType = action.getEventType();
+
+		StateVertix orrigionalState = this.getStateMachine().getCurrentState();
+
+		if (candidateElement.allConditionsSatisfied(getBrowser())) {
+			ClickResult clickResult = clickTag(new Eventable(candidateElement, eventType));
+			switch (clickResult) {
+				case cloneDetected:
+					fired = false;
+					// We are in the clone state so we continue with the cloned version to search
+					// for work.
+					this.controller.getSession().addCrawlPath(crawlPath);
+					spawnThreads(orrigionalState, false);
+					break;
+				case newState:
+					fired = true;
+					// Recurse because new state found
+					spawnThreads(orrigionalState, true);
+					break;
+				case domUnChanged:
+					// Dom not updated, continue with the next
+					break;
+				default:
+					break;
+			}
+			return clickResult;
+		} else {
+
+			LOGGER.info(""Conditions not satisfied for element: "" + candidateElement + ""; State: ""
+			        + this.getStateMachine().getCurrentState().getName());
+		}
+		return ClickResult.domUnChanged;
+	}
+
 	/**
 	 * Crawl through the clickables.
 	 * 
@@ -419,17 +439,20 @@
 		}
 
 		// Store the currentState to be able to 'back-track' later.
-		StateVertix orrigionalState = stateMachine.getCurrentState();
-		orrigionalState.searchForCandidateElements(candidateExtractor, configurationReader
+		StateVertix orrigionalState = this.getStateMachine().getCurrentState();
+
+		if (orrigionalState.searchForCandidateElements(candidateExtractor, configurationReader
 		        .getTagElements(), configurationReader.getExcludeTagElements(),
-		        configurationReader.getCrawlSpecificationReader().getClickOnce());
+		        configurationReader.getCrawlSpecificationReader().getClickOnce())) {
+			// Only execute the preStateCrawlingPlugins when it's the first time
+			LOGGER.info(""Starting preStateCrawlingPlugins..."");
+			CrawljaxPluginsUtil.runPreStateCrawlingPlugins(controller.getSession(),
+			        orrigionalState.getUnprocessedCandidateElements());
+		}
 
-		CrawljaxPluginsUtil.runPreStateCrawlingPlugins(controller.getSession(), orrigionalState
-		        .getUnprocessedCandidateElements());
-
-		boolean handleInputElements = true;
-
-		for (CandidateCrawlAction action : orrigionalState) {
+		CandidateCrawlAction action =
+		        orrigionalState.pollCandidateCrawlAction(this, crawlQueueManager);
+		while (action != null) {
 			if (depthLimitReached(depth)) {
 				return true;
 			}
@@ -437,45 +460,17 @@
 			if (!checkConstraints()) {
 				return false;
 			}
-
-			CandidateElement candidateElement = action.getCandidateElement();
-			EventType eventType = action.getEventType();
-
-			if (candidateElement.allConditionsSatisfied(browser)) {
-				ClickResult clickResult =
-				        clickTag(new Eventable(candidateElement, eventType), handleInputElements);
-				switch (clickResult) {
-					case cloneDetected:
-						fired = false;
-						// TODO A optimisation could be to check the new state (== clone) to see
-						// if there is unfinished work and continue with that so reload can be
-						// Postponed and 1 reload can be saved.
-						this.controller.getSession().addCrawlPath(crawlPath);
-						if (orrigionalState.hasMoreToExplore()) {
-							controller.addWorkToQueue(new Crawler(this.controller,
-							        getCurrentExactPaths(false)));
-						}
-						return true;
-					case newState:
-						fired = true;
-						// Recurse because new state found
-						if (orrigionalState.hasMoreToExplore()) {
-							controller.addWorkToQueue(new Crawler(this.controller,
-							        getCurrentExactPaths(true)));
-						}
-						return newStateDetected(orrigionalState);
-					case domUnChanged:
-						// Dom not updated, continue with the next
-						handleInputElements = false;
-						break;
-					default:
-						break;
-				}
-			} else {
-
-				LOGGER.info(""Conditions not satisfied for element: "" + candidateElement
-				        + ""; State: "" + stateMachine.getCurrentState().getName());
+			ClickResult result = this.crawlAction(action);
+			orrigionalState.finishedWorking(this, action);
+			switch (result) {
+				case newState:
+					return newStateDetected(orrigionalState);
+				case cloneDetected:
+					return true;
+				default:
+					break;
 			}
+			action = orrigionalState.pollCandidateCrawlAction(this, crawlQueueManager);
 		}
 		return true;
 	}
@@ -500,7 +495,7 @@
 			controller.terminate();
 			return false;
 		}
-		stateMachine.changeState(orrigionalState);
+		this.getStateMachine().changeState(orrigionalState);
 		return true;
 	}
 
@@ -535,45 +530,40 @@
 	 * specified.
 	 */
 	public void init() {
-		/**
-		 * If the browser is null place a request for a browser from the BrowserFactory
-		 */
+		this.browser = this.getBrowser();
 		if (this.browser == null) {
+			/**
+			 * As the browser is null, request one and got to the initial url, if the browser is
+			 * Already set the browser will be in the initial url.
+			 */
 			try {
 				this.browser = controller.getBrowserFactory().requestBrowser();
 			} catch (InterruptedException e1) {
 				LOGGER.error(""The request for a browser was interuped"", e1);
 			}
-			LOGGER.info(""Reloading page for navigating back since browser is not initialized."");
+			LOGGER.info(""Reloading page for navigating back"");
 			try {
 				this.goToInitialURL();
 			} catch (Exception e) {
 				LOGGER.error(""Could not load the initialURL"", e);
 			}
 		}
-
 		// TODO Stefan ideally this should be placed in the constructor
 		this.formHandler =
-		        new FormHandler(browser, configurationReader.getInputSpecification(),
+		        new FormHandler(getBrowser(), configurationReader.getInputSpecification(),
 		                configurationReader.getCrawlSpecificationReader().getRandomInputInForms());
 
 		this.candidateExtractor =
 		        new CandidateElementExtractor(controller.getElementChecker(), this.getBrowser(),
 		                formHandler);
-
-		stateMachine.rewind();
-
 		/**
-		 * Do we need to go back into a previous state?
+		 * go back into the previous state.
 		 */
-		if (exactEventPath.size() > 0) {
-			try {
-				this.goBackExact();
-			} catch (Exception e) {
-				LOGGER.error(""Failed to backtrack"", e);
-			}
+		try {
+			this.goBackExact();
+		} catch (Exception e) {
+			LOGGER.error(""Failed to backtrack"", e);
 		}
-
 	}
 
 	/**
@@ -582,12 +572,12 @@
 	 * done with {@link CrawlerExecutor#shutdown()}
 	 */
 	public void shutdown() {
-		controller.getBrowserFactory().freeBrowser(this.browser);
+		controller.getBrowserFactory().freeBrowser(this.getBrowser());
 	}
 
 	/**
 	 * The main function stated by the ExecutorService. Crawlers add themselves to the list by
-	 * calling {@link CrawljaxController#addWorkToQueue(Crawler)}. When the ExecutorService finds a
+	 * calling {@link CrawlQueueManager#addWorkToQueue(Crawler)}. When the ExecutorService finds a
 	 * free thread this method is called and when this method ends the Thread is released again and
 	 * a new Thread is started
 	 * 
@@ -596,6 +586,17 @@
 	 */
 	@Override
 	public void run() {
+		if (exactEventPath.size() > 0) {
+			try {
+				if (!exactEventPath.get(exactEventPath.size() - 1).getTargetStateVertix()
+				        .startWorking(this)) {
+					LOGGER.warn(""BAH!"");
+					return;
+				}
+			} catch (CrawljaxException e) {
+				LOGGER.error(""Received Crawljax exception"", e);
+			}
+		}
 
 		/**
 		 * Init the Crawler
@@ -612,8 +613,6 @@
 			/**
 			 * Crawling is done; so the crawlPath of the current branch is known
 			 */
-			// TODO Stefan Delete the fired variable if possible? Or move this is not the correct
-			// location.
 			if (fired) {
 				controller.getSession().addCrawlPath(crawlPath);
 			}
@@ -632,7 +631,7 @@
 	 * 
 	 * @return the browser used in this Crawler Thread
 	 */
-	public final EmbeddedBrowser getBrowser() {
+	public EmbeddedBrowser getBrowser() {
 		return browser;
 	}
 
@@ -642,23 +641,6 @@
 	}
 
 	/**
-	 * Set the stateMachine that must be used, be careful! This must only be called during the init
-	 * of the CrawljaxController.
-	 * 
-	 * @throws CrawljaxException
-	 *             will be thrown when the stateMachine is already set!
-	 * @param machine
-	 *            the stateMachine to set.
-	 */
-	public void setStateMachine(final StateMachine machine) throws CrawljaxException {
-		if (stateMachine != null) {
-			throw new CrawljaxException(
-			        ""The stateMachine is allready specified can not be overwritten!"");
-		}
-		this.stateMachine = machine;
-	}
-
-	/**
 	 * @return the state machine.
 	 */
 	public StateMachine getStateMachine() {
@@ -697,7 +679,6 @@
 	 * 
 	 * @return true if all conditions are met.
 	 */
-	@GuardedBy(""stateFlowGraph"")
 	private boolean checkConstraints() {
 		long timePassed = System.currentTimeMillis() - controller.getSession().getStartTime();
 		int maxCrawlTime = configurationReader.getCrawlSpecificationReader().getMaximumRunTime();
@@ -708,16 +689,12 @@
 			return false;
 		}
 		StateFlowGraph graph = controller.getSession().getStateFlowGraph();
-		// TODO Stefan is this needed?
 		int maxNumberOfStates =
 		        configurationReader.getCrawlSpecificationReader().getMaxNumberOfStates();
-		synchronized (graph) {
-			if ((maxNumberOfStates != 0) && (graph.getAllStates().size() >= maxNumberOfStates)) {
-				LOGGER.info(""Max number of states "" + maxNumberOfStates + "" reached!"");
-
-				/* stop crawling */
-				return false;
-			}
+		if ((maxNumberOfStates != 0) && (graph.getAllStates().size() >= maxNumberOfStates)) {
+			LOGGER.info(""Max number of states "" + maxNumberOfStates + "" reached!"");
+			/* stop crawling */
+			return false;
 		}
 		/* continue crawling */
 		return true;
"
6dd4e4bfe8d05598d30794d0c1c7e0727c52732e,Frank Groeneveld,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index ffa6107..849b80e 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -15,7 +15,6 @@
 import javax.xml.xpath.XPathExpressionException;
 import javax.xml.xpath.XPathFactory;
 
-import org.apache.log4j.Logger;
 import org.w3c.dom.Document;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
@@ -28,7 +27,6 @@
  * @version $Id$
  */
 public final class XPathHelper {
-	private static final Logger LOGGER = Logger.getLogger(XPathHelper.class.getName());
 	private static final int MAX_SEARCH_LOOPS = 10000;
 
 	private XPathHelper() {
"
40fd0b3da91babf6656b81723e57acd2d24c4107,Frank Groeneveld,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/src/main/java/com/crawljax/core/CrawljaxController.java b/src/main/java/com/crawljax/core/CrawljaxController.java
index 910823c..01d19d2 100644
--- a/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -8,7 +8,7 @@
 import org.apache.commons.configuration.ConfigurationException;
 import org.apache.log4j.Logger;
 
-import com.crawljax.browser.BrowserFactory;
+import com.crawljax.browser.BrowserPool;
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.browserwaiter.WaitConditionChecker;
 import com.crawljax.condition.crawlcondition.CrawlConditionChecker;
@@ -56,7 +56,7 @@
 
 	private final CandidateElementManager elementChecker;
 
-	private final BrowserFactory browserFactory;
+	private final BrowserPool browserFactory;
 
 	/**
 	 * @param config
@@ -79,7 +79,7 @@
 		elementChecker =
 		        new CandidateElementManager(eventableConditionChecker, crawlConditionChecker);
 
-		browserFactory = new BrowserFactory(configurationReader);
+		browserFactory = new BrowserPool(configurationReader);
 
 		workQueue = init();
 	}
@@ -310,7 +310,7 @@
 	/**
 	 * @return the browser factory.
 	 */
-	public BrowserFactory getBrowserFactory() {
+	public BrowserPool getBrowserFactory() {
 		return browserFactory;
 	}
 
"
df388cff739172946481fffe16d978e42dacdbde,Frank Groeneveld,GuidedCrawlingPlugin.java,MODIFY,"guidedCrawling -> [StateVertix currentState, CrawljaxController controler, CrawlSession session, List exactEventPaths, StateMachine stateMachine] | [StateVertix currentState, CrawljaxController controller, CrawlSession session, List exactEventPaths, StateMachine stateMachine]","diff --git a/src/main/java/com/crawljax/core/plugin/GuidedCrawlingPlugin.java b/src/main/java/com/crawljax/core/plugin/GuidedCrawlingPlugin.java
index c761ca1..5e6b29e 100644
--- a/src/main/java/com/crawljax/core/plugin/GuidedCrawlingPlugin.java
+++ b/src/main/java/com/crawljax/core/plugin/GuidedCrawlingPlugin.java
@@ -20,7 +20,7 @@
 	/**
 	 * @param currentState
 	 *            a copy of the currentState.
-	 * @param controler
+	 * @param controller
 	 *            the crawljax controller instance.
 	 * @param session
 	 *            the crawl session.
@@ -30,7 +30,7 @@
 	 * @param stateMachine
 	 *            the state machine.
 	 */
-	void guidedCrawling(StateVertix currentState, CrawljaxController controler,
+	void guidedCrawling(StateVertix currentState, CrawljaxController controller,
 	        CrawlSession session, List<Eventable> exactEventPaths, StateMachine stateMachine);
 
 }
"
5f87cb797138c55cc7339dd882f5c73ea6a1b11a,Stefan Lenselink,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload] | [String hubUrl]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 242cb2c..fe01a5b 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -1,6 +1,7 @@
 package com.crawljax.browser;
 
 import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.configuration.CrawljaxConfigurationReader;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.Identification;
 import com.crawljax.forms.FormHandler;
@@ -45,23 +46,33 @@
 /**
  * @author mesbah
  * @author Frank Groeneveld
- * @version $Id$
+ * @version $Id: WebDriverBackedEmbeddedBrowser.java 387 2010-07-13 13:55:49Z slenselink@google.com
+ *          $
  */
-public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
-	private final long crawlWaitEvent;
+public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser<WebDriver> {
+	private long crawlWaitEvent;
 	private static final Logger LOGGER = Logger.getLogger(WebDriverBackedEmbeddedBrowser.class);
 	private final WebDriver browser;
 
-	private final List<String> filterAttributes;
-	private final long crawlWaitReload;
+	private List<String> filterAttributes;
+	private long crawlWaitReload;
+
+	/**
+	 * Constructor without configuration values, these must be updated using the
+	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
+	 *
+	 * @param driver
+	 *            The WebDriver to use.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
+		this.browser = driver;
+	}
 
 	/**
 	 * Constructor.
 	 *
 	 * @param driver
 	 *            The WebDriver to use.
-	 * @param logger
-	 *            the logger instance.
 	 * @param filterAttributes
 	 *            the attributes to be filtered from DOM.
 	 * @param crawlWaitReload
@@ -71,7 +82,7 @@
 	 */
 	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
 	        long crawlWaitReload, long crawlWaitEvent) {
-		this.browser = driver;
+		this(driver);
 		this.filterAttributes = filterAttributes;
 		this.crawlWaitEvent = crawlWaitEvent;
 		this.crawlWaitReload = crawlWaitReload;
@@ -92,27 +103,8 @@
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
 	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
-		DesiredCapabilities capabilities = new DesiredCapabilities();
-		capabilities.setPlatform(Platform.ANY);
-		URL url;
-		try {
-			url = new URL(hubUrl);
-		} catch (MalformedURLException e) {
-			LOGGER.error(
-			        ""The given hub url of the remote server is malformed can not continue!"", e);
-			return null;
-		}
-		HttpCommandExecutor executor = null;
-		try {
-			executor = new HttpCommandExecutor(url);
-		} catch (Exception e) {
-			LOGGER.error(""Received unknown exception while creating the ""
-			        + ""HttpCommandExecutor, can not continue!"", e);
-			return null;
-		}
 		return WebDriverBackedEmbeddedBrowser.withDriver(
-		        new RemoteWebDriver(executor, capabilities), filterAttributes, crawlWaitEvent,
-		        crawlWaitReload);
+		        buildRemoteWebDriver(hubUrl), filterAttributes, crawlWaitEvent, crawlWaitReload);
 	}
 
 	/**
@@ -135,6 +127,59 @@
 	}
 
 	/**
+	 * Create a RemoteWebDriver backed EmbeddedBrowser.
+	 *
+	 * @param hubUrl
+	 *            Url of the server.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl) {
+
+		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl));
+	}
+
+	/**
+	 * Private used static method for creation of a RemoteWebDriver. Taking care of the default
+	 * Capabilities and using the HttpCommandExecutor.
+	 *
+	 * @param hubUrl
+	 *            the url of the hub to use.
+	 * @return the RemoteWebDriver instance.
+	 */
+	private static RemoteWebDriver buildRemoteWebDriver(String hubUrl) {
+		DesiredCapabilities capabilities = new DesiredCapabilities();
+		capabilities.setPlatform(Platform.ANY);
+		URL url;
+		try {
+			url = new URL(hubUrl);
+		} catch (MalformedURLException e) {
+			LOGGER.error(
+			        ""The given hub url of the remote server is malformed can not continue!"", e);
+			return null;
+		}
+		HttpCommandExecutor executor = null;
+		try {
+			executor = new HttpCommandExecutor(url);
+		} catch (Exception e) {
+			LOGGER.error(""Received unknown exception while creating the ""
+			        + ""HttpCommandExecutor, can not continue!"", e);
+			return null;
+		}
+		return new RemoteWebDriver(executor, capabilities);
+	}
+
+	/**
+	 * Create a WebDriver backed EmbeddedBrowser.
+	 *
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver) {
+		return new WebDriverBackedEmbeddedBrowser(driver);
+	}
+
+	/**
 	 * @param url
 	 *            The URL.
 	 * @throws CrawljaxException
@@ -317,7 +362,7 @@
 				} catch (NoSuchFrameException e) {
 					LOGGER.debug(""Frame not found, possibily while back-tracking.."", e);
 					// TODO Stefan, This exception is catched to prevent stopping from working
-					// This was the case on the Gmail case; findout if not switching (catching)
+					// This was the case on the Gmail case; find out if not switching (catching)
 					// Results in good performance...
 				}
 				handleChanged = true;
@@ -434,8 +479,7 @@
 		return document;
 	}
 
-	private void appendFrameContent(Element orig, Document document, String topFrame)
-	        throws SAXException, IOException {
+	private void appendFrameContent(Element orig, Document document, String topFrame) {
 
 		NodeList frameNodes = orig.getElementsByTagName(""IFRAME"");
 
@@ -497,7 +541,7 @@
 	 * @return the dom without the iframe contents.
 	 * @throws CrawljaxException
 	 *             if it fails.
-	 * @see com.crawljax.browser.EmbeddedBrowser#getDomWithoutIframeContent().
+	 * @see com.crawljax.browser.EmbeddedBrowser#getDomWithoutIframeContent()
 	 */
 	public String getDomWithoutIframeContent() throws CrawljaxException {
 
@@ -650,4 +694,17 @@
 		}
 	}
 
+	@Override
+	public WebDriver getBrowser() {
+		return browser;
+	}
+
+	@Override
+	public void updateConfiguration(CrawljaxConfigurationReader configuration) {
+		// Retrieve the config values used
+		this.filterAttributes = configuration.getFilterAttributeNames();
+		this.crawlWaitReload =
+		        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
+		this.crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
+	}
 }
\ No newline at end of file
"
5f87cb797138c55cc7339dd882f5c73ea6a1b11a,Stefan Lenselink,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/src/main/java/com/crawljax/core/CrawlQueue.java b/src/main/java/com/crawljax/core/CrawlQueue.java
index 5f1dabb..52dc64f 100644
--- a/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -3,18 +3,18 @@
  */
 package com.crawljax.core;
 
+import net.jcip.annotations.GuardedBy;
+
 import java.util.Collection;
 import java.util.Stack;
 import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.TimeUnit;
 
-import net.jcip.annotations.GuardedBy;
-
 /**
  * This class implements a BlockingQueue with Runnable as its Generic type and extends Stack with
  * also Runnable as generic type. This class is used in the ThreadPoolExecutor and its used to store
  * separate threads in a Queue like fashion (FILO).
- * 
+ *
  * @author Stefan Lenselink <S.R.Lenselink@student.tudelft.nl>
  * @version $Id$
  */
@@ -53,17 +53,17 @@
 	}
 
 	@Override
-	public boolean offer(Runnable e, long timeout, TimeUnit unit) throws InterruptedException {
+	public boolean offer(Runnable e, long timeout, TimeUnit unit) {
 		return this.add(e);
 	}
 
 	@Override
-	public Runnable poll(long timeout, TimeUnit unit) throws InterruptedException {
+	public Runnable poll(long timeout, TimeUnit unit) {
 		return remove();
 	}
 
 	@Override
-	public void put(Runnable e) throws InterruptedException {
+	public void put(Runnable e) {
 		this.add(e);
 
 	}
@@ -74,7 +74,7 @@
 	}
 
 	@Override
-	public Runnable take() throws InterruptedException {
+	public Runnable take() {
 		return remove();
 	}
 
"
5f87cb797138c55cc7339dd882f5c73ea6a1b11a,Stefan Lenselink,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/src/main/java/com/crawljax/core/CrawljaxController.java b/src/main/java/com/crawljax/core/CrawljaxController.java
index b6f0faa..ae6b2e3 100644
--- a/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -147,7 +147,7 @@
 
 		// TODO Stefan; Now we ""re-request"" a browser instance for the PostCrawlingPlugins Thread,
 		// this is not ideal...
-		EmbeddedBrowser b = null;
+		EmbeddedBrowser<?> b = null;
 		try {
 			b = this.getBrowserPool().requestBrowser();
 		} catch (InterruptedException e1) {
@@ -220,7 +220,7 @@
 	 * @param browser
 	 *            the browser which requires a wait condition
 	 */
-	public final void doBrowserWait(EmbeddedBrowser browser) {
+	public final void doBrowserWait(EmbeddedBrowser<?> browser) {
 		this.waitConditionChecker.wait(browser);
 	}
 
@@ -234,7 +234,7 @@
 	 *            the browser instance.
 	 * @return a stripped string of the DOM tree taken from the browser.
 	 */
-	public synchronized String getStrippedDom(EmbeddedBrowser browser) {
+	public synchronized String getStrippedDom(EmbeddedBrowser<?> browser) {
 		return this.stateComparator.getStrippedDom(browser);
 	}
 
"
5f87cb797138c55cc7339dd882f5c73ea6a1b11a,Stefan Lenselink,CrawljaxConfiguration.java,MODIFY,setBrowserBuilder -> [BrowserBuilder browserBuilder] | [EmbeddedBrowserBuilder browserBuilder],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index eeffa51..dfd65b5 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -1,15 +1,15 @@
 package com.crawljax.core.configuration;
 
-import java.util.ArrayList;
-import java.util.List;
-
-import com.crawljax.browser.BrowserBuilder;
-import com.crawljax.browser.WebDriverBrowserBuilder;
+import com.crawljax.browser.EmbeddedBrowserBuilder;
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
+import com.crawljax.browser.WebDriverBrowserBuilder;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.util.Helper;
 
+import java.util.ArrayList;
+import java.util.List;
+
 /**
  * Specifies the settings Crawljax. The methods in this class fall into two categories:Oz
  * <p/>
@@ -18,24 +18,19 @@
  * <li>Properties for the crawling
  * {@link CrawljaxConfiguration#setCrawlSpecification(CrawlSpecification)}</li>
  * </ul>
- * <p/>
- * By default Crawljax uses no database, but this can be enabled via
- * {@link CrawljaxConfiguration#setHibernateConfiguration(HibernateConfiguration)} See also
- * {@link HibernateConfiguration}
- * <p/>
- * DEFAULT VAlUES: Browser: webdriver firefox Project Full Path: empty Project Relative Path: empty
+ *  DEFAULT VAlUES: Browser: webdriver firefox Project Full Path: empty Project Relative Path: empty
  * Filter attributes: closure_hashcode_(\\w)*, jquery[0-9]+ Test invariants while crawling: true
  * EXAMPLE: CrawljaxConfiguration crawljaxConfig = new CrawljaxConfiguration(); CrawlSpecification
  * crawler = new CrawlSpecification(""http://www.google.com""); crawler.click(""a"");
  * crawljaxConfig.setCrawlSpecification(crawler);
- * 
+ *
  * @version $Id$
  */
 public final class CrawljaxConfiguration {
 
 	private BrowserType browser = BrowserType.firefox;
 
-	private BrowserBuilder browserBuilder = new WebDriverBrowserBuilder();
+	private EmbeddedBrowserBuilder browserBuilder = new WebDriverBrowserBuilder();
 
 	private String remoteHubUrl = """";
 
@@ -88,7 +83,7 @@
 
 	/**
 	 * Enable the crawljax proxy extension.
-	 * 
+	 *
 	 * @param proxyConfiguration
 	 *            The ProxyConfiguration to set.
 	 */
@@ -127,8 +122,9 @@
 		// and not by another random crawlTag
 		List<CrawlElement> crawlTags = getInputSpecification().getCrawlElements();
 		if (getCrawlSpecification() != null) {
-			for (CrawlElement crawlTag : getCrawlSpecification().crawlActions()
-			        .getCrawlElements()) {
+
+			for (CrawlElement crawlTag :
+			        getCrawlSpecification().crawlActions().getCrawlElements()) {
 				crawlTags.add(crawlTag);
 			}
 		}
@@ -141,8 +137,8 @@
 	protected List<CrawlElement> getAllCrawlElements() {
 		List<CrawlElement> crawlTags = getAllIncludedCrawlElements();
 		if (getCrawlSpecification() != null) {
-			for (CrawlElement crawlTag : getCrawlSpecification().crawlActions()
-			        .getCrawlElementsExcluded()) {
+			for (CrawlElement crawlTag :
+			        getCrawlSpecification().crawlActions().getCrawlElementsExcluded()) {
 				crawlTags.add(crawlTag);
 			}
 		}
@@ -182,13 +178,13 @@
 	/**
 	 * @return the browserBuilder
 	 */
-	protected BrowserBuilder getBrowserBuilder() {
+	protected EmbeddedBrowserBuilder getBrowserBuilder() {
 		return browserBuilder;
 	}
 
 	/**
 	 * Set the remote hub url that needs to be taken when using remote crawling.
-	 * 
+	 *
 	 * @param remoteHubUrl
 	 *            the url of the remote hub
 	 */
@@ -207,7 +203,7 @@
 	 * @param browserBuilder
 	 *            the browserBuilder to set
 	 */
-	public void setBrowserBuilder(BrowserBuilder browserBuilder) {
+	public void setBrowserBuilder(EmbeddedBrowserBuilder browserBuilder) {
 		this.browserBuilder = browserBuilder;
 	}
 
@@ -276,7 +272,7 @@
 
 	/**
 	 * Sets filter attribute names.
-	 * 
+	 *
 	 * @param filterAttributeNames
 	 *            The attribute names to filter.
 	 */
@@ -313,7 +309,7 @@
 	 * Add a plugin to the execution. Note that the order of adding is the same as running for the
 	 * same type of plugin. This means that if you add a precrawling plugin p1 and next you add a
 	 * precrawling plugin p2, p1 will be executed before p2.
-	 * 
+	 *
 	 * @param plugin
 	 *            Add a plugin. See {@link Plugin}.
 	 */
"
5f87cb797138c55cc7339dd882f5c73ea6a1b11a,Stefan Lenselink,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index e88ed25..6914c7b 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -3,18 +3,6 @@
  */
 package com.crawljax.forms;
 
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.List;
-
-import javax.xml.xpath.XPathExpressionException;
-
-import org.apache.log4j.Logger;
-import org.w3c.dom.Document;
-import org.w3c.dom.Element;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.CandidateElement;
@@ -22,10 +10,22 @@
 import com.crawljax.util.Helper;
 import com.crawljax.util.XPathHelper;
 
+import org.apache.log4j.Logger;
+import org.w3c.dom.Document;
+import org.w3c.dom.Element;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+
+import javax.xml.xpath.XPathExpressionException;
+
 /**
  * Handles form values and fills in the form input elements with random values of the defined
  * values.
- * 
+ *
  * @author dannyroest@gmail.com (Danny Roest)
  * @version $Id$
  */
@@ -33,7 +33,7 @@
 	private static final Logger LOGGER = Logger.getLogger(FormHandler.class.getName());
 
 	private boolean randomFieldValue = false;
-	private final EmbeddedBrowser browser;
+	private final EmbeddedBrowser<?> browser;
 
 	public static final int RANDOM_STRING_LENGTH = 8;
 
@@ -43,7 +43,7 @@
 
 	/**
 	 * Public constructor.
-	 * 
+	 *
 	 * @param browser
 	 *            the embedded browser.
 	 * @param inputSpecification
@@ -51,7 +51,7 @@
 	 * @param randomInput
 	 *            if random data should be generated on the input fields.
 	 */
-	public FormHandler(EmbeddedBrowser browser, InputSpecification inputSpecification,
+	public FormHandler(EmbeddedBrowser<?> browser, InputSpecification inputSpecification,
 	        boolean randomInput) {
 		this.browser = browser;
 		this.formInputValueHelper = new FormInputValueHelper(inputSpecification, randomInput);
@@ -63,10 +63,9 @@
 	/**
 	 * Fills in the element with the InputValues for input TODO: improve this by using WebDriver
 	 * options?
-	 * 
+	 *
 	 * @param element
 	 * @param input
-	 * @throws Exception
 	 */
 	private void setInputElementValue(Node element, FormInput input) {
 
@@ -118,9 +117,8 @@
 				if (input.getType().equals(""radio"")) {
 					for (InputValue inputValue : input.getInputValues()) {
 						if (inputValue.isChecked()) {
-							String js =
-							        Helper.getJSGetElement(XPathHelper
-							                .getXPathExpression(element));
+							String js = Helper.getJSGetElement(
+							        XPathHelper.getXPathExpression(element));
 							js += ""try{ATUSA_element.checked=true;}catch(e){}"";
 							browser.executeJavaScript(js);
 						}
@@ -164,9 +162,8 @@
 			for (int i = 0; i < nodeList.getLength(); i++) {
 				Node candidate = nodeList.item(i);
 				Node typeAttribute = candidate.getAttributes().getNamedItem(""type"");
-				if (typeAttribute == null
-				        || (typeAttribute != null && allowedTypes.contains(typeAttribute
-				                .getNodeValue()))) {
+				if (typeAttribute == null || (typeAttribute != null
+				        && allowedTypes.contains(typeAttribute.getNodeValue()))) {
 					nodes.add(nodeList.item(i));
 				}
 			}
@@ -210,7 +207,7 @@
 
 	/**
 	 * Handle form elements.
-	 * 
+	 *
 	 * @throws Exception
 	 *             the exception.
 	 */
@@ -220,7 +217,7 @@
 
 	/**
 	 * Fills in form/input elements.
-	 * 
+	 *
 	 * @param formInputs
 	 *            form input list.
 	 */
@@ -244,11 +241,11 @@
 	 *            the belonging eventable condition for sourceElement
 	 * @return a list with Candidate elements for the inputs.
 	 */
-	public List<CandidateElement> getCandidateElementsForInputs(Element sourceElement,
-	        EventableCondition eventableCondition) {
+	public List<CandidateElement> getCandidateElementsForInputs(
+	        Element sourceElement, EventableCondition eventableCondition) {
 
-		return formInputValueHelper.getCandidateElementsForInputs(browser, sourceElement,
-		        eventableCondition);
+		return formInputValueHelper.getCandidateElementsForInputs(
+		        browser, sourceElement, eventableCondition);
 	}
 
 }
"
5f87cb797138c55cc7339dd882f5c73ea6a1b11a,Stefan Lenselink,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/src/main/java/com/crawljax/util/ElementResolver.java b/src/main/java/com/crawljax/util/ElementResolver.java
index 80302af..94864fe 100644
--- a/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/src/main/java/com/crawljax/util/ElementResolver.java
@@ -22,7 +22,7 @@
 	// private ElementResolverSettings settings = new
 	// ElementResolverSettings();
 
-	private final EmbeddedBrowser browser;
+	private final EmbeddedBrowser<?> browser;
 	private final Eventable eventable;
 
 	/**
@@ -33,7 +33,7 @@
 	 * @param browser
 	 *            The browser.
 	 */
-	public ElementResolver(Eventable eventable, EmbeddedBrowser browser) {
+	public ElementResolver(Eventable eventable, EmbeddedBrowser<?> browser) {
 		this.browser = browser;
 		this.eventable = eventable;
 	}
"
8a981189df7218190c6475b3959b94068f26e16c,Stefan Lenselink,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index fe01a5b..30c6a46 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -287,8 +287,10 @@
 
 		// html = html.replace(""<?xml:namespace prefix = gwt >"", """");
 
-		Document doc = Helper.getDocument(htmlFormatted);
-		htmlFormatted = Helper.getDocumentToString(doc);
+		// TODO (Stefan), Following lines are a serious performance bottle neck...
+		// Document doc = Helper.getDocument(htmlFormatted);
+		// htmlFormatted = Helper.getDocumentToString(doc);
+
 		htmlFormatted = filterAttributes(htmlFormatted);
 		return htmlFormatted;
 	}
"
8a981189df7218190c6475b3959b94068f26e16c,Stefan Lenselink,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 849b80e..cbf980d 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -3,6 +3,10 @@
  */
 package com.crawljax.util;
 
+import org.w3c.dom.Document;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
@@ -15,18 +19,18 @@
 import javax.xml.xpath.XPathExpressionException;
 import javax.xml.xpath.XPathFactory;
 
-import org.w3c.dom.Document;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-
 /**
  * Utility class that contains methods used by Crawljax and some plugin to deal with XPath
  * resolving, constructing etc.
- * 
+ *
  * @author mesbah
  * @version $Id$
  */
 public final class XPathHelper {
+	/**
+     * 
+     */
+    private static final String FULL_XPATH_CACHE = ""FULL_XPATH_CACHE"";
 	private static final int MAX_SEARCH_LOOPS = 10000;
 
 	private XPathHelper() {
@@ -34,16 +38,22 @@
 
 	/**
 	 * Reverse Engineers an XPath Expression of a given Node in the DOM.
-	 * 
+	 *
 	 * @param node
 	 *            the given node.
 	 * @return string xpath expression (e.g., ""/html[1]/body[1]/div[3]"").
 	 */
 	public static String getXPathExpression(Node node) {
+		Object xpathCache = node.getUserData(FULL_XPATH_CACHE);
+		if (xpathCache != null) {
+			return xpathCache.toString();
+		}
 		Node parent = node.getParentNode();
 
 		if ((parent == null) || parent.getNodeName().contains(""#document"")) {
-			return ""/"" + node.getNodeName() + ""[1]"";
+			String xPath = ""/"" + node.getNodeName() + ""[1]"";
+			node.setUserData(FULL_XPATH_CACHE, xPath, null);
+			return xPath;
 		}
 
 		StringBuffer buffer = new StringBuffer();
@@ -64,14 +74,18 @@
 				buffer.append(""["");
 				buffer.append(Integer.toString(i + 1));
 				buffer.append(""]"");
+				// Found so break;
+				break;
 			}
 		}
-		return buffer.toString();
+		String xPath = buffer.toString();
+		node.setUserData(FULL_XPATH_CACHE, xPath, null);
+		return xPath;
 	}
 
 	/**
 	 * Get siblings of the same type as element from parent.
-	 * 
+	 *
 	 * @param parent
 	 *            parent node.
 	 * @param element
@@ -95,7 +109,7 @@
 
 	/**
 	 * Returns the list of nodes which match the expression xpathExpr in the String domStr.
-	 * 
+	 *
 	 * @param domStr
 	 *            the string of the document to search in
 	 * @param xpathExpr
@@ -114,7 +128,7 @@
 
 	/**
 	 * Returns the list of nodes which match the expression xpathExpr in the Document dom.
-	 * 
+	 *
 	 * @param dom
 	 *            the Document to search in
 	 * @param xpathExpr
@@ -138,7 +152,7 @@
 	/**
 	 * Returns the XPaths of all nodes retrieved by xpathExpression. Example: //DIV[@id='foo']
 	 * returns /HTM[1]/BODY[1]/DIV[2]
-	 * 
+	 *
 	 * @param dom
 	 *            The dom.
 	 * @param xpathExpression
@@ -217,7 +231,7 @@
 
 	/**
 	 * returns position of xpath element which match the expression xpath in the String dom.
-	 * 
+	 *
 	 * @param dom
 	 *            the Document to search in
 	 * @param xpath
@@ -238,8 +252,8 @@
 				if (element.indexOf(""["") != -1) {
 					try {
 						number =
-						        Integer.parseInt(element.substring(element.indexOf(""["") + 1,
-						                element.indexOf(""]"")));
+						        Integer.parseInt(element.substring(
+						                element.indexOf(""["") + 1, element.indexOf(""]"")));
 					} catch (Exception e) {
 						return -1;
 					}
@@ -257,8 +271,8 @@
 						// if depth>1 then goto end of current element
 						if (number > 1 && i < number - 1) {
 							pos =
-							        getCloseElementLocation(dom, pos,
-							                stripEndSquareBrackets(element));
+							        getCloseElementLocation(
+							                dom, pos, stripEndSquareBrackets(element));
 							// pos = dom.indexOf(""<"" +
 							// stripEndSquareBrackets(element), pos) + 1;
 						}
@@ -327,8 +341,8 @@
 	 * @return the position where the close element is
 	 */
 	public static int getCloseElementLocation(String dom, String xpath) {
-		return getCloseElementLocation(dom, getXPathLocation(dom, xpath) + 1,
-		        getLastElementXPath(xpath));
+		return getCloseElementLocation(
+		        dom, getXPathLocation(dom, xpath) + 1, getLastElementXPath(xpath));
 	}
 
 	/**
"
3077e7cc181bbea971db7f5ef684b0bc3c3de7ea,Stefan Lenselink,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 30c6a46..0bd8b12 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -1,14 +1,15 @@
 package com.crawljax.browser;
 
-import com.crawljax.core.CrawljaxException;
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
-import com.crawljax.core.state.Eventable;
-import com.crawljax.core.state.Identification;
-import com.crawljax.forms.FormHandler;
-import com.crawljax.forms.FormInput;
-import com.crawljax.forms.InputValue;
-import com.crawljax.forms.RandomInputValueGenerator;
-import com.crawljax.util.Helper;
+import java.io.File;
+import java.io.IOException;
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
 
 import org.apache.log4j.Logger;
 import org.openqa.selenium.ElementNotVisibleException;
@@ -32,16 +33,17 @@
 import org.w3c.dom.NodeList;
 import org.xml.sax.SAXException;
 
-import java.io.File;
-import java.io.IOException;
-import java.net.MalformedURLException;
-import java.net.URL;
-import java.util.ArrayList;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
+import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.configuration.AcceptAllFramesChecker;
+import com.crawljax.core.configuration.CrawljaxConfigurationReader;
+import com.crawljax.core.configuration.IgnoreFrameChecker;
+import com.crawljax.core.state.Eventable;
+import com.crawljax.core.state.Identification;
+import com.crawljax.forms.FormHandler;
+import com.crawljax.forms.FormInput;
+import com.crawljax.forms.InputValue;
+import com.crawljax.forms.RandomInputValueGenerator;
+import com.crawljax.util.Helper;
 
 /**
  * @author mesbah
@@ -56,6 +58,7 @@
 
 	private List<String> filterAttributes;
 	private long crawlWaitReload;
+	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
 
 	/**
 	 * Constructor without configuration values, these must be updated using the
@@ -89,6 +92,26 @@
 	}
 
 	/**
+	 * Constructor.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
+	        long crawlWaitReload, long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
+		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
+		this.ignoreFrameChecker = ignoreFrameChecker;
+	}
+
+	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
 	 *
 	 * @param hubUrl
@@ -108,8 +131,30 @@
 	}
 
 	/**
+	 * Create a RemoteWebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param hubUrl
+	 *            Url of the server.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
+	        IgnoreFrameChecker ignoreFrameChecker) {
+		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
+		        filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
+	}
+
+	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
-	 *
+	 * 
 	 * @param driver
 	 *            The WebDriver to use.
 	 * @param filterAttributes
@@ -127,14 +172,35 @@
 	}
 
 	/**
+	 * Create a WebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
+	        IgnoreFrameChecker ignoreFrameChecker) {
+		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
+		        crawlWaitReload, ignoreFrameChecker);
+	}
+
+	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 *
+	 * 
 	 * @param hubUrl
 	 *            Url of the server.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl) {
-
 		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl));
 	}
 
@@ -503,7 +569,8 @@
 
 			String nameId = Helper.getFrameIdentification(frameElement);
 
-			if (nameId != null) {
+			if (nameId != null
+			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
 				frameIdentification += nameId;
 
 				String handle = new String(browser.getWindowHandle());
@@ -708,5 +775,6 @@
 		this.crawlWaitReload =
 		        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
 		this.crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
+		this.ignoreFrameChecker = configuration.getCrawlSpecificationReader();
 	}
 }
\ No newline at end of file
"
3077e7cc181bbea971db7f5ef684b0bc3c3de7ea,Stefan Lenselink,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 57aecc0..c99983a 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -1,8 +1,5 @@
 package com.crawljax.core.configuration;
 
-import java.util.ArrayList;
-import java.util.List;
-
 import com.crawljax.condition.Condition;
 import com.crawljax.condition.browserwaiter.ExpectedCondition;
 import com.crawljax.condition.browserwaiter.WaitCondition;
@@ -12,6 +9,9 @@
 import com.crawljax.oraclecomparator.Comparator;
 import com.crawljax.oraclecomparator.OracleComparator;
 
+import java.util.ArrayList;
+import java.util.List;
+
 /**
  * Specifies the crawl options for a single crawl session. The user must specify which HTML elements
  * should be clicked during the crawl session.
@@ -72,6 +72,7 @@
 	private final List<WaitCondition> waitConditions = new ArrayList<WaitCondition>();
 	private final List<CrawlCondition> crawlConditions = new ArrayList<CrawlCondition>();
 	private boolean clicklOnce = true;
+	private final List<String> ignoredFrameIdentifiers = new ArrayList<String>();
 
 	/**
 	 * @param url
@@ -96,7 +97,7 @@
 	/**
 	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
 	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}.
-	 * 
+	 *
 	 * @param tagName
 	 *            the tag name of the elements to be included
 	 * @return this CrawlElement
@@ -110,7 +111,7 @@
 	 * click and dontClick sets, then the element will not be clicked. For example: 1) <a
 	 * href=""#"">Some text</a> 2) <a class=""foo"" .../> 3) <div class=""foo"" .../> click(""a"")
 	 * dontClick(""a"").withAttribute(""class"", ""foo""); Will include only include HTML element 2
-	 * 
+	 *
 	 * @param tagName
 	 *            the tag name of the elements to be excluded
 	 * @return this CrawlElement
@@ -123,7 +124,7 @@
 	 * Crawljax will the HTML elements while crawling if and only if all the specified conditions
 	 * are satisfied. IMPORTANT: only works with click()!!! For example:
 	 * when(onContactPageCondition) will only click the HTML element if it is on the contact page
-	 * 
+	 *
 	 * @param conditions
 	 *            the condition to be met.
 	 * @return this CrawlActions
@@ -148,7 +149,7 @@
 
 	/**
 	 * Sets the maximum crawl depth. 1 is one click, 2 is two clicks deep, ...
-	 * 
+	 *
 	 * @param crawlDepth
 	 *            the maximum crawl depth. 0 to ignore
 	 */
@@ -166,7 +167,7 @@
 	/**
 	 * Sets the maximum number of states. Crawljax will stop crawling when this maximum number of
 	 * states are found
-	 * 
+	 *
 	 * @param crawlMaximumStates
 	 *            the maximum number of states. 0 specifies no bound for the number of crawl states.
 	 */
@@ -184,7 +185,7 @@
 	/**
 	 * Sets the maximum time for Crawljax to run. Crawljax will stop crawling when this timelimit is
 	 * reached.
-	 * 
+	 *
 	 * @param seconds
 	 *            the crawlMaximumRuntime to set
 	 */
@@ -275,7 +276,7 @@
 
 	/**
 	 * Adds the Oracle Comparator to the list of comparators.
-	 * 
+	 *
 	 * @param id
 	 *            a name for the Oracle Comparator.
 	 * @param oracleComparator
@@ -287,7 +288,7 @@
 
 	/**
 	 * Adds an Oracle Comparator with preconditions to the list of comparators.
-	 * 
+	 *
 	 * @param id
 	 *            a name for the Oracle Comparator
 	 * @param oracleComparator
@@ -295,8 +296,8 @@
 	 * @param preConditions
 	 *            the preconditions to be met.
 	 */
-	public void addOracleComparator(String id, Comparator oracleComparator,
-	        Condition... preConditions) {
+	public void addOracleComparator(
+	        String id, Comparator oracleComparator, Condition... preConditions) {
 		this.oracleComparators.add(new OracleComparator(id, oracleComparator, preConditions));
 	}
 
@@ -325,7 +326,8 @@
 	 * @param preConditions
 	 *            the precondition.
 	 */
-	public void addInvariant(String description, Condition condition, Condition... preConditions) {
+	public void addInvariant(
+	        String description, Condition condition, Condition... preConditions) {
 		this.invariants.add(new Invariant(description, condition, preConditions));
 	}
 
@@ -400,8 +402,8 @@
 	 * @param preConditions
 	 *            the preConditions
 	 */
-	public void addCrawlCondition(String description, Condition crawlCondition,
-	        Condition... preConditions) {
+	public void addCrawlCondition(
+	        String description, Condition crawlCondition, Condition... preConditions) {
 		this.crawlConditions.add(new CrawlCondition(description, crawlCondition, preConditions));
 	}
 
@@ -428,4 +430,19 @@
 		this.crawlEvents = crawlEvents;
 	}
 
+	/**
+	 * @param string
+	 *            the frame identifier to ignore when descending into (i)frames
+	 */
+	public void dontCrawlFrame(String string) {
+		this.ignoredFrameIdentifiers.add(string);
+	}
+
+	/**
+	 * @return the list of ignored frames
+	 */
+	protected List<String> ignoredFrameIdentifiers() {
+		return ignoredFrameIdentifiers;
+	}
+
 }
"
50422db767dbb49bc52a497a9bb3f4ef21574a80,Stefan Lenselink,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 0bd8b12..bdddbcb 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -51,7 +51,7 @@
  * @version $Id: WebDriverBackedEmbeddedBrowser.java 387 2010-07-13 13:55:49Z slenselink@google.com
  *          $
  */
-public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser<WebDriver> {
+public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
 	private long crawlWaitEvent;
 	private static final Logger LOGGER = Logger.getLogger(WebDriverBackedEmbeddedBrowser.class);
 	private final WebDriver browser;
@@ -763,7 +763,9 @@
 		}
 	}
 
-	@Override
+	/**
+	 * @return the WebDriver used as an EmbeddedBrowser.
+	 */
 	public WebDriver getBrowser() {
 		return browser;
 	}
"
50422db767dbb49bc52a497a9bb3f4ef21574a80,Stefan Lenselink,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/src/main/java/com/crawljax/core/CrawljaxController.java b/src/main/java/com/crawljax/core/CrawljaxController.java
index ae6b2e3..b6f0faa 100644
--- a/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -147,7 +147,7 @@
 
 		// TODO Stefan; Now we ""re-request"" a browser instance for the PostCrawlingPlugins Thread,
 		// this is not ideal...
-		EmbeddedBrowser<?> b = null;
+		EmbeddedBrowser b = null;
 		try {
 			b = this.getBrowserPool().requestBrowser();
 		} catch (InterruptedException e1) {
@@ -220,7 +220,7 @@
 	 * @param browser
 	 *            the browser which requires a wait condition
 	 */
-	public final void doBrowserWait(EmbeddedBrowser<?> browser) {
+	public final void doBrowserWait(EmbeddedBrowser browser) {
 		this.waitConditionChecker.wait(browser);
 	}
 
@@ -234,7 +234,7 @@
 	 *            the browser instance.
 	 * @return a stripped string of the DOM tree taken from the browser.
 	 */
-	public synchronized String getStrippedDom(EmbeddedBrowser<?> browser) {
+	public synchronized String getStrippedDom(EmbeddedBrowser browser) {
 		return this.stateComparator.getStrippedDom(browser);
 	}
 
"
50422db767dbb49bc52a497a9bb3f4ef21574a80,Stefan Lenselink,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 6914c7b..58e7fe8 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -33,7 +33,7 @@
 	private static final Logger LOGGER = Logger.getLogger(FormHandler.class.getName());
 
 	private boolean randomFieldValue = false;
-	private final EmbeddedBrowser<?> browser;
+	private final EmbeddedBrowser browser;
 
 	public static final int RANDOM_STRING_LENGTH = 8;
 
@@ -51,7 +51,7 @@
 	 * @param randomInput
 	 *            if random data should be generated on the input fields.
 	 */
-	public FormHandler(EmbeddedBrowser<?> browser, InputSpecification inputSpecification,
+	public FormHandler(EmbeddedBrowser browser, InputSpecification inputSpecification,
 	        boolean randomInput) {
 		this.browser = browser;
 		this.formInputValueHelper = new FormInputValueHelper(inputSpecification, randomInput);
"
50422db767dbb49bc52a497a9bb3f4ef21574a80,Stefan Lenselink,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/src/main/java/com/crawljax/util/ElementResolver.java b/src/main/java/com/crawljax/util/ElementResolver.java
index 94864fe..4d56a18 100644
--- a/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/src/main/java/com/crawljax/util/ElementResolver.java
@@ -12,9 +12,11 @@
 import com.crawljax.core.state.Eventable;
 
 /**
+ * class for finding
+ *          and checking elements.
+ * 
  * @author danny
- * @version $Id$ class for finding
- *          and checking elements
+ * @version $Id$ 
  */
 public class ElementResolver {
 	private static final Logger LOGGER = Logger.getLogger(ElementResolver.class.getName());
@@ -22,7 +24,7 @@
 	// private ElementResolverSettings settings = new
 	// ElementResolverSettings();
 
-	private final EmbeddedBrowser<?> browser;
+	private final EmbeddedBrowser browser;
 	private final Eventable eventable;
 
 	/**
@@ -33,7 +35,7 @@
 	 * @param browser
 	 *            The browser.
 	 */
-	public ElementResolver(Eventable eventable, EmbeddedBrowser<?> browser) {
+	public ElementResolver(Eventable eventable, EmbeddedBrowser browser) {
 		this.browser = browser;
 		this.eventable = eventable;
 	}
"
aeacf7e80022d5cb6ba05db9916d5ce8760247c7,Stefan Lenselink,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index c99983a..5e7c53f 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -1,5 +1,8 @@
 package com.crawljax.core.configuration;
 
+import java.util.ArrayList;
+import java.util.List;
+
 import com.crawljax.condition.Condition;
 import com.crawljax.condition.browserwaiter.ExpectedCondition;
 import com.crawljax.condition.browserwaiter.WaitCondition;
@@ -9,9 +12,6 @@
 import com.crawljax.oraclecomparator.Comparator;
 import com.crawljax.oraclecomparator.OracleComparator;
 
-import java.util.ArrayList;
-import java.util.List;
-
 /**
  * Specifies the crawl options for a single crawl session. The user must specify which HTML elements
  * should be clicked during the crawl session.
@@ -73,6 +73,7 @@
 	private final List<CrawlCondition> crawlConditions = new ArrayList<CrawlCondition>();
 	private boolean clicklOnce = true;
 	private final List<String> ignoredFrameIdentifiers = new ArrayList<String>();
+	private boolean disableCrawlFrames = false;
 
 	/**
 	 * @param url
@@ -445,4 +446,19 @@
 		return ignoredFrameIdentifiers;
 	}
 
+	/**
+	 * disable the crawling of Frames in total.
+	 */
+	public void disableCrawlFrames() {
+		this.disableCrawlFrames = true;
+	}
+
+	/**
+	 * Is the crawling of Frames enabled.
+	 * 
+	 * @return true if frames should be crawled false otherwise.
+	 */
+	protected boolean isCrawlFrames() {
+		return !disableCrawlFrames;
+	}
 }
"
767d9b732853745393ea3bf0f9059b6e4e0333c8,Stefan Lenselink,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/src/main/java/com/crawljax/core/CrawljaxController.java b/src/main/java/com/crawljax/core/CrawljaxController.java
index b6f0faa..8d9451a 100644
--- a/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -307,7 +307,7 @@
 		/**
 		 * TODO: Needs some more testing when Threads are not finished, the browser gets locked...
 		 */
-		browserPool.close();
+		browserPool.shutdown();
 	}
 
 	/**
@@ -369,4 +369,9 @@
 		return startCrawl;
 	}
 
+	@Override
+	public void waitForTermination() throws InterruptedException {
+		this.workQueue.waitForTermination();
+	}
+
 }
"
397da61063615383549ee75eaeec7ec0bf386a9d,Stefan Lenselink,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index bdddbcb..debe32d 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -1,15 +1,16 @@
 package com.crawljax.browser;
 
-import java.io.File;
-import java.io.IOException;
-import java.net.MalformedURLException;
-import java.net.URL;
-import java.util.ArrayList;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
+import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.configuration.AcceptAllFramesChecker;
+import com.crawljax.core.configuration.CrawljaxConfigurationReader;
+import com.crawljax.core.configuration.IgnoreFrameChecker;
+import com.crawljax.core.state.Eventable;
+import com.crawljax.core.state.Identification;
+import com.crawljax.forms.FormHandler;
+import com.crawljax.forms.FormInput;
+import com.crawljax.forms.InputValue;
+import com.crawljax.forms.RandomInputValueGenerator;
+import com.crawljax.util.Helper;
 
 import org.apache.log4j.Logger;
 import org.openqa.selenium.ElementNotVisibleException;
@@ -33,17 +34,16 @@
 import org.w3c.dom.NodeList;
 import org.xml.sax.SAXException;
 
-import com.crawljax.core.CrawljaxException;
-import com.crawljax.core.configuration.AcceptAllFramesChecker;
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
-import com.crawljax.core.configuration.IgnoreFrameChecker;
-import com.crawljax.core.state.Eventable;
-import com.crawljax.core.state.Identification;
-import com.crawljax.forms.FormHandler;
-import com.crawljax.forms.FormInput;
-import com.crawljax.forms.InputValue;
-import com.crawljax.forms.RandomInputValueGenerator;
-import com.crawljax.util.Helper;
+import java.io.File;
+import java.io.IOException;
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
 
 /**
  * @author mesbah
@@ -581,14 +581,12 @@
 
 					LOGGER.debug(""switching to frame: "" + frameIdentification);
 					browser.switchTo().frame(frameIdentification);
-					String toAppend = new String(browser.getPageSource());
+					String toAppend = browser.getPageSource();
 
 					LOGGER.debug(""frame dom: "" + toAppend);
 
 					browser.switchTo().defaultContent();
 
-					LOGGER.debug(""default handle window source: "" + browser.getPageSource());
-
 					Element toAppendElement = Helper.getDocument(toAppend).getDocumentElement();
 					Element importedElement =
 					        (Element) document.importNode(toAppendElement, true);
"
eeb899375bd9cedb680aff0821cf922079b30d40,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index dfd65b5..05ac7b7 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -1,15 +1,15 @@
 package com.crawljax.core.configuration;
 
+import java.util.ArrayList;
+import java.util.List;
+
 import com.crawljax.browser.EmbeddedBrowserBuilder;
-import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.browser.WebDriverBrowserBuilder;
+import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.util.Helper;
 
-import java.util.ArrayList;
-import java.util.List;
-
 /**
  * Specifies the settings Crawljax. The methods in this class fall into two categories:Oz
  * <p/>
@@ -18,12 +18,12 @@
  * <li>Properties for the crawling
  * {@link CrawljaxConfiguration#setCrawlSpecification(CrawlSpecification)}</li>
  * </ul>
- *  DEFAULT VAlUES: Browser: webdriver firefox Project Full Path: empty Project Relative Path: empty
+ * DEFAULT VAlUES: Browser: webdriver firefox Project Full Path: empty Project Relative Path: empty
  * Filter attributes: closure_hashcode_(\\w)*, jquery[0-9]+ Test invariants while crawling: true
  * EXAMPLE: CrawljaxConfiguration crawljaxConfig = new CrawljaxConfiguration(); CrawlSpecification
  * crawler = new CrawlSpecification(""http://www.google.com""); crawler.click(""a"");
  * crawljaxConfig.setCrawlSpecification(crawler);
- *
+ * 
  * @version $Id$
  */
 public final class CrawljaxConfiguration {
@@ -83,7 +83,7 @@
 
 	/**
 	 * Enable the crawljax proxy extension.
-	 *
+	 * 
 	 * @param proxyConfiguration
 	 *            The ProxyConfiguration to set.
 	 */
@@ -123,8 +123,8 @@
 		List<CrawlElement> crawlTags = getInputSpecification().getCrawlElements();
 		if (getCrawlSpecification() != null) {
 
-			for (CrawlElement crawlTag :
-			        getCrawlSpecification().crawlActions().getCrawlElements()) {
+			for (CrawlElement crawlTag : getCrawlSpecification().crawlActions()
+			        .getCrawlElements()) {
 				crawlTags.add(crawlTag);
 			}
 		}
@@ -137,8 +137,8 @@
 	protected List<CrawlElement> getAllCrawlElements() {
 		List<CrawlElement> crawlTags = getAllIncludedCrawlElements();
 		if (getCrawlSpecification() != null) {
-			for (CrawlElement crawlTag :
-			        getCrawlSpecification().crawlActions().getCrawlElementsExcluded()) {
+			for (CrawlElement crawlTag : getCrawlSpecification().crawlActions()
+			        .getCrawlElementsExcluded()) {
 				crawlTags.add(crawlTag);
 			}
 		}
@@ -184,7 +184,7 @@
 
 	/**
 	 * Set the remote hub url that needs to be taken when using remote crawling.
-	 *
+	 * 
 	 * @param remoteHubUrl
 	 *            the url of the remote hub
 	 */
@@ -272,7 +272,7 @@
 
 	/**
 	 * Sets filter attribute names.
-	 *
+	 * 
 	 * @param filterAttributeNames
 	 *            The attribute names to filter.
 	 */
@@ -309,7 +309,7 @@
 	 * Add a plugin to the execution. Note that the order of adding is the same as running for the
 	 * same type of plugin. This means that if you add a precrawling plugin p1 and next you add a
 	 * precrawling plugin p2, p1 will be executed before p2.
-	 *
+	 * 
 	 * @param plugin
 	 *            Add a plugin. See {@link Plugin}.
 	 */
"
9cd6011048871a00512f2fbb485066b44468839a,Ali Mesbah,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index cbf980d..34fd22a 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -3,10 +3,6 @@
  */
 package com.crawljax.util;
 
-import org.w3c.dom.Document;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
@@ -19,10 +15,14 @@
 import javax.xml.xpath.XPathExpressionException;
 import javax.xml.xpath.XPathFactory;
 
+import org.w3c.dom.Document;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+
 /**
  * Utility class that contains methods used by Crawljax and some plugin to deal with XPath
  * resolving, constructing etc.
- *
+ * 
  * @author mesbah
  * @version $Id$
  */
@@ -30,7 +30,7 @@
 	/**
      * 
      */
-    private static final String FULL_XPATH_CACHE = ""FULL_XPATH_CACHE"";
+	private static final String FULL_XPATH_CACHE = ""FULL_XPATH_CACHE"";
 	private static final int MAX_SEARCH_LOOPS = 10000;
 
 	private XPathHelper() {
@@ -38,7 +38,7 @@
 
 	/**
 	 * Reverse Engineers an XPath Expression of a given Node in the DOM.
-	 *
+	 * 
 	 * @param node
 	 *            the given node.
 	 * @return string xpath expression (e.g., ""/html[1]/body[1]/div[3]"").
@@ -85,7 +85,7 @@
 
 	/**
 	 * Get siblings of the same type as element from parent.
-	 *
+	 * 
 	 * @param parent
 	 *            parent node.
 	 * @param element
@@ -109,7 +109,7 @@
 
 	/**
 	 * Returns the list of nodes which match the expression xpathExpr in the String domStr.
-	 *
+	 * 
 	 * @param domStr
 	 *            the string of the document to search in
 	 * @param xpathExpr
@@ -128,7 +128,7 @@
 
 	/**
 	 * Returns the list of nodes which match the expression xpathExpr in the Document dom.
-	 *
+	 * 
 	 * @param dom
 	 *            the Document to search in
 	 * @param xpathExpr
@@ -152,7 +152,7 @@
 	/**
 	 * Returns the XPaths of all nodes retrieved by xpathExpression. Example: //DIV[@id='foo']
 	 * returns /HTM[1]/BODY[1]/DIV[2]
-	 *
+	 * 
 	 * @param dom
 	 *            The dom.
 	 * @param xpathExpression
@@ -208,10 +208,9 @@
 	public static String getLastElementXPath(String xpath) {
 		String[] elements = xpath.split(""/"");
 		for (int i = elements.length - 1; i >= 0; i--) {
-			if (!elements[i].equals("""")) {
-				if (elements[i].indexOf(""()"") == -1 && !elements[i].startsWith(""@"")) {
-					return stripEndSquareBrackets(elements[i]);
-				}
+			if (!elements[i].equals("""") && elements[i].indexOf(""()"") == -1
+			        && !elements[i].startsWith(""@"")) {
+				return stripEndSquareBrackets(elements[i]);
 			}
 		}
 		return """";
@@ -231,7 +230,7 @@
 
 	/**
 	 * returns position of xpath element which match the expression xpath in the String dom.
-	 *
+	 * 
 	 * @param dom
 	 *            the Document to search in
 	 * @param xpath
@@ -252,8 +251,8 @@
 				if (element.indexOf(""["") != -1) {
 					try {
 						number =
-						        Integer.parseInt(element.substring(
-						                element.indexOf(""["") + 1, element.indexOf(""]"")));
+						        Integer.parseInt(element.substring(element.indexOf(""["") + 1,
+						                element.indexOf(""]"")));
 					} catch (Exception e) {
 						return -1;
 					}
@@ -271,8 +270,8 @@
 						// if depth>1 then goto end of current element
 						if (number > 1 && i < number - 1) {
 							pos =
-							        getCloseElementLocation(
-							                dom, pos, stripEndSquareBrackets(element));
+							        getCloseElementLocation(dom, pos,
+							                stripEndSquareBrackets(element));
 							// pos = dom.indexOf(""<"" +
 							// stripEndSquareBrackets(element), pos) + 1;
 						}
@@ -341,8 +340,8 @@
 	 * @return the position where the close element is
 	 */
 	public static int getCloseElementLocation(String dom, String xpath) {
-		return getCloseElementLocation(
-		        dom, getXPathLocation(dom, xpath) + 1, getLastElementXPath(xpath));
+		return getCloseElementLocation(dom, getXPathLocation(dom, xpath) + 1,
+		        getLastElementXPath(xpath));
 	}
 
 	/**
"
c2d87aaada2da97cd82df71da9897d4a28e49d6f,Ali Mesbah,PrettyHTML.java,MODIFY,"prettyHTML -> [String html] | [String html, String strIndent]","diff --git a/src/main/java/com/crawljax/util/PrettyHTML.java b/src/main/java/com/crawljax/util/PrettyHTML.java
index f4be1ed..6339910 100644
--- a/src/main/java/com/crawljax/util/PrettyHTML.java
+++ b/src/main/java/com/crawljax/util/PrettyHTML.java
@@ -45,11 +45,11 @@
 
 					// only indent if element is not a single element (like
 					// <img src='..' />)
-					if (!temp[0].endsWith(""/"") || temp.length == 1) {
-						if (!temp[0].startsWith(""!--"")) {
-							indent++;
-						}
+					if ((!temp[0].endsWith(""/"") || temp.length == 1)
+					        && !temp[0].startsWith(""!--"")) {
+						indent++;
 					}
+
 					// if there is text after the element, print it
 					if (temp.length > 1 && !temp[1].trim().equals("""")) {
 						prettyHTML += repeatString(strIndent, indent);
@@ -145,16 +145,15 @@
 						// the element is open --> close element on top of
 						// stack
 						int index = stackIndexElements.peek();
-						if (!isSingleElement(elements[index])) {
+						if (!isSingleElement(elements[index])
+						        && elements[index].lastIndexOf("">"") != -1) {
 							// close this element
-							if (elements[index].lastIndexOf("">"") != -1) {
-								elements[index] =
-								        elements[index].substring(0, elements[index]
-								                .lastIndexOf("">""))
-								                + ""/""
-								                + elements[index].substring(elements[index]
-								                        .lastIndexOf("">""));
-							}
+							elements[index] =
+							        elements[index]
+							                .substring(0, elements[index].lastIndexOf("">""))
+							                + ""/""
+							                + elements[index].substring(elements[index]
+							                        .lastIndexOf("">""));
 						}
 						stackElements.pop();
 						stackIndexElements.pop();
"
002ae6c27634bd5d4c0d440509e07e3f7745813c,Ali Mesbah,PrettyHTML.java,MODIFY,"prettyHTML -> [String html] | [String html, String strIndent]","diff --git a/src/main/java/com/crawljax/util/PrettyHTML.java b/src/main/java/com/crawljax/util/PrettyHTML.java
index 6339910..55b0d41 100644
--- a/src/main/java/com/crawljax/util/PrettyHTML.java
+++ b/src/main/java/com/crawljax/util/PrettyHTML.java
@@ -187,13 +187,4 @@
 		return elements;
 	}
 
-	// /**
-	// * @param args
-	// * Arguments of main method.
-	// */
-	// public static void main(String[] args) {
-	// String html = ""<a><fout></b><!-- comment --></c><c class='foo'>aap<img />jee</c></a>"";
-	// System.out.println(prettyHTML(html));
-	// }
-
 }
"
ce0ba368b266193498e66037c4aa6def677cdc1f,Ali Mesbah,Helper.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/src/main/java/com/crawljax/util/Helper.java b/src/main/java/com/crawljax/util/Helper.java
index 9a03f27..277609f 100644
--- a/src/main/java/com/crawljax/util/Helper.java
+++ b/src/main/java/com/crawljax/util/Helper.java
@@ -1,23 +1,5 @@
 package com.crawljax.util;
 
-import com.google.common.collect.Lists;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.log4j.Logger;
-import org.custommonkey.xmlunit.DetailedDiff;
-import org.custommonkey.xmlunit.Diff;
-import org.custommonkey.xmlunit.Difference;
-import org.custommonkey.xmlunit.DifferenceListener;
-import org.cyberneko.html.parsers.DOMParser;
-import org.w3c.dom.Attr;
-import org.w3c.dom.Document;
-import org.w3c.dom.Element;
-import org.w3c.dom.NamedNodeMap;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-import org.xml.sax.InputSource;
-import org.xml.sax.SAXException;
-
 import java.io.BufferedReader;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
@@ -51,9 +33,27 @@
 import javax.xml.xpath.XPathExpressionException;
 import javax.xml.xpath.XPathFactory;
 
+import org.apache.commons.io.FileUtils;
+import org.apache.log4j.Logger;
+import org.custommonkey.xmlunit.DetailedDiff;
+import org.custommonkey.xmlunit.Diff;
+import org.custommonkey.xmlunit.Difference;
+import org.custommonkey.xmlunit.DifferenceListener;
+import org.cyberneko.html.parsers.DOMParser;
+import org.w3c.dom.Attr;
+import org.w3c.dom.Document;
+import org.w3c.dom.Element;
+import org.w3c.dom.NamedNodeMap;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+import org.xml.sax.InputSource;
+import org.xml.sax.SAXException;
+
+import com.google.common.collect.Lists;
+
 /**
  * Utility class that contains a number of helper functions used by Crawljax and some plugins.
- *
+ * 
  * @author mesbah
  * @version $Id$
  */
@@ -70,7 +70,7 @@
 
 	/**
 	 * Internal used function to strip the basePath from a given url.
-	 *
+	 * 
 	 * @param url
 	 *            the url to examine
 	 * @return the base path with file stipped
@@ -87,7 +87,6 @@
 	 * @return Whether location and link are on the same domain.
 	 */
 	public static boolean isLinkExternal(String location, String link) {
-		boolean check = false;
 
 		if (!location.contains(""://"")) {
 			// location must always contain :// by rule, it not link is handled as not external
@@ -110,9 +109,8 @@
 				try {
 					URL linkUrl = new URL(link);
 					if (linkUrl.getHost().equals(locationUrl.getHost())) {
-						String locationPath = getBasePath(locationUrl);
 						String linkPath = getBasePath(linkUrl);
-						return !(linkPath.startsWith(locationPath));
+						return !(linkPath.startsWith(getBasePath(locationUrl)));
 					}
 					return true;
 				} catch (MalformedURLException e) {
@@ -146,9 +144,9 @@
 
 	/**
 	 * transforms a string into a Document object. TODO This needs more optimizations. As it seems
-	 * the getDocument is called way to much times causing a lot of parsing which is slow and not
+	 * the getDocument is called way too much times causing a lot of parsing which is slow and not
 	 * necessary.
-	 *
+	 * 
 	 * @param html
 	 *            the HTML string.
 	 * @return The DOM Document version of the HTML string.
@@ -259,7 +257,7 @@
 
 	/**
 	 * Removes all the <SCRIPT/> tags from the document.
-	 *
+	 * 
 	 * @param dom
 	 *            the document object.
 	 * @return the changed dom.
@@ -270,7 +268,7 @@
 
 	/**
 	 * Removes all the given tags from the document.
-	 *
+	 * 
 	 * @param dom
 	 *            the document object.
 	 * @param tagName
@@ -307,7 +305,7 @@
 
 	/**
 	 * Checks the existence of the directory. If it does not exist, the method creates it.
-	 *
+	 * 
 	 * @param dir
 	 *            the directory to check.
 	 * @throws IOException
@@ -323,7 +321,7 @@
 
 	/**
 	 * Checks whether the folder exists for fname, and creates it if neccessary.
-	 *
+	 * 
 	 * @param fname
 	 *            folder name.
 	 * @throws IOException
@@ -340,7 +338,7 @@
 	/**
 	 * Retrieve the var value for varName from a HTTP query string (format is
 	 * ""var1=val1&var2=val2"").
-	 *
+	 * 
 	 * @param varName
 	 *            the name.
 	 * @param haystack
@@ -393,7 +391,7 @@
 
 	/**
 	 * Serialize the Document object.
-	 *
+	 * 
 	 * @param dom
 	 *            the document to serialize
 	 * @return the serialized dom String
@@ -435,7 +433,7 @@
 
 	/**
 	 * Save a string to a file and append a newline character to that string.
-	 *
+	 * 
 	 * @param filename
 	 *            The filename to save to.
 	 * @param text
@@ -468,7 +466,7 @@
 	/**
 	 * Returns the text value of an element (title, alt or contents). Note that the result is 50
 	 * characters or less in length.
-	 *
+	 * 
 	 * @param element
 	 *            The element.
 	 * @return The text value of the element.
@@ -495,7 +493,7 @@
 
 	/**
 	 * Get differences between doms.
-	 *
+	 * 
 	 * @param controlDom
 	 *            The control dom.
 	 * @param testDom
@@ -508,7 +506,7 @@
 
 	/**
 	 * Get differences between doms.
-	 *
+	 * 
 	 * @param controlDom
 	 *            The control dom.
 	 * @param testDom
@@ -518,8 +516,8 @@
 	 * @return The differences.
 	 */
 	@SuppressWarnings(""unchecked"")
-	public static List<Difference> getDifferences(
-	        String controlDom, String testDom, final List<String> ignoreAttributes) {
+	public static List<Difference> getDifferences(String controlDom, String testDom,
+	        final List<String> ignoreAttributes) {
 		try {
 			Diff d = new Diff(Helper.getDocument(controlDom), Helper.getDocument(testDom));
 			DetailedDiff dd = new DetailedDiff(d);
@@ -537,10 +535,10 @@
 					        || difference.getTestNodeDetail().getNode() == null) {
 						return RETURN_ACCEPT_DIFFERENCE;
 					}
-					if (ignoreAttributes.contains(
-					        difference.getTestNodeDetail().getNode().getNodeName())
-					        || ignoreAttributes.contains(
-					                difference.getControlNodeDetail().getNode().getNodeName())) {
+					if (ignoreAttributes.contains(difference.getTestNodeDetail().getNode()
+					        .getNodeName())
+					        || ignoreAttributes.contains(difference.getControlNodeDetail()
+					                .getNode().getNodeName())) {
 						return RETURN_IGNORE_DIFFERENCE_NODES_IDENTICAL;
 					}
 					return RETURN_ACCEPT_DIFFERENCE;
@@ -556,7 +554,7 @@
 
 	/**
 	 * Removes newlines from a string.
-	 *
+	 * 
 	 * @param html
 	 *            The string.
 	 * @return The new string without the newlines or tabs.
@@ -585,7 +583,7 @@
 
 	/**
 	 * Adds a slash to a path if it doesn't end with a slash.
-	 *
+	 * 
 	 * @param folderName
 	 *            The path to append a possible slash.
 	 * @return The new, correct path.
@@ -601,7 +599,7 @@
 	/**
 	 * Returns the filename in a path. For example with path = ""foo/bar/crawljax.txt"" returns
 	 * ""crawljax.txt""
-	 *
+	 * 
 	 * @param path
 	 * @return the filename from the path
 	 */
@@ -618,7 +616,7 @@
 	/**
 	 * Retrieves the content of the filename. Also reads from JAR Searches for the resource in the
 	 * root folder in the jar
-	 *
+	 * 
 	 * @param fname
 	 *            Filename.
 	 * @return The contents of the file.
@@ -654,24 +652,45 @@
 	 * @return The JavaScript to get an element.
 	 */
 	public static String getJSGetElement(String xpath) {
-		        String js =
-		        """" + ""function ATUSA_getElementInNodes(nodes, tagName, number){"" + ""try{""
-		                + ""var pos = 1;"" + ""for(i=0; i<nodes.length; i++){""
+		String js =
+		        """"
+		                + ""function ATUSA_getElementInNodes(nodes, tagName, number){""
+		                + ""try{""
+		                + ""var pos = 1;""
+		                + ""for(i=0; i<nodes.length; i++){""
 		                + ""if(nodes[i]!=null && nodes[i].tagName!=null && ""
-		                + ""nodes[i].tagName.toLowerCase() == tagName){"" + ""if(number==pos){""
-		                + ""return nodes[i];"" + ""}else{"" + ""pos++;"" + ""}"" + ""}"" + ""}""
-		                + ""}catch(e){}"" + ""return null;"" + ""}""
-		                + ""function ATUSA_getElementByXpath(xpath){"" + ""try{""
+		                + ""nodes[i].tagName.toLowerCase() == tagName){""
+		                + ""if(number==pos){""
+		                + ""return nodes[i];""
+		                + ""}else{""
+		                + ""pos++;""
+		                + ""}""
+		                + ""}""
+		                + ""}""
+		                + ""}catch(e){}""
+		                + ""return null;""
+		                + ""}""
+		                + ""function ATUSA_getElementByXpath(xpath){""
+		                + ""try{""
 		                + ""var elements = xpath.toLowerCase().split('/');""
-		                + ""var curNode = window.document.body;"" + ""var tagName, number;""
-		                + ""for(j=0; j<elements.length; j++){"" + ""if(elements[j]!=''){""
-		                + ""if(elements[j].indexOf('[')==-1){"" + ""tagName = elements[j];""
-		                + ""number = 1;"" + ""}else{""
+		                + ""var curNode = window.document.body;""
+		                + ""var tagName, number;""
+		                + ""for(j=0; j<elements.length; j++){""
+		                + ""if(elements[j]!=''){""
+		                + ""if(elements[j].indexOf('[')==-1){""
+		                + ""tagName = elements[j];""
+		                + ""number = 1;""
+		                + ""}else{""
 		                + ""tagName = elements[j].substring(0, elements[j].indexOf('['));""
 		                + ""number = elements[j].substring(elements[j].indexOf('[')+1, ""
-		                + ""elements[j].lastIndexOf(']'));"" + ""}""
+		                + ""elements[j].lastIndexOf(']'));""
+		                + ""}""
 		                + ""if(tagName!='body' && tagName!='html'){""
-		                + ""curNode = ATUSA_getElementInNodes(curNode.childNodes, tagName, number);"" + ""if(curNode==null){"" + ""return null;"" + ""}"" + ""}"" + ""}"" + ""}"" + ""}catch(e){return null;}"" + ""return curNode;"" + ""}"" + ""try{var ATUSA_element = ATUSA_getElementByXpath('"" + xpath + ""');}catch(e){return null;}"";
+		                + ""curNode = ATUSA_getElementInNodes(curNode.childNodes, tagName, number);""
+		                + ""if(curNode==null){"" + ""return null;"" + ""}"" + ""}"" + ""}"" + ""}""
+		                + ""}catch(e){return null;}"" + ""return curNode;"" + ""}""
+		                + ""try{var ATUSA_element = ATUSA_getElementByXpath('"" + xpath
+		                + ""');}catch(e){return null;}"";
 
 		return js;
 	}
@@ -699,7 +718,7 @@
 
 	/**
 	 * Write the document object to a file.
-	 *
+	 * 
 	 * @param document
 	 *            the document object.
 	 * @param filePathname
@@ -713,9 +732,8 @@
 	 * @throws IOException
 	 *             if an IO exception occurs.
 	 */
-	public static void writeDocumentToFile(
-	        Document document, String filePathname, String method, int indent)
-	        throws TransformerException, IOException {
+	public static void writeDocumentToFile(Document document, String filePathname, String method,
+	        int indent) throws TransformerException, IOException {
 
 		checkFolderForFile(filePathname);
 		Transformer transformer = TransformerFactory.newInstance().newTransformer();
@@ -728,13 +746,13 @@
 			        org.apache.xml.serializer.OutputPropertiesFactory.S_KEY_INDENT_AMOUNT,
 			        Integer.toString(indent));
 		}
-		transformer.transform(
-		        new DOMSource(document), new StreamResult(new FileOutputStream(filePathname)));
+		transformer.transform(new DOMSource(document), new StreamResult(new FileOutputStream(
+		        filePathname)));
 	}
 
 	/**
 	 * Returns the file contents without stripping line-endings.
-	 *
+	 * 
 	 * @param file
 	 *            File to read out.
 	 * @return Contents including line-endings.
"
b6328339c6148e19eafc43856999223504414541,Ali Mesbah,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/src/main/java/com/crawljax/util/ElementResolver.java b/src/main/java/com/crawljax/util/ElementResolver.java
index 4d56a18..e86e5a8 100644
--- a/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/src/main/java/com/crawljax/util/ElementResolver.java
@@ -12,11 +12,10 @@
 import com.crawljax.core.state.Eventable;
 
 /**
- * class for finding
- *          and checking elements.
+ * class for finding and checking elements.
  * 
  * @author danny
- * @version $Id$ 
+ * @version $Id$
  */
 public class ElementResolver {
 	private static final Logger LOGGER = Logger.getLogger(ElementResolver.class.getName());
@@ -129,13 +128,14 @@
 			return true;
 		}
 
-		if (!eventable.getElement().getText().equals("""")) {
-			if (eventable.getElement().equalText(otherElement)) {
-				if (logging) {
-					LOGGER.info(""Element text equal"");
-				}
-				return true;
+		if (!eventable.getElement().getText().equals("""")
+		        && eventable.getElement().equalText(otherElement)) {
+
+			if (logging) {
+				LOGGER.info(""Element text equal"");
 			}
+
+			return true;
 		}
 
 		return false;
"
39cd1d960cbd1fbda72268e8f9daa3b7b2beacb1,Ali Mesbah,StateFlowGraph.java,MODIFY,"addState -> [StateVertix stateVertix, boolean correctName] | [StateVertix stateVertix]","diff --git a/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index 1e4e852..a68aa1f 100644
--- a/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -182,7 +182,7 @@
 	}
 
 	/**
-	 * TODO: DOCUMENT ME!
+	 * Returns the set of outgoing states.
 	 * 
 	 * @param stateVertix
 	 *            the state.
@@ -278,18 +278,13 @@
 	 * @return Dom string average size (byte).
 	 */
 	public int getMeanStateStringSize() {
-		Mean mean = new Mean();
-		List<Integer> list = new ArrayList<Integer>();
+		final Mean mean = new Mean();
 
 		for (StateVertix state : getAllStates()) {
-			list.add(new Integer(state.getDomSize()));
+			mean.increment(state.getDomSize());
 		}
 
-		/* calculate the mean */
-		for (Integer num : list) {
-			mean.increment(num.intValue());
-		}
-		return new Double(mean.getResult()).intValue();
+		return (int) mean.getResult();
 	}
 
 	/**
"
0eb3942a140368609d17db4811768e77f4a94b4e,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 05ac7b7..24c101f 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -37,8 +37,6 @@
 	private String outputFolder = """";
 	private String projectRelativePath = """";
 
-	private final boolean useDatabase = false;
-
 	private List<String> filterAttributeNames = new ArrayList<String>();
 
 	private List<Plugin> plugins = new ArrayList<Plugin>();
@@ -238,24 +236,6 @@
 	}
 
 	/**
-	 * @return Whether a database is used.
-	 */
-	protected boolean getUseDatabase() {
-		return useDatabase;
-	}
-
-	/**
-	 * @return Whether a database is used as an integer.
-	 */
-	protected Integer getUseDatabaseAsInt() {
-		if (useDatabase) {
-			return 1;
-		} else {
-			return 0;
-		}
-	}
-
-	/**
 	 * @return The attributes which are filtered before the DOM is used.
 	 */
 	protected List<String> getFilterAttributeNames() {
"
0eb3942a140368609d17db4811768e77f4a94b4e,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 58e7fe8..46f2dcb 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -3,29 +3,32 @@
  */
 package com.crawljax.forms;
 
-import com.crawljax.browser.EmbeddedBrowser;
-import com.crawljax.condition.eventablecondition.EventableCondition;
-import com.crawljax.core.CandidateElement;
-import com.crawljax.core.configuration.InputSpecification;
-import com.crawljax.util.Helper;
-import com.crawljax.util.XPathHelper;
-
-import org.apache.log4j.Logger;
-import org.w3c.dom.Document;
-import org.w3c.dom.Element;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-
+import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
 
 import javax.xml.xpath.XPathExpressionException;
 
+import org.apache.log4j.Logger;
+import org.w3c.dom.Document;
+import org.w3c.dom.Element;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+import org.xml.sax.SAXException;
+
+import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.condition.eventablecondition.EventableCondition;
+import com.crawljax.core.CandidateElement;
+import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.configuration.InputSpecification;
+import com.crawljax.util.Helper;
+import com.crawljax.util.XPathHelper;
+
 /**
  * Handles form values and fills in the form input elements with random values of the defined
  * values.
- *
+ * 
  * @author dannyroest@gmail.com (Danny Roest)
  * @version $Id$
  */
@@ -43,7 +46,7 @@
 
 	/**
 	 * Public constructor.
-	 *
+	 * 
 	 * @param browser
 	 *            the embedded browser.
 	 * @param inputSpecification
@@ -63,7 +66,7 @@
 	/**
 	 * Fills in the element with the InputValues for input TODO: improve this by using WebDriver
 	 * options?
-	 *
+	 * 
 	 * @param element
 	 * @param input
 	 */
@@ -117,8 +120,9 @@
 				if (input.getType().equals(""radio"")) {
 					for (InputValue inputValue : input.getInputValues()) {
 						if (inputValue.isChecked()) {
-							String js = Helper.getJSGetElement(
-							        XPathHelper.getXPathExpression(element));
+							String js =
+							        Helper.getJSGetElement(XPathHelper
+							                .getXPathExpression(element));
 							js += ""try{ATUSA_element.checked=true;}catch(e){}"";
 							browser.executeJavaScript(js);
 						}
@@ -162,8 +166,9 @@
 			for (int i = 0; i < nodeList.getLength(); i++) {
 				Node candidate = nodeList.item(i);
 				Node typeAttribute = candidate.getAttributes().getNamedItem(""type"");
-				if (typeAttribute == null || (typeAttribute != null
-				        && allowedTypes.contains(typeAttribute.getNodeValue()))) {
+				if (typeAttribute == null
+				        || (typeAttribute != null && allowedTypes.contains(typeAttribute
+				                .getNodeValue()))) {
 					nodes.add(nodeList.item(i));
 				}
 			}
@@ -207,7 +212,7 @@
 
 	/**
 	 * Handle form elements.
-	 *
+	 * 
 	 * @throws Exception
 	 *             the exception.
 	 */
@@ -217,21 +222,29 @@
 
 	/**
 	 * Fills in form/input elements.
-	 *
+	 * 
 	 * @param formInputs
 	 *            form input list.
 	 */
 	public void handleFormElements(List<FormInput> formInputs) {
 		Document dom;
+
 		try {
 			dom = Helper.getDocument(browser.getDomWithoutIframeContent());
 			for (FormInput input : formInputs) {
 				LOGGER.debug(""Filling in: "" + input);
 				setInputElementValue(formInputValueHelper.getBelongingNode(input, dom), input);
 			}
-		} catch (Exception e) {
-			LOGGER.warn(""Could not handle form elements"");
+		} catch (SAXException e) {
+			LOGGER.error(e.getMessage(), e);
+		} catch (IOException e) {
+			LOGGER.error(e.getMessage(), e);
+		} catch (CrawljaxException e) {
+			LOGGER.error(e.getMessage(), e);
+		} catch (XPathExpressionException e) {
+			LOGGER.error(e.getMessage(), e);
 		}
+
 	}
 
 	/**
@@ -241,11 +254,11 @@
 	 *            the belonging eventable condition for sourceElement
 	 * @return a list with Candidate elements for the inputs.
 	 */
-	public List<CandidateElement> getCandidateElementsForInputs(
-	        Element sourceElement, EventableCondition eventableCondition) {
+	public List<CandidateElement> getCandidateElementsForInputs(Element sourceElement,
+	        EventableCondition eventableCondition) {
 
-		return formInputValueHelper.getCandidateElementsForInputs(
-		        browser, sourceElement, eventableCondition);
+		return formInputValueHelper.getCandidateElementsForInputs(browser, sourceElement,
+		        eventableCondition);
 	}
 
 }
"
0eb3942a140368609d17db4811768e77f4a94b4e,Ali Mesbah,Helper.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/src/main/java/com/crawljax/util/Helper.java b/src/main/java/com/crawljax/util/Helper.java
index 277609f..7b60695 100644
--- a/src/main/java/com/crawljax/util/Helper.java
+++ b/src/main/java/com/crawljax/util/Helper.java
@@ -636,13 +636,16 @@
 				throw new IOException(""Cannot find "" + fname + "" or "" + fnameJar);
 			}
 		}
-		InputStreamReader streamReader = new InputStreamReader(inStream);
-		BufferedReader bufferedReader = new BufferedReader(streamReader);
+
+		BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inStream));
 		String line;
 		StringBuilder stringBuilder = new StringBuilder();
+
 		while ((line = bufferedReader.readLine()) != null) {
 			stringBuilder.append(line + ""\n"");
 		}
+
+		bufferedReader.close();
 		return stringBuilder.toString();
 	}
 
"
a255111e8decbbcb3141db4006f3c154a317414e,Stefan Lenselink,Crawler.java,MODIFY,"spawnThreads -> [StateVertix state, boolean removeLastStateFromEventPath] | [StateVertix state]","diff --git a/src/main/java/com/crawljax/core/Crawler.java b/src/main/java/com/crawljax/core/Crawler.java
index 8ffd3bf..2b84873 100644
--- a/src/main/java/com/crawljax/core/Crawler.java
+++ b/src/main/java/com/crawljax/core/Crawler.java
@@ -1,23 +1,23 @@
 package com.crawljax.core;
 
-import java.util.List;
-
-import org.apache.log4j.Logger;
-
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.core.configuration.CrawljaxConfigurationReader;
 import com.crawljax.core.plugin.CrawljaxPluginsUtil;
 import com.crawljax.core.state.CrawlPath;
 import com.crawljax.core.state.Eventable;
+import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.core.state.Identification;
 import com.crawljax.core.state.StateFlowGraph;
 import com.crawljax.core.state.StateMachine;
 import com.crawljax.core.state.StateVertix;
-import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.forms.FormHandler;
 import com.crawljax.forms.FormInput;
 import com.crawljax.util.ElementResolver;
 
+import org.apache.log4j.Logger;
+
+import java.util.List;
+
 /**
  * Class that performs crawl actions. It is designed to be run inside a Thread.
  * 
@@ -175,10 +175,6 @@
 	 */
 	private boolean fireEvent(Eventable eventable) {
 		try {
-
-			// TODO Stefan; FindBugs found this bug, not yet solved
-			// Should be changed with:
-			// eventable.getIdentification().getHow().toString().equals(""xpath"")
 			if (eventable.getIdentification().getHow().toString().equals(""xpath"")
 			        && eventable.getRelatedFrame().equals("""")) {
 
@@ -376,15 +372,15 @@
 		}
 	}
 
-	private void spawnThreads(StateVertix state, boolean removeLastStateFromEventPath) {
+	private void spawnThreads(StateVertix state) {
 		Crawler c = null;
 		do {
 			if (c != null) {
 				this.crawlQueueManager.addWorkToQueue(c);
 			}
 			c =
-			        new Crawler(this.controller, controller.getSession().getCurrentCrawlPath()
-			                .immutableCopy(true));
+			        new Crawler(this.controller,
+			                controller.getSession().getCurrentCrawlPath().immutableCopy(true));
 		} while (state.registerCrawler(c));
 	}
 
@@ -402,12 +398,12 @@
 					// We are in the clone state so we continue with the cloned version to search
 					// for work.
 					this.controller.getSession().branchCrawlPath();
-					spawnThreads(orrigionalState, false);
+					spawnThreads(orrigionalState);
 					break;
 				case newState:
 					fired = true;
 					// Recurse because new state found
-					spawnThreads(orrigionalState, true);
+					spawnThreads(orrigionalState);
 					break;
 				case domUnChanged:
 					// Dom not updated, continue with the next
"
ff47fe03f3e251b698c5fb6ed9b60799b3aee224,Stefan Lenselink,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index debe32d..0b05327 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -25,6 +25,8 @@
 import org.openqa.selenium.WebDriverException;
 import org.openqa.selenium.WebElement;
 import org.openqa.selenium.internal.FileHandler;
+import org.openqa.selenium.internal.WrapsDriver;
+import org.openqa.selenium.remote.Augmenter;
 import org.openqa.selenium.remote.DesiredCapabilities;
 import org.openqa.selenium.remote.HttpCommandExecutor;
 import org.openqa.selenium.remote.RemoteWebDriver;
@@ -730,11 +732,10 @@
 	protected long getCrawlWaitReload() {
 		return crawlWaitReload;
 	}
-
-	@Override
-	public void saveScreenShot(File file) throws CrawljaxException {
-		if (browser instanceof TakesScreenshot) {
-			File tmpfile = ((TakesScreenshot) browser).getScreenshotAs(OutputType.FILE);
+	
+	private void takeScreenShotOnBrowser(WebDriver driver, File file) throws CrawljaxException {
+		if (driver instanceof TakesScreenshot) {
+			File tmpfile = ((TakesScreenshot) driver).getScreenshotAs(OutputType.FILE);
 
 			try {
 				FileHandler.copy(tmpfile, file);
@@ -743,11 +744,21 @@
 			}
 
 			removeCanvasGeneratedByFirefoxDriverForScreenshots();
+		} else if (driver instanceof RemoteWebDriver) {
+			WebDriver augmentedWebdriver = new Augmenter().augment(driver);
+			takeScreenShotOnBrowser(augmentedWebdriver, file);
+		} else if (driver instanceof WrapsDriver) {
+			takeScreenShotOnBrowser(((WrapsDriver) driver).getWrappedDriver(), file);
 		} else {
 			throw new CrawljaxException(""Your current WebDriver doesn't support screenshots."");
 		}
 	}
 
+	@Override
+	public void saveScreenShot(File file) throws CrawljaxException {
+		takeScreenShotOnBrowser(browser, file);
+	}
+
 	private void removeCanvasGeneratedByFirefoxDriverForScreenshots() {
 		String js = """";
 		js += ""var canvas = document.getElementById('fxdriver-screenshot-canvas');"";
"
bf859c1eaa81b3d8f0975fc6cdb35cf5fb00ad47,Stefan Lenselink,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 0b05327..e404104 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -575,7 +575,7 @@
 			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
 				frameIdentification += nameId;
 
-				String handle = new String(browser.getWindowHandle());
+				String handle = browser.getWindowHandle();
 
 				LOGGER.debug(""The current H: "" + handle);
 
@@ -686,7 +686,7 @@
 		browser.switchTo().frame(iframeIdentification);
 
 		// make a copy of the dom before changing into the top page
-		String frameDom = new String(browser.getPageSource());
+		String frameDom = browser.getPageSource();
 
 		browser.switchTo().defaultContent();
 
"
bf859c1eaa81b3d8f0975fc6cdb35cf5fb00ad47,Stefan Lenselink,Helper.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/src/main/java/com/crawljax/util/Helper.java b/src/main/java/com/crawljax/util/Helper.java
index 7b60695..ceab745 100644
--- a/src/main/java/com/crawljax/util/Helper.java
+++ b/src/main/java/com/crawljax/util/Helper.java
@@ -1,5 +1,23 @@
 package com.crawljax.util;
 
+import com.google.common.collect.Lists;
+
+import org.apache.commons.io.FileUtils;
+import org.apache.log4j.Logger;
+import org.custommonkey.xmlunit.DetailedDiff;
+import org.custommonkey.xmlunit.Diff;
+import org.custommonkey.xmlunit.Difference;
+import org.custommonkey.xmlunit.DifferenceListener;
+import org.cyberneko.html.parsers.DOMParser;
+import org.w3c.dom.Attr;
+import org.w3c.dom.Document;
+import org.w3c.dom.Element;
+import org.w3c.dom.NamedNodeMap;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+import org.xml.sax.InputSource;
+import org.xml.sax.SAXException;
+
 import java.io.BufferedReader;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
@@ -33,24 +51,6 @@
 import javax.xml.xpath.XPathExpressionException;
 import javax.xml.xpath.XPathFactory;
 
-import org.apache.commons.io.FileUtils;
-import org.apache.log4j.Logger;
-import org.custommonkey.xmlunit.DetailedDiff;
-import org.custommonkey.xmlunit.Diff;
-import org.custommonkey.xmlunit.Difference;
-import org.custommonkey.xmlunit.DifferenceListener;
-import org.cyberneko.html.parsers.DOMParser;
-import org.w3c.dom.Attr;
-import org.w3c.dom.Document;
-import org.w3c.dom.Element;
-import org.w3c.dom.NamedNodeMap;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-import org.xml.sax.InputSource;
-import org.xml.sax.SAXException;
-
-import com.google.common.collect.Lists;
-
 /**
  * Utility class that contains a number of helper functions used by Crawljax and some plugins.
  * 
@@ -135,10 +135,8 @@
 	 * @return the base part of the URL.
 	 */
 	public static String getBaseUrl(String url) {
-		String temp = new String(url);
-		String head = temp.substring(0, temp.indexOf("":""));
+		String head = url.substring(0, url.indexOf("":""));
 		String subLoc = url.substring(head.length() + BASE_LENGTH);
-
 		return head + ""://"" + subLoc.substring(0, subLoc.indexOf(""/""));
 	}
 
@@ -446,8 +444,13 @@
 	public static void writeToFile(String filename, String text, boolean append)
 	        throws IOException {
 		FileWriter fw = new FileWriter(filename, append);
-		fw.write(text + ""\n"");
-		fw.close();
+		try {
+			fw.write(text + ""\n"");
+		} catch (IOException e) {
+			throw e;
+		} finally {
+			fw.close();
+		}
 	}
 
 	/**
"
bf859c1eaa81b3d8f0975fc6cdb35cf5fb00ad47,Stefan Lenselink,PrettyHTML.java,MODIFY,"prettyHTML -> [String html] | [String html, String strIndent]","diff --git a/src/main/java/com/crawljax/util/PrettyHTML.java b/src/main/java/com/crawljax/util/PrettyHTML.java
index 55b0d41..13b56af 100644
--- a/src/main/java/com/crawljax/util/PrettyHTML.java
+++ b/src/main/java/com/crawljax/util/PrettyHTML.java
@@ -28,7 +28,7 @@
 	 */
 	public static String prettyHTML(String html, String strIndent) {
 		String[] elements = html.split(""<"");
-		String prettyHTML = """";
+		StringBuffer prettyHTML = new StringBuffer();
 		int indent = 0;
 		// preparsing for not closing elements
 		elements = fixElements(elements);
@@ -39,9 +39,9 @@
 
 				if (!element.startsWith(""/"")) {
 					// open element
-					prettyHTML += repeatString(strIndent, indent);
+					prettyHTML.append(repeatString(strIndent, indent));
 					String[] temp = element.split("">"");
-					prettyHTML += ""<"" + temp[0].trim() + "">\n"";
+					prettyHTML.append(""<"" + temp[0].trim() + "">\n"");
 
 					// only indent if element is not a single element (like
 					// <img src='..' />)
@@ -52,21 +52,21 @@
 
 					// if there is text after the element, print it
 					if (temp.length > 1 && !temp[1].trim().equals("""")) {
-						prettyHTML += repeatString(strIndent, indent);
-						prettyHTML += temp[1].trim() + ""\n"";
+						prettyHTML.append(repeatString(strIndent, indent));
+						prettyHTML.append(temp[1].trim() + ""\n"");
 					}
 				} else {
 					// close element
 					indent--;
-					prettyHTML += repeatString(strIndent, indent);
-					prettyHTML += ""<"" + element + ""\n"";
+					prettyHTML.append(repeatString(strIndent, indent));
+					prettyHTML.append(""<"" + element + ""\n"");
 				}
 				if (element.endsWith(""/>"")) {
 					indent--;
 				}
 			}
 		}
-		return prettyHTML;
+		return prettyHTML.toString();
 
 	}
 
@@ -85,11 +85,11 @@
 	 * @return s repreated number of times
 	 */
 	private static String repeatString(String s, int number) {
-		String ret = """";
+		StringBuffer ret = new StringBuffer();
 		for (int i = 0; i < number; i++) {
-			ret += s;
+			ret.append(s);
 		}
-		return ret;
+		return ret.toString();
 	}
 
 	/**
"
b98a12c26372905a8b48f7ebf595146ee6b8713c,Stefan Lenselink,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/src/main/java/com/crawljax/core/CrawljaxController.java b/src/main/java/com/crawljax/core/CrawljaxController.java
index 8d9451a..e4c0cee 100644
--- a/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -37,7 +37,7 @@
 	private long startCrawl;
 
 	private final StateComparator stateComparator;
-	private final CrawlConditionChecker crawlConditionChecker = new CrawlConditionChecker();
+	private final CrawlConditionChecker crawlConditionChecker;
 	private final EventableConditionChecker eventableConditionChecker;
 
 	private final WaitConditionChecker waitConditionChecker = new WaitConditionChecker();
@@ -71,7 +71,7 @@
 
 		stateComparator = new StateComparator(crawlerReader.getOracleComparators());
 		invariantList = crawlerReader.getInvariants();
-		crawlConditionChecker.setCrawlConditions(crawlerReader.getCrawlConditions());
+		crawlConditionChecker = new CrawlConditionChecker(crawlerReader.getCrawlConditions());
 		waitConditionChecker.setWaitConditions(crawlerReader.getWaitConditions());
 		eventableConditionChecker =
 		        new EventableConditionChecker(configurationReader.getEventableConditions());
"
0fee18d4d398d8f876c2b9f68632b4053851af00,Stefan Lenselink,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index e404104..5f577c7 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -31,6 +31,7 @@
 import org.openqa.selenium.remote.HttpCommandExecutor;
 import org.openqa.selenium.remote.RemoteWebDriver;
 import org.openqa.selenium.support.ui.Select;
+import org.w3c.dom.DOMException;
 import org.w3c.dom.Document;
 import org.w3c.dom.Element;
 import org.w3c.dom.NodeList;
@@ -95,7 +96,7 @@
 
 	/**
 	 * Constructor.
-	 * 
+	 *
 	 * @param driver
 	 *            The WebDriver to use.
 	 * @param filterAttributes
@@ -134,7 +135,7 @@
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 * 
+	 *
 	 * @param hubUrl
 	 *            Url of the server.
 	 * @param filterAttributes
@@ -156,7 +157,7 @@
 
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
-	 * 
+	 *
 	 * @param driver
 	 *            The WebDriver to use.
 	 * @param filterAttributes
@@ -175,7 +176,7 @@
 
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
-	 * 
+	 *
 	 * @param driver
 	 *            The WebDriver to use.
 	 * @param filterAttributes
@@ -191,13 +192,13 @@
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
 	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
 	        IgnoreFrameChecker ignoreFrameChecker) {
-		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
-		        crawlWaitReload, ignoreFrameChecker);
+		return new WebDriverBackedEmbeddedBrowser(
+		        driver, filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
 	}
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 * 
+	 *
 	 * @param hubUrl
 	 *            Url of the server.
 	 * @return The EmbeddedBrowser.
@@ -229,6 +230,8 @@
 		try {
 			executor = new HttpCommandExecutor(url);
 		} catch (Exception e) {
+			// TODO Stefan; refactor this catch, this will definitely result in NullPointers, why
+			// not throw RuntimeExcption direct?
 			LOGGER.error(""Received unknown exception while creating the ""
 			        + ""HttpCommandExecutor, can not continue!"", e);
 			return null;
@@ -250,27 +253,32 @@
 	/**
 	 * @param url
 	 *            The URL.
-	 * @throws CrawljaxException
-	 *             if fails.
 	 */
-	public void goToUrl(String url) throws CrawljaxException {
-		browser.navigate().to(url);
+	public void goToUrl(String url) {
 		try {
+			browser.navigate().to(url);
 			Thread.sleep(this.crawlWaitReload);
 			handlePopups();
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return;
 		} catch (InterruptedException e) {
-			throw new CrawljaxException(e.getMessage(), e);
+			LOGGER.error(""goToUrl got interrupted while waiting for the page to be loaded"", e);
+			return;
 		}
-
 	}
 
 	/**
 	 * alert, prompt, and confirm behave as if the OK button is always clicked.
 	 */
 	private void handlePopups() {
-		executeJavaScript(""window.alert = function(msg){return true;};""
-		        + ""window.confirm = function(msg){return true;};""
-		        + ""window.prompt = function(msg){return true;};"");
+		try {
+			executeJavaScript(""window.alert = function(msg){return true;};""
+			        + ""window.confirm = function(msg){return true;};""
+			        + ""window.prompt = function(msg){return true;};"");
+		} catch (CrawljaxException e) {
+			LOGGER.error(""Handling of PopUp windows failed"", e);
+		}
 	}
 
 	/**
@@ -281,12 +289,8 @@
 	 * @param eventable
 	 *            The HTML event type (onclick, onmouseover, ...).
 	 * @return true if firing event is successful.
-	 * @throws CrawljaxException
-	 *             if fails.
 	 */
-	protected boolean fireEventWait(WebElement webElement, Eventable eventable)
-	        throws CrawljaxException {
-
+	protected boolean fireEventWait(WebElement webElement, Eventable eventable) {
 		switch (eventable.getEventType()) {
 			case click:
 				try {
@@ -295,8 +299,8 @@
 					LOGGER.info(""Element not visible, so cannot be clicked: ""
 					        + webElement.getTagName().toUpperCase() + "" "" + webElement.getText());
 					return false;
-				} catch (Exception e) {
-					LOGGER.error(e.getMessage());
+				} catch (WebDriverException e) {
+					throwIfConnectionException(e);
 					return false;
 				}
 				break;
@@ -313,25 +317,32 @@
 		try {
 			Thread.sleep(this.crawlWaitEvent);
 		} catch (InterruptedException e) {
-			throw new CrawljaxException(e.getMessage(), e);
+			LOGGER.error(""fireEventWait got interrupted during wait process"", e);
+			return false;
 		}
-
 		return true;
 	}
 
 	@Override
 	public void close() {
 		LOGGER.info(""Closing the browser..."");
-		// close browser and close every associated window.
-		browser.quit();
+		try {
+			// close browser and close every associated window.
+			browser.quit();
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
 	}
 
 	@Override
-	public String getDom() throws CrawljaxException {
+	public String getDom() {
 		try {
 			return toUniformDOM(Helper.getDocumentToString(getDomTreeWithFrames()));
-		} catch (Exception e) {
-			throw new CrawljaxException(e.getMessage(), e);
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return """";
+		} catch (CrawljaxException e) {
+			return """";
 		}
 	}
 
@@ -339,10 +350,8 @@
 	 * @param html
 	 *            The html string.
 	 * @return uniform version of dom with predefined attributes stripped
-	 * @throws Exception
-	 *             On error.
 	 */
-	private String toUniformDOM(String html) throws Exception {
+	private String toUniformDOM(String html) {
 
 		Pattern p = Pattern.compile(
 		        ""<SCRIPT(.*?)</SCRIPT>"", Pattern.DOTALL | Pattern.CASE_INSENSITIVE);
@@ -384,7 +393,11 @@
 
 	@Override
 	public void goBack() {
-		browser.navigate().back();
+		try {
+			browser.navigate().back();
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
 	}
 
 	/**
@@ -395,19 +408,22 @@
 	 * @return true if succeeds.
 	 */
 	public boolean input(Identification identification, String text) {
-		WebElement field = browser.findElement(identification.getWebDriverBy());
+		try {
+			WebElement field = browser.findElement(identification.getWebDriverBy());
+			if (field != null) {
+				// first clear the field
+				field.clear();
+				// then fill in
+				field.sendKeys(text);
 
-		if (field != null) {
-			// first clear the field
-			field.clear();
-			// then fill in
-			field.sendKeys(text);
-
-			// this.activeElement = field;
-			return true;
+				// this.activeElement = field;
+				return true;
+			}
+			return false;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return false;
 		}
-
-		return false;
 	}
 
 	/**
@@ -416,10 +432,8 @@
 	 * @param eventable
 	 *            The eventable.
 	 * @return true if it is able to fire the event successfully on the element.
-	 * @throws CrawljaxException
-	 *             On failure.
 	 */
-	public synchronized boolean fireEvent(Eventable eventable) throws CrawljaxException {
+	public synchronized boolean fireEvent(Eventable eventable) {
 		try {
 
 			boolean handleChanged = false;
@@ -448,16 +462,12 @@
 			if (handleChanged) {
 				browser.switchTo().defaultContent();
 			}
-
 			return result;
-
 		} catch (NoSuchElementException e) {
-
 			LOGGER.warn(""Could not fire eventable: "" + eventable.toString());
 			return false;
-		} catch (RuntimeException e) {
-			LOGGER.error(""Caught Exception: "" + e.getMessage(), e);
-
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
 			return false;
 		}
 	}
@@ -468,10 +478,17 @@
 	 * @param code
 	 *            The code to execute.
 	 * @return The return value of the JavaScript.
+	 * @throws CrawljaxException
+	 *             when javascript execution failed.
 	 */
-	public Object executeJavaScript(String code) {
-		JavascriptExecutor js = (JavascriptExecutor) browser;
-		return js.executeScript(code);
+	public Object executeJavaScript(String code) throws CrawljaxException {
+		try {
+			JavascriptExecutor js = (JavascriptExecutor) browser;
+			return js.executeScript(code);
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			throw new CrawljaxException(e);
+		}
 	}
 
 	/**
@@ -489,7 +506,8 @@
 			}
 
 			return false;
-		} catch (Exception e) {
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
 			return false;
 		}
 	}
@@ -498,21 +516,29 @@
 	 * @return The current browser url.
 	 */
 	public String getCurrentUrl() {
-		return browser.getCurrentUrl();
+		try {
+			return browser.getCurrentUrl();
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
 	}
 
 	@Override
 	public void closeOtherWindows() {
-		String current = browser.getWindowHandle();
-		for (String handle : browser.getWindowHandles()) {
-			if (!handle.equals(browser.getWindowHandle())) {
+		try {
+			String current = browser.getWindowHandle();
+			for (String handle : browser.getWindowHandles()) {
+				if (!handle.equals(browser.getWindowHandle())) {
 
-				browser.switchTo().window(handle);
-				LOGGER.info(""Closing other window with title \"""" + browser.getTitle() + ""\"""");
-				browser.close();
-				// browser.switchTo().defaultContent();
-				browser.switchTo().window(current);
+					browser.switchTo().window(handle);
+					LOGGER.info(""Closing other window with title \"""" + browser.getTitle() + ""\"""");
+					browser.close();
+					// browser.switchTo().defaultContent();
+					browser.switchTo().window(current);
+				}
 			}
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
 	}
 
@@ -535,7 +561,7 @@
 					// TODO Stefan find out if this error is a Webdriver bug??
 					LOGGER.info(""Skiped parsing dom tree because no html content is defined"");
 				} else {
-					throw new CrawljaxException(e.getMessage(), e);
+					throw e;
 				}
 			}
 			document = Helper.getDocument(s);
@@ -579,51 +605,50 @@
 
 				LOGGER.debug(""The current H: "" + handle);
 
+				LOGGER.debug(""switching to frame: "" + frameIdentification);
+				browser.switchTo().frame(frameIdentification);
+				String toAppend = browser.getPageSource();
+
+				LOGGER.debug(""frame dom: "" + toAppend);
+
+				browser.switchTo().defaultContent();
+
 				try {
-
-					LOGGER.debug(""switching to frame: "" + frameIdentification);
-					browser.switchTo().frame(frameIdentification);
-					String toAppend = browser.getPageSource();
-
-					LOGGER.debug(""frame dom: "" + toAppend);
-
-					browser.switchTo().defaultContent();
-
 					Element toAppendElement = Helper.getDocument(toAppend).getDocumentElement();
 					Element importedElement =
 					        (Element) document.importNode(toAppendElement, true);
 					frameElement.appendChild(importedElement);
 
-					appendFrameContent(importedElement, document, frameIdentification);
-
-				} catch (Exception e) {
+                    appendFrameContent(importedElement, document, frameIdentification);
+				} catch (DOMException e) {
 					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
 					        + "" continuing..."", e);
-				}
-
+				} catch (SAXException e) {
+					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
+					        + "" continuing..."", e);
+				} catch (IOException e) {
+					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
+					        + "" continuing..."", e);
+                }
 			}
 		}
-
 	}
 
 	/**
 	 * @return the dom without the iframe contents.
-	 * @throws CrawljaxException
-	 *             if it fails.
 	 * @see com.crawljax.browser.EmbeddedBrowser#getDomWithoutIframeContent()
 	 */
-	public String getDomWithoutIframeContent() throws CrawljaxException {
-
+	public String getDomWithoutIframeContent() {
 		try {
 			String dom = browser.getPageSource();
 			// logger.debug(""driver.source: "" + dom);
 			String result = toUniformDOM(dom);
 			// logger.debug(""driver.source toUniformDom: "" + result);
 			return result;
-		} catch (Exception e) {
-			throw new CrawljaxException(e.getMessage(), e);
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return """";
 		}
-
 	}
 
 	/**
@@ -639,8 +664,8 @@
 			if (!((RenderedWebElement) webElement).isDisplayed()) {
 				return null;
 			}
-		} catch (Exception e) {
-			LOGGER.error(e.getMessage(), e);
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
 			return null;
 		}
 
@@ -665,8 +690,8 @@
 				WebElement option = (WebElement) new RandomInputValueGenerator().getRandomOption(
 				        select.getOptions());
 				values.add(new InputValue(option.getText(), true));
-			} catch (Exception e) {
-				LOGGER.error(e.getMessage(), e);
+			} catch (WebDriverException e) {
+				throwIfConnectionException(e);
 				return null;
 			}
 		}
@@ -681,16 +706,20 @@
 
 	@Override
 	public String getFrameDom(String iframeIdentification) {
+		try {
+			LOGGER.debug(""switching to frame: "" + iframeIdentification);
+			browser.switchTo().frame(iframeIdentification);
 
-		LOGGER.debug(""switching to frame: "" + iframeIdentification);
-		browser.switchTo().frame(iframeIdentification);
+			// make a copy of the dom before changing into the top page
+			String frameDom = browser.getPageSource();
 
-		// make a copy of the dom before changing into the top page
-		String frameDom = browser.getPageSource();
+			browser.switchTo().defaultContent();
 
-		browser.switchTo().defaultContent();
-
-		return frameDom;
+			return frameDom;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return """";
+		}
 	}
 
 	/**
@@ -699,8 +728,15 @@
 	 * @return true if the element can be found in the DOM tree.
 	 */
 	public boolean elementExists(Identification identification) {
-		WebElement el = browser.findElement(identification.getWebDriverBy());
-		return el != null;
+		try {
+			WebElement el = browser.findElement(identification.getWebDriverBy());
+			// TODO Stefan; I think el will never be null as a NoSuchElementExcpetion will be
+			// thrown, catched below.
+			return el != null;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return false;
+		}
 	}
 
 	/**
@@ -709,7 +745,11 @@
 	 * @return the found element.
 	 */
 	public WebElement getWebElement(Identification identification) {
-		return browser.findElement(identification.getWebDriverBy());
+		try {
+			return browser.findElement(identification.getWebDriverBy());
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
 	}
 
 	/**
@@ -732,7 +772,7 @@
 	protected long getCrawlWaitReload() {
 		return crawlWaitReload;
 	}
-	
+
 	private void takeScreenShotOnBrowser(WebDriver driver, File file) throws CrawljaxException {
 		if (driver instanceof TakesScreenshot) {
 			File tmpfile = ((TakesScreenshot) driver).getScreenshotAs(OutputType.FILE);
@@ -740,7 +780,7 @@
 			try {
 				FileHandler.copy(tmpfile, file);
 			} catch (IOException e) {
-				throw new WebDriverException(e);
+				throw new CrawljaxException(e);
 			}
 
 			removeCanvasGeneratedByFirefoxDriverForScreenshots();
@@ -756,7 +796,11 @@
 
 	@Override
 	public void saveScreenShot(File file) throws CrawljaxException {
-		takeScreenShotOnBrowser(browser, file);
+		try {
+			takeScreenShotOnBrowser(browser, file);
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
 	}
 
 	private void removeCanvasGeneratedByFirefoxDriverForScreenshots() {
@@ -767,8 +811,9 @@
 		js += ""}"";
 		try {
 			executeJavaScript(js);
-		} catch (Exception e) {
-			LOGGER.warn(""Could not remove the screenshot canvas from the DOM."");
+		} catch (CrawljaxException e) {
+			LOGGER.error(""Removing of Canvas Generated By FirefoxDriver failed,""
+			        + "" most likely leaving it in the browser"", e);
 		}
 	}
 
@@ -788,4 +833,23 @@
 		this.crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
 		this.ignoreFrameChecker = configuration.getCrawlSpecificationReader();
 	}
+
+	private boolean exceptionIsConnectionException(WebDriverException exception) {
+		return exception != null && exception.getCause() != null
+		        && exception.getCause() instanceof IOException;
+	}
+
+	private RuntimeException wrapWebDriverExceptionIfConnectionException(
+	        WebDriverException exception) {
+		if (exceptionIsConnectionException(exception)) {
+			return new BrowserConnectionException(exception);
+		}
+		return exception;
+	}
+
+	private void throwIfConnectionException(WebDriverException exception) {
+		if (exceptionIsConnectionException(exception)) {
+			throw wrapWebDriverExceptionIfConnectionException(exception);
+		}
+	}
 }
\ No newline at end of file
"
0fee18d4d398d8f876c2b9f68632b4053851af00,Stefan Lenselink,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/src/main/java/com/crawljax/core/CrawljaxController.java b/src/main/java/com/crawljax/core/CrawljaxController.java
index e4c0cee..7a3b33b 100644
--- a/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -42,7 +42,7 @@
 
 	private final WaitConditionChecker waitConditionChecker = new WaitConditionChecker();
 
-	// TODO Stefan, Can not be final because, must be created aftet the loading of the plugins
+	// TODO Stefan, Can not be final because, must be created after the loading of the plugins
 	private Crawler initialCrawler;
 
 	private final CrawljaxConfigurationReader configurationReader;
@@ -142,8 +142,20 @@
 		} catch (InterruptedException e) {
 			LOGGER.error(e.getMessage(), e);
 		}
-
+		
+		if (workQueue.isAborted()) {
+			LOGGER.warn(""It apears to be that the workQueue was Aborted, ""
+			        + ""not running postcrawling plugins and not closing the browsers"");
+			return;
+		}
+		
 		long timeCrawlCalc = System.currentTimeMillis() - startCrawl;
+		
+		/**
+		 * Close all the opened browsers, this is run in separate thread to have the post crawl
+		 * plugins to execute in the meanwhile.
+		 */
+		Thread shutdownThread = browserPool.close();
 
 		// TODO Stefan; Now we ""re-request"" a browser instance for the PostCrawlingPlugins Thread,
 		// this is not ideal...
@@ -156,30 +168,14 @@
 		CrawljaxPluginsUtil.runPostCrawlingPlugins(session);
 		this.getBrowserPool().freeBrowser(b);
 
-		/**
-		 * Close all the opened browsers, this is run in separate thread to have the post crawl
-		 * plugins to execute in the meanwhile.
-		 */
-		Thread shutdownThread = browserPool.close();
-
-		StateFlowGraph stateFlowGraph = this.getSession().getStateFlowGraph();
-		for (Eventable c : stateFlowGraph.getAllEdges()) {
-			LOGGER.info(""Interaction Element= "" + c.toString());
-		}
-
-		LOGGER.info(""Total Crawling time("" + timeCrawlCalc + ""ms) ~= ""
-		        + formatRunningTime(timeCrawlCalc));
-		LOGGER.info(""EXAMINED ELEMENTS: "" + elementChecker.numberOfExaminedElements());
-		LOGGER.info(""CLICKABLES: "" + stateFlowGraph.getAllEdges().size());
-		LOGGER.info(""STATES: "" + stateFlowGraph.getAllStates().size());
-		LOGGER.info(""Dom average size (byte): "" + stateFlowGraph.getMeanStateStringSize());
+		this.shutdown(timeCrawlCalc);
 
 		try {
 			shutdownThread.join();
 		} catch (InterruptedException e) {
 			LOGGER.error(""could not wait for browsers to close."", e);
 		}
-		LOGGER.info(""DONE!!!"");
+		
 	}
 
 	/**
@@ -282,32 +278,35 @@
 	/**
 	 * Terminate the crawling, Stop all threads this will cause the controller which is sleeping to
 	 * reactive and do the final work....
+	 *
+	 * @param isAbort
+	 *            if set true the terminate must be as an abort not allowing running PostCrawling
+	 *            plugins.
 	 */
 	@GuardedBy(""this"")
-	public final synchronized void terminate() {
+	public final synchronized void terminate(boolean isAbort) {
 		LOGGER.warn(""After "" + this.formatRunningTime()
 		        + "" the crawling process was requested to terminate @ "" + Thread.currentThread());
-		LOGGER.info(""Trying to stop all the threads"");
-		// TODO Stefan do the actual termination of all the threads. Also test if it works!
-		LOGGER.info(""There are "" + workQueue.getActiveCount() + "" threads active"");
-		workQueue.shutdownNow();
-
-		if (workQueue.isShutdown()) {
-			LOGGER.info(""ThreadPoolExecuter is shutdown"");
-		} else {
-			LOGGER.warn(""ThreadPoolExecuter is not shutdown"");
-		}
-		if (workQueue.isTerminated()) {
-			LOGGER.info(""All threads are terminated"");
-		} else {
-			LOGGER.warn(""Not All threads are terminated, there still are ""
-			        + workQueue.getActiveCount() + "" threads active"");
-		}
-		LOGGER.info(""Trying to close all browsers"");
-		/**
-		 * TODO: Needs some more testing when Threads are not finished, the browser gets locked...
-		 */
 		browserPool.shutdown();
+		workQueue.shutdownNow(isAbort);
+		this.shutdown(System.currentTimeMillis() - startCrawl);
+	}
+
+	/**
+	 * The general shutdown procedure without running plugins or using browsers.
+	 */
+	private void shutdown(long timeCrawlCalc) {
+		StateFlowGraph stateFlowGraph = this.getSession().getStateFlowGraph();
+		for (Eventable c : stateFlowGraph.getAllEdges()) {
+			LOGGER.info(""Interaction Element= "" + c.toString());
+		}
+		LOGGER.info(""Total Crawling time("" + timeCrawlCalc + ""ms) ~= ""
+		        + formatRunningTime(timeCrawlCalc));
+		LOGGER.info(""EXAMINED ELEMENTS: "" + elementChecker.numberOfExaminedElements());
+		LOGGER.info(""CLICKABLES: "" + stateFlowGraph.getAllEdges().size());
+		LOGGER.info(""STATES: "" + stateFlowGraph.getAllStates().size());
+		LOGGER.info(""Dom average size (byte): "" + stateFlowGraph.getMeanStateStringSize());
+		LOGGER.info(""DONE!!!"");
 	}
 
 	/**
"
0fee18d4d398d8f876c2b9f68632b4053851af00,Stefan Lenselink,StateFlowGraph.java,MODIFY,"addState -> [StateVertix stateVertix, boolean correctName] | [StateVertix stateVertix]","diff --git a/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index a68aa1f..a38fa43 100644
--- a/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -1,11 +1,5 @@
 package com.crawljax.core.state;
 
-import java.util.ArrayList;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-import java.util.concurrent.atomic.AtomicInteger;
-
 import net.jcip.annotations.GuardedBy;
 
 import org.apache.commons.math.stat.descriptive.moment.Mean;
@@ -16,6 +10,12 @@
 import org.jgrapht.alg.KShortestPaths;
 import org.jgrapht.graph.DirectedMultigraph;
 
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+import java.util.concurrent.atomic.AtomicInteger;
+
 /**
  * The State-Flow Graph is a directed graph with states on the vertices and clickables on the edges.
  * 
@@ -363,7 +363,7 @@
 				List<GraphPath<StateVertix, Eventable>> paths = kPaths.getPaths(state);
 				results.add(paths);
 			} catch (Exception e) {
-
+				// TODO Stefan; which Exception is catched here???Can this be removed?
 				LOGGER.error(""Error with "" + state.toString(), e);
 			}
 
"
0fee18d4d398d8f876c2b9f68632b4053851af00,Stefan Lenselink,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 46f2dcb..bda0ddb 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -3,12 +3,13 @@
  */
 package com.crawljax.forms;
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.List;
-
-import javax.xml.xpath.XPathExpressionException;
+import com.crawljax.browser.BrowserConnectionException;
+import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.condition.eventablecondition.EventableCondition;
+import com.crawljax.core.CandidateElement;
+import com.crawljax.core.configuration.InputSpecification;
+import com.crawljax.util.Helper;
+import com.crawljax.util.XPathHelper;
 
 import org.apache.log4j.Logger;
 import org.w3c.dom.Document;
@@ -17,13 +18,12 @@
 import org.w3c.dom.NodeList;
 import org.xml.sax.SAXException;
 
-import com.crawljax.browser.EmbeddedBrowser;
-import com.crawljax.condition.eventablecondition.EventableCondition;
-import com.crawljax.core.CandidateElement;
-import com.crawljax.core.CrawljaxException;
-import com.crawljax.core.configuration.InputSpecification;
-import com.crawljax.util.Helper;
-import com.crawljax.util.XPathHelper;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+
+import javax.xml.xpath.XPathExpressionException;
 
 /**
  * Handles form values and fills in the form input elements with random values of the defined
@@ -147,6 +147,10 @@
 					}
 				}
 			} catch (Exception e) {
+				//TODO Stefan; refactor this catch
+				if (e instanceof BrowserConnectionException) {
+					throw (BrowserConnectionException) e;
+				}
 				LOGGER.error(e.getMessage(), e);
 			}
 		}
@@ -205,6 +209,10 @@
 				}
 			}
 		} catch (Exception e) {
+			// TODO Stefan; refactor this Exception
+			if (e instanceof BrowserConnectionException) {
+				throw (BrowserConnectionException) e;
+			}
 			LOGGER.error(e.getMessage(), e);
 		}
 		return formInputs;
@@ -239,8 +247,6 @@
 			LOGGER.error(e.getMessage(), e);
 		} catch (IOException e) {
 			LOGGER.error(e.getMessage(), e);
-		} catch (CrawljaxException e) {
-			LOGGER.error(e.getMessage(), e);
 		} catch (XPathExpressionException e) {
 			LOGGER.error(e.getMessage(), e);
 		}
"
0fee18d4d398d8f876c2b9f68632b4053851af00,Stefan Lenselink,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/src/main/java/com/crawljax/util/ElementResolver.java b/src/main/java/com/crawljax/util/ElementResolver.java
index e86e5a8..c50af37 100644
--- a/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/src/main/java/com/crawljax/util/ElementResolver.java
@@ -1,15 +1,18 @@
 package com.crawljax.util;
 
-import javax.xml.xpath.XPathExpressionException;
+import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.core.state.Element;
+import com.crawljax.core.state.Eventable;
 
 import org.apache.log4j.Logger;
 import org.w3c.dom.Document;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
+import org.xml.sax.SAXException;
 
-import com.crawljax.browser.EmbeddedBrowser;
-import com.crawljax.core.state.Element;
-import com.crawljax.core.state.Eventable;
+import java.io.IOException;
+
+import javax.xml.xpath.XPathExpressionException;
 
 /**
  * class for finding and checking elements.
@@ -54,11 +57,15 @@
 	public String resolve(boolean logging) {
 		Document dom = null;
 		try {
-			dom = Helper.getDocument(browser.getDom());
-		} catch (Exception e) {
+	        dom = Helper.getDocument(browser.getDom());
+		} catch (SAXException e) {
 			LOGGER.error(e.getMessage(), e);
+			return """";
+		} catch (IOException e) {
+			LOGGER.error(e.getMessage(), e);
+			return """";
 		}
-
+		
 		try {
 			String xpathEventable = eventable.getIdentification().getValue();
 			Node nodeSameXpath = Helper.getElementByXpath(dom, xpathEventable);
"
b36da20eefbed34fc246f4ccf4821ce63b3e5846,Stefan Lenselink,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 5f577c7..896d7af 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -4,6 +4,7 @@
 import com.crawljax.core.configuration.AcceptAllFramesChecker;
 import com.crawljax.core.configuration.CrawljaxConfigurationReader;
 import com.crawljax.core.configuration.IgnoreFrameChecker;
+import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.Identification;
 import com.crawljax.forms.FormHandler;
"
b36da20eefbed34fc246f4ccf4821ce63b3e5846,Stefan Lenselink,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index bda0ddb..439d088 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -3,11 +3,11 @@
  */
 package com.crawljax.forms;
 
-import com.crawljax.browser.BrowserConnectionException;
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.CandidateElement;
 import com.crawljax.core.configuration.InputSpecification;
+import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.util.Helper;
 import com.crawljax.util.XPathHelper;
 
"
69e58f0820531b51715600a953e446dbb29a82fd,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 896d7af..e396bdd 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -1,17 +1,15 @@
 package com.crawljax.browser;
 
-import com.crawljax.core.CrawljaxException;
-import com.crawljax.core.configuration.AcceptAllFramesChecker;
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
-import com.crawljax.core.configuration.IgnoreFrameChecker;
-import com.crawljax.core.exception.BrowserConnectionException;
-import com.crawljax.core.state.Eventable;
-import com.crawljax.core.state.Identification;
-import com.crawljax.forms.FormHandler;
-import com.crawljax.forms.FormInput;
-import com.crawljax.forms.InputValue;
-import com.crawljax.forms.RandomInputValueGenerator;
-import com.crawljax.util.Helper;
+import java.io.File;
+import java.io.IOException;
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
 
 import org.apache.log4j.Logger;
 import org.openqa.selenium.ElementNotVisibleException;
@@ -38,16 +36,18 @@
 import org.w3c.dom.NodeList;
 import org.xml.sax.SAXException;
 
-import java.io.File;
-import java.io.IOException;
-import java.net.MalformedURLException;
-import java.net.URL;
-import java.util.ArrayList;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
+import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.configuration.AcceptAllFramesChecker;
+import com.crawljax.core.configuration.CrawljaxConfigurationReader;
+import com.crawljax.core.configuration.IgnoreFrameChecker;
+import com.crawljax.core.exception.BrowserConnectionException;
+import com.crawljax.core.state.Eventable;
+import com.crawljax.core.state.Identification;
+import com.crawljax.forms.FormHandler;
+import com.crawljax.forms.FormInput;
+import com.crawljax.forms.InputValue;
+import com.crawljax.forms.RandomInputValueGenerator;
+import com.crawljax.util.Helper;
 
 /**
  * @author mesbah
@@ -67,7 +67,7 @@
 	/**
 	 * Constructor without configuration values, these must be updated using the
 	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
-	 *
+	 * 
 	 * @param driver
 	 *            The WebDriver to use.
 	 */
@@ -77,7 +77,7 @@
 
 	/**
 	 * Constructor.
-	 *
+	 * 
 	 * @param driver
 	 *            The WebDriver to use.
 	 * @param filterAttributes
@@ -97,7 +97,7 @@
 
 	/**
 	 * Constructor.
-	 *
+	 * 
 	 * @param driver
 	 *            The WebDriver to use.
 	 * @param filterAttributes
@@ -117,7 +117,7 @@
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 *
+	 * 
 	 * @param hubUrl
 	 *            Url of the server.
 	 * @param filterAttributes
@@ -130,13 +130,13 @@
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
 	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
-		return WebDriverBackedEmbeddedBrowser.withDriver(
-		        buildRemoteWebDriver(hubUrl), filterAttributes, crawlWaitEvent, crawlWaitReload);
+		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
+		        filterAttributes, crawlWaitEvent, crawlWaitReload);
 	}
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 *
+	 * 
 	 * @param hubUrl
 	 *            Url of the server.
 	 * @param filterAttributes
@@ -158,7 +158,7 @@
 
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
-	 *
+	 * 
 	 * @param driver
 	 *            The WebDriver to use.
 	 * @param filterAttributes
@@ -171,13 +171,13 @@
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
 	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
-		return new WebDriverBackedEmbeddedBrowser(
-		        driver, filterAttributes, crawlWaitEvent, crawlWaitReload);
+		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
+		        crawlWaitReload);
 	}
 
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
-	 *
+	 * 
 	 * @param driver
 	 *            The WebDriver to use.
 	 * @param filterAttributes
@@ -193,13 +193,13 @@
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
 	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
 	        IgnoreFrameChecker ignoreFrameChecker) {
-		return new WebDriverBackedEmbeddedBrowser(
-		        driver, filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
+		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
+		        crawlWaitReload, ignoreFrameChecker);
 	}
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 *
+	 * 
 	 * @param hubUrl
 	 *            Url of the server.
 	 * @return The EmbeddedBrowser.
@@ -211,7 +211,7 @@
 	/**
 	 * Private used static method for creation of a RemoteWebDriver. Taking care of the default
 	 * Capabilities and using the HttpCommandExecutor.
-	 *
+	 * 
 	 * @param hubUrl
 	 *            the url of the hub to use.
 	 * @return the RemoteWebDriver instance.
@@ -223,8 +223,8 @@
 		try {
 			url = new URL(hubUrl);
 		} catch (MalformedURLException e) {
-			LOGGER.error(
-			        ""The given hub url of the remote server is malformed can not continue!"", e);
+			LOGGER.error(""The given hub url of the remote server is malformed can not continue!"",
+			        e);
 			return null;
 		}
 		HttpCommandExecutor executor = null;
@@ -242,7 +242,7 @@
 
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
-	 *
+	 * 
 	 * @param driver
 	 *            The WebDriver to use.
 	 * @return The EmbeddedBrowser.
@@ -284,7 +284,7 @@
 
 	/**
 	 * Fires the event and waits for a specified time.
-	 *
+	 * 
 	 * @param webElement
 	 *            the element to fire event on.
 	 * @param eventable
@@ -310,8 +310,8 @@
 				break;
 
 			default:
-				LOGGER.info(
-				        ""EventType "" + eventable.getEventType() + "" not supported in WebDriver."");
+				LOGGER.info(""EventType "" + eventable.getEventType()
+				        + "" not supported in WebDriver."");
 				return false;
 		}
 
@@ -354,8 +354,9 @@
 	 */
 	private String toUniformDOM(String html) {
 
-		Pattern p = Pattern.compile(
-		        ""<SCRIPT(.*?)</SCRIPT>"", Pattern.DOTALL | Pattern.CASE_INSENSITIVE);
+		Pattern p =
+		        Pattern.compile(""<SCRIPT(.*?)</SCRIPT>"", Pattern.DOTALL
+		                | Pattern.CASE_INSENSITIVE);
 		Matcher m = p.matcher(html);
 		String htmlFormatted = m.replaceAll("""");
 
@@ -375,7 +376,7 @@
 
 	/**
 	 * Filters attributes from the HTML string.
-	 *
+	 * 
 	 * @param html
 	 *            The HTML to filter.
 	 * @return The filtered HTML string.
@@ -429,7 +430,7 @@
 
 	/**
 	 * Fires an event on an element using its identification.
-	 *
+	 * 
 	 * @param eventable
 	 *            The eventable.
 	 * @return true if it is able to fire the event successfully on the element.
@@ -475,7 +476,7 @@
 
 	/**
 	 * Execute JavaScript in the browser.
-	 *
+	 * 
 	 * @param code
 	 *            The code to execute.
 	 * @return The return value of the JavaScript.
@@ -494,7 +495,7 @@
 
 	/**
 	 * Determines whether the corresponding element is visible.
-	 *
+	 * 
 	 * @param identification
 	 *            The element to search for.
 	 * @return true if the element is visible
@@ -555,9 +556,11 @@
 			String s = """";
 			try {
 				s = browser.getPageSource();
+				System.out.println(s);
 			} catch (WebDriverException e) {
-				if (e.getMessage().contains(""Utils.getDocument(respond.context).""
-				        + ""getElementsByTagName(\\\""html\\\"")[0] is undefined"")) {
+				if (e.getMessage().contains(
+				        ""Utils.getDocument(respond.context).""
+				                + ""getElementsByTagName(\\\""html\\\"")[0] is undefined"")) {
 					// There is no html tag... ignore!
 					// TODO Stefan find out if this error is a Webdriver bug??
 					LOGGER.info(""Skiped parsing dom tree because no html content is defined"");
@@ -620,7 +623,7 @@
 					        (Element) document.importNode(toAppendElement, true);
 					frameElement.appendChild(importedElement);
 
-                    appendFrameContent(importedElement, document, frameIdentification);
+					appendFrameContent(importedElement, document, frameIdentification);
 				} catch (DOMException e) {
 					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
 					        + "" continuing..."", e);
@@ -630,7 +633,7 @@
 				} catch (IOException e) {
 					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
 					        + "" continuing..."", e);
-                }
+				}
 			}
 		}
 	}
@@ -675,8 +678,8 @@
 		// create some random value
 
 		if (input.getType().toLowerCase().startsWith(""text"")) {
-			values.add(new InputValue(new RandomInputValueGenerator().getRandomString(
-			        FormHandler.RANDOM_STRING_LENGTH), true));
+			values.add(new InputValue(new RandomInputValueGenerator()
+			        .getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
 		} else if (input.getType().equalsIgnoreCase(""checkbox"")
 		        || input.getType().equalsIgnoreCase(""radio"") && !webElement.isSelected()) {
 			if (new RandomInputValueGenerator().getCheck()) {
@@ -688,8 +691,9 @@
 		} else if (input.getType().equalsIgnoreCase(""select"")) {
 			try {
 				Select select = new Select(webElement);
-				WebElement option = (WebElement) new RandomInputValueGenerator().getRandomOption(
-				        select.getOptions());
+				WebElement option =
+				        (WebElement) new RandomInputValueGenerator().getRandomOption(select
+				                .getOptions());
 				values.add(new InputValue(option.getText(), true));
 			} catch (WebDriverException e) {
 				throwIfConnectionException(e);
"
69e58f0820531b51715600a953e446dbb29a82fd,Ali Mesbah,Helper.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/src/main/java/com/crawljax/util/Helper.java b/src/main/java/com/crawljax/util/Helper.java
index ceab745..991c16e 100644
--- a/src/main/java/com/crawljax/util/Helper.java
+++ b/src/main/java/com/crawljax/util/Helper.java
@@ -1,23 +1,5 @@
 package com.crawljax.util;
 
-import com.google.common.collect.Lists;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.log4j.Logger;
-import org.custommonkey.xmlunit.DetailedDiff;
-import org.custommonkey.xmlunit.Diff;
-import org.custommonkey.xmlunit.Difference;
-import org.custommonkey.xmlunit.DifferenceListener;
-import org.cyberneko.html.parsers.DOMParser;
-import org.w3c.dom.Attr;
-import org.w3c.dom.Document;
-import org.w3c.dom.Element;
-import org.w3c.dom.NamedNodeMap;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-import org.xml.sax.InputSource;
-import org.xml.sax.SAXException;
-
 import java.io.BufferedReader;
 import java.io.ByteArrayOutputStream;
 import java.io.File;
@@ -51,6 +33,24 @@
 import javax.xml.xpath.XPathExpressionException;
 import javax.xml.xpath.XPathFactory;
 
+import org.apache.commons.io.FileUtils;
+import org.apache.log4j.Logger;
+import org.custommonkey.xmlunit.DetailedDiff;
+import org.custommonkey.xmlunit.Diff;
+import org.custommonkey.xmlunit.Difference;
+import org.custommonkey.xmlunit.DifferenceListener;
+import org.cyberneko.html.parsers.DOMParser;
+import org.w3c.dom.Attr;
+import org.w3c.dom.Document;
+import org.w3c.dom.Element;
+import org.w3c.dom.NamedNodeMap;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+import org.xml.sax.InputSource;
+import org.xml.sax.SAXException;
+
+import com.google.common.collect.Lists;
+
 /**
  * Utility class that contains a number of helper functions used by Crawljax and some plugins.
  * 
@@ -156,6 +156,7 @@
 	public static Document getDocument(String html) throws SAXException, IOException {
 		DOMParser domParser = new DOMParser();
 		domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
+		domParser.setFeature(""http://xml.org/sax/features/namespaces"", false);
 		domParser.parse(new InputSource(new StringReader(html)));
 		return domParser.getDocument();
 	}
"
b99ed3f37f605e19d18827a5a217ea7e95108a5b,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index e396bdd..b3c3d8f 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -556,7 +556,6 @@
 			String s = """";
 			try {
 				s = browser.getPageSource();
-				System.out.println(s);
 			} catch (WebDriverException e) {
 				if (e.getMessage().contains(
 				        ""Utils.getDocument(respond.context).""
"
9467f5ebbb108ee3ef410e3bd634a4270e52ea07,Ali Mesbah,AttributeInjector.java,MODIFY,"removeInjectedAttributes -> [HTMLElement element, String attrName] | [Vector injectedElements, String attrName]","diff --git a/src/main/java/com/crawljax/util/AttributeInjector.java b/src/main/java/com/crawljax/util/AttributeInjector.java
index 2f152b4..bbb5a37 100644
--- a/src/main/java/com/crawljax/util/AttributeInjector.java
+++ b/src/main/java/com/crawljax/util/AttributeInjector.java
@@ -66,7 +66,7 @@
 			return null;
 		}
 		srcAttrValue += ""?"" + attrName + ""="" + value;
-		System.out.println(""Setting value for src to: "" + srcAttrValue);
+		// System.out.println(""Setting value for src to: "" + srcAttrValue);
 		element.setAttribute(""src"", srcAttrValue);
 		return element;
 	}
"
e2aef42da46edd2dcb0431f81820f15d0f71ec0f,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index b3c3d8f..5ff1bc1 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -551,31 +551,16 @@
 	 */
 	private Document getDomTreeWithFrames() throws CrawljaxException {
 
-		Document document;
 		try {
-			String s = """";
-			try {
-				s = browser.getPageSource();
-			} catch (WebDriverException e) {
-				if (e.getMessage().contains(
-				        ""Utils.getDocument(respond.context).""
-				                + ""getElementsByTagName(\\\""html\\\"")[0] is undefined"")) {
-					// There is no html tag... ignore!
-					// TODO Stefan find out if this error is a Webdriver bug??
-					LOGGER.info(""Skiped parsing dom tree because no html content is defined"");
-				} else {
-					throw e;
-				}
-			}
-			document = Helper.getDocument(s);
+			Document document = Helper.getDocument(browser.getPageSource());
 			appendFrameContent(document.getDocumentElement(), document, """");
+			return document;
 		} catch (SAXException e) {
 			throw new CrawljaxException(e.getMessage(), e);
 		} catch (IOException e) {
 			throw new CrawljaxException(e.getMessage(), e);
 		}
 
-		return document;
 	}
 
 	private void appendFrameContent(Element orig, Document document, String topFrame) {
"
fa09b05d2244c21a648657e2fbb9b8eef0f55df9,Ali Mesbah,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 5e7c53f..589fa3d 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -55,7 +55,7 @@
 
 	private List<EventType> crawlEvents = new ArrayList<EventType>();
 
-	private int depth = 0;
+	private int depth = 2;
 	private int maximumStates = 0;
 	private int maximumRuntime = DEFAULT_MAXIMUMRUNTIME; // in seconds
 	private int waitTimeAfterReloadUrl = DEFAULT_WAITTIMEAFTERRELOADURL; // in milliseconds
@@ -98,7 +98,7 @@
 	/**
 	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
 	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}.
-	 *
+	 * 
 	 * @param tagName
 	 *            the tag name of the elements to be included
 	 * @return this CrawlElement
@@ -112,7 +112,7 @@
 	 * click and dontClick sets, then the element will not be clicked. For example: 1) <a
 	 * href=""#"">Some text</a> 2) <a class=""foo"" .../> 3) <div class=""foo"" .../> click(""a"")
 	 * dontClick(""a"").withAttribute(""class"", ""foo""); Will include only include HTML element 2
-	 *
+	 * 
 	 * @param tagName
 	 *            the tag name of the elements to be excluded
 	 * @return this CrawlElement
@@ -125,7 +125,7 @@
 	 * Crawljax will the HTML elements while crawling if and only if all the specified conditions
 	 * are satisfied. IMPORTANT: only works with click()!!! For example:
 	 * when(onContactPageCondition) will only click the HTML element if it is on the contact page
-	 *
+	 * 
 	 * @param conditions
 	 *            the condition to be met.
 	 * @return this CrawlActions
@@ -150,7 +150,7 @@
 
 	/**
 	 * Sets the maximum crawl depth. 1 is one click, 2 is two clicks deep, ...
-	 *
+	 * 
 	 * @param crawlDepth
 	 *            the maximum crawl depth. 0 to ignore
 	 */
@@ -168,7 +168,7 @@
 	/**
 	 * Sets the maximum number of states. Crawljax will stop crawling when this maximum number of
 	 * states are found
-	 *
+	 * 
 	 * @param crawlMaximumStates
 	 *            the maximum number of states. 0 specifies no bound for the number of crawl states.
 	 */
@@ -186,7 +186,7 @@
 	/**
 	 * Sets the maximum time for Crawljax to run. Crawljax will stop crawling when this timelimit is
 	 * reached.
-	 *
+	 * 
 	 * @param seconds
 	 *            the crawlMaximumRuntime to set
 	 */
@@ -277,7 +277,7 @@
 
 	/**
 	 * Adds the Oracle Comparator to the list of comparators.
-	 *
+	 * 
 	 * @param id
 	 *            a name for the Oracle Comparator.
 	 * @param oracleComparator
@@ -289,7 +289,7 @@
 
 	/**
 	 * Adds an Oracle Comparator with preconditions to the list of comparators.
-	 *
+	 * 
 	 * @param id
 	 *            a name for the Oracle Comparator
 	 * @param oracleComparator
@@ -297,8 +297,8 @@
 	 * @param preConditions
 	 *            the preconditions to be met.
 	 */
-	public void addOracleComparator(
-	        String id, Comparator oracleComparator, Condition... preConditions) {
+	public void addOracleComparator(String id, Comparator oracleComparator,
+	        Condition... preConditions) {
 		this.oracleComparators.add(new OracleComparator(id, oracleComparator, preConditions));
 	}
 
@@ -327,8 +327,7 @@
 	 * @param preConditions
 	 *            the precondition.
 	 */
-	public void addInvariant(
-	        String description, Condition condition, Condition... preConditions) {
+	public void addInvariant(String description, Condition condition, Condition... preConditions) {
 		this.invariants.add(new Invariant(description, condition, preConditions));
 	}
 
@@ -403,8 +402,8 @@
 	 * @param preConditions
 	 *            the preConditions
 	 */
-	public void addCrawlCondition(
-	        String description, Condition crawlCondition, Condition... preConditions) {
+	public void addCrawlCondition(String description, Condition crawlCondition,
+	        Condition... preConditions) {
 		this.crawlConditions.add(new CrawlCondition(description, crawlCondition, preConditions));
 	}
 
"
2915f5366e42f984aefadcb44a4d5e99a942c486,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 5ff1bc1..30bd59d 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -18,13 +18,12 @@
 import org.openqa.selenium.NoSuchFrameException;
 import org.openqa.selenium.OutputType;
 import org.openqa.selenium.Platform;
-import org.openqa.selenium.RenderedWebElement;
 import org.openqa.selenium.TakesScreenshot;
 import org.openqa.selenium.WebDriver;
 import org.openqa.selenium.WebDriverException;
 import org.openqa.selenium.WebElement;
-import org.openqa.selenium.internal.FileHandler;
 import org.openqa.selenium.internal.WrapsDriver;
+import org.openqa.selenium.io.FileHandler;
 import org.openqa.selenium.remote.Augmenter;
 import org.openqa.selenium.remote.DesiredCapabilities;
 import org.openqa.selenium.remote.HttpCommandExecutor;
@@ -337,12 +336,17 @@
 
 	@Override
 	public String getDom() {
+
 		try {
-			return toUniformDOM(Helper.getDocumentToString(getDomTreeWithFrames()));
+			String dom = toUniformDOM(Helper.getDocumentToString(getDomTreeWithFrames()));
+			LOGGER.debug(dom);
+			return dom;
 		} catch (WebDriverException e) {
 			throwIfConnectionException(e);
+			LOGGER.warn(e.getMessage(), e);
 			return """";
 		} catch (CrawljaxException e) {
+			LOGGER.warn(e.getMessage(), e);
 			return """";
 		}
 	}
@@ -444,7 +448,8 @@
 			if (eventable.getRelatedFrame() != null && !eventable.getRelatedFrame().equals("""")) {
 				LOGGER.debug(""switching to frame: "" + eventable.getRelatedFrame());
 				try {
-					browser.switchTo().frame(eventable.getRelatedFrame());
+
+					switchToFrame(eventable.getRelatedFrame());
 				} catch (NoSuchFrameException e) {
 					LOGGER.debug(""Frame not found, possibily while back-tracking.."", e);
 					// TODO Stefan, This exception is catched to prevent stopping from working
@@ -504,7 +509,7 @@
 		try {
 			WebElement el = browser.findElement(identification.getWebDriverBy());
 			if (el != null) {
-				return ((RenderedWebElement) el).isDisplayed();
+				return el.isDisplayed();
 			}
 
 			return false;
@@ -593,8 +598,8 @@
 
 				LOGGER.debug(""The current H: "" + handle);
 
-				LOGGER.debug(""switching to frame: "" + frameIdentification);
-				browser.switchTo().frame(frameIdentification);
+				switchToFrame(frameIdentification);
+
 				String toAppend = browser.getPageSource();
 
 				LOGGER.debug(""frame dom: "" + toAppend);
@@ -622,6 +627,23 @@
 		}
 	}
 
+	private void switchToFrame(String frameIdentification) {
+		LOGGER.debug(""frame identification: "" + frameIdentification);
+
+		if (frameIdentification.contains(""."")) {
+			String[] frames = frameIdentification.split(""\\."");
+
+			for (String frameId : frames) {
+				LOGGER.debug(""switching to frame: "" + frameId);
+				browser.switchTo().frame(frameId);
+			}
+
+		} else {
+			browser.switchTo().frame(frameIdentification);
+		}
+
+	}
+
 	/**
 	 * @return the dom without the iframe contents.
 	 * @see com.crawljax.browser.EmbeddedBrowser#getDomWithoutIframeContent()
@@ -649,7 +671,8 @@
 		WebElement webElement;
 		try {
 			webElement = browser.findElement(input.getIdentification().getWebDriverBy());
-			if (!((RenderedWebElement) webElement).isDisplayed()) {
+			if (!(webElement.isDisplayed())) {
+
 				return null;
 			}
 		} catch (WebDriverException e) {
@@ -696,8 +719,8 @@
 	@Override
 	public String getFrameDom(String iframeIdentification) {
 		try {
-			LOGGER.debug(""switching to frame: "" + iframeIdentification);
-			browser.switchTo().frame(iframeIdentification);
+
+			switchToFrame(iframeIdentification);
 
 			// make a copy of the dom before changing into the top page
 			String frameDom = browser.getPageSource();
"
b3976921c4e9e8c74ffe22bdd1cc0d59d6322aa2,Ali Mesbah,Helper.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/src/main/java/com/crawljax/util/Helper.java b/src/main/java/com/crawljax/util/Helper.java
index 991c16e..16e21e5 100644
--- a/src/main/java/com/crawljax/util/Helper.java
+++ b/src/main/java/com/crawljax/util/Helper.java
@@ -18,6 +18,7 @@
 import java.util.List;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
+import java.util.regex.PatternSyntaxException;
 
 import javax.xml.transform.OutputKeys;
 import javax.xml.transform.Result;
@@ -76,7 +77,15 @@
 	 * @return the base path with file stipped
 	 */
 	private static String getBasePath(URL url) {
-		return url.getPath().replaceAll(url.getFile(), """");
+		String file = url.getFile().replaceAll(""\\*"", """");
+
+		try {
+			return url.getPath().replaceAll(file, """");
+		} catch (PatternSyntaxException pe) {
+			LOGGER.error(pe.getMessage());
+			return """";
+		}
+
 	}
 
 	/**
"
256727f83e8a64420722fcaa9a06f9114b03ecf9,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 30bd59d..c694a01 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -579,7 +579,13 @@
 			nodeList.add(frameElement);
 		}
 
-		for (int i = 0; i < nodeList.size(); i++) {
+                // Guifre Ruiz: Added support for FRAMES
+                frameNodes = orig.getElementsByTagName(""FRAME"");
+                for (int i = 0; i < frameNodes.getLength(); i++) {
+                    Element frameElement = (Element) frameNodes.item(i);
+                    nodeList.add(frameElement);
+                }
+                		for (int i = 0; i < nodeList.size(); i++) {
 			String frameIdentification = """";
 
 			if (topFrame != null && !topFrame.equals("""")) {
"
2de4bf136a44337e7fbbd5819ef9daad0b35c165,Ali Mesbah,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 34fd22a..3693671 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -183,17 +183,19 @@
 	 */
 	public static String formatXPath(String xpath) {
 		String formatted = xpath;
-		Pattern p = Pattern.compile(""(/[a-z]+)"");
-		Matcher m = p.matcher(xpath);
+		Pattern p = Pattern.compile(""(/(?:[-a-zA-Z]+::)?+)([a-zA-Z]+)"");
+		Matcher m = p.matcher(formatted);
 
-		while (m.find()) {
-			formatted = m.replaceFirst(m.group().toUpperCase());
+		for (int i = 0; m.find(i); i++) {
+			i = m.start();
+			formatted = m.replaceFirst(m.group(1) + m.group(2).toUpperCase());
 			m = p.matcher(formatted);
 		}
-		p = Pattern.compile(""(@[A-Z]+)"");
+		p = Pattern.compile(""(@[a-zA-Z]+)"");
 		m = p.matcher(formatted);
 
-		while (m.find()) {
+		for (int i = 0; m.find(i); i++) {
+			i = m.start();
 			formatted = m.replaceFirst(m.group().toLowerCase());
 			m = p.matcher(formatted);
 		}
"
724b6f9c71caa3bef73c739987a80dbb9f0ddcfd,Alex Nederlof,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/src/main/java/com/crawljax/util/XPathHelper.java b/src/main/java/com/crawljax/util/XPathHelper.java
index 34fd22a..3693671 100644
--- a/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/src/main/java/com/crawljax/util/XPathHelper.java
@@ -183,17 +183,19 @@
 	 */
 	public static String formatXPath(String xpath) {
 		String formatted = xpath;
-		Pattern p = Pattern.compile(""(/[a-z]+)"");
-		Matcher m = p.matcher(xpath);
+		Pattern p = Pattern.compile(""(/(?:[-a-zA-Z]+::)?+)([a-zA-Z]+)"");
+		Matcher m = p.matcher(formatted);
 
-		while (m.find()) {
-			formatted = m.replaceFirst(m.group().toUpperCase());
+		for (int i = 0; m.find(i); i++) {
+			i = m.start();
+			formatted = m.replaceFirst(m.group(1) + m.group(2).toUpperCase());
 			m = p.matcher(formatted);
 		}
-		p = Pattern.compile(""(@[A-Z]+)"");
+		p = Pattern.compile(""(@[a-zA-Z]+)"");
 		m = p.matcher(formatted);
 
-		while (m.find()) {
+		for (int i = 0; m.find(i); i++) {
+			i = m.start();
 			formatted = m.replaceFirst(m.group().toLowerCase());
 			m = p.matcher(formatted);
 		}
"
c0ac9030a6140db3169a11574dd108f74827546e,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index c694a01..72ec044 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -579,13 +579,14 @@
 			nodeList.add(frameElement);
 		}
 
-                // Guifre Ruiz: Added support for FRAMES
-                frameNodes = orig.getElementsByTagName(""FRAME"");
-                for (int i = 0; i < frameNodes.getLength(); i++) {
-                    Element frameElement = (Element) frameNodes.item(i);
-                    nodeList.add(frameElement);
-                }
-                		for (int i = 0; i < nodeList.size(); i++) {
+		// Added support for FRAMES
+		frameNodes = orig.getElementsByTagName(""FRAME"");
+		for (int i = 0; i < frameNodes.getLength(); i++) {
+			Element frameElement = (Element) frameNodes.item(i);
+			nodeList.add(frameElement);
+		}
+
+		for (int i = 0; i < nodeList.size(); i++) {
 			String frameIdentification = """";
 
 			if (topFrame != null && !topFrame.equals("""")) {
"
60104099b74d56d34144bfbc0dfd5c0f8d91c18a,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 30bd59d..72ec044 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -579,6 +579,13 @@
 			nodeList.add(frameElement);
 		}
 
+		// Added support for FRAMES
+		frameNodes = orig.getElementsByTagName(""FRAME"");
+		for (int i = 0; i < frameNodes.getLength(); i++) {
+			Element frameElement = (Element) frameNodes.item(i);
+			nodeList.add(frameElement);
+		}
+
 		for (int i = 0; i < nodeList.size(); i++) {
 			String frameIdentification = """";
 
"
60104099b74d56d34144bfbc0dfd5c0f8d91c18a,Alex Nederlof,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 589fa3d..225ec9e 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -95,6 +95,39 @@
 		crawlActions.click(""input"").withAttribute(""type"", ""button"");
 	}
 
+        
+	/**
+         * Guifre Ruiz: This method can be used to crawl more tags and, therefore,
+         * more pages in the target. However, it slow down a bit the process.
+         */ 
+        public void clickMoreElements() {
+            crawlActions.click(""a"");
+            crawlActions.click(""button"");
+            crawlActions.click(""td"");
+            crawlActions.click(""span"");
+            crawlActions.click(""div"");
+            crawlActions.click(""tr"");
+            crawlActions.click(""table"");
+            crawlActions.click(""tbody"");
+            crawlActions.click(""ol"");
+            crawlActions.click(""center"");
+            crawlActions.click(""li"");
+            crawlActions.click(""radio"");
+            crawlActions.click(""non"");
+            crawlActions.click(""meta"");
+            crawlActions.click(""refresh"");
+            crawlActions.click(""xhr"");
+            crawlActions.click(""relative"");
+            crawlActions.click(""link"");
+            crawlActions.click(""self"");
+            crawlActions.click(""form"");
+            crawlActions.click(""input"");
+            crawlActions.click(""option"");
+            crawlActions.click(""img"");
+            crawlActions.click(""p"");    
+        }
+
+        
 	/**
 	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
 	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}.
"
0e381f2707fe54ee5047acd676f876998d6fa0f1,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 72ec044..d97ab0c 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -1,874 +1,875 @@
-package com.crawljax.browser;
-
-import java.io.File;
-import java.io.IOException;
-import java.net.MalformedURLException;
-import java.net.URL;
-import java.util.ArrayList;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
-import org.apache.log4j.Logger;
-import org.openqa.selenium.ElementNotVisibleException;
-import org.openqa.selenium.JavascriptExecutor;
-import org.openqa.selenium.NoSuchElementException;
-import org.openqa.selenium.NoSuchFrameException;
-import org.openqa.selenium.OutputType;
-import org.openqa.selenium.Platform;
-import org.openqa.selenium.TakesScreenshot;
-import org.openqa.selenium.WebDriver;
-import org.openqa.selenium.WebDriverException;
-import org.openqa.selenium.WebElement;
-import org.openqa.selenium.internal.WrapsDriver;
-import org.openqa.selenium.io.FileHandler;
-import org.openqa.selenium.remote.Augmenter;
-import org.openqa.selenium.remote.DesiredCapabilities;
-import org.openqa.selenium.remote.HttpCommandExecutor;
-import org.openqa.selenium.remote.RemoteWebDriver;
-import org.openqa.selenium.support.ui.Select;
-import org.w3c.dom.DOMException;
-import org.w3c.dom.Document;
-import org.w3c.dom.Element;
-import org.w3c.dom.NodeList;
-import org.xml.sax.SAXException;
-
-import com.crawljax.core.CrawljaxException;
-import com.crawljax.core.configuration.AcceptAllFramesChecker;
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
-import com.crawljax.core.configuration.IgnoreFrameChecker;
-import com.crawljax.core.exception.BrowserConnectionException;
-import com.crawljax.core.state.Eventable;
-import com.crawljax.core.state.Identification;
-import com.crawljax.forms.FormHandler;
-import com.crawljax.forms.FormInput;
-import com.crawljax.forms.InputValue;
-import com.crawljax.forms.RandomInputValueGenerator;
-import com.crawljax.util.Helper;
-
-/**
- * @author mesbah
- * @author Frank Groeneveld
- * @version $Id: WebDriverBackedEmbeddedBrowser.java 387 2010-07-13 13:55:49Z slenselink@google.com
- *          $
- */
-public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
-	private long crawlWaitEvent;
-	private static final Logger LOGGER = Logger.getLogger(WebDriverBackedEmbeddedBrowser.class);
-	private final WebDriver browser;
-
-	private List<String> filterAttributes;
-	private long crawlWaitReload;
-	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
-
-	/**
-	 * Constructor without configuration values, these must be updated using the
-	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
-		this.browser = driver;
-	}
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent) {
-		this(driver);
-		this.filterAttributes = filterAttributes;
-		this.crawlWaitEvent = crawlWaitEvent;
-		this.crawlWaitReload = crawlWaitReload;
-	}
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
-		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
-		this.ignoreFrameChecker = ignoreFrameChecker;
-	}
-
-	/**
-	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param hubUrl
-	 *            Url of the server.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
-		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
-		        filterAttributes, crawlWaitEvent, crawlWaitReload);
-	}
-
-	/**
-	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param hubUrl
-	 *            Url of the server.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-	        IgnoreFrameChecker ignoreFrameChecker) {
-		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
-		        filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
-	}
-
-	/**
-	 * Create a WebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
-		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
-		        crawlWaitReload);
-	}
-
-	/**
-	 * Create a WebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-	        IgnoreFrameChecker ignoreFrameChecker) {
-		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
-		        crawlWaitReload, ignoreFrameChecker);
-	}
-
-	/**
-	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param hubUrl
-	 *            Url of the server.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl) {
-		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl));
-	}
-
-	/**
-	 * Private used static method for creation of a RemoteWebDriver. Taking care of the default
-	 * Capabilities and using the HttpCommandExecutor.
-	 * 
-	 * @param hubUrl
-	 *            the url of the hub to use.
-	 * @return the RemoteWebDriver instance.
-	 */
-	private static RemoteWebDriver buildRemoteWebDriver(String hubUrl) {
-		DesiredCapabilities capabilities = new DesiredCapabilities();
-		capabilities.setPlatform(Platform.ANY);
-		URL url;
-		try {
-			url = new URL(hubUrl);
-		} catch (MalformedURLException e) {
-			LOGGER.error(""The given hub url of the remote server is malformed can not continue!"",
-			        e);
-			return null;
-		}
-		HttpCommandExecutor executor = null;
-		try {
-			executor = new HttpCommandExecutor(url);
-		} catch (Exception e) {
-			// TODO Stefan; refactor this catch, this will definitely result in NullPointers, why
-			// not throw RuntimeExcption direct?
-			LOGGER.error(""Received unknown exception while creating the ""
-			        + ""HttpCommandExecutor, can not continue!"", e);
-			return null;
-		}
-		return new RemoteWebDriver(executor, capabilities);
-	}
-
-	/**
-	 * Create a WebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver) {
-		return new WebDriverBackedEmbeddedBrowser(driver);
-	}
-
-	/**
-	 * @param url
-	 *            The URL.
-	 */
-	public void goToUrl(String url) {
-		try {
-			browser.navigate().to(url);
-			Thread.sleep(this.crawlWaitReload);
-			handlePopups();
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return;
-		} catch (InterruptedException e) {
-			LOGGER.error(""goToUrl got interrupted while waiting for the page to be loaded"", e);
-			return;
-		}
-	}
-
-	/**
-	 * alert, prompt, and confirm behave as if the OK button is always clicked.
-	 */
-	private void handlePopups() {
-		try {
-			executeJavaScript(""window.alert = function(msg){return true;};""
-			        + ""window.confirm = function(msg){return true;};""
-			        + ""window.prompt = function(msg){return true;};"");
-		} catch (CrawljaxException e) {
-			LOGGER.error(""Handling of PopUp windows failed"", e);
-		}
-	}
-
-	/**
-	 * Fires the event and waits for a specified time.
-	 * 
-	 * @param webElement
-	 *            the element to fire event on.
-	 * @param eventable
-	 *            The HTML event type (onclick, onmouseover, ...).
-	 * @return true if firing event is successful.
-	 */
-	protected boolean fireEventWait(WebElement webElement, Eventable eventable) {
-		switch (eventable.getEventType()) {
-			case click:
-				try {
-					webElement.click();
-				} catch (ElementNotVisibleException e1) {
-					LOGGER.info(""Element not visible, so cannot be clicked: ""
-					        + webElement.getTagName().toUpperCase() + "" "" + webElement.getText());
-					return false;
-				} catch (WebDriverException e) {
-					throwIfConnectionException(e);
-					return false;
-				}
-				break;
-			case hover:
-				// todo
-				break;
-
-			default:
-				LOGGER.info(""EventType "" + eventable.getEventType()
-				        + "" not supported in WebDriver."");
-				return false;
-		}
-
-		try {
-			Thread.sleep(this.crawlWaitEvent);
-		} catch (InterruptedException e) {
-			LOGGER.error(""fireEventWait got interrupted during wait process"", e);
-			return false;
-		}
-		return true;
-	}
-
-	@Override
-	public void close() {
-		LOGGER.info(""Closing the browser..."");
-		try {
-			// close browser and close every associated window.
-			browser.quit();
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	@Override
-	public String getDom() {
-
-		try {
-			String dom = toUniformDOM(Helper.getDocumentToString(getDomTreeWithFrames()));
-			LOGGER.debug(dom);
-			return dom;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			LOGGER.warn(e.getMessage(), e);
-			return """";
-		} catch (CrawljaxException e) {
-			LOGGER.warn(e.getMessage(), e);
-			return """";
-		}
-	}
-
-	/**
-	 * @param html
-	 *            The html string.
-	 * @return uniform version of dom with predefined attributes stripped
-	 */
-	private String toUniformDOM(String html) {
-
-		Pattern p =
-		        Pattern.compile(""<SCRIPT(.*?)</SCRIPT>"", Pattern.DOTALL
-		                | Pattern.CASE_INSENSITIVE);
-		Matcher m = p.matcher(html);
-		String htmlFormatted = m.replaceAll("""");
-
-		p = Pattern.compile(""<\\?xml:(.*?)>"");
-		m = p.matcher(html);
-		htmlFormatted = m.replaceAll("""");
-
-		// html = html.replace(""<?xml:namespace prefix = gwt >"", """");
-
-		// TODO (Stefan), Following lines are a serious performance bottle neck...
-		// Document doc = Helper.getDocument(htmlFormatted);
-		// htmlFormatted = Helper.getDocumentToString(doc);
-
-		htmlFormatted = filterAttributes(htmlFormatted);
-		return htmlFormatted;
-	}
-
-	/**
-	 * Filters attributes from the HTML string.
-	 * 
-	 * @param html
-	 *            The HTML to filter.
-	 * @return The filtered HTML string.
-	 */
-	private String filterAttributes(String html) {
-		if (this.filterAttributes != null) {
-			for (String attribute : this.filterAttributes) {
-				String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
-				Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
-				Matcher m = p.matcher(html);
-				html = m.replaceAll("""");
-			}
-		}
-		return html;
-	}
-
-	@Override
-	public void goBack() {
-		try {
-			browser.navigate().back();
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	/**
-	 * @param identification
-	 *            The identification object.
-	 * @param text
-	 *            The input.
-	 * @return true if succeeds.
-	 */
-	public boolean input(Identification identification, String text) {
-		try {
-			WebElement field = browser.findElement(identification.getWebDriverBy());
-			if (field != null) {
-				// first clear the field
-				field.clear();
-				// then fill in
-				field.sendKeys(text);
-
-				// this.activeElement = field;
-				return true;
-			}
-			return false;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return false;
-		}
-	}
-
-	/**
-	 * Fires an event on an element using its identification.
-	 * 
-	 * @param eventable
-	 *            The eventable.
-	 * @return true if it is able to fire the event successfully on the element.
-	 */
-	public synchronized boolean fireEvent(Eventable eventable) {
-		try {
-
-			boolean handleChanged = false;
-			boolean result = false;
-
-			if (eventable.getRelatedFrame() != null && !eventable.getRelatedFrame().equals("""")) {
-				LOGGER.debug(""switching to frame: "" + eventable.getRelatedFrame());
-				try {
-
-					switchToFrame(eventable.getRelatedFrame());
-				} catch (NoSuchFrameException e) {
-					LOGGER.debug(""Frame not found, possibily while back-tracking.."", e);
-					// TODO Stefan, This exception is catched to prevent stopping from working
-					// This was the case on the Gmail case; find out if not switching (catching)
-					// Results in good performance...
-				}
-				handleChanged = true;
-			}
-
-			WebElement webElement =
-			        browser.findElement(eventable.getIdentification().getWebDriverBy());
-
-			if (webElement != null) {
-				result = fireEventWait(webElement, eventable);
-			}
-
-			if (handleChanged) {
-				browser.switchTo().defaultContent();
-			}
-			return result;
-		} catch (NoSuchElementException e) {
-			LOGGER.warn(""Could not fire eventable: "" + eventable.toString());
-			return false;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return false;
-		}
-	}
-
-	/**
-	 * Execute JavaScript in the browser.
-	 * 
-	 * @param code
-	 *            The code to execute.
-	 * @return The return value of the JavaScript.
-	 * @throws CrawljaxException
-	 *             when javascript execution failed.
-	 */
-	public Object executeJavaScript(String code) throws CrawljaxException {
-		try {
-			JavascriptExecutor js = (JavascriptExecutor) browser;
-			return js.executeScript(code);
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			throw new CrawljaxException(e);
-		}
-	}
-
-	/**
-	 * Determines whether the corresponding element is visible.
-	 * 
-	 * @param identification
-	 *            The element to search for.
-	 * @return true if the element is visible
-	 */
-	public boolean isVisible(Identification identification) {
-		try {
-			WebElement el = browser.findElement(identification.getWebDriverBy());
-			if (el != null) {
-				return el.isDisplayed();
-			}
-
-			return false;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return false;
-		}
-	}
-
-	/**
-	 * @return The current browser url.
-	 */
-	public String getCurrentUrl() {
-		try {
-			return browser.getCurrentUrl();
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	@Override
-	public void closeOtherWindows() {
-		try {
-			String current = browser.getWindowHandle();
-			for (String handle : browser.getWindowHandles()) {
-				if (!handle.equals(browser.getWindowHandle())) {
-
-					browser.switchTo().window(handle);
-					LOGGER.info(""Closing other window with title \"""" + browser.getTitle() + ""\"""");
-					browser.close();
-					// browser.switchTo().defaultContent();
-					browser.switchTo().window(current);
-				}
-			}
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	/**
-	 * @return a Document object containing the contents of iframes as well.
-	 * @throws CrawljaxException
-	 *             if an exception is thrown.
-	 */
-	private Document getDomTreeWithFrames() throws CrawljaxException {
-
-		try {
-			Document document = Helper.getDocument(browser.getPageSource());
-			appendFrameContent(document.getDocumentElement(), document, """");
-			return document;
-		} catch (SAXException e) {
-			throw new CrawljaxException(e.getMessage(), e);
-		} catch (IOException e) {
-			throw new CrawljaxException(e.getMessage(), e);
-		}
-
-	}
-
-	private void appendFrameContent(Element orig, Document document, String topFrame) {
-
-		NodeList frameNodes = orig.getElementsByTagName(""IFRAME"");
-
-		List<Element> nodeList = new ArrayList<Element>();
-
-		for (int i = 0; i < frameNodes.getLength(); i++) {
-			Element frameElement = (Element) frameNodes.item(i);
-			nodeList.add(frameElement);
-		}
-
-		// Added support for FRAMES
-		frameNodes = orig.getElementsByTagName(""FRAME"");
-		for (int i = 0; i < frameNodes.getLength(); i++) {
-			Element frameElement = (Element) frameNodes.item(i);
-			nodeList.add(frameElement);
-		}
-
-		for (int i = 0; i < nodeList.size(); i++) {
-			String frameIdentification = """";
-
-			if (topFrame != null && !topFrame.equals("""")) {
-				frameIdentification += topFrame + ""."";
-			}
-
-			Element frameElement = nodeList.get(i);
-
-			String nameId = Helper.getFrameIdentification(frameElement);
-
-			if (nameId != null
-			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
-				frameIdentification += nameId;
-
-				String handle = browser.getWindowHandle();
-
-				LOGGER.debug(""The current H: "" + handle);
-
-				switchToFrame(frameIdentification);
-
-				String toAppend = browser.getPageSource();
-
-				LOGGER.debug(""frame dom: "" + toAppend);
-
-				browser.switchTo().defaultContent();
-
-				try {
-					Element toAppendElement = Helper.getDocument(toAppend).getDocumentElement();
-					Element importedElement =
-					        (Element) document.importNode(toAppendElement, true);
-					frameElement.appendChild(importedElement);
-
-					appendFrameContent(importedElement, document, frameIdentification);
-				} catch (DOMException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				} catch (SAXException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				} catch (IOException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				}
-			}
-		}
-	}
-
-	private void switchToFrame(String frameIdentification) {
-		LOGGER.debug(""frame identification: "" + frameIdentification);
-
-		if (frameIdentification.contains(""."")) {
-			String[] frames = frameIdentification.split(""\\."");
-
-			for (String frameId : frames) {
-				LOGGER.debug(""switching to frame: "" + frameId);
-				browser.switchTo().frame(frameId);
-			}
-
-		} else {
-			browser.switchTo().frame(frameIdentification);
-		}
-
-	}
-
-	/**
-	 * @return the dom without the iframe contents.
-	 * @see com.crawljax.browser.EmbeddedBrowser#getDomWithoutIframeContent()
-	 */
-	public String getDomWithoutIframeContent() {
-		try {
-			String dom = browser.getPageSource();
-			// logger.debug(""driver.source: "" + dom);
-			String result = toUniformDOM(dom);
-			// logger.debug(""driver.source toUniformDom: "" + result);
-			return result;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return """";
-		}
-	}
-
-	/**
-	 * @param input
-	 *            the input to be filled.
-	 * @return FormInput with random value assigned if possible
-	 */
-	public FormInput getInputWithRandomValue(FormInput input) {
-
-		WebElement webElement;
-		try {
-			webElement = browser.findElement(input.getIdentification().getWebDriverBy());
-			if (!(webElement.isDisplayed())) {
-
-				return null;
-			}
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return null;
-		}
-
-		Set<InputValue> values = new HashSet<InputValue>();
-
-		// create some random value
-
-		if (input.getType().toLowerCase().startsWith(""text"")) {
-			values.add(new InputValue(new RandomInputValueGenerator()
-			        .getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
-		} else if (input.getType().equalsIgnoreCase(""checkbox"")
-		        || input.getType().equalsIgnoreCase(""radio"") && !webElement.isSelected()) {
-			if (new RandomInputValueGenerator().getCheck()) {
-				values.add(new InputValue(""1"", true));
-			} else {
-				values.add(new InputValue(""0"", false));
-
-			}
-		} else if (input.getType().equalsIgnoreCase(""select"")) {
-			try {
-				Select select = new Select(webElement);
-				WebElement option =
-				        (WebElement) new RandomInputValueGenerator().getRandomOption(select
-				                .getOptions());
-				values.add(new InputValue(option.getText(), true));
-			} catch (WebDriverException e) {
-				throwIfConnectionException(e);
-				return null;
-			}
-		}
-
-		if (values.size() == 0) {
-			return null;
-		}
-		input.setInputValues(values);
-		return input;
-
-	}
-
-	@Override
-	public String getFrameDom(String iframeIdentification) {
-		try {
-
-			switchToFrame(iframeIdentification);
-
-			// make a copy of the dom before changing into the top page
-			String frameDom = browser.getPageSource();
-
-			browser.switchTo().defaultContent();
-
-			return frameDom;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return """";
-		}
-	}
-
-	/**
-	 * @param identification
-	 *            the identification of the element.
-	 * @return true if the element can be found in the DOM tree.
-	 */
-	public boolean elementExists(Identification identification) {
-		try {
-			WebElement el = browser.findElement(identification.getWebDriverBy());
-			// TODO Stefan; I think el will never be null as a NoSuchElementExcpetion will be
-			// thrown, catched below.
-			return el != null;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return false;
-		}
-	}
-
-	/**
-	 * @param identification
-	 *            the identification of the element.
-	 * @return the found element.
-	 */
-	public WebElement getWebElement(Identification identification) {
-		try {
-			return browser.findElement(identification.getWebDriverBy());
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	/**
-	 * @return the period to wait after an event.
-	 */
-	protected long getCrawlWaitEvent() {
-		return crawlWaitEvent;
-	}
-
-	/**
-	 * @return the list of attributes to be filtered from DOM.
-	 */
-	protected List<String> getFilterAttributes() {
-		return filterAttributes;
-	}
-
-	/**
-	 * @return the period to waint after a reload.
-	 */
-	protected long getCrawlWaitReload() {
-		return crawlWaitReload;
-	}
-
-	private void takeScreenShotOnBrowser(WebDriver driver, File file) throws CrawljaxException {
-		if (driver instanceof TakesScreenshot) {
-			File tmpfile = ((TakesScreenshot) driver).getScreenshotAs(OutputType.FILE);
-
-			try {
-				FileHandler.copy(tmpfile, file);
-			} catch (IOException e) {
-				throw new CrawljaxException(e);
-			}
-
-			removeCanvasGeneratedByFirefoxDriverForScreenshots();
-		} else if (driver instanceof RemoteWebDriver) {
-			WebDriver augmentedWebdriver = new Augmenter().augment(driver);
-			takeScreenShotOnBrowser(augmentedWebdriver, file);
-		} else if (driver instanceof WrapsDriver) {
-			takeScreenShotOnBrowser(((WrapsDriver) driver).getWrappedDriver(), file);
-		} else {
-			throw new CrawljaxException(""Your current WebDriver doesn't support screenshots."");
-		}
-	}
-
-	@Override
-	public void saveScreenShot(File file) throws CrawljaxException {
-		try {
-			takeScreenShotOnBrowser(browser, file);
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	private void removeCanvasGeneratedByFirefoxDriverForScreenshots() {
-		String js = """";
-		js += ""var canvas = document.getElementById('fxdriver-screenshot-canvas');"";
-		js += ""if(canvas != null){"";
-		js += ""canvas.parentNode.removeChild(canvas);"";
-		js += ""}"";
-		try {
-			executeJavaScript(js);
-		} catch (CrawljaxException e) {
-			LOGGER.error(""Removing of Canvas Generated By FirefoxDriver failed,""
-			        + "" most likely leaving it in the browser"", e);
-		}
-	}
-
-	/**
-	 * @return the WebDriver used as an EmbeddedBrowser.
-	 */
-	public WebDriver getBrowser() {
-		return browser;
-	}
-
-	@Override
-	public void updateConfiguration(CrawljaxConfigurationReader configuration) {
-		// Retrieve the config values used
-		this.filterAttributes = configuration.getFilterAttributeNames();
-		this.crawlWaitReload =
-		        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
-		this.crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
-		this.ignoreFrameChecker = configuration.getCrawlSpecificationReader();
-	}
-
-	private boolean exceptionIsConnectionException(WebDriverException exception) {
-		return exception != null && exception.getCause() != null
-		        && exception.getCause() instanceof IOException;
-	}
-
-	private RuntimeException wrapWebDriverExceptionIfConnectionException(
-	        WebDriverException exception) {
-		if (exceptionIsConnectionException(exception)) {
-			return new BrowserConnectionException(exception);
-		}
-		return exception;
-	}
-
-	private void throwIfConnectionException(WebDriverException exception) {
-		if (exceptionIsConnectionException(exception)) {
-			throw wrapWebDriverExceptionIfConnectionException(exception);
-		}
-	}
-}
\ No newline at end of file
+package com.crawljax.browser;
+
+import java.io.File;
+import java.io.IOException;
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.openqa.selenium.ElementNotVisibleException;
+import org.openqa.selenium.JavascriptExecutor;
+import org.openqa.selenium.NoSuchElementException;
+import org.openqa.selenium.NoSuchFrameException;
+import org.openqa.selenium.OutputType;
+import org.openqa.selenium.Platform;
+import org.openqa.selenium.TakesScreenshot;
+import org.openqa.selenium.WebDriver;
+import org.openqa.selenium.WebDriverException;
+import org.openqa.selenium.WebElement;
+import org.openqa.selenium.internal.WrapsDriver;
+import org.openqa.selenium.io.FileHandler;
+import org.openqa.selenium.remote.Augmenter;
+import org.openqa.selenium.remote.DesiredCapabilities;
+import org.openqa.selenium.remote.HttpCommandExecutor;
+import org.openqa.selenium.remote.RemoteWebDriver;
+import org.openqa.selenium.support.ui.Select;
+import org.w3c.dom.DOMException;
+import org.w3c.dom.Document;
+import org.w3c.dom.Element;
+import org.w3c.dom.NodeList;
+import org.xml.sax.SAXException;
+
+import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.configuration.AcceptAllFramesChecker;
+import com.crawljax.core.configuration.CrawljaxConfigurationReader;
+import com.crawljax.core.configuration.IgnoreFrameChecker;
+import com.crawljax.core.exception.BrowserConnectionException;
+import com.crawljax.core.state.Eventable;
+import com.crawljax.core.state.Identification;
+import com.crawljax.forms.FormHandler;
+import com.crawljax.forms.FormInput;
+import com.crawljax.forms.InputValue;
+import com.crawljax.forms.RandomInputValueGenerator;
+import com.crawljax.util.Helper;
+
+/**
+ * @author mesbah
+ * @author Frank Groeneveld
+ * @version $Id: WebDriverBackedEmbeddedBrowser.java 387 2010-07-13 13:55:49Z slenselink@google.com
+ *          $
+ */
+public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
+	private long crawlWaitEvent;
+	private static final Logger LOGGER = LoggerFactory.getLogger(WebDriverBackedEmbeddedBrowser.class);
+	private final WebDriver browser;
+
+	private List<String> filterAttributes;
+	private long crawlWaitReload;
+	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
+
+	/**
+	 * Constructor without configuration values, these must be updated using the
+	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
+		this.browser = driver;
+	}
+
+	/**
+	 * Constructor.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
+	        long crawlWaitReload, long crawlWaitEvent) {
+		this(driver);
+		this.filterAttributes = filterAttributes;
+		this.crawlWaitEvent = crawlWaitEvent;
+		this.crawlWaitReload = crawlWaitReload;
+	}
+
+	/**
+	 * Constructor.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
+	        long crawlWaitReload, long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
+		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
+		this.ignoreFrameChecker = ignoreFrameChecker;
+	}
+
+	/**
+	 * Create a RemoteWebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param hubUrl
+	 *            Url of the server.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
+		        filterAttributes, crawlWaitEvent, crawlWaitReload);
+	}
+
+	/**
+	 * Create a RemoteWebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param hubUrl
+	 *            Url of the server.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
+	        IgnoreFrameChecker ignoreFrameChecker) {
+		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
+		        filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
+	}
+
+	/**
+	 * Create a WebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
+		        crawlWaitReload);
+	}
+
+	/**
+	 * Create a WebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
+	        IgnoreFrameChecker ignoreFrameChecker) {
+		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
+		        crawlWaitReload, ignoreFrameChecker);
+	}
+
+	/**
+	 * Create a RemoteWebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param hubUrl
+	 *            Url of the server.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl) {
+		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl));
+	}
+
+	/**
+	 * Private used static method for creation of a RemoteWebDriver. Taking care of the default
+	 * Capabilities and using the HttpCommandExecutor.
+	 * 
+	 * @param hubUrl
+	 *            the url of the hub to use.
+	 * @return the RemoteWebDriver instance.
+	 */
+	private static RemoteWebDriver buildRemoteWebDriver(String hubUrl) {
+		DesiredCapabilities capabilities = new DesiredCapabilities();
+		capabilities.setPlatform(Platform.ANY);
+		URL url;
+		try {
+			url = new URL(hubUrl);
+		} catch (MalformedURLException e) {
+			LOGGER.error(""The given hub url of the remote server is malformed can not continue!"",
+			        e);
+			return null;
+		}
+		HttpCommandExecutor executor = null;
+		try {
+			executor = new HttpCommandExecutor(url);
+		} catch (Exception e) {
+			// TODO Stefan; refactor this catch, this will definitely result in NullPointers, why
+			// not throw RuntimeExcption direct?
+			LOGGER.error(""Received unknown exception while creating the ""
+			        + ""HttpCommandExecutor, can not continue!"", e);
+			return null;
+		}
+		return new RemoteWebDriver(executor, capabilities);
+	}
+
+	/**
+	 * Create a WebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver) {
+		return new WebDriverBackedEmbeddedBrowser(driver);
+	}
+
+	/**
+	 * @param url
+	 *            The URL.
+	 */
+	public void goToUrl(String url) {
+		try {
+			browser.navigate().to(url);
+			Thread.sleep(this.crawlWaitReload);
+			handlePopups();
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return;
+		} catch (InterruptedException e) {
+			LOGGER.error(""goToUrl got interrupted while waiting for the page to be loaded"", e);
+			return;
+		}
+	}
+
+	/**
+	 * alert, prompt, and confirm behave as if the OK button is always clicked.
+	 */
+	private void handlePopups() {
+		try {
+			executeJavaScript(""window.alert = function(msg){return true;};""
+			        + ""window.confirm = function(msg){return true;};""
+			        + ""window.prompt = function(msg){return true;};"");
+		} catch (CrawljaxException e) {
+			LOGGER.error(""Handling of PopUp windows failed"", e);
+		}
+	}
+
+	/**
+	 * Fires the event and waits for a specified time.
+	 * 
+	 * @param webElement
+	 *            the element to fire event on.
+	 * @param eventable
+	 *            The HTML event type (onclick, onmouseover, ...).
+	 * @return true if firing event is successful.
+	 */
+	protected boolean fireEventWait(WebElement webElement, Eventable eventable) {
+		switch (eventable.getEventType()) {
+			case click:
+				try {
+					webElement.click();
+				} catch (ElementNotVisibleException e1) {
+					LOGGER.info(""Element not visible, so cannot be clicked: ""
+					        + webElement.getTagName().toUpperCase() + "" "" + webElement.getText());
+					return false;
+				} catch (WebDriverException e) {
+					throwIfConnectionException(e);
+					return false;
+				}
+				break;
+			case hover:
+				// todo
+				break;
+
+			default:
+				LOGGER.info(""EventType "" + eventable.getEventType()
+				        + "" not supported in WebDriver."");
+				return false;
+		}
+
+		try {
+			Thread.sleep(this.crawlWaitEvent);
+		} catch (InterruptedException e) {
+			LOGGER.error(""fireEventWait got interrupted during wait process"", e);
+			return false;
+		}
+		return true;
+	}
+
+	@Override
+	public void close() {
+		LOGGER.info(""Closing the browser..."");
+		try {
+			// close browser and close every associated window.
+			browser.quit();
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	@Override
+	public String getDom() {
+
+		try {
+			String dom = toUniformDOM(Helper.getDocumentToString(getDomTreeWithFrames()));
+			LOGGER.debug(dom);
+			return dom;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			LOGGER.warn(e.getMessage(), e);
+			return """";
+		} catch (CrawljaxException e) {
+			LOGGER.warn(e.getMessage(), e);
+			return """";
+		}
+	}
+
+	/**
+	 * @param html
+	 *            The html string.
+	 * @return uniform version of dom with predefined attributes stripped
+	 */
+	private String toUniformDOM(String html) {
+
+		Pattern p =
+		        Pattern.compile(""<SCRIPT(.*?)</SCRIPT>"", Pattern.DOTALL
+		                | Pattern.CASE_INSENSITIVE);
+		Matcher m = p.matcher(html);
+		String htmlFormatted = m.replaceAll("""");
+
+		p = Pattern.compile(""<\\?xml:(.*?)>"");
+		m = p.matcher(html);
+		htmlFormatted = m.replaceAll("""");
+
+		// html = html.replace(""<?xml:namespace prefix = gwt >"", """");
+
+		// TODO (Stefan), Following lines are a serious performance bottle neck...
+		// Document doc = Helper.getDocument(htmlFormatted);
+		// htmlFormatted = Helper.getDocumentToString(doc);
+
+		htmlFormatted = filterAttributes(htmlFormatted);
+		return htmlFormatted;
+	}
+
+	/**
+	 * Filters attributes from the HTML string.
+	 * 
+	 * @param html
+	 *            The HTML to filter.
+	 * @return The filtered HTML string.
+	 */
+	private String filterAttributes(String html) {
+		if (this.filterAttributes != null) {
+			for (String attribute : this.filterAttributes) {
+				String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
+				Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
+				Matcher m = p.matcher(html);
+				html = m.replaceAll("""");
+			}
+		}
+		return html;
+	}
+
+	@Override
+	public void goBack() {
+		try {
+			browser.navigate().back();
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	/**
+	 * @param identification
+	 *            The identification object.
+	 * @param text
+	 *            The input.
+	 * @return true if succeeds.
+	 */
+	public boolean input(Identification identification, String text) {
+		try {
+			WebElement field = browser.findElement(identification.getWebDriverBy());
+			if (field != null) {
+				// first clear the field
+				field.clear();
+				// then fill in
+				field.sendKeys(text);
+
+				// this.activeElement = field;
+				return true;
+			}
+			return false;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return false;
+		}
+	}
+
+	/**
+	 * Fires an event on an element using its identification.
+	 * 
+	 * @param eventable
+	 *            The eventable.
+	 * @return true if it is able to fire the event successfully on the element.
+	 */
+	public synchronized boolean fireEvent(Eventable eventable) {
+		try {
+
+			boolean handleChanged = false;
+			boolean result = false;
+
+			if (eventable.getRelatedFrame() != null && !eventable.getRelatedFrame().equals("""")) {
+				LOGGER.debug(""switching to frame: "" + eventable.getRelatedFrame());
+				try {
+
+					switchToFrame(eventable.getRelatedFrame());
+				} catch (NoSuchFrameException e) {
+					LOGGER.debug(""Frame not found, possibily while back-tracking.."", e);
+					// TODO Stefan, This exception is catched to prevent stopping from working
+					// This was the case on the Gmail case; find out if not switching (catching)
+					// Results in good performance...
+				}
+				handleChanged = true;
+			}
+
+			WebElement webElement =
+			        browser.findElement(eventable.getIdentification().getWebDriverBy());
+
+			if (webElement != null) {
+				result = fireEventWait(webElement, eventable);
+			}
+
+			if (handleChanged) {
+				browser.switchTo().defaultContent();
+			}
+			return result;
+		} catch (NoSuchElementException e) {
+			LOGGER.warn(""Could not fire eventable: "" + eventable.toString());
+			return false;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return false;
+		}
+	}
+
+	/**
+	 * Execute JavaScript in the browser.
+	 * 
+	 * @param code
+	 *            The code to execute.
+	 * @return The return value of the JavaScript.
+	 * @throws CrawljaxException
+	 *             when javascript execution failed.
+	 */
+	public Object executeJavaScript(String code) throws CrawljaxException {
+		try {
+			JavascriptExecutor js = (JavascriptExecutor) browser;
+			return js.executeScript(code);
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			throw new CrawljaxException(e);
+		}
+	}
+
+	/**
+	 * Determines whether the corresponding element is visible.
+	 * 
+	 * @param identification
+	 *            The element to search for.
+	 * @return true if the element is visible
+	 */
+	public boolean isVisible(Identification identification) {
+		try {
+			WebElement el = browser.findElement(identification.getWebDriverBy());
+			if (el != null) {
+				return el.isDisplayed();
+			}
+
+			return false;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return false;
+		}
+	}
+
+	/**
+	 * @return The current browser url.
+	 */
+	public String getCurrentUrl() {
+		try {
+			return browser.getCurrentUrl();
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	@Override
+	public void closeOtherWindows() {
+		try {
+			String current = browser.getWindowHandle();
+			for (String handle : browser.getWindowHandles()) {
+				if (!handle.equals(browser.getWindowHandle())) {
+
+					browser.switchTo().window(handle);
+					LOGGER.info(""Closing other window with title \"""" + browser.getTitle() + ""\"""");
+					browser.close();
+					// browser.switchTo().defaultContent();
+					browser.switchTo().window(current);
+				}
+			}
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	/**
+	 * @return a Document object containing the contents of iframes as well.
+	 * @throws CrawljaxException
+	 *             if an exception is thrown.
+	 */
+	private Document getDomTreeWithFrames() throws CrawljaxException {
+
+		try {
+			Document document = Helper.getDocument(browser.getPageSource());
+			appendFrameContent(document.getDocumentElement(), document, """");
+			return document;
+		} catch (SAXException e) {
+			throw new CrawljaxException(e.getMessage(), e);
+		} catch (IOException e) {
+			throw new CrawljaxException(e.getMessage(), e);
+		}
+
+	}
+
+	private void appendFrameContent(Element orig, Document document, String topFrame) {
+
+		NodeList frameNodes = orig.getElementsByTagName(""IFRAME"");
+
+		List<Element> nodeList = new ArrayList<Element>();
+
+		for (int i = 0; i < frameNodes.getLength(); i++) {
+			Element frameElement = (Element) frameNodes.item(i);
+			nodeList.add(frameElement);
+		}
+
+		// Added support for FRAMES
+		frameNodes = orig.getElementsByTagName(""FRAME"");
+		for (int i = 0; i < frameNodes.getLength(); i++) {
+			Element frameElement = (Element) frameNodes.item(i);
+			nodeList.add(frameElement);
+		}
+
+		for (int i = 0; i < nodeList.size(); i++) {
+			String frameIdentification = """";
+
+			if (topFrame != null && !topFrame.equals("""")) {
+				frameIdentification += topFrame + ""."";
+			}
+
+			Element frameElement = nodeList.get(i);
+
+			String nameId = Helper.getFrameIdentification(frameElement);
+
+			if (nameId != null
+			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
+				frameIdentification += nameId;
+
+				String handle = browser.getWindowHandle();
+
+				LOGGER.debug(""The current H: "" + handle);
+
+				switchToFrame(frameIdentification);
+
+				String toAppend = browser.getPageSource();
+
+				LOGGER.debug(""frame dom: "" + toAppend);
+
+				browser.switchTo().defaultContent();
+
+				try {
+					Element toAppendElement = Helper.getDocument(toAppend).getDocumentElement();
+					Element importedElement =
+					        (Element) document.importNode(toAppendElement, true);
+					frameElement.appendChild(importedElement);
+
+					appendFrameContent(importedElement, document, frameIdentification);
+				} catch (DOMException e) {
+					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
+					        + "" continuing..."", e);
+				} catch (SAXException e) {
+					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
+					        + "" continuing..."", e);
+				} catch (IOException e) {
+					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
+					        + "" continuing..."", e);
+				}
+			}
+		}
+	}
+
+	private void switchToFrame(String frameIdentification) {
+		LOGGER.debug(""frame identification: "" + frameIdentification);
+
+		if (frameIdentification.contains(""."")) {
+			String[] frames = frameIdentification.split(""\\."");
+
+			for (String frameId : frames) {
+				LOGGER.debug(""switching to frame: "" + frameId);
+				browser.switchTo().frame(frameId);
+			}
+
+		} else {
+			browser.switchTo().frame(frameIdentification);
+		}
+
+	}
+
+	/**
+	 * @return the dom without the iframe contents.
+	 * @see com.crawljax.browser.EmbeddedBrowser#getDomWithoutIframeContent()
+	 */
+	public String getDomWithoutIframeContent() {
+		try {
+			String dom = browser.getPageSource();
+			// logger.debug(""driver.source: "" + dom);
+			String result = toUniformDOM(dom);
+			// logger.debug(""driver.source toUniformDom: "" + result);
+			return result;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return """";
+		}
+	}
+
+	/**
+	 * @param input
+	 *            the input to be filled.
+	 * @return FormInput with random value assigned if possible
+	 */
+	public FormInput getInputWithRandomValue(FormInput input) {
+
+		WebElement webElement;
+		try {
+			webElement = browser.findElement(input.getIdentification().getWebDriverBy());
+			if (!(webElement.isDisplayed())) {
+
+				return null;
+			}
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return null;
+		}
+
+		Set<InputValue> values = new HashSet<InputValue>();
+
+		// create some random value
+
+		if (input.getType().toLowerCase().startsWith(""text"")) {
+			values.add(new InputValue(new RandomInputValueGenerator()
+			        .getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
+		} else if (input.getType().equalsIgnoreCase(""checkbox"")
+		        || input.getType().equalsIgnoreCase(""radio"") && !webElement.isSelected()) {
+			if (new RandomInputValueGenerator().getCheck()) {
+				values.add(new InputValue(""1"", true));
+			} else {
+				values.add(new InputValue(""0"", false));
+
+			}
+		} else if (input.getType().equalsIgnoreCase(""select"")) {
+			try {
+				Select select = new Select(webElement);
+				WebElement option =
+				        (WebElement) new RandomInputValueGenerator().getRandomOption(select
+				                .getOptions());
+				values.add(new InputValue(option.getText(), true));
+			} catch (WebDriverException e) {
+				throwIfConnectionException(e);
+				return null;
+			}
+		}
+
+		if (values.size() == 0) {
+			return null;
+		}
+		input.setInputValues(values);
+		return input;
+
+	}
+
+	@Override
+	public String getFrameDom(String iframeIdentification) {
+		try {
+
+			switchToFrame(iframeIdentification);
+
+			// make a copy of the dom before changing into the top page
+			String frameDom = browser.getPageSource();
+
+			browser.switchTo().defaultContent();
+
+			return frameDom;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return """";
+		}
+	}
+
+	/**
+	 * @param identification
+	 *            the identification of the element.
+	 * @return true if the element can be found in the DOM tree.
+	 */
+	public boolean elementExists(Identification identification) {
+		try {
+			WebElement el = browser.findElement(identification.getWebDriverBy());
+			// TODO Stefan; I think el will never be null as a NoSuchElementExcpetion will be
+			// thrown, catched below.
+			return el != null;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return false;
+		}
+	}
+
+	/**
+	 * @param identification
+	 *            the identification of the element.
+	 * @return the found element.
+	 */
+	public WebElement getWebElement(Identification identification) {
+		try {
+			return browser.findElement(identification.getWebDriverBy());
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	/**
+	 * @return the period to wait after an event.
+	 */
+	protected long getCrawlWaitEvent() {
+		return crawlWaitEvent;
+	}
+
+	/**
+	 * @return the list of attributes to be filtered from DOM.
+	 */
+	protected List<String> getFilterAttributes() {
+		return filterAttributes;
+	}
+
+	/**
+	 * @return the period to waint after a reload.
+	 */
+	protected long getCrawlWaitReload() {
+		return crawlWaitReload;
+	}
+
+	private void takeScreenShotOnBrowser(WebDriver driver, File file) throws CrawljaxException {
+		if (driver instanceof TakesScreenshot) {
+			File tmpfile = ((TakesScreenshot) driver).getScreenshotAs(OutputType.FILE);
+
+			try {
+				FileHandler.copy(tmpfile, file);
+			} catch (IOException e) {
+				throw new CrawljaxException(e);
+			}
+
+			removeCanvasGeneratedByFirefoxDriverForScreenshots();
+		} else if (driver instanceof RemoteWebDriver) {
+			WebDriver augmentedWebdriver = new Augmenter().augment(driver);
+			takeScreenShotOnBrowser(augmentedWebdriver, file);
+		} else if (driver instanceof WrapsDriver) {
+			takeScreenShotOnBrowser(((WrapsDriver) driver).getWrappedDriver(), file);
+		} else {
+			throw new CrawljaxException(""Your current WebDriver doesn't support screenshots."");
+		}
+	}
+
+	@Override
+	public void saveScreenShot(File file) throws CrawljaxException {
+		try {
+			takeScreenShotOnBrowser(browser, file);
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	private void removeCanvasGeneratedByFirefoxDriverForScreenshots() {
+		String js = """";
+		js += ""var canvas = document.getElementById('fxdriver-screenshot-canvas');"";
+		js += ""if(canvas != null){"";
+		js += ""canvas.parentNode.removeChild(canvas);"";
+		js += ""}"";
+		try {
+			executeJavaScript(js);
+		} catch (CrawljaxException e) {
+			LOGGER.error(""Removing of Canvas Generated By FirefoxDriver failed,""
+			        + "" most likely leaving it in the browser"", e);
+		}
+	}
+
+	/**
+	 * @return the WebDriver used as an EmbeddedBrowser.
+	 */
+	public WebDriver getBrowser() {
+		return browser;
+	}
+
+	@Override
+	public void updateConfiguration(CrawljaxConfigurationReader configuration) {
+		// Retrieve the config values used
+		this.filterAttributes = configuration.getFilterAttributeNames();
+		this.crawlWaitReload =
+		        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
+		this.crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
+		this.ignoreFrameChecker = configuration.getCrawlSpecificationReader();
+	}
+
+	private boolean exceptionIsConnectionException(WebDriverException exception) {
+		return exception != null && exception.getCause() != null
+		        && exception.getCause() instanceof IOException;
+	}
+
+	private RuntimeException wrapWebDriverExceptionIfConnectionException(
+	        WebDriverException exception) {
+		if (exceptionIsConnectionException(exception)) {
+			return new BrowserConnectionException(exception);
+		}
+		return exception;
+	}
+
+	private void throwIfConnectionException(WebDriverException exception) {
+		if (exceptionIsConnectionException(exception)) {
+			throw wrapWebDriverExceptionIfConnectionException(exception);
+		}
+	}
+}
"
0e381f2707fe54ee5047acd676f876998d6fa0f1,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/src/main/java/com/crawljax/core/CrawljaxController.java b/src/main/java/com/crawljax/core/CrawljaxController.java
index 7a3b33b..61d1efd 100644
--- a/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -17,7 +17,8 @@
 import net.jcip.annotations.GuardedBy;
 
 import org.apache.commons.configuration.ConfigurationException;
-import org.apache.log4j.Logger;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 
 import java.util.List;
 import java.util.concurrent.TimeUnit;
@@ -30,7 +31,7 @@
  */
 public class CrawljaxController implements CrawlQueueManager {
 
-	private static final Logger LOGGER = Logger.getLogger(CrawljaxController.class.getName());
+	private static final Logger LOGGER = LoggerFactory.getLogger(CrawljaxController.class.getName());
 
 	private CrawlSession session;
 
"
0e381f2707fe54ee5047acd676f876998d6fa0f1,Alex Nederlof,StateFlowGraph.java,MODIFY,"addState -> [StateVertix stateVertix, boolean correctName] | [StateVertix stateVertix]","diff --git a/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index a38fa43..bbcead3 100644
--- a/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -3,7 +3,8 @@
 import net.jcip.annotations.GuardedBy;
 
 import org.apache.commons.math.stat.descriptive.moment.Mean;
-import org.apache.log4j.Logger;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 import org.jgrapht.DirectedGraph;
 import org.jgrapht.GraphPath;
 import org.jgrapht.alg.DijkstraShortestPath;
@@ -23,7 +24,7 @@
  * @version $Id$
  */
 public class StateFlowGraph {
-	private static final Logger LOGGER = Logger.getLogger(StateFlowGraph.class.getName());
+	private static final Logger LOGGER = LoggerFactory.getLogger(StateFlowGraph.class.getName());
 
 	private final DirectedGraph<StateVertix, Eventable> sfg;
 
"
0e381f2707fe54ee5047acd676f876998d6fa0f1,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 439d088..cf51040 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -11,7 +11,8 @@
 import com.crawljax.util.Helper;
 import com.crawljax.util.XPathHelper;
 
-import org.apache.log4j.Logger;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 import org.w3c.dom.Document;
 import org.w3c.dom.Element;
 import org.w3c.dom.Node;
@@ -33,7 +34,7 @@
  * @version $Id$
  */
 public class FormHandler {
-	private static final Logger LOGGER = Logger.getLogger(FormHandler.class.getName());
+	private static final Logger LOGGER = LoggerFactory.getLogger(FormHandler.class.getName());
 
 	private boolean randomFieldValue = false;
 	private final EmbeddedBrowser browser;
"
0e381f2707fe54ee5047acd676f876998d6fa0f1,Alex Nederlof,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/src/main/java/com/crawljax/util/ElementResolver.java b/src/main/java/com/crawljax/util/ElementResolver.java
index c50af37..65a531d 100644
--- a/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/src/main/java/com/crawljax/util/ElementResolver.java
@@ -1,151 +1,152 @@
-package com.crawljax.util;
-
-import com.crawljax.browser.EmbeddedBrowser;
-import com.crawljax.core.state.Element;
-import com.crawljax.core.state.Eventable;
-
-import org.apache.log4j.Logger;
-import org.w3c.dom.Document;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-import org.xml.sax.SAXException;
-
-import java.io.IOException;
-
-import javax.xml.xpath.XPathExpressionException;
-
-/**
- * class for finding and checking elements.
- * 
- * @author danny
- * @version $Id$
- */
-public class ElementResolver {
-	private static final Logger LOGGER = Logger.getLogger(ElementResolver.class.getName());
-
-	// private ElementResolverSettings settings = new
-	// ElementResolverSettings();
-
-	private final EmbeddedBrowser browser;
-	private final Eventable eventable;
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param eventable
-	 *            Eventable.
-	 * @param browser
-	 *            The browser.
-	 */
-	public ElementResolver(Eventable eventable, EmbeddedBrowser browser) {
-		this.browser = browser;
-		this.eventable = eventable;
-	}
-
-	/**
-	 * @return equivalent xpath of element equivalent to Eventable
-	 */
-	public String resolve() {
-		return resolve(false);
-	}
-
-	/**
-	 * @param logging
-	 *            Whether to do logging.
-	 * @return equivalent xpath of element equivalent to Eventable
-	 */
-	public String resolve(boolean logging) {
-		Document dom = null;
-		try {
-	        dom = Helper.getDocument(browser.getDom());
-		} catch (SAXException e) {
-			LOGGER.error(e.getMessage(), e);
-			return """";
-		} catch (IOException e) {
-			LOGGER.error(e.getMessage(), e);
-			return """";
-		}
-		
-		try {
-			String xpathEventable = eventable.getIdentification().getValue();
-			Node nodeSameXpath = Helper.getElementByXpath(dom, xpathEventable);
-			if (nodeSameXpath != null) {
-				Element elementSameXpath = new Element(nodeSameXpath);
-				if (logging) {
-					LOGGER.info(""Try element with same xpath expression"");
-				}
-				if (equivalent(elementSameXpath, logging)) {
-					return xpathEventable;
-				}
-			}
-
-			if (logging) {
-				LOGGER.info(""Search other candidate elements"");
-			}
-			NodeList candidateElements =
-			        XPathHelper.evaluateXpathExpression(dom, ""//""
-			                + eventable.getElement().getTag().toUpperCase());
-			if (logging) {
-				LOGGER.info(""Candidates: "" + candidateElements.getLength());
-			}
-			for (int i = 0; i < candidateElements.getLength(); i++) {
-				Element candidateElement = new Element(candidateElements.item(i));
-				if (equivalent(candidateElement, logging)) {
-					return XPathHelper.getXPathExpression(candidateElements.item(i));
-				}
-			}
-
-		} catch (XPathExpressionException e) {
-			LOGGER.error(e.getMessage(), e);
-		}
-		if (logging) {
-			LOGGER.info(""No equivalent element found"");
-		}
-		return null;
-	}
-
-	/**
-	 * Comparator against other element.
-	 * 
-	 * @param otherElement
-	 *            The other element.
-	 * @param logging
-	 *            Whether to do logging.
-	 * @return Whether the elements are equal.
-	 */
-	public boolean equivalent(Element otherElement, boolean logging) {
-		if (eventable.getElement().equals(otherElement)) {
-			if (logging) {
-				LOGGER.info(""Element equal"");
-			}
-			return true;
-		}
-
-		if (eventable.getElement().equalAttributes(otherElement)) {
-			if (logging) {
-				LOGGER.info(""Element attributes equal"");
-			}
-			return true;
-		}
-
-		if (eventable.getElement().equalId(otherElement)) {
-			if (logging) {
-				LOGGER.info(""Element ID equal"");
-			}
-			return true;
-		}
-
-		if (!eventable.getElement().getText().equals("""")
-		        && eventable.getElement().equalText(otherElement)) {
-
-			if (logging) {
-				LOGGER.info(""Element text equal"");
-			}
-
-			return true;
-		}
-
-		return false;
-	}
-
-}
+package com.crawljax.util;
+
+import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.core.state.Element;
+import com.crawljax.core.state.Eventable;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.w3c.dom.Document;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+import org.xml.sax.SAXException;
+
+import java.io.IOException;
+
+import javax.xml.xpath.XPathExpressionException;
+
+/**
+ * class for finding and checking elements.
+ * 
+ * @author danny
+ * @version $Id$
+ */
+public class ElementResolver {
+	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class.getName());
+
+	// private ElementResolverSettings settings = new
+	// ElementResolverSettings();
+
+	private final EmbeddedBrowser browser;
+	private final Eventable eventable;
+
+	/**
+	 * Constructor.
+	 * 
+	 * @param eventable
+	 *            Eventable.
+	 * @param browser
+	 *            The browser.
+	 */
+	public ElementResolver(Eventable eventable, EmbeddedBrowser browser) {
+		this.browser = browser;
+		this.eventable = eventable;
+	}
+
+	/**
+	 * @return equivalent xpath of element equivalent to Eventable
+	 */
+	public String resolve() {
+		return resolve(false);
+	}
+
+	/**
+	 * @param logging
+	 *            Whether to do logging.
+	 * @return equivalent xpath of element equivalent to Eventable
+	 */
+	public String resolve(boolean logging) {
+		Document dom = null;
+		try {
+	        dom = Helper.getDocument(browser.getDom());
+		} catch (SAXException e) {
+			LOGGER.error(e.getMessage(), e);
+			return """";
+		} catch (IOException e) {
+			LOGGER.error(e.getMessage(), e);
+			return """";
+		}
+		
+		try {
+			String xpathEventable = eventable.getIdentification().getValue();
+			Node nodeSameXpath = Helper.getElementByXpath(dom, xpathEventable);
+			if (nodeSameXpath != null) {
+				Element elementSameXpath = new Element(nodeSameXpath);
+				if (logging) {
+					LOGGER.info(""Try element with same xpath expression"");
+				}
+				if (equivalent(elementSameXpath, logging)) {
+					return xpathEventable;
+				}
+			}
+
+			if (logging) {
+				LOGGER.info(""Search other candidate elements"");
+			}
+			NodeList candidateElements =
+			        XPathHelper.evaluateXpathExpression(dom, ""//""
+			                + eventable.getElement().getTag().toUpperCase());
+			if (logging) {
+				LOGGER.info(""Candidates: "" + candidateElements.getLength());
+			}
+			for (int i = 0; i < candidateElements.getLength(); i++) {
+				Element candidateElement = new Element(candidateElements.item(i));
+				if (equivalent(candidateElement, logging)) {
+					return XPathHelper.getXPathExpression(candidateElements.item(i));
+				}
+			}
+
+		} catch (XPathExpressionException e) {
+			LOGGER.error(e.getMessage(), e);
+		}
+		if (logging) {
+			LOGGER.info(""No equivalent element found"");
+		}
+		return null;
+	}
+
+	/**
+	 * Comparator against other element.
+	 * 
+	 * @param otherElement
+	 *            The other element.
+	 * @param logging
+	 *            Whether to do logging.
+	 * @return Whether the elements are equal.
+	 */
+	public boolean equivalent(Element otherElement, boolean logging) {
+		if (eventable.getElement().equals(otherElement)) {
+			if (logging) {
+				LOGGER.info(""Element equal"");
+			}
+			return true;
+		}
+
+		if (eventable.getElement().equalAttributes(otherElement)) {
+			if (logging) {
+				LOGGER.info(""Element attributes equal"");
+			}
+			return true;
+		}
+
+		if (eventable.getElement().equalId(otherElement)) {
+			if (logging) {
+				LOGGER.info(""Element ID equal"");
+			}
+			return true;
+		}
+
+		if (!eventable.getElement().getText().equals("""")
+		        && eventable.getElement().equalText(otherElement)) {
+
+			if (logging) {
+				LOGGER.info(""Element text equal"");
+			}
+
+			return true;
+		}
+
+		return false;
+	}
+
+}
"
0e381f2707fe54ee5047acd676f876998d6fa0f1,Alex Nederlof,Helper.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/src/main/java/com/crawljax/util/Helper.java b/src/main/java/com/crawljax/util/Helper.java
index 16e21e5..e4815b8 100644
--- a/src/main/java/com/crawljax/util/Helper.java
+++ b/src/main/java/com/crawljax/util/Helper.java
@@ -1,797 +1,798 @@
-package com.crawljax.util;
-
-import java.io.BufferedReader;
-import java.io.ByteArrayOutputStream;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.FileOutputStream;
-import java.io.FileReader;
-import java.io.FileWriter;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.InputStreamReader;
-import java.io.StringReader;
-import java.io.StringWriter;
-import java.net.MalformedURLException;
-import java.net.URL;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-import java.util.regex.PatternSyntaxException;
-
-import javax.xml.transform.OutputKeys;
-import javax.xml.transform.Result;
-import javax.xml.transform.Source;
-import javax.xml.transform.Transformer;
-import javax.xml.transform.TransformerConfigurationException;
-import javax.xml.transform.TransformerException;
-import javax.xml.transform.TransformerFactory;
-import javax.xml.transform.dom.DOMSource;
-import javax.xml.transform.stream.StreamResult;
-import javax.xml.xpath.XPath;
-import javax.xml.xpath.XPathConstants;
-import javax.xml.xpath.XPathExpressionException;
-import javax.xml.xpath.XPathFactory;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.log4j.Logger;
-import org.custommonkey.xmlunit.DetailedDiff;
-import org.custommonkey.xmlunit.Diff;
-import org.custommonkey.xmlunit.Difference;
-import org.custommonkey.xmlunit.DifferenceListener;
-import org.cyberneko.html.parsers.DOMParser;
-import org.w3c.dom.Attr;
-import org.w3c.dom.Document;
-import org.w3c.dom.Element;
-import org.w3c.dom.NamedNodeMap;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-import org.xml.sax.InputSource;
-import org.xml.sax.SAXException;
-
-import com.google.common.collect.Lists;
-
-/**
- * Utility class that contains a number of helper functions used by Crawljax and some plugins.
- * 
- * @author mesbah
- * @version $Id$
- */
-public final class Helper {
-
-	private static final int BASE_LENGTH = 3;
-
-	private static final int TEXT_CUTOFF = 50;
-
-	public static final Logger LOGGER = Logger.getLogger(Helper.class.getName());
-
-	private Helper() {
-	}
-
-	/**
-	 * Internal used function to strip the basePath from a given url.
-	 * 
-	 * @param url
-	 *            the url to examine
-	 * @return the base path with file stipped
-	 */
-	private static String getBasePath(URL url) {
-		String file = url.getFile().replaceAll(""\\*"", """");
-
-		try {
-			return url.getPath().replaceAll(file, """");
-		} catch (PatternSyntaxException pe) {
-			LOGGER.error(pe.getMessage());
-			return """";
-		}
-
-	}
-
-	/**
-	 * @param location
-	 *            Current location.
-	 * @param link
-	 *            Link to check.
-	 * @return Whether location and link are on the same domain.
-	 */
-	public static boolean isLinkExternal(String location, String link) {
-
-		if (!location.contains(""://"")) {
-			// location must always contain :// by rule, it not link is handled as not external
-			return false;
-		}
-
-		// This will jump out of the local file location
-		if (location.startsWith(""file"") && link.startsWith(""/"")) {
-			return true;
-		}
-
-		if (link.contains(""://"")) {
-			if (location.startsWith(""file"") && link.startsWith(""http"") || link.startsWith(""file"")
-			        && location.startsWith(""http"")) {
-				// Jump from file to http(s) or from http(s) to file, so external
-				return true;
-			}
-			try {
-				URL locationUrl = new URL(location);
-				try {
-					URL linkUrl = new URL(link);
-					if (linkUrl.getHost().equals(locationUrl.getHost())) {
-						String linkPath = getBasePath(linkUrl);
-						return !(linkPath.startsWith(getBasePath(locationUrl)));
-					}
-					return true;
-				} catch (MalformedURLException e) {
-					LOGGER.info(""Can not parse link "" + link + "" to check its externalOf ""
-					        + location);
-					return false;
-				}
-			} catch (MalformedURLException e) {
-				LOGGER.info(""Can not parse location "" + location + "" to check if "" + link
-				        + "" isExternal"", e);
-				return false;
-			}
-		} else {
-			// No full url specifier so internal link...
-			return false;
-		}
-	}
-
-	/**
-	 * @param url
-	 *            the URL string.
-	 * @return the base part of the URL.
-	 */
-	public static String getBaseUrl(String url) {
-		String head = url.substring(0, url.indexOf("":""));
-		String subLoc = url.substring(head.length() + BASE_LENGTH);
-		return head + ""://"" + subLoc.substring(0, subLoc.indexOf(""/""));
-	}
-
-	/**
-	 * transforms a string into a Document object. TODO This needs more optimizations. As it seems
-	 * the getDocument is called way too much times causing a lot of parsing which is slow and not
-	 * necessary.
-	 * 
-	 * @param html
-	 *            the HTML string.
-	 * @return The DOM Document version of the HTML string.
-	 * @throws IOException
-	 *             if an IO failure occurs.
-	 * @throws SAXException
-	 *             if an exception occurs while parsing the HTML string.
-	 */
-	public static Document getDocument(String html) throws SAXException, IOException {
-		DOMParser domParser = new DOMParser();
-		domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
-		domParser.setFeature(""http://xml.org/sax/features/namespaces"", false);
-		domParser.parse(new InputSource(new StringReader(html)));
-		return domParser.getDocument();
-	}
-
-	/**
-	 * @param html
-	 *            the HTML string.
-	 * @return a Document object made from the HTML string.
-	 * @throws SAXException
-	 *             if an exception occurs while parsing the HTML string.
-	 * @throws IOException
-	 *             if an IO failure occurs.
-	 */
-	public static Document getDocumentNoBalance(String html) throws SAXException, IOException {
-		DOMParser domParser = new DOMParser();
-		domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
-		domParser.setFeature(""http://cyberneko.org/html/features/balance-tags"", false);
-		domParser.parse(new InputSource(new StringReader(html)));
-		return domParser.getDocument();
-	}
-
-	/**
-	 * @param element
-	 *            The DOM Element.
-	 * @return A string representation of all the element's attributes.
-	 */
-	public static String getAllElementAttributes(Element element) {
-		return getElementAttributes(element, new ArrayList<String>());
-	}
-
-	/**
-	 * @param element
-	 *            The DOM Element.
-	 * @param exclude
-	 *            the list of exclude strings.
-	 * @return A string representation of the element's attributes excluding exclude.
-	 */
-	public static String getElementAttributes(Element element, List<String> exclude) {
-		StringBuffer buffer = new StringBuffer();
-
-		if (element != null) {
-			NamedNodeMap attributes = element.getAttributes();
-			if (attributes != null) {
-				for (int i = 0; i < attributes.getLength(); i++) {
-					Attr attr = (Attr) attributes.item(i);
-					if (!exclude.contains(attr.getNodeName())) {
-						buffer.append(attr.getNodeName() + ""="");
-						buffer.append(attr.getNodeValue() + "" "");
-					}
-				}
-			}
-		}
-
-		return buffer.toString().trim();
-	}
-
-	/**
-	 * @param element
-	 *            the element.
-	 * @return a string representation of the element including its attributes.
-	 */
-	public static String getElementString(Element element) {
-		if (element == null) {
-			return """";
-		}
-		String text = Helper.removeNewLines(Helper.getTextValue(element)).trim();
-		String info = """";
-		if (!text.equals("""")) {
-			info += ""\"""" + text + ""\"" "";
-			// Helper.removeNewLines(this.text.trim()) + "" - "";
-		}
-		if (element != null) {
-			if (element.hasAttribute(""id"")) {
-				info += ""ID: "" + element.getAttribute(""id"") + "" "";
-			}
-			info += Helper.getAllElementAttributes(element) + "" "";
-		}
-		return info;
-	}
-
-	/**
-	 * @param dom
-	 *            the DOM document.
-	 * @param xpath
-	 *            the xpath.
-	 * @return The element found on DOM having the xpath position.
-	 * @throws XPathExpressionException
-	 *             if the xpath fails.
-	 */
-	public static Element getElementByXpath(Document dom, String xpath)
-	        throws XPathExpressionException {
-		XPath xp = XPathFactory.newInstance().newXPath();
-		xp.setNamespaceContext(new HtmlNamespace());
-
-		return (Element) xp.evaluate(xpath, dom, XPathConstants.NODE);
-	}
-
-	/**
-	 * Removes all the <SCRIPT/> tags from the document.
-	 * 
-	 * @param dom
-	 *            the document object.
-	 * @return the changed dom.
-	 */
-	public static Document removeScriptTags(Document dom) {
-		return removeTags(dom, ""SCRIPT"");
-	}
-
-	/**
-	 * Removes all the given tags from the document.
-	 * 
-	 * @param dom
-	 *            the document object.
-	 * @param tagName
-	 *            the tag name, examples: script, style, meta
-	 * @return the changed dom.
-	 */
-	public static Document removeTags(Document dom, String tagName) {
-		if (dom != null) {
-			// NodeList list = dom.getElementsByTagName(""SCRIPT"");
-
-			NodeList list;
-			try {
-				list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
-
-				while (list.getLength() > 0) {
-					Node sc = list.item(0);
-
-					if (sc != null) {
-						sc.getParentNode().removeChild(sc);
-					}
-
-					list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
-					// list = dom.getElementsByTagName(""SCRIPT"");
-				}
-			} catch (XPathExpressionException e) {
-				LOGGER.error(e.getMessage(), e);
-			}
-
-			return dom;
-		}
-
-		return null;
-	}
-
-	/**
-	 * Checks the existence of the directory. If it does not exist, the method creates it.
-	 * 
-	 * @param dir
-	 *            the directory to check.
-	 * @throws IOException
-	 *             if fails.
-	 */
-	public static void directoryCheck(String dir) throws IOException {
-		final File file = new File(dir);
-
-		if (!file.exists()) {
-			FileUtils.forceMkdir(file);
-		}
-	}
-
-	/**
-	 * Checks whether the folder exists for fname, and creates it if neccessary.
-	 * 
-	 * @param fname
-	 *            folder name.
-	 * @throws IOException
-	 *             an IO exception.
-	 */
-	public static void checkFolderForFile(String fname) throws IOException {
-
-		if (fname.lastIndexOf(File.separator) > 0) {
-			String folder = fname.substring(0, fname.lastIndexOf(File.separator));
-			Helper.directoryCheck(folder);
-		}
-	}
-
-	/**
-	 * Retrieve the var value for varName from a HTTP query string (format is
-	 * ""var1=val1&var2=val2"").
-	 * 
-	 * @param varName
-	 *            the name.
-	 * @param haystack
-	 *            the haystack.
-	 * @return variable value for varName
-	 */
-	public static String getVarFromQueryString(String varName, String haystack) {
-		if (haystack == null || haystack.length() == 0) {
-			return null;
-		}
-		if (haystack.charAt(0) == '?') {
-			haystack = haystack.substring(1);
-		}
-		String[] vars = haystack.split(""&"");
-
-		for (String var : vars) {
-			String[] tuple = var.split(""="");
-			if (tuple.length == 2 && tuple[0].equals(varName)) {
-				return tuple[1];
-			}
-		}
-		return null;
-	}
-
-	/**
-	 * @param dom
-	 *            the DOM document.
-	 * @return a string representation of the DOM.
-	 */
-	public static String getDocumentToString(Document dom) {
-		try {
-			Source source = new DOMSource(dom);
-			StringWriter stringWriter = new StringWriter();
-			Result result = new StreamResult(stringWriter);
-			TransformerFactory factory = TransformerFactory.newInstance();
-			Transformer transformer = factory.newTransformer();
-			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
-			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""yes"");
-			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
-			transformer.transform(source, result);
-			return stringWriter.getBuffer().toString();
-		} catch (TransformerConfigurationException e) {
-			LOGGER.error(e.getMessage(), e);
-		} catch (TransformerException e) {
-			LOGGER.error(e.getMessage(), e);
-		}
-		return null;
-
-	}
-
-	/**
-	 * Serialize the Document object.
-	 * 
-	 * @param dom
-	 *            the document to serialize
-	 * @return the serialized dom String
-	 */
-	public static byte[] getDocumentToByteArray(Document dom) {
-		try {
-			TransformerFactory tFactory = TransformerFactory.newInstance();
-
-			Transformer transformer = tFactory.newTransformer();
-			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
-			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
-			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
-			// TODO should be fixed to read doctype declaration
-			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			// ""-//W3C//DTD XHTML 1.0 Transitional//EN\""
-			// \""http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"");
-			transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			        ""-//W3C//DTD XHTML 1.0 Strict//EN\"" ""
-			                + ""\""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"");
-
-			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			// ""-//W3C//DTD HTML 4.01//EN\"" \""http://www.w3.org/TR/html4/strict.dtd"");
-			DOMSource source = new DOMSource(dom);
-
-			ByteArrayOutputStream out = new ByteArrayOutputStream();
-			Result result = new StreamResult(out);
-			transformer.transform(source, result);
-
-			// System.out.println(""Injected Javascript!"");
-			return out.toByteArray();
-		} catch (TransformerConfigurationException e) {
-			LOGGER.error(e.getMessage(), e);
-		} catch (TransformerException e) {
-			LOGGER.error(e.getMessage(), e);
-		}
-		return null;
-
-	}
-
-	/**
-	 * Save a string to a file and append a newline character to that string.
-	 * 
-	 * @param filename
-	 *            The filename to save to.
-	 * @param text
-	 *            The text to save.
-	 * @param append
-	 *            Whether to append to existing file.
-	 * @throws IOException
-	 *             On error.
-	 */
-	public static void writeToFile(String filename, String text, boolean append)
-	        throws IOException {
-		FileWriter fw = new FileWriter(filename, append);
-		try {
-			fw.write(text + ""\n"");
-		} catch (IOException e) {
-			throw e;
-		} finally {
-			fw.close();
-		}
-	}
-
-	/**
-	 * @param code
-	 *            hashcode.
-	 * @return String version of hashcode.
-	 */
-	public static String hashCodeToString(long code) {
-		if (code < 0) {
-			return ""0"" + (code * -1);
-		} else {
-			return """" + code;
-		}
-	}
-
-	/**
-	 * Returns the text value of an element (title, alt or contents). Note that the result is 50
-	 * characters or less in length.
-	 * 
-	 * @param element
-	 *            The element.
-	 * @return The text value of the element.
-	 */
-	public static String getTextValue(Element element) {
-		String ret = """";
-		if (element == null) {
-			return """";
-		}
-
-		if (element.getTextContent() != null) {
-			ret = element.getTextContent();
-		} else if (element.hasAttribute(""title"")) {
-			ret = element.getAttribute(""title"");
-		} else if (element.hasAttribute(""alt"")) {
-			ret = element.getAttribute(""alt"");
-		}
-		if (ret.length() > TEXT_CUTOFF) {
-			return ret.substring(0, TEXT_CUTOFF);
-		} else {
-			return ret;
-		}
-	}
-
-	/**
-	 * Get differences between doms.
-	 * 
-	 * @param controlDom
-	 *            The control dom.
-	 * @param testDom
-	 *            The test dom.
-	 * @return The differences.
-	 */
-	public static List<Difference> getDifferences(String controlDom, String testDom) {
-		return getDifferences(controlDom, testDom, Lists.<String> newArrayList());
-	}
-
-	/**
-	 * Get differences between doms.
-	 * 
-	 * @param controlDom
-	 *            The control dom.
-	 * @param testDom
-	 *            The test dom.
-	 * @param ignoreAttributes
-	 *            The list of attributes to ignore.
-	 * @return The differences.
-	 */
-	@SuppressWarnings(""unchecked"")
-	public static List<Difference> getDifferences(String controlDom, String testDom,
-	        final List<String> ignoreAttributes) {
-		try {
-			Diff d = new Diff(Helper.getDocument(controlDom), Helper.getDocument(testDom));
-			DetailedDiff dd = new DetailedDiff(d);
-			dd.overrideDifferenceListener(new DifferenceListener() {
-
-				@Override
-				public void skippedComparison(Node control, Node test) {
-				}
-
-				@Override
-				public int differenceFound(Difference difference) {
-					if (difference.getControlNodeDetail() == null
-					        || difference.getControlNodeDetail().getNode() == null
-					        || difference.getTestNodeDetail() == null
-					        || difference.getTestNodeDetail().getNode() == null) {
-						return RETURN_ACCEPT_DIFFERENCE;
-					}
-					if (ignoreAttributes.contains(difference.getTestNodeDetail().getNode()
-					        .getNodeName())
-					        || ignoreAttributes.contains(difference.getControlNodeDetail()
-					                .getNode().getNodeName())) {
-						return RETURN_IGNORE_DIFFERENCE_NODES_IDENTICAL;
-					}
-					return RETURN_ACCEPT_DIFFERENCE;
-				}
-			});
-
-			return dd.getAllDifferences();
-		} catch (Exception e) {
-			LOGGER.error(""Error with getDifferences: "" + e.getMessage(), e);
-		}
-		return null;
-	}
-
-	/**
-	 * Removes newlines from a string.
-	 * 
-	 * @param html
-	 *            The string.
-	 * @return The new string without the newlines or tabs.
-	 */
-	public static String removeNewLines(String html) {
-		return html.replaceAll(""[\\t\\n\\x0B\\f\\r]"", """");
-	}
-
-	/**
-	 * @param string
-	 *            The original string.
-	 * @param regex
-	 *            The regular expression.
-	 * @param replace
-	 *            What to replace it with.
-	 * @return replaces regex in str by replace where the dot sign also supports newlines
-	 */
-	public static String replaceString(String string, String regex, String replace) {
-		Pattern p = Pattern.compile(regex, Pattern.DOTALL);
-		Matcher m = p.matcher(string);
-		String replaced = m.replaceAll(replace);
-		p = Pattern.compile(""  "", Pattern.DOTALL);
-		m = p.matcher(replaced);
-		return m.replaceAll("" "");
-	}
-
-	/**
-	 * Adds a slash to a path if it doesn't end with a slash.
-	 * 
-	 * @param folderName
-	 *            The path to append a possible slash.
-	 * @return The new, correct path.
-	 */
-	public static String addFolderSlashIfNeeded(String folderName) {
-		if (!folderName.equals("""") && !folderName.endsWith(""/"")) {
-			return folderName + ""/"";
-		} else {
-			return folderName;
-		}
-	}
-
-	/**
-	 * Returns the filename in a path. For example with path = ""foo/bar/crawljax.txt"" returns
-	 * ""crawljax.txt""
-	 * 
-	 * @param path
-	 * @return the filename from the path
-	 */
-	private static String getFileNameInPath(String path) {
-		String fname;
-		if (path.indexOf(""/"") != -1) {
-			fname = path.substring(path.lastIndexOf(""/"") + 1);
-		} else {
-			fname = path;
-		}
-		return fname;
-	}
-
-	/**
-	 * Retrieves the content of the filename. Also reads from JAR Searches for the resource in the
-	 * root folder in the jar
-	 * 
-	 * @param fname
-	 *            Filename.
-	 * @return The contents of the file.
-	 * @throws IOException
-	 *             On error.
-	 */
-	public static String getTemplateAsString(String fname) throws IOException {
-		// in .jar file
-		String fnameJar = getFileNameInPath(fname);
-		InputStream inStream = Helper.class.getResourceAsStream(""/"" + fnameJar);
-		if (inStream == null) {
-			// try to find file normally
-			File f = new File(fname);
-			if (f.exists()) {
-				inStream = new FileInputStream(f);
-			} else {
-				throw new IOException(""Cannot find "" + fname + "" or "" + fnameJar);
-			}
-		}
-
-		BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inStream));
-		String line;
-		StringBuilder stringBuilder = new StringBuilder();
-
-		while ((line = bufferedReader.readLine()) != null) {
-			stringBuilder.append(line + ""\n"");
-		}
-
-		bufferedReader.close();
-		return stringBuilder.toString();
-	}
-
-	/**
-	 * @param xpath
-	 *            The xpath of the element.
-	 * @return The JavaScript to get an element.
-	 */
-	public static String getJSGetElement(String xpath) {
-		String js =
-		        """"
-		                + ""function ATUSA_getElementInNodes(nodes, tagName, number){""
-		                + ""try{""
-		                + ""var pos = 1;""
-		                + ""for(i=0; i<nodes.length; i++){""
-		                + ""if(nodes[i]!=null && nodes[i].tagName!=null && ""
-		                + ""nodes[i].tagName.toLowerCase() == tagName){""
-		                + ""if(number==pos){""
-		                + ""return nodes[i];""
-		                + ""}else{""
-		                + ""pos++;""
-		                + ""}""
-		                + ""}""
-		                + ""}""
-		                + ""}catch(e){}""
-		                + ""return null;""
-		                + ""}""
-		                + ""function ATUSA_getElementByXpath(xpath){""
-		                + ""try{""
-		                + ""var elements = xpath.toLowerCase().split('/');""
-		                + ""var curNode = window.document.body;""
-		                + ""var tagName, number;""
-		                + ""for(j=0; j<elements.length; j++){""
-		                + ""if(elements[j]!=''){""
-		                + ""if(elements[j].indexOf('[')==-1){""
-		                + ""tagName = elements[j];""
-		                + ""number = 1;""
-		                + ""}else{""
-		                + ""tagName = elements[j].substring(0, elements[j].indexOf('['));""
-		                + ""number = elements[j].substring(elements[j].indexOf('[')+1, ""
-		                + ""elements[j].lastIndexOf(']'));""
-		                + ""}""
-		                + ""if(tagName!='body' && tagName!='html'){""
-		                + ""curNode = ATUSA_getElementInNodes(curNode.childNodes, tagName, number);""
-		                + ""if(curNode==null){"" + ""return null;"" + ""}"" + ""}"" + ""}"" + ""}""
-		                + ""}catch(e){return null;}"" + ""return curNode;"" + ""}""
-		                + ""try{var ATUSA_element = ATUSA_getElementByXpath('"" + xpath
-		                + ""');}catch(e){return null;}"";
-
-		return js;
-	}
-
-	/**
-	 * @param frame
-	 *            the frame element.
-	 * @return the name or id of this element if they are present, otherwise null.
-	 */
-	public static String getFrameIdentification(Element frame) {
-
-		Attr attr = frame.getAttributeNode(""id"");
-		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
-			return attr.getNodeValue();
-		}
-
-		attr = frame.getAttributeNode(""name"");
-		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
-			return attr.getNodeValue();
-		}
-
-		return null;
-
-	}
-
-	/**
-	 * Write the document object to a file.
-	 * 
-	 * @param document
-	 *            the document object.
-	 * @param filePathname
-	 *            the path name of the file to be written to.
-	 * @param method
-	 *            the output method: for instance html, xml, text
-	 * @param indent
-	 *            amount of indentation. -1 to use the default.
-	 * @throws TransformerException
-	 *             if an exception occurs.
-	 * @throws IOException
-	 *             if an IO exception occurs.
-	 */
-	public static void writeDocumentToFile(Document document, String filePathname, String method,
-	        int indent) throws TransformerException, IOException {
-
-		checkFolderForFile(filePathname);
-		Transformer transformer = TransformerFactory.newInstance().newTransformer();
-		transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
-		transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
-		transformer.setOutputProperty(OutputKeys.METHOD, method);
-
-		if (indent > -1) {
-			transformer.setOutputProperty(
-			        org.apache.xml.serializer.OutputPropertiesFactory.S_KEY_INDENT_AMOUNT,
-			        Integer.toString(indent));
-		}
-		transformer.transform(new DOMSource(document), new StreamResult(new FileOutputStream(
-		        filePathname)));
-	}
-
-	/**
-	 * Returns the file contents without stripping line-endings.
-	 * 
-	 * @param file
-	 *            File to read out.
-	 * @return Contents including line-endings.
-	 */
-	public static String getContent(File file) {
-		StringBuilder contents = new StringBuilder();
-
-		try {
-			BufferedReader input = new BufferedReader(new FileReader(file));
-			try {
-				String line = null; // not declared within while loop
-				while ((line = input.readLine()) != null) {
-					contents.append(line);
-					contents.append(""\n"");
-				}
-			} finally {
-				input.close();
-			}
-		} catch (IOException e) {
-			e.printStackTrace();
-		}
-
-		return contents.toString();
-	}
-
-}
+package com.crawljax.util;
+
+import java.io.BufferedReader;
+import java.io.ByteArrayOutputStream;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.FileReader;
+import java.io.FileWriter;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.io.StringReader;
+import java.io.StringWriter;
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.regex.PatternSyntaxException;
+
+import javax.xml.transform.OutputKeys;
+import javax.xml.transform.Result;
+import javax.xml.transform.Source;
+import javax.xml.transform.Transformer;
+import javax.xml.transform.TransformerConfigurationException;
+import javax.xml.transform.TransformerException;
+import javax.xml.transform.TransformerFactory;
+import javax.xml.transform.dom.DOMSource;
+import javax.xml.transform.stream.StreamResult;
+import javax.xml.xpath.XPath;
+import javax.xml.xpath.XPathConstants;
+import javax.xml.xpath.XPathExpressionException;
+import javax.xml.xpath.XPathFactory;
+
+import org.apache.commons.io.FileUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.custommonkey.xmlunit.DetailedDiff;
+import org.custommonkey.xmlunit.Diff;
+import org.custommonkey.xmlunit.Difference;
+import org.custommonkey.xmlunit.DifferenceListener;
+import org.cyberneko.html.parsers.DOMParser;
+import org.w3c.dom.Attr;
+import org.w3c.dom.Document;
+import org.w3c.dom.Element;
+import org.w3c.dom.NamedNodeMap;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+import org.xml.sax.InputSource;
+import org.xml.sax.SAXException;
+
+import com.google.common.collect.Lists;
+
+/**
+ * Utility class that contains a number of helper functions used by Crawljax and some plugins.
+ * 
+ * @author mesbah
+ * @version $Id$
+ */
+public final class Helper {
+
+	private static final int BASE_LENGTH = 3;
+
+	private static final int TEXT_CUTOFF = 50;
+
+	public static final Logger LOGGER = LoggerFactory.getLogger(Helper.class.getName());
+
+	private Helper() {
+	}
+
+	/**
+	 * Internal used function to strip the basePath from a given url.
+	 * 
+	 * @param url
+	 *            the url to examine
+	 * @return the base path with file stipped
+	 */
+	private static String getBasePath(URL url) {
+		String file = url.getFile().replaceAll(""\\*"", """");
+
+		try {
+			return url.getPath().replaceAll(file, """");
+		} catch (PatternSyntaxException pe) {
+			LOGGER.error(pe.getMessage());
+			return """";
+		}
+
+	}
+
+	/**
+	 * @param location
+	 *            Current location.
+	 * @param link
+	 *            Link to check.
+	 * @return Whether location and link are on the same domain.
+	 */
+	public static boolean isLinkExternal(String location, String link) {
+
+		if (!location.contains(""://"")) {
+			// location must always contain :// by rule, it not link is handled as not external
+			return false;
+		}
+
+		// This will jump out of the local file location
+		if (location.startsWith(""file"") && link.startsWith(""/"")) {
+			return true;
+		}
+
+		if (link.contains(""://"")) {
+			if (location.startsWith(""file"") && link.startsWith(""http"") || link.startsWith(""file"")
+			        && location.startsWith(""http"")) {
+				// Jump from file to http(s) or from http(s) to file, so external
+				return true;
+			}
+			try {
+				URL locationUrl = new URL(location);
+				try {
+					URL linkUrl = new URL(link);
+					if (linkUrl.getHost().equals(locationUrl.getHost())) {
+						String linkPath = getBasePath(linkUrl);
+						return !(linkPath.startsWith(getBasePath(locationUrl)));
+					}
+					return true;
+				} catch (MalformedURLException e) {
+					LOGGER.info(""Can not parse link "" + link + "" to check its externalOf ""
+					        + location);
+					return false;
+				}
+			} catch (MalformedURLException e) {
+				LOGGER.info(""Can not parse location "" + location + "" to check if "" + link
+				        + "" isExternal"", e);
+				return false;
+			}
+		} else {
+			// No full url specifier so internal link...
+			return false;
+		}
+	}
+
+	/**
+	 * @param url
+	 *            the URL string.
+	 * @return the base part of the URL.
+	 */
+	public static String getBaseUrl(String url) {
+		String head = url.substring(0, url.indexOf("":""));
+		String subLoc = url.substring(head.length() + BASE_LENGTH);
+		return head + ""://"" + subLoc.substring(0, subLoc.indexOf(""/""));
+	}
+
+	/**
+	 * transforms a string into a Document object. TODO This needs more optimizations. As it seems
+	 * the getDocument is called way too much times causing a lot of parsing which is slow and not
+	 * necessary.
+	 * 
+	 * @param html
+	 *            the HTML string.
+	 * @return The DOM Document version of the HTML string.
+	 * @throws IOException
+	 *             if an IO failure occurs.
+	 * @throws SAXException
+	 *             if an exception occurs while parsing the HTML string.
+	 */
+	public static Document getDocument(String html) throws SAXException, IOException {
+		DOMParser domParser = new DOMParser();
+		domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
+		domParser.setFeature(""http://xml.org/sax/features/namespaces"", false);
+		domParser.parse(new InputSource(new StringReader(html)));
+		return domParser.getDocument();
+	}
+
+	/**
+	 * @param html
+	 *            the HTML string.
+	 * @return a Document object made from the HTML string.
+	 * @throws SAXException
+	 *             if an exception occurs while parsing the HTML string.
+	 * @throws IOException
+	 *             if an IO failure occurs.
+	 */
+	public static Document getDocumentNoBalance(String html) throws SAXException, IOException {
+		DOMParser domParser = new DOMParser();
+		domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
+		domParser.setFeature(""http://cyberneko.org/html/features/balance-tags"", false);
+		domParser.parse(new InputSource(new StringReader(html)));
+		return domParser.getDocument();
+	}
+
+	/**
+	 * @param element
+	 *            The DOM Element.
+	 * @return A string representation of all the element's attributes.
+	 */
+	public static String getAllElementAttributes(Element element) {
+		return getElementAttributes(element, new ArrayList<String>());
+	}
+
+	/**
+	 * @param element
+	 *            The DOM Element.
+	 * @param exclude
+	 *            the list of exclude strings.
+	 * @return A string representation of the element's attributes excluding exclude.
+	 */
+	public static String getElementAttributes(Element element, List<String> exclude) {
+		StringBuffer buffer = new StringBuffer();
+
+		if (element != null) {
+			NamedNodeMap attributes = element.getAttributes();
+			if (attributes != null) {
+				for (int i = 0; i < attributes.getLength(); i++) {
+					Attr attr = (Attr) attributes.item(i);
+					if (!exclude.contains(attr.getNodeName())) {
+						buffer.append(attr.getNodeName() + ""="");
+						buffer.append(attr.getNodeValue() + "" "");
+					}
+				}
+			}
+		}
+
+		return buffer.toString().trim();
+	}
+
+	/**
+	 * @param element
+	 *            the element.
+	 * @return a string representation of the element including its attributes.
+	 */
+	public static String getElementString(Element element) {
+		if (element == null) {
+			return """";
+		}
+		String text = Helper.removeNewLines(Helper.getTextValue(element)).trim();
+		String info = """";
+		if (!text.equals("""")) {
+			info += ""\"""" + text + ""\"" "";
+			// Helper.removeNewLines(this.text.trim()) + "" - "";
+		}
+		if (element != null) {
+			if (element.hasAttribute(""id"")) {
+				info += ""ID: "" + element.getAttribute(""id"") + "" "";
+			}
+			info += Helper.getAllElementAttributes(element) + "" "";
+		}
+		return info;
+	}
+
+	/**
+	 * @param dom
+	 *            the DOM document.
+	 * @param xpath
+	 *            the xpath.
+	 * @return The element found on DOM having the xpath position.
+	 * @throws XPathExpressionException
+	 *             if the xpath fails.
+	 */
+	public static Element getElementByXpath(Document dom, String xpath)
+	        throws XPathExpressionException {
+		XPath xp = XPathFactory.newInstance().newXPath();
+		xp.setNamespaceContext(new HtmlNamespace());
+
+		return (Element) xp.evaluate(xpath, dom, XPathConstants.NODE);
+	}
+
+	/**
+	 * Removes all the <SCRIPT/> tags from the document.
+	 * 
+	 * @param dom
+	 *            the document object.
+	 * @return the changed dom.
+	 */
+	public static Document removeScriptTags(Document dom) {
+		return removeTags(dom, ""SCRIPT"");
+	}
+
+	/**
+	 * Removes all the given tags from the document.
+	 * 
+	 * @param dom
+	 *            the document object.
+	 * @param tagName
+	 *            the tag name, examples: script, style, meta
+	 * @return the changed dom.
+	 */
+	public static Document removeTags(Document dom, String tagName) {
+		if (dom != null) {
+			// NodeList list = dom.getElementsByTagName(""SCRIPT"");
+
+			NodeList list;
+			try {
+				list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
+
+				while (list.getLength() > 0) {
+					Node sc = list.item(0);
+
+					if (sc != null) {
+						sc.getParentNode().removeChild(sc);
+					}
+
+					list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
+					// list = dom.getElementsByTagName(""SCRIPT"");
+				}
+			} catch (XPathExpressionException e) {
+				LOGGER.error(e.getMessage(), e);
+			}
+
+			return dom;
+		}
+
+		return null;
+	}
+
+	/**
+	 * Checks the existence of the directory. If it does not exist, the method creates it.
+	 * 
+	 * @param dir
+	 *            the directory to check.
+	 * @throws IOException
+	 *             if fails.
+	 */
+	public static void directoryCheck(String dir) throws IOException {
+		final File file = new File(dir);
+
+		if (!file.exists()) {
+			FileUtils.forceMkdir(file);
+		}
+	}
+
+	/**
+	 * Checks whether the folder exists for fname, and creates it if neccessary.
+	 * 
+	 * @param fname
+	 *            folder name.
+	 * @throws IOException
+	 *             an IO exception.
+	 */
+	public static void checkFolderForFile(String fname) throws IOException {
+
+		if (fname.lastIndexOf(File.separator) > 0) {
+			String folder = fname.substring(0, fname.lastIndexOf(File.separator));
+			Helper.directoryCheck(folder);
+		}
+	}
+
+	/**
+	 * Retrieve the var value for varName from a HTTP query string (format is
+	 * ""var1=val1&var2=val2"").
+	 * 
+	 * @param varName
+	 *            the name.
+	 * @param haystack
+	 *            the haystack.
+	 * @return variable value for varName
+	 */
+	public static String getVarFromQueryString(String varName, String haystack) {
+		if (haystack == null || haystack.length() == 0) {
+			return null;
+		}
+		if (haystack.charAt(0) == '?') {
+			haystack = haystack.substring(1);
+		}
+		String[] vars = haystack.split(""&"");
+
+		for (String var : vars) {
+			String[] tuple = var.split(""="");
+			if (tuple.length == 2 && tuple[0].equals(varName)) {
+				return tuple[1];
+			}
+		}
+		return null;
+	}
+
+	/**
+	 * @param dom
+	 *            the DOM document.
+	 * @return a string representation of the DOM.
+	 */
+	public static String getDocumentToString(Document dom) {
+		try {
+			Source source = new DOMSource(dom);
+			StringWriter stringWriter = new StringWriter();
+			Result result = new StreamResult(stringWriter);
+			TransformerFactory factory = TransformerFactory.newInstance();
+			Transformer transformer = factory.newTransformer();
+			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
+			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""yes"");
+			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
+			transformer.transform(source, result);
+			return stringWriter.getBuffer().toString();
+		} catch (TransformerConfigurationException e) {
+			LOGGER.error(e.getMessage(), e);
+		} catch (TransformerException e) {
+			LOGGER.error(e.getMessage(), e);
+		}
+		return null;
+
+	}
+
+	/**
+	 * Serialize the Document object.
+	 * 
+	 * @param dom
+	 *            the document to serialize
+	 * @return the serialized dom String
+	 */
+	public static byte[] getDocumentToByteArray(Document dom) {
+		try {
+			TransformerFactory tFactory = TransformerFactory.newInstance();
+
+			Transformer transformer = tFactory.newTransformer();
+			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
+			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
+			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
+			// TODO should be fixed to read doctype declaration
+			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
+			// ""-//W3C//DTD XHTML 1.0 Transitional//EN\""
+			// \""http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"");
+			transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
+			        ""-//W3C//DTD XHTML 1.0 Strict//EN\"" ""
+			                + ""\""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"");
+
+			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
+			// ""-//W3C//DTD HTML 4.01//EN\"" \""http://www.w3.org/TR/html4/strict.dtd"");
+			DOMSource source = new DOMSource(dom);
+
+			ByteArrayOutputStream out = new ByteArrayOutputStream();
+			Result result = new StreamResult(out);
+			transformer.transform(source, result);
+
+			// System.out.println(""Injected Javascript!"");
+			return out.toByteArray();
+		} catch (TransformerConfigurationException e) {
+			LOGGER.error(e.getMessage(), e);
+		} catch (TransformerException e) {
+			LOGGER.error(e.getMessage(), e);
+		}
+		return null;
+
+	}
+
+	/**
+	 * Save a string to a file and append a newline character to that string.
+	 * 
+	 * @param filename
+	 *            The filename to save to.
+	 * @param text
+	 *            The text to save.
+	 * @param append
+	 *            Whether to append to existing file.
+	 * @throws IOException
+	 *             On error.
+	 */
+	public static void writeToFile(String filename, String text, boolean append)
+	        throws IOException {
+		FileWriter fw = new FileWriter(filename, append);
+		try {
+			fw.write(text + ""\n"");
+		} catch (IOException e) {
+			throw e;
+		} finally {
+			fw.close();
+		}
+	}
+
+	/**
+	 * @param code
+	 *            hashcode.
+	 * @return String version of hashcode.
+	 */
+	public static String hashCodeToString(long code) {
+		if (code < 0) {
+			return ""0"" + (code * -1);
+		} else {
+			return """" + code;
+		}
+	}
+
+	/**
+	 * Returns the text value of an element (title, alt or contents). Note that the result is 50
+	 * characters or less in length.
+	 * 
+	 * @param element
+	 *            The element.
+	 * @return The text value of the element.
+	 */
+	public static String getTextValue(Element element) {
+		String ret = """";
+		if (element == null) {
+			return """";
+		}
+
+		if (element.getTextContent() != null) {
+			ret = element.getTextContent();
+		} else if (element.hasAttribute(""title"")) {
+			ret = element.getAttribute(""title"");
+		} else if (element.hasAttribute(""alt"")) {
+			ret = element.getAttribute(""alt"");
+		}
+		if (ret.length() > TEXT_CUTOFF) {
+			return ret.substring(0, TEXT_CUTOFF);
+		} else {
+			return ret;
+		}
+	}
+
+	/**
+	 * Get differences between doms.
+	 * 
+	 * @param controlDom
+	 *            The control dom.
+	 * @param testDom
+	 *            The test dom.
+	 * @return The differences.
+	 */
+	public static List<Difference> getDifferences(String controlDom, String testDom) {
+		return getDifferences(controlDom, testDom, Lists.<String> newArrayList());
+	}
+
+	/**
+	 * Get differences between doms.
+	 * 
+	 * @param controlDom
+	 *            The control dom.
+	 * @param testDom
+	 *            The test dom.
+	 * @param ignoreAttributes
+	 *            The list of attributes to ignore.
+	 * @return The differences.
+	 */
+	@SuppressWarnings(""unchecked"")
+	public static List<Difference> getDifferences(String controlDom, String testDom,
+	        final List<String> ignoreAttributes) {
+		try {
+			Diff d = new Diff(Helper.getDocument(controlDom), Helper.getDocument(testDom));
+			DetailedDiff dd = new DetailedDiff(d);
+			dd.overrideDifferenceListener(new DifferenceListener() {
+
+				@Override
+				public void skippedComparison(Node control, Node test) {
+				}
+
+				@Override
+				public int differenceFound(Difference difference) {
+					if (difference.getControlNodeDetail() == null
+					        || difference.getControlNodeDetail().getNode() == null
+					        || difference.getTestNodeDetail() == null
+					        || difference.getTestNodeDetail().getNode() == null) {
+						return RETURN_ACCEPT_DIFFERENCE;
+					}
+					if (ignoreAttributes.contains(difference.getTestNodeDetail().getNode()
+					        .getNodeName())
+					        || ignoreAttributes.contains(difference.getControlNodeDetail()
+					                .getNode().getNodeName())) {
+						return RETURN_IGNORE_DIFFERENCE_NODES_IDENTICAL;
+					}
+					return RETURN_ACCEPT_DIFFERENCE;
+				}
+			});
+
+			return dd.getAllDifferences();
+		} catch (Exception e) {
+			LOGGER.error(""Error with getDifferences: "" + e.getMessage(), e);
+		}
+		return null;
+	}
+
+	/**
+	 * Removes newlines from a string.
+	 * 
+	 * @param html
+	 *            The string.
+	 * @return The new string without the newlines or tabs.
+	 */
+	public static String removeNewLines(String html) {
+		return html.replaceAll(""[\\t\\n\\x0B\\f\\r]"", """");
+	}
+
+	/**
+	 * @param string
+	 *            The original string.
+	 * @param regex
+	 *            The regular expression.
+	 * @param replace
+	 *            What to replace it with.
+	 * @return replaces regex in str by replace where the dot sign also supports newlines
+	 */
+	public static String replaceString(String string, String regex, String replace) {
+		Pattern p = Pattern.compile(regex, Pattern.DOTALL);
+		Matcher m = p.matcher(string);
+		String replaced = m.replaceAll(replace);
+		p = Pattern.compile(""  "", Pattern.DOTALL);
+		m = p.matcher(replaced);
+		return m.replaceAll("" "");
+	}
+
+	/**
+	 * Adds a slash to a path if it doesn't end with a slash.
+	 * 
+	 * @param folderName
+	 *            The path to append a possible slash.
+	 * @return The new, correct path.
+	 */
+	public static String addFolderSlashIfNeeded(String folderName) {
+		if (!folderName.equals("""") && !folderName.endsWith(""/"")) {
+			return folderName + ""/"";
+		} else {
+			return folderName;
+		}
+	}
+
+	/**
+	 * Returns the filename in a path. For example with path = ""foo/bar/crawljax.txt"" returns
+	 * ""crawljax.txt""
+	 * 
+	 * @param path
+	 * @return the filename from the path
+	 */
+	private static String getFileNameInPath(String path) {
+		String fname;
+		if (path.indexOf(""/"") != -1) {
+			fname = path.substring(path.lastIndexOf(""/"") + 1);
+		} else {
+			fname = path;
+		}
+		return fname;
+	}
+
+	/**
+	 * Retrieves the content of the filename. Also reads from JAR Searches for the resource in the
+	 * root folder in the jar
+	 * 
+	 * @param fname
+	 *            Filename.
+	 * @return The contents of the file.
+	 * @throws IOException
+	 *             On error.
+	 */
+	public static String getTemplateAsString(String fname) throws IOException {
+		// in .jar file
+		String fnameJar = getFileNameInPath(fname);
+		InputStream inStream = Helper.class.getResourceAsStream(""/"" + fnameJar);
+		if (inStream == null) {
+			// try to find file normally
+			File f = new File(fname);
+			if (f.exists()) {
+				inStream = new FileInputStream(f);
+			} else {
+				throw new IOException(""Cannot find "" + fname + "" or "" + fnameJar);
+			}
+		}
+
+		BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inStream));
+		String line;
+		StringBuilder stringBuilder = new StringBuilder();
+
+		while ((line = bufferedReader.readLine()) != null) {
+			stringBuilder.append(line + ""\n"");
+		}
+
+		bufferedReader.close();
+		return stringBuilder.toString();
+	}
+
+	/**
+	 * @param xpath
+	 *            The xpath of the element.
+	 * @return The JavaScript to get an element.
+	 */
+	public static String getJSGetElement(String xpath) {
+		String js =
+		        """"
+		                + ""function ATUSA_getElementInNodes(nodes, tagName, number){""
+		                + ""try{""
+		                + ""var pos = 1;""
+		                + ""for(i=0; i<nodes.length; i++){""
+		                + ""if(nodes[i]!=null && nodes[i].tagName!=null && ""
+		                + ""nodes[i].tagName.toLowerCase() == tagName){""
+		                + ""if(number==pos){""
+		                + ""return nodes[i];""
+		                + ""}else{""
+		                + ""pos++;""
+		                + ""}""
+		                + ""}""
+		                + ""}""
+		                + ""}catch(e){}""
+		                + ""return null;""
+		                + ""}""
+		                + ""function ATUSA_getElementByXpath(xpath){""
+		                + ""try{""
+		                + ""var elements = xpath.toLowerCase().split('/');""
+		                + ""var curNode = window.document.body;""
+		                + ""var tagName, number;""
+		                + ""for(j=0; j<elements.length; j++){""
+		                + ""if(elements[j]!=''){""
+		                + ""if(elements[j].indexOf('[')==-1){""
+		                + ""tagName = elements[j];""
+		                + ""number = 1;""
+		                + ""}else{""
+		                + ""tagName = elements[j].substring(0, elements[j].indexOf('['));""
+		                + ""number = elements[j].substring(elements[j].indexOf('[')+1, ""
+		                + ""elements[j].lastIndexOf(']'));""
+		                + ""}""
+		                + ""if(tagName!='body' && tagName!='html'){""
+		                + ""curNode = ATUSA_getElementInNodes(curNode.childNodes, tagName, number);""
+		                + ""if(curNode==null){"" + ""return null;"" + ""}"" + ""}"" + ""}"" + ""}""
+		                + ""}catch(e){return null;}"" + ""return curNode;"" + ""}""
+		                + ""try{var ATUSA_element = ATUSA_getElementByXpath('"" + xpath
+		                + ""');}catch(e){return null;}"";
+
+		return js;
+	}
+
+	/**
+	 * @param frame
+	 *            the frame element.
+	 * @return the name or id of this element if they are present, otherwise null.
+	 */
+	public static String getFrameIdentification(Element frame) {
+
+		Attr attr = frame.getAttributeNode(""id"");
+		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
+			return attr.getNodeValue();
+		}
+
+		attr = frame.getAttributeNode(""name"");
+		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
+			return attr.getNodeValue();
+		}
+
+		return null;
+
+	}
+
+	/**
+	 * Write the document object to a file.
+	 * 
+	 * @param document
+	 *            the document object.
+	 * @param filePathname
+	 *            the path name of the file to be written to.
+	 * @param method
+	 *            the output method: for instance html, xml, text
+	 * @param indent
+	 *            amount of indentation. -1 to use the default.
+	 * @throws TransformerException
+	 *             if an exception occurs.
+	 * @throws IOException
+	 *             if an IO exception occurs.
+	 */
+	public static void writeDocumentToFile(Document document, String filePathname, String method,
+	        int indent) throws TransformerException, IOException {
+
+		checkFolderForFile(filePathname);
+		Transformer transformer = TransformerFactory.newInstance().newTransformer();
+		transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
+		transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
+		transformer.setOutputProperty(OutputKeys.METHOD, method);
+
+		if (indent > -1) {
+			transformer.setOutputProperty(
+			        org.apache.xml.serializer.OutputPropertiesFactory.S_KEY_INDENT_AMOUNT,
+			        Integer.toString(indent));
+		}
+		transformer.transform(new DOMSource(document), new StreamResult(new FileOutputStream(
+		        filePathname)));
+	}
+
+	/**
+	 * Returns the file contents without stripping line-endings.
+	 * 
+	 * @param file
+	 *            File to read out.
+	 * @return Contents including line-endings.
+	 */
+	public static String getContent(File file) {
+		StringBuilder contents = new StringBuilder();
+
+		try {
+			BufferedReader input = new BufferedReader(new FileReader(file));
+			try {
+				String line = null; // not declared within while loop
+				while ((line = input.readLine()) != null) {
+					contents.append(line);
+					contents.append(""\n"");
+				}
+			} finally {
+				input.close();
+			}
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+
+		return contents.toString();
+	}
+
+}
"
0e381f2707fe54ee5047acd676f876998d6fa0f1,Alex Nederlof,PrettyHTML.java,MODIFY,"prettyHTML -> [String html] | [String html, String strIndent]","diff --git a/src/main/java/com/crawljax/util/PrettyHTML.java b/src/main/java/com/crawljax/util/PrettyHTML.java
index 13b56af..b13adc9 100644
--- a/src/main/java/com/crawljax/util/PrettyHTML.java
+++ b/src/main/java/com/crawljax/util/PrettyHTML.java
@@ -1,190 +1,190 @@
-package com.crawljax.util;
-
-import java.util.Stack;
-
-/**
- * Class for making presenting HTML without changing it's structure.
- * 
- * @author Danny
- * @version $Id$
- */
-public final class PrettyHTML {
-
-	private PrettyHTML() {
-
-	}
-
-	// private static final Logger LOGGER =
-	// Logger.getLogger(PrettyHTML.class.getName());
-
-	/**
-	 * Pretty print HTML string.
-	 * 
-	 * @param html
-	 *            The HTML string.
-	 * @param strIndent
-	 *            The indentation string.
-	 * @return The pretty HTML.
-	 */
-	public static String prettyHTML(String html, String strIndent) {
-		String[] elements = html.split(""<"");
-		StringBuffer prettyHTML = new StringBuffer();
-		int indent = 0;
-		// preparsing for not closing elements
-		elements = fixElements(elements);
-
-		for (String element : elements) {
-			if (!element.equals("""")) {
-				element = element.trim();
-
-				if (!element.startsWith(""/"")) {
-					// open element
-					prettyHTML.append(repeatString(strIndent, indent));
-					String[] temp = element.split("">"");
-					prettyHTML.append(""<"" + temp[0].trim() + "">\n"");
-
-					// only indent if element is not a single element (like
-					// <img src='..' />)
-					if ((!temp[0].endsWith(""/"") || temp.length == 1)
-					        && !temp[0].startsWith(""!--"")) {
-						indent++;
-					}
-
-					// if there is text after the element, print it
-					if (temp.length > 1 && !temp[1].trim().equals("""")) {
-						prettyHTML.append(repeatString(strIndent, indent));
-						prettyHTML.append(temp[1].trim() + ""\n"");
-					}
-				} else {
-					// close element
-					indent--;
-					prettyHTML.append(repeatString(strIndent, indent));
-					prettyHTML.append(""<"" + element + ""\n"");
-				}
-				if (element.endsWith(""/>"")) {
-					indent--;
-				}
-			}
-		}
-		return prettyHTML.toString();
-
-	}
-
-	/**
-	 * @param html
-	 *            The HTML string.
-	 * @return Pretty HTML.
-	 */
-	public static String prettyHTML(String html) {
-		return prettyHTML(html, ""\t"");
-	}
-
-	/**
-	 * @param s
-	 * @param number
-	 * @return s repreated number of times
-	 */
-	private static String repeatString(String s, int number) {
-		StringBuffer ret = new StringBuffer();
-		for (int i = 0; i < number; i++) {
-			ret.append(s);
-		}
-		return ret.toString();
-	}
-
-	/**
-	 * @param openElement
-	 * @param closeElement
-	 * @return wheter element has a seperate closing element
-	 */
-	private static boolean elementsRelated(String openElement, String closeElement) {
-		openElement = openElement.split("">"")[0];
-		openElement = openElement.split("" "")[0];
-		closeElement = closeElement.split("">"")[0];
-		return closeElement.startsWith(""/"" + openElement);
-	}
-
-	/**
-	 * @param stack
-	 * @param element
-	 * @return whether the element is open
-	 */
-	private static boolean elementIsOpen(Stack<String> stack, String element) {
-		for (int i = stack.size() - 1; i >= 0; i--) {
-			if (elementsRelated(stack.get(i), element)) {
-				return true;
-			}
-		}
-		return false;
-	}
-
-	/**
-	 * @param element
-	 * @return wheter the element is a single element (<foo ... />)
-	 */
-	private static boolean isSingleElement(String element) {
-		return element.indexOf(""/>"") != -1;
-	}
-
-	/**
-	 * @param elements
-	 * @return list with elements with added closing elements if needed
-	 */
-	private static String[] fixElements(String[] elements) {
-		Stack<String> stackElements = new Stack<String>();
-		Stack<Integer> stackIndexElements = new Stack<Integer>();
-		for (int i = 0; i < elements.length; i++) {
-			elements[i] = elements[i].trim();
-			String element = elements[i];
-			if (!element.equals("""") && !element.startsWith(""!--"") && !element.endsWith(""-->"")) {
-				while (stackElements.size() > 0 && element.startsWith(""/"")
-				        && !elementsRelated(stackElements.peek(), element)) {
-					// found a close element which is not on top of stack,
-					// thus fix
-					if (elementIsOpen(stackElements, element)) {
-						// the element is open --> close element on top of
-						// stack
-						int index = stackIndexElements.peek();
-						if (!isSingleElement(elements[index])
-						        && elements[index].lastIndexOf("">"") != -1) {
-							// close this element
-							elements[index] =
-							        elements[index]
-							                .substring(0, elements[index].lastIndexOf("">""))
-							                + ""/""
-							                + elements[index].substring(elements[index]
-							                        .lastIndexOf("">""));
-						}
-						stackElements.pop();
-						stackIndexElements.pop();
-					} else {
-						// element is closing element while element is not
-						// open--> remove.
-						elements[i] = """";
-						element = """";
-						break;
-					}
-
-				}
-				if (!element.equals("""")) {
-					// open element
-					if (!element.startsWith(""/"")) {
-						// only add to stack if has an open and close element
-						if (!isSingleElement(element)) {
-							stackElements.push(element);
-							stackIndexElements.push(i);
-						}
-					} else {
-						// close element, pop from stack if possible
-						if (stackElements.size() > 0) {
-							stackElements.pop();
-							stackIndexElements.pop();
-						}
-					}
-				}
-			}
-		}
-		return elements;
-	}
-
-}
+package com.crawljax.util;
+
+import java.util.Stack;
+
+/**
+ * Class for making presenting HTML without changing it's structure.
+ * 
+ * @author Danny
+ * @version $Id$
+ */
+public final class PrettyHTML {
+
+	private PrettyHTML() {
+
+	}
+
+	// private static final Logger LOGGER =
+	// LoggerFactory.getLogger(PrettyHTML.class.getName());
+
+	/**
+	 * Pretty print HTML string.
+	 * 
+	 * @param html
+	 *            The HTML string.
+	 * @param strIndent
+	 *            The indentation string.
+	 * @return The pretty HTML.
+	 */
+	public static String prettyHTML(String html, String strIndent) {
+		String[] elements = html.split(""<"");
+		StringBuffer prettyHTML = new StringBuffer();
+		int indent = 0;
+		// preparsing for not closing elements
+		elements = fixElements(elements);
+
+		for (String element : elements) {
+			if (!element.equals("""")) {
+				element = element.trim();
+
+				if (!element.startsWith(""/"")) {
+					// open element
+					prettyHTML.append(repeatString(strIndent, indent));
+					String[] temp = element.split("">"");
+					prettyHTML.append(""<"" + temp[0].trim() + "">\n"");
+
+					// only indent if element is not a single element (like
+					// <img src='..' />)
+					if ((!temp[0].endsWith(""/"") || temp.length == 1)
+					        && !temp[0].startsWith(""!--"")) {
+						indent++;
+					}
+
+					// if there is text after the element, print it
+					if (temp.length > 1 && !temp[1].trim().equals("""")) {
+						prettyHTML.append(repeatString(strIndent, indent));
+						prettyHTML.append(temp[1].trim() + ""\n"");
+					}
+				} else {
+					// close element
+					indent--;
+					prettyHTML.append(repeatString(strIndent, indent));
+					prettyHTML.append(""<"" + element + ""\n"");
+				}
+				if (element.endsWith(""/>"")) {
+					indent--;
+				}
+			}
+		}
+		return prettyHTML.toString();
+
+	}
+
+	/**
+	 * @param html
+	 *            The HTML string.
+	 * @return Pretty HTML.
+	 */
+	public static String prettyHTML(String html) {
+		return prettyHTML(html, ""\t"");
+	}
+
+	/**
+	 * @param s
+	 * @param number
+	 * @return s repreated number of times
+	 */
+	private static String repeatString(String s, int number) {
+		StringBuffer ret = new StringBuffer();
+		for (int i = 0; i < number; i++) {
+			ret.append(s);
+		}
+		return ret.toString();
+	}
+
+	/**
+	 * @param openElement
+	 * @param closeElement
+	 * @return wheter element has a seperate closing element
+	 */
+	private static boolean elementsRelated(String openElement, String closeElement) {
+		openElement = openElement.split("">"")[0];
+		openElement = openElement.split("" "")[0];
+		closeElement = closeElement.split("">"")[0];
+		return closeElement.startsWith(""/"" + openElement);
+	}
+
+	/**
+	 * @param stack
+	 * @param element
+	 * @return whether the element is open
+	 */
+	private static boolean elementIsOpen(Stack<String> stack, String element) {
+		for (int i = stack.size() - 1; i >= 0; i--) {
+			if (elementsRelated(stack.get(i), element)) {
+				return true;
+			}
+		}
+		return false;
+	}
+
+	/**
+	 * @param element
+	 * @return wheter the element is a single element (<foo ... />)
+	 */
+	private static boolean isSingleElement(String element) {
+		return element.indexOf(""/>"") != -1;
+	}
+
+	/**
+	 * @param elements
+	 * @return list with elements with added closing elements if needed
+	 */
+	private static String[] fixElements(String[] elements) {
+		Stack<String> stackElements = new Stack<String>();
+		Stack<Integer> stackIndexElements = new Stack<Integer>();
+		for (int i = 0; i < elements.length; i++) {
+			elements[i] = elements[i].trim();
+			String element = elements[i];
+			if (!element.equals("""") && !element.startsWith(""!--"") && !element.endsWith(""-->"")) {
+				while (stackElements.size() > 0 && element.startsWith(""/"")
+				        && !elementsRelated(stackElements.peek(), element)) {
+					// found a close element which is not on top of stack,
+					// thus fix
+					if (elementIsOpen(stackElements, element)) {
+						// the element is open --> close element on top of
+						// stack
+						int index = stackIndexElements.peek();
+						if (!isSingleElement(elements[index])
+						        && elements[index].lastIndexOf("">"") != -1) {
+							// close this element
+							elements[index] =
+							        elements[index]
+							                .substring(0, elements[index].lastIndexOf("">""))
+							                + ""/""
+							                + elements[index].substring(elements[index]
+							                        .lastIndexOf("">""));
+						}
+						stackElements.pop();
+						stackIndexElements.pop();
+					} else {
+						// element is closing element while element is not
+						// open--> remove.
+						elements[i] = """";
+						element = """";
+						break;
+					}
+
+				}
+				if (!element.equals("""")) {
+					// open element
+					if (!element.startsWith(""/"")) {
+						// only add to stack if has an open and close element
+						if (!isSingleElement(element)) {
+							stackElements.push(element);
+							stackIndexElements.push(i);
+						}
+					} else {
+						// close element, pop from stack if possible
+						if (stackElements.size() > 0) {
+							stackElements.pop();
+							stackIndexElements.pop();
+						}
+					}
+				}
+			}
+		}
+		return elements;
+	}
+
+}
"
08b2d85ebd395ff2948c9f1cc594a24b5aaedea7,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 72ec044..d97ab0c 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -1,874 +1,875 @@
-package com.crawljax.browser;
-
-import java.io.File;
-import java.io.IOException;
-import java.net.MalformedURLException;
-import java.net.URL;
-import java.util.ArrayList;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
-import org.apache.log4j.Logger;
-import org.openqa.selenium.ElementNotVisibleException;
-import org.openqa.selenium.JavascriptExecutor;
-import org.openqa.selenium.NoSuchElementException;
-import org.openqa.selenium.NoSuchFrameException;
-import org.openqa.selenium.OutputType;
-import org.openqa.selenium.Platform;
-import org.openqa.selenium.TakesScreenshot;
-import org.openqa.selenium.WebDriver;
-import org.openqa.selenium.WebDriverException;
-import org.openqa.selenium.WebElement;
-import org.openqa.selenium.internal.WrapsDriver;
-import org.openqa.selenium.io.FileHandler;
-import org.openqa.selenium.remote.Augmenter;
-import org.openqa.selenium.remote.DesiredCapabilities;
-import org.openqa.selenium.remote.HttpCommandExecutor;
-import org.openqa.selenium.remote.RemoteWebDriver;
-import org.openqa.selenium.support.ui.Select;
-import org.w3c.dom.DOMException;
-import org.w3c.dom.Document;
-import org.w3c.dom.Element;
-import org.w3c.dom.NodeList;
-import org.xml.sax.SAXException;
-
-import com.crawljax.core.CrawljaxException;
-import com.crawljax.core.configuration.AcceptAllFramesChecker;
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
-import com.crawljax.core.configuration.IgnoreFrameChecker;
-import com.crawljax.core.exception.BrowserConnectionException;
-import com.crawljax.core.state.Eventable;
-import com.crawljax.core.state.Identification;
-import com.crawljax.forms.FormHandler;
-import com.crawljax.forms.FormInput;
-import com.crawljax.forms.InputValue;
-import com.crawljax.forms.RandomInputValueGenerator;
-import com.crawljax.util.Helper;
-
-/**
- * @author mesbah
- * @author Frank Groeneveld
- * @version $Id: WebDriverBackedEmbeddedBrowser.java 387 2010-07-13 13:55:49Z slenselink@google.com
- *          $
- */
-public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
-	private long crawlWaitEvent;
-	private static final Logger LOGGER = Logger.getLogger(WebDriverBackedEmbeddedBrowser.class);
-	private final WebDriver browser;
-
-	private List<String> filterAttributes;
-	private long crawlWaitReload;
-	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
-
-	/**
-	 * Constructor without configuration values, these must be updated using the
-	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
-		this.browser = driver;
-	}
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent) {
-		this(driver);
-		this.filterAttributes = filterAttributes;
-		this.crawlWaitEvent = crawlWaitEvent;
-		this.crawlWaitReload = crawlWaitReload;
-	}
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
-		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
-		this.ignoreFrameChecker = ignoreFrameChecker;
-	}
-
-	/**
-	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param hubUrl
-	 *            Url of the server.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
-		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
-		        filterAttributes, crawlWaitEvent, crawlWaitReload);
-	}
-
-	/**
-	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param hubUrl
-	 *            Url of the server.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-	        IgnoreFrameChecker ignoreFrameChecker) {
-		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
-		        filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
-	}
-
-	/**
-	 * Create a WebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
-		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
-		        crawlWaitReload);
-	}
-
-	/**
-	 * Create a WebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-	        IgnoreFrameChecker ignoreFrameChecker) {
-		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
-		        crawlWaitReload, ignoreFrameChecker);
-	}
-
-	/**
-	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param hubUrl
-	 *            Url of the server.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl) {
-		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl));
-	}
-
-	/**
-	 * Private used static method for creation of a RemoteWebDriver. Taking care of the default
-	 * Capabilities and using the HttpCommandExecutor.
-	 * 
-	 * @param hubUrl
-	 *            the url of the hub to use.
-	 * @return the RemoteWebDriver instance.
-	 */
-	private static RemoteWebDriver buildRemoteWebDriver(String hubUrl) {
-		DesiredCapabilities capabilities = new DesiredCapabilities();
-		capabilities.setPlatform(Platform.ANY);
-		URL url;
-		try {
-			url = new URL(hubUrl);
-		} catch (MalformedURLException e) {
-			LOGGER.error(""The given hub url of the remote server is malformed can not continue!"",
-			        e);
-			return null;
-		}
-		HttpCommandExecutor executor = null;
-		try {
-			executor = new HttpCommandExecutor(url);
-		} catch (Exception e) {
-			// TODO Stefan; refactor this catch, this will definitely result in NullPointers, why
-			// not throw RuntimeExcption direct?
-			LOGGER.error(""Received unknown exception while creating the ""
-			        + ""HttpCommandExecutor, can not continue!"", e);
-			return null;
-		}
-		return new RemoteWebDriver(executor, capabilities);
-	}
-
-	/**
-	 * Create a WebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver) {
-		return new WebDriverBackedEmbeddedBrowser(driver);
-	}
-
-	/**
-	 * @param url
-	 *            The URL.
-	 */
-	public void goToUrl(String url) {
-		try {
-			browser.navigate().to(url);
-			Thread.sleep(this.crawlWaitReload);
-			handlePopups();
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return;
-		} catch (InterruptedException e) {
-			LOGGER.error(""goToUrl got interrupted while waiting for the page to be loaded"", e);
-			return;
-		}
-	}
-
-	/**
-	 * alert, prompt, and confirm behave as if the OK button is always clicked.
-	 */
-	private void handlePopups() {
-		try {
-			executeJavaScript(""window.alert = function(msg){return true;};""
-			        + ""window.confirm = function(msg){return true;};""
-			        + ""window.prompt = function(msg){return true;};"");
-		} catch (CrawljaxException e) {
-			LOGGER.error(""Handling of PopUp windows failed"", e);
-		}
-	}
-
-	/**
-	 * Fires the event and waits for a specified time.
-	 * 
-	 * @param webElement
-	 *            the element to fire event on.
-	 * @param eventable
-	 *            The HTML event type (onclick, onmouseover, ...).
-	 * @return true if firing event is successful.
-	 */
-	protected boolean fireEventWait(WebElement webElement, Eventable eventable) {
-		switch (eventable.getEventType()) {
-			case click:
-				try {
-					webElement.click();
-				} catch (ElementNotVisibleException e1) {
-					LOGGER.info(""Element not visible, so cannot be clicked: ""
-					        + webElement.getTagName().toUpperCase() + "" "" + webElement.getText());
-					return false;
-				} catch (WebDriverException e) {
-					throwIfConnectionException(e);
-					return false;
-				}
-				break;
-			case hover:
-				// todo
-				break;
-
-			default:
-				LOGGER.info(""EventType "" + eventable.getEventType()
-				        + "" not supported in WebDriver."");
-				return false;
-		}
-
-		try {
-			Thread.sleep(this.crawlWaitEvent);
-		} catch (InterruptedException e) {
-			LOGGER.error(""fireEventWait got interrupted during wait process"", e);
-			return false;
-		}
-		return true;
-	}
-
-	@Override
-	public void close() {
-		LOGGER.info(""Closing the browser..."");
-		try {
-			// close browser and close every associated window.
-			browser.quit();
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	@Override
-	public String getDom() {
-
-		try {
-			String dom = toUniformDOM(Helper.getDocumentToString(getDomTreeWithFrames()));
-			LOGGER.debug(dom);
-			return dom;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			LOGGER.warn(e.getMessage(), e);
-			return """";
-		} catch (CrawljaxException e) {
-			LOGGER.warn(e.getMessage(), e);
-			return """";
-		}
-	}
-
-	/**
-	 * @param html
-	 *            The html string.
-	 * @return uniform version of dom with predefined attributes stripped
-	 */
-	private String toUniformDOM(String html) {
-
-		Pattern p =
-		        Pattern.compile(""<SCRIPT(.*?)</SCRIPT>"", Pattern.DOTALL
-		                | Pattern.CASE_INSENSITIVE);
-		Matcher m = p.matcher(html);
-		String htmlFormatted = m.replaceAll("""");
-
-		p = Pattern.compile(""<\\?xml:(.*?)>"");
-		m = p.matcher(html);
-		htmlFormatted = m.replaceAll("""");
-
-		// html = html.replace(""<?xml:namespace prefix = gwt >"", """");
-
-		// TODO (Stefan), Following lines are a serious performance bottle neck...
-		// Document doc = Helper.getDocument(htmlFormatted);
-		// htmlFormatted = Helper.getDocumentToString(doc);
-
-		htmlFormatted = filterAttributes(htmlFormatted);
-		return htmlFormatted;
-	}
-
-	/**
-	 * Filters attributes from the HTML string.
-	 * 
-	 * @param html
-	 *            The HTML to filter.
-	 * @return The filtered HTML string.
-	 */
-	private String filterAttributes(String html) {
-		if (this.filterAttributes != null) {
-			for (String attribute : this.filterAttributes) {
-				String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
-				Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
-				Matcher m = p.matcher(html);
-				html = m.replaceAll("""");
-			}
-		}
-		return html;
-	}
-
-	@Override
-	public void goBack() {
-		try {
-			browser.navigate().back();
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	/**
-	 * @param identification
-	 *            The identification object.
-	 * @param text
-	 *            The input.
-	 * @return true if succeeds.
-	 */
-	public boolean input(Identification identification, String text) {
-		try {
-			WebElement field = browser.findElement(identification.getWebDriverBy());
-			if (field != null) {
-				// first clear the field
-				field.clear();
-				// then fill in
-				field.sendKeys(text);
-
-				// this.activeElement = field;
-				return true;
-			}
-			return false;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return false;
-		}
-	}
-
-	/**
-	 * Fires an event on an element using its identification.
-	 * 
-	 * @param eventable
-	 *            The eventable.
-	 * @return true if it is able to fire the event successfully on the element.
-	 */
-	public synchronized boolean fireEvent(Eventable eventable) {
-		try {
-
-			boolean handleChanged = false;
-			boolean result = false;
-
-			if (eventable.getRelatedFrame() != null && !eventable.getRelatedFrame().equals("""")) {
-				LOGGER.debug(""switching to frame: "" + eventable.getRelatedFrame());
-				try {
-
-					switchToFrame(eventable.getRelatedFrame());
-				} catch (NoSuchFrameException e) {
-					LOGGER.debug(""Frame not found, possibily while back-tracking.."", e);
-					// TODO Stefan, This exception is catched to prevent stopping from working
-					// This was the case on the Gmail case; find out if not switching (catching)
-					// Results in good performance...
-				}
-				handleChanged = true;
-			}
-
-			WebElement webElement =
-			        browser.findElement(eventable.getIdentification().getWebDriverBy());
-
-			if (webElement != null) {
-				result = fireEventWait(webElement, eventable);
-			}
-
-			if (handleChanged) {
-				browser.switchTo().defaultContent();
-			}
-			return result;
-		} catch (NoSuchElementException e) {
-			LOGGER.warn(""Could not fire eventable: "" + eventable.toString());
-			return false;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return false;
-		}
-	}
-
-	/**
-	 * Execute JavaScript in the browser.
-	 * 
-	 * @param code
-	 *            The code to execute.
-	 * @return The return value of the JavaScript.
-	 * @throws CrawljaxException
-	 *             when javascript execution failed.
-	 */
-	public Object executeJavaScript(String code) throws CrawljaxException {
-		try {
-			JavascriptExecutor js = (JavascriptExecutor) browser;
-			return js.executeScript(code);
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			throw new CrawljaxException(e);
-		}
-	}
-
-	/**
-	 * Determines whether the corresponding element is visible.
-	 * 
-	 * @param identification
-	 *            The element to search for.
-	 * @return true if the element is visible
-	 */
-	public boolean isVisible(Identification identification) {
-		try {
-			WebElement el = browser.findElement(identification.getWebDriverBy());
-			if (el != null) {
-				return el.isDisplayed();
-			}
-
-			return false;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return false;
-		}
-	}
-
-	/**
-	 * @return The current browser url.
-	 */
-	public String getCurrentUrl() {
-		try {
-			return browser.getCurrentUrl();
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	@Override
-	public void closeOtherWindows() {
-		try {
-			String current = browser.getWindowHandle();
-			for (String handle : browser.getWindowHandles()) {
-				if (!handle.equals(browser.getWindowHandle())) {
-
-					browser.switchTo().window(handle);
-					LOGGER.info(""Closing other window with title \"""" + browser.getTitle() + ""\"""");
-					browser.close();
-					// browser.switchTo().defaultContent();
-					browser.switchTo().window(current);
-				}
-			}
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	/**
-	 * @return a Document object containing the contents of iframes as well.
-	 * @throws CrawljaxException
-	 *             if an exception is thrown.
-	 */
-	private Document getDomTreeWithFrames() throws CrawljaxException {
-
-		try {
-			Document document = Helper.getDocument(browser.getPageSource());
-			appendFrameContent(document.getDocumentElement(), document, """");
-			return document;
-		} catch (SAXException e) {
-			throw new CrawljaxException(e.getMessage(), e);
-		} catch (IOException e) {
-			throw new CrawljaxException(e.getMessage(), e);
-		}
-
-	}
-
-	private void appendFrameContent(Element orig, Document document, String topFrame) {
-
-		NodeList frameNodes = orig.getElementsByTagName(""IFRAME"");
-
-		List<Element> nodeList = new ArrayList<Element>();
-
-		for (int i = 0; i < frameNodes.getLength(); i++) {
-			Element frameElement = (Element) frameNodes.item(i);
-			nodeList.add(frameElement);
-		}
-
-		// Added support for FRAMES
-		frameNodes = orig.getElementsByTagName(""FRAME"");
-		for (int i = 0; i < frameNodes.getLength(); i++) {
-			Element frameElement = (Element) frameNodes.item(i);
-			nodeList.add(frameElement);
-		}
-
-		for (int i = 0; i < nodeList.size(); i++) {
-			String frameIdentification = """";
-
-			if (topFrame != null && !topFrame.equals("""")) {
-				frameIdentification += topFrame + ""."";
-			}
-
-			Element frameElement = nodeList.get(i);
-
-			String nameId = Helper.getFrameIdentification(frameElement);
-
-			if (nameId != null
-			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
-				frameIdentification += nameId;
-
-				String handle = browser.getWindowHandle();
-
-				LOGGER.debug(""The current H: "" + handle);
-
-				switchToFrame(frameIdentification);
-
-				String toAppend = browser.getPageSource();
-
-				LOGGER.debug(""frame dom: "" + toAppend);
-
-				browser.switchTo().defaultContent();
-
-				try {
-					Element toAppendElement = Helper.getDocument(toAppend).getDocumentElement();
-					Element importedElement =
-					        (Element) document.importNode(toAppendElement, true);
-					frameElement.appendChild(importedElement);
-
-					appendFrameContent(importedElement, document, frameIdentification);
-				} catch (DOMException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				} catch (SAXException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				} catch (IOException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				}
-			}
-		}
-	}
-
-	private void switchToFrame(String frameIdentification) {
-		LOGGER.debug(""frame identification: "" + frameIdentification);
-
-		if (frameIdentification.contains(""."")) {
-			String[] frames = frameIdentification.split(""\\."");
-
-			for (String frameId : frames) {
-				LOGGER.debug(""switching to frame: "" + frameId);
-				browser.switchTo().frame(frameId);
-			}
-
-		} else {
-			browser.switchTo().frame(frameIdentification);
-		}
-
-	}
-
-	/**
-	 * @return the dom without the iframe contents.
-	 * @see com.crawljax.browser.EmbeddedBrowser#getDomWithoutIframeContent()
-	 */
-	public String getDomWithoutIframeContent() {
-		try {
-			String dom = browser.getPageSource();
-			// logger.debug(""driver.source: "" + dom);
-			String result = toUniformDOM(dom);
-			// logger.debug(""driver.source toUniformDom: "" + result);
-			return result;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return """";
-		}
-	}
-
-	/**
-	 * @param input
-	 *            the input to be filled.
-	 * @return FormInput with random value assigned if possible
-	 */
-	public FormInput getInputWithRandomValue(FormInput input) {
-
-		WebElement webElement;
-		try {
-			webElement = browser.findElement(input.getIdentification().getWebDriverBy());
-			if (!(webElement.isDisplayed())) {
-
-				return null;
-			}
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return null;
-		}
-
-		Set<InputValue> values = new HashSet<InputValue>();
-
-		// create some random value
-
-		if (input.getType().toLowerCase().startsWith(""text"")) {
-			values.add(new InputValue(new RandomInputValueGenerator()
-			        .getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
-		} else if (input.getType().equalsIgnoreCase(""checkbox"")
-		        || input.getType().equalsIgnoreCase(""radio"") && !webElement.isSelected()) {
-			if (new RandomInputValueGenerator().getCheck()) {
-				values.add(new InputValue(""1"", true));
-			} else {
-				values.add(new InputValue(""0"", false));
-
-			}
-		} else if (input.getType().equalsIgnoreCase(""select"")) {
-			try {
-				Select select = new Select(webElement);
-				WebElement option =
-				        (WebElement) new RandomInputValueGenerator().getRandomOption(select
-				                .getOptions());
-				values.add(new InputValue(option.getText(), true));
-			} catch (WebDriverException e) {
-				throwIfConnectionException(e);
-				return null;
-			}
-		}
-
-		if (values.size() == 0) {
-			return null;
-		}
-		input.setInputValues(values);
-		return input;
-
-	}
-
-	@Override
-	public String getFrameDom(String iframeIdentification) {
-		try {
-
-			switchToFrame(iframeIdentification);
-
-			// make a copy of the dom before changing into the top page
-			String frameDom = browser.getPageSource();
-
-			browser.switchTo().defaultContent();
-
-			return frameDom;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return """";
-		}
-	}
-
-	/**
-	 * @param identification
-	 *            the identification of the element.
-	 * @return true if the element can be found in the DOM tree.
-	 */
-	public boolean elementExists(Identification identification) {
-		try {
-			WebElement el = browser.findElement(identification.getWebDriverBy());
-			// TODO Stefan; I think el will never be null as a NoSuchElementExcpetion will be
-			// thrown, catched below.
-			return el != null;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return false;
-		}
-	}
-
-	/**
-	 * @param identification
-	 *            the identification of the element.
-	 * @return the found element.
-	 */
-	public WebElement getWebElement(Identification identification) {
-		try {
-			return browser.findElement(identification.getWebDriverBy());
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	/**
-	 * @return the period to wait after an event.
-	 */
-	protected long getCrawlWaitEvent() {
-		return crawlWaitEvent;
-	}
-
-	/**
-	 * @return the list of attributes to be filtered from DOM.
-	 */
-	protected List<String> getFilterAttributes() {
-		return filterAttributes;
-	}
-
-	/**
-	 * @return the period to waint after a reload.
-	 */
-	protected long getCrawlWaitReload() {
-		return crawlWaitReload;
-	}
-
-	private void takeScreenShotOnBrowser(WebDriver driver, File file) throws CrawljaxException {
-		if (driver instanceof TakesScreenshot) {
-			File tmpfile = ((TakesScreenshot) driver).getScreenshotAs(OutputType.FILE);
-
-			try {
-				FileHandler.copy(tmpfile, file);
-			} catch (IOException e) {
-				throw new CrawljaxException(e);
-			}
-
-			removeCanvasGeneratedByFirefoxDriverForScreenshots();
-		} else if (driver instanceof RemoteWebDriver) {
-			WebDriver augmentedWebdriver = new Augmenter().augment(driver);
-			takeScreenShotOnBrowser(augmentedWebdriver, file);
-		} else if (driver instanceof WrapsDriver) {
-			takeScreenShotOnBrowser(((WrapsDriver) driver).getWrappedDriver(), file);
-		} else {
-			throw new CrawljaxException(""Your current WebDriver doesn't support screenshots."");
-		}
-	}
-
-	@Override
-	public void saveScreenShot(File file) throws CrawljaxException {
-		try {
-			takeScreenShotOnBrowser(browser, file);
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	private void removeCanvasGeneratedByFirefoxDriverForScreenshots() {
-		String js = """";
-		js += ""var canvas = document.getElementById('fxdriver-screenshot-canvas');"";
-		js += ""if(canvas != null){"";
-		js += ""canvas.parentNode.removeChild(canvas);"";
-		js += ""}"";
-		try {
-			executeJavaScript(js);
-		} catch (CrawljaxException e) {
-			LOGGER.error(""Removing of Canvas Generated By FirefoxDriver failed,""
-			        + "" most likely leaving it in the browser"", e);
-		}
-	}
-
-	/**
-	 * @return the WebDriver used as an EmbeddedBrowser.
-	 */
-	public WebDriver getBrowser() {
-		return browser;
-	}
-
-	@Override
-	public void updateConfiguration(CrawljaxConfigurationReader configuration) {
-		// Retrieve the config values used
-		this.filterAttributes = configuration.getFilterAttributeNames();
-		this.crawlWaitReload =
-		        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
-		this.crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
-		this.ignoreFrameChecker = configuration.getCrawlSpecificationReader();
-	}
-
-	private boolean exceptionIsConnectionException(WebDriverException exception) {
-		return exception != null && exception.getCause() != null
-		        && exception.getCause() instanceof IOException;
-	}
-
-	private RuntimeException wrapWebDriverExceptionIfConnectionException(
-	        WebDriverException exception) {
-		if (exceptionIsConnectionException(exception)) {
-			return new BrowserConnectionException(exception);
-		}
-		return exception;
-	}
-
-	private void throwIfConnectionException(WebDriverException exception) {
-		if (exceptionIsConnectionException(exception)) {
-			throw wrapWebDriverExceptionIfConnectionException(exception);
-		}
-	}
-}
\ No newline at end of file
+package com.crawljax.browser;
+
+import java.io.File;
+import java.io.IOException;
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.openqa.selenium.ElementNotVisibleException;
+import org.openqa.selenium.JavascriptExecutor;
+import org.openqa.selenium.NoSuchElementException;
+import org.openqa.selenium.NoSuchFrameException;
+import org.openqa.selenium.OutputType;
+import org.openqa.selenium.Platform;
+import org.openqa.selenium.TakesScreenshot;
+import org.openqa.selenium.WebDriver;
+import org.openqa.selenium.WebDriverException;
+import org.openqa.selenium.WebElement;
+import org.openqa.selenium.internal.WrapsDriver;
+import org.openqa.selenium.io.FileHandler;
+import org.openqa.selenium.remote.Augmenter;
+import org.openqa.selenium.remote.DesiredCapabilities;
+import org.openqa.selenium.remote.HttpCommandExecutor;
+import org.openqa.selenium.remote.RemoteWebDriver;
+import org.openqa.selenium.support.ui.Select;
+import org.w3c.dom.DOMException;
+import org.w3c.dom.Document;
+import org.w3c.dom.Element;
+import org.w3c.dom.NodeList;
+import org.xml.sax.SAXException;
+
+import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.configuration.AcceptAllFramesChecker;
+import com.crawljax.core.configuration.CrawljaxConfigurationReader;
+import com.crawljax.core.configuration.IgnoreFrameChecker;
+import com.crawljax.core.exception.BrowserConnectionException;
+import com.crawljax.core.state.Eventable;
+import com.crawljax.core.state.Identification;
+import com.crawljax.forms.FormHandler;
+import com.crawljax.forms.FormInput;
+import com.crawljax.forms.InputValue;
+import com.crawljax.forms.RandomInputValueGenerator;
+import com.crawljax.util.Helper;
+
+/**
+ * @author mesbah
+ * @author Frank Groeneveld
+ * @version $Id: WebDriverBackedEmbeddedBrowser.java 387 2010-07-13 13:55:49Z slenselink@google.com
+ *          $
+ */
+public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
+	private long crawlWaitEvent;
+	private static final Logger LOGGER = LoggerFactory.getLogger(WebDriverBackedEmbeddedBrowser.class);
+	private final WebDriver browser;
+
+	private List<String> filterAttributes;
+	private long crawlWaitReload;
+	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
+
+	/**
+	 * Constructor without configuration values, these must be updated using the
+	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
+		this.browser = driver;
+	}
+
+	/**
+	 * Constructor.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
+	        long crawlWaitReload, long crawlWaitEvent) {
+		this(driver);
+		this.filterAttributes = filterAttributes;
+		this.crawlWaitEvent = crawlWaitEvent;
+		this.crawlWaitReload = crawlWaitReload;
+	}
+
+	/**
+	 * Constructor.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
+	        long crawlWaitReload, long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
+		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
+		this.ignoreFrameChecker = ignoreFrameChecker;
+	}
+
+	/**
+	 * Create a RemoteWebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param hubUrl
+	 *            Url of the server.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
+		        filterAttributes, crawlWaitEvent, crawlWaitReload);
+	}
+
+	/**
+	 * Create a RemoteWebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param hubUrl
+	 *            Url of the server.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
+	        IgnoreFrameChecker ignoreFrameChecker) {
+		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
+		        filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
+	}
+
+	/**
+	 * Create a WebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
+		        crawlWaitReload);
+	}
+
+	/**
+	 * Create a WebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
+	        IgnoreFrameChecker ignoreFrameChecker) {
+		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
+		        crawlWaitReload, ignoreFrameChecker);
+	}
+
+	/**
+	 * Create a RemoteWebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param hubUrl
+	 *            Url of the server.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl) {
+		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl));
+	}
+
+	/**
+	 * Private used static method for creation of a RemoteWebDriver. Taking care of the default
+	 * Capabilities and using the HttpCommandExecutor.
+	 * 
+	 * @param hubUrl
+	 *            the url of the hub to use.
+	 * @return the RemoteWebDriver instance.
+	 */
+	private static RemoteWebDriver buildRemoteWebDriver(String hubUrl) {
+		DesiredCapabilities capabilities = new DesiredCapabilities();
+		capabilities.setPlatform(Platform.ANY);
+		URL url;
+		try {
+			url = new URL(hubUrl);
+		} catch (MalformedURLException e) {
+			LOGGER.error(""The given hub url of the remote server is malformed can not continue!"",
+			        e);
+			return null;
+		}
+		HttpCommandExecutor executor = null;
+		try {
+			executor = new HttpCommandExecutor(url);
+		} catch (Exception e) {
+			// TODO Stefan; refactor this catch, this will definitely result in NullPointers, why
+			// not throw RuntimeExcption direct?
+			LOGGER.error(""Received unknown exception while creating the ""
+			        + ""HttpCommandExecutor, can not continue!"", e);
+			return null;
+		}
+		return new RemoteWebDriver(executor, capabilities);
+	}
+
+	/**
+	 * Create a WebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver) {
+		return new WebDriverBackedEmbeddedBrowser(driver);
+	}
+
+	/**
+	 * @param url
+	 *            The URL.
+	 */
+	public void goToUrl(String url) {
+		try {
+			browser.navigate().to(url);
+			Thread.sleep(this.crawlWaitReload);
+			handlePopups();
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return;
+		} catch (InterruptedException e) {
+			LOGGER.error(""goToUrl got interrupted while waiting for the page to be loaded"", e);
+			return;
+		}
+	}
+
+	/**
+	 * alert, prompt, and confirm behave as if the OK button is always clicked.
+	 */
+	private void handlePopups() {
+		try {
+			executeJavaScript(""window.alert = function(msg){return true;};""
+			        + ""window.confirm = function(msg){return true;};""
+			        + ""window.prompt = function(msg){return true;};"");
+		} catch (CrawljaxException e) {
+			LOGGER.error(""Handling of PopUp windows failed"", e);
+		}
+	}
+
+	/**
+	 * Fires the event and waits for a specified time.
+	 * 
+	 * @param webElement
+	 *            the element to fire event on.
+	 * @param eventable
+	 *            The HTML event type (onclick, onmouseover, ...).
+	 * @return true if firing event is successful.
+	 */
+	protected boolean fireEventWait(WebElement webElement, Eventable eventable) {
+		switch (eventable.getEventType()) {
+			case click:
+				try {
+					webElement.click();
+				} catch (ElementNotVisibleException e1) {
+					LOGGER.info(""Element not visible, so cannot be clicked: ""
+					        + webElement.getTagName().toUpperCase() + "" "" + webElement.getText());
+					return false;
+				} catch (WebDriverException e) {
+					throwIfConnectionException(e);
+					return false;
+				}
+				break;
+			case hover:
+				// todo
+				break;
+
+			default:
+				LOGGER.info(""EventType "" + eventable.getEventType()
+				        + "" not supported in WebDriver."");
+				return false;
+		}
+
+		try {
+			Thread.sleep(this.crawlWaitEvent);
+		} catch (InterruptedException e) {
+			LOGGER.error(""fireEventWait got interrupted during wait process"", e);
+			return false;
+		}
+		return true;
+	}
+
+	@Override
+	public void close() {
+		LOGGER.info(""Closing the browser..."");
+		try {
+			// close browser and close every associated window.
+			browser.quit();
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	@Override
+	public String getDom() {
+
+		try {
+			String dom = toUniformDOM(Helper.getDocumentToString(getDomTreeWithFrames()));
+			LOGGER.debug(dom);
+			return dom;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			LOGGER.warn(e.getMessage(), e);
+			return """";
+		} catch (CrawljaxException e) {
+			LOGGER.warn(e.getMessage(), e);
+			return """";
+		}
+	}
+
+	/**
+	 * @param html
+	 *            The html string.
+	 * @return uniform version of dom with predefined attributes stripped
+	 */
+	private String toUniformDOM(String html) {
+
+		Pattern p =
+		        Pattern.compile(""<SCRIPT(.*?)</SCRIPT>"", Pattern.DOTALL
+		                | Pattern.CASE_INSENSITIVE);
+		Matcher m = p.matcher(html);
+		String htmlFormatted = m.replaceAll("""");
+
+		p = Pattern.compile(""<\\?xml:(.*?)>"");
+		m = p.matcher(html);
+		htmlFormatted = m.replaceAll("""");
+
+		// html = html.replace(""<?xml:namespace prefix = gwt >"", """");
+
+		// TODO (Stefan), Following lines are a serious performance bottle neck...
+		// Document doc = Helper.getDocument(htmlFormatted);
+		// htmlFormatted = Helper.getDocumentToString(doc);
+
+		htmlFormatted = filterAttributes(htmlFormatted);
+		return htmlFormatted;
+	}
+
+	/**
+	 * Filters attributes from the HTML string.
+	 * 
+	 * @param html
+	 *            The HTML to filter.
+	 * @return The filtered HTML string.
+	 */
+	private String filterAttributes(String html) {
+		if (this.filterAttributes != null) {
+			for (String attribute : this.filterAttributes) {
+				String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
+				Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
+				Matcher m = p.matcher(html);
+				html = m.replaceAll("""");
+			}
+		}
+		return html;
+	}
+
+	@Override
+	public void goBack() {
+		try {
+			browser.navigate().back();
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	/**
+	 * @param identification
+	 *            The identification object.
+	 * @param text
+	 *            The input.
+	 * @return true if succeeds.
+	 */
+	public boolean input(Identification identification, String text) {
+		try {
+			WebElement field = browser.findElement(identification.getWebDriverBy());
+			if (field != null) {
+				// first clear the field
+				field.clear();
+				// then fill in
+				field.sendKeys(text);
+
+				// this.activeElement = field;
+				return true;
+			}
+			return false;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return false;
+		}
+	}
+
+	/**
+	 * Fires an event on an element using its identification.
+	 * 
+	 * @param eventable
+	 *            The eventable.
+	 * @return true if it is able to fire the event successfully on the element.
+	 */
+	public synchronized boolean fireEvent(Eventable eventable) {
+		try {
+
+			boolean handleChanged = false;
+			boolean result = false;
+
+			if (eventable.getRelatedFrame() != null && !eventable.getRelatedFrame().equals("""")) {
+				LOGGER.debug(""switching to frame: "" + eventable.getRelatedFrame());
+				try {
+
+					switchToFrame(eventable.getRelatedFrame());
+				} catch (NoSuchFrameException e) {
+					LOGGER.debug(""Frame not found, possibily while back-tracking.."", e);
+					// TODO Stefan, This exception is catched to prevent stopping from working
+					// This was the case on the Gmail case; find out if not switching (catching)
+					// Results in good performance...
+				}
+				handleChanged = true;
+			}
+
+			WebElement webElement =
+			        browser.findElement(eventable.getIdentification().getWebDriverBy());
+
+			if (webElement != null) {
+				result = fireEventWait(webElement, eventable);
+			}
+
+			if (handleChanged) {
+				browser.switchTo().defaultContent();
+			}
+			return result;
+		} catch (NoSuchElementException e) {
+			LOGGER.warn(""Could not fire eventable: "" + eventable.toString());
+			return false;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return false;
+		}
+	}
+
+	/**
+	 * Execute JavaScript in the browser.
+	 * 
+	 * @param code
+	 *            The code to execute.
+	 * @return The return value of the JavaScript.
+	 * @throws CrawljaxException
+	 *             when javascript execution failed.
+	 */
+	public Object executeJavaScript(String code) throws CrawljaxException {
+		try {
+			JavascriptExecutor js = (JavascriptExecutor) browser;
+			return js.executeScript(code);
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			throw new CrawljaxException(e);
+		}
+	}
+
+	/**
+	 * Determines whether the corresponding element is visible.
+	 * 
+	 * @param identification
+	 *            The element to search for.
+	 * @return true if the element is visible
+	 */
+	public boolean isVisible(Identification identification) {
+		try {
+			WebElement el = browser.findElement(identification.getWebDriverBy());
+			if (el != null) {
+				return el.isDisplayed();
+			}
+
+			return false;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return false;
+		}
+	}
+
+	/**
+	 * @return The current browser url.
+	 */
+	public String getCurrentUrl() {
+		try {
+			return browser.getCurrentUrl();
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	@Override
+	public void closeOtherWindows() {
+		try {
+			String current = browser.getWindowHandle();
+			for (String handle : browser.getWindowHandles()) {
+				if (!handle.equals(browser.getWindowHandle())) {
+
+					browser.switchTo().window(handle);
+					LOGGER.info(""Closing other window with title \"""" + browser.getTitle() + ""\"""");
+					browser.close();
+					// browser.switchTo().defaultContent();
+					browser.switchTo().window(current);
+				}
+			}
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	/**
+	 * @return a Document object containing the contents of iframes as well.
+	 * @throws CrawljaxException
+	 *             if an exception is thrown.
+	 */
+	private Document getDomTreeWithFrames() throws CrawljaxException {
+
+		try {
+			Document document = Helper.getDocument(browser.getPageSource());
+			appendFrameContent(document.getDocumentElement(), document, """");
+			return document;
+		} catch (SAXException e) {
+			throw new CrawljaxException(e.getMessage(), e);
+		} catch (IOException e) {
+			throw new CrawljaxException(e.getMessage(), e);
+		}
+
+	}
+
+	private void appendFrameContent(Element orig, Document document, String topFrame) {
+
+		NodeList frameNodes = orig.getElementsByTagName(""IFRAME"");
+
+		List<Element> nodeList = new ArrayList<Element>();
+
+		for (int i = 0; i < frameNodes.getLength(); i++) {
+			Element frameElement = (Element) frameNodes.item(i);
+			nodeList.add(frameElement);
+		}
+
+		// Added support for FRAMES
+		frameNodes = orig.getElementsByTagName(""FRAME"");
+		for (int i = 0; i < frameNodes.getLength(); i++) {
+			Element frameElement = (Element) frameNodes.item(i);
+			nodeList.add(frameElement);
+		}
+
+		for (int i = 0; i < nodeList.size(); i++) {
+			String frameIdentification = """";
+
+			if (topFrame != null && !topFrame.equals("""")) {
+				frameIdentification += topFrame + ""."";
+			}
+
+			Element frameElement = nodeList.get(i);
+
+			String nameId = Helper.getFrameIdentification(frameElement);
+
+			if (nameId != null
+			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
+				frameIdentification += nameId;
+
+				String handle = browser.getWindowHandle();
+
+				LOGGER.debug(""The current H: "" + handle);
+
+				switchToFrame(frameIdentification);
+
+				String toAppend = browser.getPageSource();
+
+				LOGGER.debug(""frame dom: "" + toAppend);
+
+				browser.switchTo().defaultContent();
+
+				try {
+					Element toAppendElement = Helper.getDocument(toAppend).getDocumentElement();
+					Element importedElement =
+					        (Element) document.importNode(toAppendElement, true);
+					frameElement.appendChild(importedElement);
+
+					appendFrameContent(importedElement, document, frameIdentification);
+				} catch (DOMException e) {
+					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
+					        + "" continuing..."", e);
+				} catch (SAXException e) {
+					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
+					        + "" continuing..."", e);
+				} catch (IOException e) {
+					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
+					        + "" continuing..."", e);
+				}
+			}
+		}
+	}
+
+	private void switchToFrame(String frameIdentification) {
+		LOGGER.debug(""frame identification: "" + frameIdentification);
+
+		if (frameIdentification.contains(""."")) {
+			String[] frames = frameIdentification.split(""\\."");
+
+			for (String frameId : frames) {
+				LOGGER.debug(""switching to frame: "" + frameId);
+				browser.switchTo().frame(frameId);
+			}
+
+		} else {
+			browser.switchTo().frame(frameIdentification);
+		}
+
+	}
+
+	/**
+	 * @return the dom without the iframe contents.
+	 * @see com.crawljax.browser.EmbeddedBrowser#getDomWithoutIframeContent()
+	 */
+	public String getDomWithoutIframeContent() {
+		try {
+			String dom = browser.getPageSource();
+			// logger.debug(""driver.source: "" + dom);
+			String result = toUniformDOM(dom);
+			// logger.debug(""driver.source toUniformDom: "" + result);
+			return result;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return """";
+		}
+	}
+
+	/**
+	 * @param input
+	 *            the input to be filled.
+	 * @return FormInput with random value assigned if possible
+	 */
+	public FormInput getInputWithRandomValue(FormInput input) {
+
+		WebElement webElement;
+		try {
+			webElement = browser.findElement(input.getIdentification().getWebDriverBy());
+			if (!(webElement.isDisplayed())) {
+
+				return null;
+			}
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return null;
+		}
+
+		Set<InputValue> values = new HashSet<InputValue>();
+
+		// create some random value
+
+		if (input.getType().toLowerCase().startsWith(""text"")) {
+			values.add(new InputValue(new RandomInputValueGenerator()
+			        .getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
+		} else if (input.getType().equalsIgnoreCase(""checkbox"")
+		        || input.getType().equalsIgnoreCase(""radio"") && !webElement.isSelected()) {
+			if (new RandomInputValueGenerator().getCheck()) {
+				values.add(new InputValue(""1"", true));
+			} else {
+				values.add(new InputValue(""0"", false));
+
+			}
+		} else if (input.getType().equalsIgnoreCase(""select"")) {
+			try {
+				Select select = new Select(webElement);
+				WebElement option =
+				        (WebElement) new RandomInputValueGenerator().getRandomOption(select
+				                .getOptions());
+				values.add(new InputValue(option.getText(), true));
+			} catch (WebDriverException e) {
+				throwIfConnectionException(e);
+				return null;
+			}
+		}
+
+		if (values.size() == 0) {
+			return null;
+		}
+		input.setInputValues(values);
+		return input;
+
+	}
+
+	@Override
+	public String getFrameDom(String iframeIdentification) {
+		try {
+
+			switchToFrame(iframeIdentification);
+
+			// make a copy of the dom before changing into the top page
+			String frameDom = browser.getPageSource();
+
+			browser.switchTo().defaultContent();
+
+			return frameDom;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return """";
+		}
+	}
+
+	/**
+	 * @param identification
+	 *            the identification of the element.
+	 * @return true if the element can be found in the DOM tree.
+	 */
+	public boolean elementExists(Identification identification) {
+		try {
+			WebElement el = browser.findElement(identification.getWebDriverBy());
+			// TODO Stefan; I think el will never be null as a NoSuchElementExcpetion will be
+			// thrown, catched below.
+			return el != null;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return false;
+		}
+	}
+
+	/**
+	 * @param identification
+	 *            the identification of the element.
+	 * @return the found element.
+	 */
+	public WebElement getWebElement(Identification identification) {
+		try {
+			return browser.findElement(identification.getWebDriverBy());
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	/**
+	 * @return the period to wait after an event.
+	 */
+	protected long getCrawlWaitEvent() {
+		return crawlWaitEvent;
+	}
+
+	/**
+	 * @return the list of attributes to be filtered from DOM.
+	 */
+	protected List<String> getFilterAttributes() {
+		return filterAttributes;
+	}
+
+	/**
+	 * @return the period to waint after a reload.
+	 */
+	protected long getCrawlWaitReload() {
+		return crawlWaitReload;
+	}
+
+	private void takeScreenShotOnBrowser(WebDriver driver, File file) throws CrawljaxException {
+		if (driver instanceof TakesScreenshot) {
+			File tmpfile = ((TakesScreenshot) driver).getScreenshotAs(OutputType.FILE);
+
+			try {
+				FileHandler.copy(tmpfile, file);
+			} catch (IOException e) {
+				throw new CrawljaxException(e);
+			}
+
+			removeCanvasGeneratedByFirefoxDriverForScreenshots();
+		} else if (driver instanceof RemoteWebDriver) {
+			WebDriver augmentedWebdriver = new Augmenter().augment(driver);
+			takeScreenShotOnBrowser(augmentedWebdriver, file);
+		} else if (driver instanceof WrapsDriver) {
+			takeScreenShotOnBrowser(((WrapsDriver) driver).getWrappedDriver(), file);
+		} else {
+			throw new CrawljaxException(""Your current WebDriver doesn't support screenshots."");
+		}
+	}
+
+	@Override
+	public void saveScreenShot(File file) throws CrawljaxException {
+		try {
+			takeScreenShotOnBrowser(browser, file);
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	private void removeCanvasGeneratedByFirefoxDriverForScreenshots() {
+		String js = """";
+		js += ""var canvas = document.getElementById('fxdriver-screenshot-canvas');"";
+		js += ""if(canvas != null){"";
+		js += ""canvas.parentNode.removeChild(canvas);"";
+		js += ""}"";
+		try {
+			executeJavaScript(js);
+		} catch (CrawljaxException e) {
+			LOGGER.error(""Removing of Canvas Generated By FirefoxDriver failed,""
+			        + "" most likely leaving it in the browser"", e);
+		}
+	}
+
+	/**
+	 * @return the WebDriver used as an EmbeddedBrowser.
+	 */
+	public WebDriver getBrowser() {
+		return browser;
+	}
+
+	@Override
+	public void updateConfiguration(CrawljaxConfigurationReader configuration) {
+		// Retrieve the config values used
+		this.filterAttributes = configuration.getFilterAttributeNames();
+		this.crawlWaitReload =
+		        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
+		this.crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
+		this.ignoreFrameChecker = configuration.getCrawlSpecificationReader();
+	}
+
+	private boolean exceptionIsConnectionException(WebDriverException exception) {
+		return exception != null && exception.getCause() != null
+		        && exception.getCause() instanceof IOException;
+	}
+
+	private RuntimeException wrapWebDriverExceptionIfConnectionException(
+	        WebDriverException exception) {
+		if (exceptionIsConnectionException(exception)) {
+			return new BrowserConnectionException(exception);
+		}
+		return exception;
+	}
+
+	private void throwIfConnectionException(WebDriverException exception) {
+		if (exceptionIsConnectionException(exception)) {
+			throw wrapWebDriverExceptionIfConnectionException(exception);
+		}
+	}
+}
"
08b2d85ebd395ff2948c9f1cc594a24b5aaedea7,Ali Mesbah,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/src/main/java/com/crawljax/core/CrawljaxController.java b/src/main/java/com/crawljax/core/CrawljaxController.java
index 7a3b33b..61d1efd 100644
--- a/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -17,7 +17,8 @@
 import net.jcip.annotations.GuardedBy;
 
 import org.apache.commons.configuration.ConfigurationException;
-import org.apache.log4j.Logger;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 
 import java.util.List;
 import java.util.concurrent.TimeUnit;
@@ -30,7 +31,7 @@
  */
 public class CrawljaxController implements CrawlQueueManager {
 
-	private static final Logger LOGGER = Logger.getLogger(CrawljaxController.class.getName());
+	private static final Logger LOGGER = LoggerFactory.getLogger(CrawljaxController.class.getName());
 
 	private CrawlSession session;
 
"
08b2d85ebd395ff2948c9f1cc594a24b5aaedea7,Ali Mesbah,StateFlowGraph.java,MODIFY,"addState -> [StateVertix stateVertix, boolean correctName] | [StateVertix stateVertix]","diff --git a/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index a38fa43..bbcead3 100644
--- a/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -3,7 +3,8 @@
 import net.jcip.annotations.GuardedBy;
 
 import org.apache.commons.math.stat.descriptive.moment.Mean;
-import org.apache.log4j.Logger;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 import org.jgrapht.DirectedGraph;
 import org.jgrapht.GraphPath;
 import org.jgrapht.alg.DijkstraShortestPath;
@@ -23,7 +24,7 @@
  * @version $Id$
  */
 public class StateFlowGraph {
-	private static final Logger LOGGER = Logger.getLogger(StateFlowGraph.class.getName());
+	private static final Logger LOGGER = LoggerFactory.getLogger(StateFlowGraph.class.getName());
 
 	private final DirectedGraph<StateVertix, Eventable> sfg;
 
"
08b2d85ebd395ff2948c9f1cc594a24b5aaedea7,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 439d088..cf51040 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -11,7 +11,8 @@
 import com.crawljax.util.Helper;
 import com.crawljax.util.XPathHelper;
 
-import org.apache.log4j.Logger;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 import org.w3c.dom.Document;
 import org.w3c.dom.Element;
 import org.w3c.dom.Node;
@@ -33,7 +34,7 @@
  * @version $Id$
  */
 public class FormHandler {
-	private static final Logger LOGGER = Logger.getLogger(FormHandler.class.getName());
+	private static final Logger LOGGER = LoggerFactory.getLogger(FormHandler.class.getName());
 
 	private boolean randomFieldValue = false;
 	private final EmbeddedBrowser browser;
"
08b2d85ebd395ff2948c9f1cc594a24b5aaedea7,Ali Mesbah,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/src/main/java/com/crawljax/util/ElementResolver.java b/src/main/java/com/crawljax/util/ElementResolver.java
index c50af37..65a531d 100644
--- a/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/src/main/java/com/crawljax/util/ElementResolver.java
@@ -1,151 +1,152 @@
-package com.crawljax.util;
-
-import com.crawljax.browser.EmbeddedBrowser;
-import com.crawljax.core.state.Element;
-import com.crawljax.core.state.Eventable;
-
-import org.apache.log4j.Logger;
-import org.w3c.dom.Document;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-import org.xml.sax.SAXException;
-
-import java.io.IOException;
-
-import javax.xml.xpath.XPathExpressionException;
-
-/**
- * class for finding and checking elements.
- * 
- * @author danny
- * @version $Id$
- */
-public class ElementResolver {
-	private static final Logger LOGGER = Logger.getLogger(ElementResolver.class.getName());
-
-	// private ElementResolverSettings settings = new
-	// ElementResolverSettings();
-
-	private final EmbeddedBrowser browser;
-	private final Eventable eventable;
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param eventable
-	 *            Eventable.
-	 * @param browser
-	 *            The browser.
-	 */
-	public ElementResolver(Eventable eventable, EmbeddedBrowser browser) {
-		this.browser = browser;
-		this.eventable = eventable;
-	}
-
-	/**
-	 * @return equivalent xpath of element equivalent to Eventable
-	 */
-	public String resolve() {
-		return resolve(false);
-	}
-
-	/**
-	 * @param logging
-	 *            Whether to do logging.
-	 * @return equivalent xpath of element equivalent to Eventable
-	 */
-	public String resolve(boolean logging) {
-		Document dom = null;
-		try {
-	        dom = Helper.getDocument(browser.getDom());
-		} catch (SAXException e) {
-			LOGGER.error(e.getMessage(), e);
-			return """";
-		} catch (IOException e) {
-			LOGGER.error(e.getMessage(), e);
-			return """";
-		}
-		
-		try {
-			String xpathEventable = eventable.getIdentification().getValue();
-			Node nodeSameXpath = Helper.getElementByXpath(dom, xpathEventable);
-			if (nodeSameXpath != null) {
-				Element elementSameXpath = new Element(nodeSameXpath);
-				if (logging) {
-					LOGGER.info(""Try element with same xpath expression"");
-				}
-				if (equivalent(elementSameXpath, logging)) {
-					return xpathEventable;
-				}
-			}
-
-			if (logging) {
-				LOGGER.info(""Search other candidate elements"");
-			}
-			NodeList candidateElements =
-			        XPathHelper.evaluateXpathExpression(dom, ""//""
-			                + eventable.getElement().getTag().toUpperCase());
-			if (logging) {
-				LOGGER.info(""Candidates: "" + candidateElements.getLength());
-			}
-			for (int i = 0; i < candidateElements.getLength(); i++) {
-				Element candidateElement = new Element(candidateElements.item(i));
-				if (equivalent(candidateElement, logging)) {
-					return XPathHelper.getXPathExpression(candidateElements.item(i));
-				}
-			}
-
-		} catch (XPathExpressionException e) {
-			LOGGER.error(e.getMessage(), e);
-		}
-		if (logging) {
-			LOGGER.info(""No equivalent element found"");
-		}
-		return null;
-	}
-
-	/**
-	 * Comparator against other element.
-	 * 
-	 * @param otherElement
-	 *            The other element.
-	 * @param logging
-	 *            Whether to do logging.
-	 * @return Whether the elements are equal.
-	 */
-	public boolean equivalent(Element otherElement, boolean logging) {
-		if (eventable.getElement().equals(otherElement)) {
-			if (logging) {
-				LOGGER.info(""Element equal"");
-			}
-			return true;
-		}
-
-		if (eventable.getElement().equalAttributes(otherElement)) {
-			if (logging) {
-				LOGGER.info(""Element attributes equal"");
-			}
-			return true;
-		}
-
-		if (eventable.getElement().equalId(otherElement)) {
-			if (logging) {
-				LOGGER.info(""Element ID equal"");
-			}
-			return true;
-		}
-
-		if (!eventable.getElement().getText().equals("""")
-		        && eventable.getElement().equalText(otherElement)) {
-
-			if (logging) {
-				LOGGER.info(""Element text equal"");
-			}
-
-			return true;
-		}
-
-		return false;
-	}
-
-}
+package com.crawljax.util;
+
+import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.core.state.Element;
+import com.crawljax.core.state.Eventable;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.w3c.dom.Document;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+import org.xml.sax.SAXException;
+
+import java.io.IOException;
+
+import javax.xml.xpath.XPathExpressionException;
+
+/**
+ * class for finding and checking elements.
+ * 
+ * @author danny
+ * @version $Id$
+ */
+public class ElementResolver {
+	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class.getName());
+
+	// private ElementResolverSettings settings = new
+	// ElementResolverSettings();
+
+	private final EmbeddedBrowser browser;
+	private final Eventable eventable;
+
+	/**
+	 * Constructor.
+	 * 
+	 * @param eventable
+	 *            Eventable.
+	 * @param browser
+	 *            The browser.
+	 */
+	public ElementResolver(Eventable eventable, EmbeddedBrowser browser) {
+		this.browser = browser;
+		this.eventable = eventable;
+	}
+
+	/**
+	 * @return equivalent xpath of element equivalent to Eventable
+	 */
+	public String resolve() {
+		return resolve(false);
+	}
+
+	/**
+	 * @param logging
+	 *            Whether to do logging.
+	 * @return equivalent xpath of element equivalent to Eventable
+	 */
+	public String resolve(boolean logging) {
+		Document dom = null;
+		try {
+	        dom = Helper.getDocument(browser.getDom());
+		} catch (SAXException e) {
+			LOGGER.error(e.getMessage(), e);
+			return """";
+		} catch (IOException e) {
+			LOGGER.error(e.getMessage(), e);
+			return """";
+		}
+		
+		try {
+			String xpathEventable = eventable.getIdentification().getValue();
+			Node nodeSameXpath = Helper.getElementByXpath(dom, xpathEventable);
+			if (nodeSameXpath != null) {
+				Element elementSameXpath = new Element(nodeSameXpath);
+				if (logging) {
+					LOGGER.info(""Try element with same xpath expression"");
+				}
+				if (equivalent(elementSameXpath, logging)) {
+					return xpathEventable;
+				}
+			}
+
+			if (logging) {
+				LOGGER.info(""Search other candidate elements"");
+			}
+			NodeList candidateElements =
+			        XPathHelper.evaluateXpathExpression(dom, ""//""
+			                + eventable.getElement().getTag().toUpperCase());
+			if (logging) {
+				LOGGER.info(""Candidates: "" + candidateElements.getLength());
+			}
+			for (int i = 0; i < candidateElements.getLength(); i++) {
+				Element candidateElement = new Element(candidateElements.item(i));
+				if (equivalent(candidateElement, logging)) {
+					return XPathHelper.getXPathExpression(candidateElements.item(i));
+				}
+			}
+
+		} catch (XPathExpressionException e) {
+			LOGGER.error(e.getMessage(), e);
+		}
+		if (logging) {
+			LOGGER.info(""No equivalent element found"");
+		}
+		return null;
+	}
+
+	/**
+	 * Comparator against other element.
+	 * 
+	 * @param otherElement
+	 *            The other element.
+	 * @param logging
+	 *            Whether to do logging.
+	 * @return Whether the elements are equal.
+	 */
+	public boolean equivalent(Element otherElement, boolean logging) {
+		if (eventable.getElement().equals(otherElement)) {
+			if (logging) {
+				LOGGER.info(""Element equal"");
+			}
+			return true;
+		}
+
+		if (eventable.getElement().equalAttributes(otherElement)) {
+			if (logging) {
+				LOGGER.info(""Element attributes equal"");
+			}
+			return true;
+		}
+
+		if (eventable.getElement().equalId(otherElement)) {
+			if (logging) {
+				LOGGER.info(""Element ID equal"");
+			}
+			return true;
+		}
+
+		if (!eventable.getElement().getText().equals("""")
+		        && eventable.getElement().equalText(otherElement)) {
+
+			if (logging) {
+				LOGGER.info(""Element text equal"");
+			}
+
+			return true;
+		}
+
+		return false;
+	}
+
+}
"
08b2d85ebd395ff2948c9f1cc594a24b5aaedea7,Ali Mesbah,Helper.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/src/main/java/com/crawljax/util/Helper.java b/src/main/java/com/crawljax/util/Helper.java
index 16e21e5..e4815b8 100644
--- a/src/main/java/com/crawljax/util/Helper.java
+++ b/src/main/java/com/crawljax/util/Helper.java
@@ -1,797 +1,798 @@
-package com.crawljax.util;
-
-import java.io.BufferedReader;
-import java.io.ByteArrayOutputStream;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.FileOutputStream;
-import java.io.FileReader;
-import java.io.FileWriter;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.InputStreamReader;
-import java.io.StringReader;
-import java.io.StringWriter;
-import java.net.MalformedURLException;
-import java.net.URL;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-import java.util.regex.PatternSyntaxException;
-
-import javax.xml.transform.OutputKeys;
-import javax.xml.transform.Result;
-import javax.xml.transform.Source;
-import javax.xml.transform.Transformer;
-import javax.xml.transform.TransformerConfigurationException;
-import javax.xml.transform.TransformerException;
-import javax.xml.transform.TransformerFactory;
-import javax.xml.transform.dom.DOMSource;
-import javax.xml.transform.stream.StreamResult;
-import javax.xml.xpath.XPath;
-import javax.xml.xpath.XPathConstants;
-import javax.xml.xpath.XPathExpressionException;
-import javax.xml.xpath.XPathFactory;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.log4j.Logger;
-import org.custommonkey.xmlunit.DetailedDiff;
-import org.custommonkey.xmlunit.Diff;
-import org.custommonkey.xmlunit.Difference;
-import org.custommonkey.xmlunit.DifferenceListener;
-import org.cyberneko.html.parsers.DOMParser;
-import org.w3c.dom.Attr;
-import org.w3c.dom.Document;
-import org.w3c.dom.Element;
-import org.w3c.dom.NamedNodeMap;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-import org.xml.sax.InputSource;
-import org.xml.sax.SAXException;
-
-import com.google.common.collect.Lists;
-
-/**
- * Utility class that contains a number of helper functions used by Crawljax and some plugins.
- * 
- * @author mesbah
- * @version $Id$
- */
-public final class Helper {
-
-	private static final int BASE_LENGTH = 3;
-
-	private static final int TEXT_CUTOFF = 50;
-
-	public static final Logger LOGGER = Logger.getLogger(Helper.class.getName());
-
-	private Helper() {
-	}
-
-	/**
-	 * Internal used function to strip the basePath from a given url.
-	 * 
-	 * @param url
-	 *            the url to examine
-	 * @return the base path with file stipped
-	 */
-	private static String getBasePath(URL url) {
-		String file = url.getFile().replaceAll(""\\*"", """");
-
-		try {
-			return url.getPath().replaceAll(file, """");
-		} catch (PatternSyntaxException pe) {
-			LOGGER.error(pe.getMessage());
-			return """";
-		}
-
-	}
-
-	/**
-	 * @param location
-	 *            Current location.
-	 * @param link
-	 *            Link to check.
-	 * @return Whether location and link are on the same domain.
-	 */
-	public static boolean isLinkExternal(String location, String link) {
-
-		if (!location.contains(""://"")) {
-			// location must always contain :// by rule, it not link is handled as not external
-			return false;
-		}
-
-		// This will jump out of the local file location
-		if (location.startsWith(""file"") && link.startsWith(""/"")) {
-			return true;
-		}
-
-		if (link.contains(""://"")) {
-			if (location.startsWith(""file"") && link.startsWith(""http"") || link.startsWith(""file"")
-			        && location.startsWith(""http"")) {
-				// Jump from file to http(s) or from http(s) to file, so external
-				return true;
-			}
-			try {
-				URL locationUrl = new URL(location);
-				try {
-					URL linkUrl = new URL(link);
-					if (linkUrl.getHost().equals(locationUrl.getHost())) {
-						String linkPath = getBasePath(linkUrl);
-						return !(linkPath.startsWith(getBasePath(locationUrl)));
-					}
-					return true;
-				} catch (MalformedURLException e) {
-					LOGGER.info(""Can not parse link "" + link + "" to check its externalOf ""
-					        + location);
-					return false;
-				}
-			} catch (MalformedURLException e) {
-				LOGGER.info(""Can not parse location "" + location + "" to check if "" + link
-				        + "" isExternal"", e);
-				return false;
-			}
-		} else {
-			// No full url specifier so internal link...
-			return false;
-		}
-	}
-
-	/**
-	 * @param url
-	 *            the URL string.
-	 * @return the base part of the URL.
-	 */
-	public static String getBaseUrl(String url) {
-		String head = url.substring(0, url.indexOf("":""));
-		String subLoc = url.substring(head.length() + BASE_LENGTH);
-		return head + ""://"" + subLoc.substring(0, subLoc.indexOf(""/""));
-	}
-
-	/**
-	 * transforms a string into a Document object. TODO This needs more optimizations. As it seems
-	 * the getDocument is called way too much times causing a lot of parsing which is slow and not
-	 * necessary.
-	 * 
-	 * @param html
-	 *            the HTML string.
-	 * @return The DOM Document version of the HTML string.
-	 * @throws IOException
-	 *             if an IO failure occurs.
-	 * @throws SAXException
-	 *             if an exception occurs while parsing the HTML string.
-	 */
-	public static Document getDocument(String html) throws SAXException, IOException {
-		DOMParser domParser = new DOMParser();
-		domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
-		domParser.setFeature(""http://xml.org/sax/features/namespaces"", false);
-		domParser.parse(new InputSource(new StringReader(html)));
-		return domParser.getDocument();
-	}
-
-	/**
-	 * @param html
-	 *            the HTML string.
-	 * @return a Document object made from the HTML string.
-	 * @throws SAXException
-	 *             if an exception occurs while parsing the HTML string.
-	 * @throws IOException
-	 *             if an IO failure occurs.
-	 */
-	public static Document getDocumentNoBalance(String html) throws SAXException, IOException {
-		DOMParser domParser = new DOMParser();
-		domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
-		domParser.setFeature(""http://cyberneko.org/html/features/balance-tags"", false);
-		domParser.parse(new InputSource(new StringReader(html)));
-		return domParser.getDocument();
-	}
-
-	/**
-	 * @param element
-	 *            The DOM Element.
-	 * @return A string representation of all the element's attributes.
-	 */
-	public static String getAllElementAttributes(Element element) {
-		return getElementAttributes(element, new ArrayList<String>());
-	}
-
-	/**
-	 * @param element
-	 *            The DOM Element.
-	 * @param exclude
-	 *            the list of exclude strings.
-	 * @return A string representation of the element's attributes excluding exclude.
-	 */
-	public static String getElementAttributes(Element element, List<String> exclude) {
-		StringBuffer buffer = new StringBuffer();
-
-		if (element != null) {
-			NamedNodeMap attributes = element.getAttributes();
-			if (attributes != null) {
-				for (int i = 0; i < attributes.getLength(); i++) {
-					Attr attr = (Attr) attributes.item(i);
-					if (!exclude.contains(attr.getNodeName())) {
-						buffer.append(attr.getNodeName() + ""="");
-						buffer.append(attr.getNodeValue() + "" "");
-					}
-				}
-			}
-		}
-
-		return buffer.toString().trim();
-	}
-
-	/**
-	 * @param element
-	 *            the element.
-	 * @return a string representation of the element including its attributes.
-	 */
-	public static String getElementString(Element element) {
-		if (element == null) {
-			return """";
-		}
-		String text = Helper.removeNewLines(Helper.getTextValue(element)).trim();
-		String info = """";
-		if (!text.equals("""")) {
-			info += ""\"""" + text + ""\"" "";
-			// Helper.removeNewLines(this.text.trim()) + "" - "";
-		}
-		if (element != null) {
-			if (element.hasAttribute(""id"")) {
-				info += ""ID: "" + element.getAttribute(""id"") + "" "";
-			}
-			info += Helper.getAllElementAttributes(element) + "" "";
-		}
-		return info;
-	}
-
-	/**
-	 * @param dom
-	 *            the DOM document.
-	 * @param xpath
-	 *            the xpath.
-	 * @return The element found on DOM having the xpath position.
-	 * @throws XPathExpressionException
-	 *             if the xpath fails.
-	 */
-	public static Element getElementByXpath(Document dom, String xpath)
-	        throws XPathExpressionException {
-		XPath xp = XPathFactory.newInstance().newXPath();
-		xp.setNamespaceContext(new HtmlNamespace());
-
-		return (Element) xp.evaluate(xpath, dom, XPathConstants.NODE);
-	}
-
-	/**
-	 * Removes all the <SCRIPT/> tags from the document.
-	 * 
-	 * @param dom
-	 *            the document object.
-	 * @return the changed dom.
-	 */
-	public static Document removeScriptTags(Document dom) {
-		return removeTags(dom, ""SCRIPT"");
-	}
-
-	/**
-	 * Removes all the given tags from the document.
-	 * 
-	 * @param dom
-	 *            the document object.
-	 * @param tagName
-	 *            the tag name, examples: script, style, meta
-	 * @return the changed dom.
-	 */
-	public static Document removeTags(Document dom, String tagName) {
-		if (dom != null) {
-			// NodeList list = dom.getElementsByTagName(""SCRIPT"");
-
-			NodeList list;
-			try {
-				list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
-
-				while (list.getLength() > 0) {
-					Node sc = list.item(0);
-
-					if (sc != null) {
-						sc.getParentNode().removeChild(sc);
-					}
-
-					list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
-					// list = dom.getElementsByTagName(""SCRIPT"");
-				}
-			} catch (XPathExpressionException e) {
-				LOGGER.error(e.getMessage(), e);
-			}
-
-			return dom;
-		}
-
-		return null;
-	}
-
-	/**
-	 * Checks the existence of the directory. If it does not exist, the method creates it.
-	 * 
-	 * @param dir
-	 *            the directory to check.
-	 * @throws IOException
-	 *             if fails.
-	 */
-	public static void directoryCheck(String dir) throws IOException {
-		final File file = new File(dir);
-
-		if (!file.exists()) {
-			FileUtils.forceMkdir(file);
-		}
-	}
-
-	/**
-	 * Checks whether the folder exists for fname, and creates it if neccessary.
-	 * 
-	 * @param fname
-	 *            folder name.
-	 * @throws IOException
-	 *             an IO exception.
-	 */
-	public static void checkFolderForFile(String fname) throws IOException {
-
-		if (fname.lastIndexOf(File.separator) > 0) {
-			String folder = fname.substring(0, fname.lastIndexOf(File.separator));
-			Helper.directoryCheck(folder);
-		}
-	}
-
-	/**
-	 * Retrieve the var value for varName from a HTTP query string (format is
-	 * ""var1=val1&var2=val2"").
-	 * 
-	 * @param varName
-	 *            the name.
-	 * @param haystack
-	 *            the haystack.
-	 * @return variable value for varName
-	 */
-	public static String getVarFromQueryString(String varName, String haystack) {
-		if (haystack == null || haystack.length() == 0) {
-			return null;
-		}
-		if (haystack.charAt(0) == '?') {
-			haystack = haystack.substring(1);
-		}
-		String[] vars = haystack.split(""&"");
-
-		for (String var : vars) {
-			String[] tuple = var.split(""="");
-			if (tuple.length == 2 && tuple[0].equals(varName)) {
-				return tuple[1];
-			}
-		}
-		return null;
-	}
-
-	/**
-	 * @param dom
-	 *            the DOM document.
-	 * @return a string representation of the DOM.
-	 */
-	public static String getDocumentToString(Document dom) {
-		try {
-			Source source = new DOMSource(dom);
-			StringWriter stringWriter = new StringWriter();
-			Result result = new StreamResult(stringWriter);
-			TransformerFactory factory = TransformerFactory.newInstance();
-			Transformer transformer = factory.newTransformer();
-			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
-			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""yes"");
-			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
-			transformer.transform(source, result);
-			return stringWriter.getBuffer().toString();
-		} catch (TransformerConfigurationException e) {
-			LOGGER.error(e.getMessage(), e);
-		} catch (TransformerException e) {
-			LOGGER.error(e.getMessage(), e);
-		}
-		return null;
-
-	}
-
-	/**
-	 * Serialize the Document object.
-	 * 
-	 * @param dom
-	 *            the document to serialize
-	 * @return the serialized dom String
-	 */
-	public static byte[] getDocumentToByteArray(Document dom) {
-		try {
-			TransformerFactory tFactory = TransformerFactory.newInstance();
-
-			Transformer transformer = tFactory.newTransformer();
-			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
-			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
-			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
-			// TODO should be fixed to read doctype declaration
-			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			// ""-//W3C//DTD XHTML 1.0 Transitional//EN\""
-			// \""http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"");
-			transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			        ""-//W3C//DTD XHTML 1.0 Strict//EN\"" ""
-			                + ""\""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"");
-
-			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			// ""-//W3C//DTD HTML 4.01//EN\"" \""http://www.w3.org/TR/html4/strict.dtd"");
-			DOMSource source = new DOMSource(dom);
-
-			ByteArrayOutputStream out = new ByteArrayOutputStream();
-			Result result = new StreamResult(out);
-			transformer.transform(source, result);
-
-			// System.out.println(""Injected Javascript!"");
-			return out.toByteArray();
-		} catch (TransformerConfigurationException e) {
-			LOGGER.error(e.getMessage(), e);
-		} catch (TransformerException e) {
-			LOGGER.error(e.getMessage(), e);
-		}
-		return null;
-
-	}
-
-	/**
-	 * Save a string to a file and append a newline character to that string.
-	 * 
-	 * @param filename
-	 *            The filename to save to.
-	 * @param text
-	 *            The text to save.
-	 * @param append
-	 *            Whether to append to existing file.
-	 * @throws IOException
-	 *             On error.
-	 */
-	public static void writeToFile(String filename, String text, boolean append)
-	        throws IOException {
-		FileWriter fw = new FileWriter(filename, append);
-		try {
-			fw.write(text + ""\n"");
-		} catch (IOException e) {
-			throw e;
-		} finally {
-			fw.close();
-		}
-	}
-
-	/**
-	 * @param code
-	 *            hashcode.
-	 * @return String version of hashcode.
-	 */
-	public static String hashCodeToString(long code) {
-		if (code < 0) {
-			return ""0"" + (code * -1);
-		} else {
-			return """" + code;
-		}
-	}
-
-	/**
-	 * Returns the text value of an element (title, alt or contents). Note that the result is 50
-	 * characters or less in length.
-	 * 
-	 * @param element
-	 *            The element.
-	 * @return The text value of the element.
-	 */
-	public static String getTextValue(Element element) {
-		String ret = """";
-		if (element == null) {
-			return """";
-		}
-
-		if (element.getTextContent() != null) {
-			ret = element.getTextContent();
-		} else if (element.hasAttribute(""title"")) {
-			ret = element.getAttribute(""title"");
-		} else if (element.hasAttribute(""alt"")) {
-			ret = element.getAttribute(""alt"");
-		}
-		if (ret.length() > TEXT_CUTOFF) {
-			return ret.substring(0, TEXT_CUTOFF);
-		} else {
-			return ret;
-		}
-	}
-
-	/**
-	 * Get differences between doms.
-	 * 
-	 * @param controlDom
-	 *            The control dom.
-	 * @param testDom
-	 *            The test dom.
-	 * @return The differences.
-	 */
-	public static List<Difference> getDifferences(String controlDom, String testDom) {
-		return getDifferences(controlDom, testDom, Lists.<String> newArrayList());
-	}
-
-	/**
-	 * Get differences between doms.
-	 * 
-	 * @param controlDom
-	 *            The control dom.
-	 * @param testDom
-	 *            The test dom.
-	 * @param ignoreAttributes
-	 *            The list of attributes to ignore.
-	 * @return The differences.
-	 */
-	@SuppressWarnings(""unchecked"")
-	public static List<Difference> getDifferences(String controlDom, String testDom,
-	        final List<String> ignoreAttributes) {
-		try {
-			Diff d = new Diff(Helper.getDocument(controlDom), Helper.getDocument(testDom));
-			DetailedDiff dd = new DetailedDiff(d);
-			dd.overrideDifferenceListener(new DifferenceListener() {
-
-				@Override
-				public void skippedComparison(Node control, Node test) {
-				}
-
-				@Override
-				public int differenceFound(Difference difference) {
-					if (difference.getControlNodeDetail() == null
-					        || difference.getControlNodeDetail().getNode() == null
-					        || difference.getTestNodeDetail() == null
-					        || difference.getTestNodeDetail().getNode() == null) {
-						return RETURN_ACCEPT_DIFFERENCE;
-					}
-					if (ignoreAttributes.contains(difference.getTestNodeDetail().getNode()
-					        .getNodeName())
-					        || ignoreAttributes.contains(difference.getControlNodeDetail()
-					                .getNode().getNodeName())) {
-						return RETURN_IGNORE_DIFFERENCE_NODES_IDENTICAL;
-					}
-					return RETURN_ACCEPT_DIFFERENCE;
-				}
-			});
-
-			return dd.getAllDifferences();
-		} catch (Exception e) {
-			LOGGER.error(""Error with getDifferences: "" + e.getMessage(), e);
-		}
-		return null;
-	}
-
-	/**
-	 * Removes newlines from a string.
-	 * 
-	 * @param html
-	 *            The string.
-	 * @return The new string without the newlines or tabs.
-	 */
-	public static String removeNewLines(String html) {
-		return html.replaceAll(""[\\t\\n\\x0B\\f\\r]"", """");
-	}
-
-	/**
-	 * @param string
-	 *            The original string.
-	 * @param regex
-	 *            The regular expression.
-	 * @param replace
-	 *            What to replace it with.
-	 * @return replaces regex in str by replace where the dot sign also supports newlines
-	 */
-	public static String replaceString(String string, String regex, String replace) {
-		Pattern p = Pattern.compile(regex, Pattern.DOTALL);
-		Matcher m = p.matcher(string);
-		String replaced = m.replaceAll(replace);
-		p = Pattern.compile(""  "", Pattern.DOTALL);
-		m = p.matcher(replaced);
-		return m.replaceAll("" "");
-	}
-
-	/**
-	 * Adds a slash to a path if it doesn't end with a slash.
-	 * 
-	 * @param folderName
-	 *            The path to append a possible slash.
-	 * @return The new, correct path.
-	 */
-	public static String addFolderSlashIfNeeded(String folderName) {
-		if (!folderName.equals("""") && !folderName.endsWith(""/"")) {
-			return folderName + ""/"";
-		} else {
-			return folderName;
-		}
-	}
-
-	/**
-	 * Returns the filename in a path. For example with path = ""foo/bar/crawljax.txt"" returns
-	 * ""crawljax.txt""
-	 * 
-	 * @param path
-	 * @return the filename from the path
-	 */
-	private static String getFileNameInPath(String path) {
-		String fname;
-		if (path.indexOf(""/"") != -1) {
-			fname = path.substring(path.lastIndexOf(""/"") + 1);
-		} else {
-			fname = path;
-		}
-		return fname;
-	}
-
-	/**
-	 * Retrieves the content of the filename. Also reads from JAR Searches for the resource in the
-	 * root folder in the jar
-	 * 
-	 * @param fname
-	 *            Filename.
-	 * @return The contents of the file.
-	 * @throws IOException
-	 *             On error.
-	 */
-	public static String getTemplateAsString(String fname) throws IOException {
-		// in .jar file
-		String fnameJar = getFileNameInPath(fname);
-		InputStream inStream = Helper.class.getResourceAsStream(""/"" + fnameJar);
-		if (inStream == null) {
-			// try to find file normally
-			File f = new File(fname);
-			if (f.exists()) {
-				inStream = new FileInputStream(f);
-			} else {
-				throw new IOException(""Cannot find "" + fname + "" or "" + fnameJar);
-			}
-		}
-
-		BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inStream));
-		String line;
-		StringBuilder stringBuilder = new StringBuilder();
-
-		while ((line = bufferedReader.readLine()) != null) {
-			stringBuilder.append(line + ""\n"");
-		}
-
-		bufferedReader.close();
-		return stringBuilder.toString();
-	}
-
-	/**
-	 * @param xpath
-	 *            The xpath of the element.
-	 * @return The JavaScript to get an element.
-	 */
-	public static String getJSGetElement(String xpath) {
-		String js =
-		        """"
-		                + ""function ATUSA_getElementInNodes(nodes, tagName, number){""
-		                + ""try{""
-		                + ""var pos = 1;""
-		                + ""for(i=0; i<nodes.length; i++){""
-		                + ""if(nodes[i]!=null && nodes[i].tagName!=null && ""
-		                + ""nodes[i].tagName.toLowerCase() == tagName){""
-		                + ""if(number==pos){""
-		                + ""return nodes[i];""
-		                + ""}else{""
-		                + ""pos++;""
-		                + ""}""
-		                + ""}""
-		                + ""}""
-		                + ""}catch(e){}""
-		                + ""return null;""
-		                + ""}""
-		                + ""function ATUSA_getElementByXpath(xpath){""
-		                + ""try{""
-		                + ""var elements = xpath.toLowerCase().split('/');""
-		                + ""var curNode = window.document.body;""
-		                + ""var tagName, number;""
-		                + ""for(j=0; j<elements.length; j++){""
-		                + ""if(elements[j]!=''){""
-		                + ""if(elements[j].indexOf('[')==-1){""
-		                + ""tagName = elements[j];""
-		                + ""number = 1;""
-		                + ""}else{""
-		                + ""tagName = elements[j].substring(0, elements[j].indexOf('['));""
-		                + ""number = elements[j].substring(elements[j].indexOf('[')+1, ""
-		                + ""elements[j].lastIndexOf(']'));""
-		                + ""}""
-		                + ""if(tagName!='body' && tagName!='html'){""
-		                + ""curNode = ATUSA_getElementInNodes(curNode.childNodes, tagName, number);""
-		                + ""if(curNode==null){"" + ""return null;"" + ""}"" + ""}"" + ""}"" + ""}""
-		                + ""}catch(e){return null;}"" + ""return curNode;"" + ""}""
-		                + ""try{var ATUSA_element = ATUSA_getElementByXpath('"" + xpath
-		                + ""');}catch(e){return null;}"";
-
-		return js;
-	}
-
-	/**
-	 * @param frame
-	 *            the frame element.
-	 * @return the name or id of this element if they are present, otherwise null.
-	 */
-	public static String getFrameIdentification(Element frame) {
-
-		Attr attr = frame.getAttributeNode(""id"");
-		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
-			return attr.getNodeValue();
-		}
-
-		attr = frame.getAttributeNode(""name"");
-		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
-			return attr.getNodeValue();
-		}
-
-		return null;
-
-	}
-
-	/**
-	 * Write the document object to a file.
-	 * 
-	 * @param document
-	 *            the document object.
-	 * @param filePathname
-	 *            the path name of the file to be written to.
-	 * @param method
-	 *            the output method: for instance html, xml, text
-	 * @param indent
-	 *            amount of indentation. -1 to use the default.
-	 * @throws TransformerException
-	 *             if an exception occurs.
-	 * @throws IOException
-	 *             if an IO exception occurs.
-	 */
-	public static void writeDocumentToFile(Document document, String filePathname, String method,
-	        int indent) throws TransformerException, IOException {
-
-		checkFolderForFile(filePathname);
-		Transformer transformer = TransformerFactory.newInstance().newTransformer();
-		transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
-		transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
-		transformer.setOutputProperty(OutputKeys.METHOD, method);
-
-		if (indent > -1) {
-			transformer.setOutputProperty(
-			        org.apache.xml.serializer.OutputPropertiesFactory.S_KEY_INDENT_AMOUNT,
-			        Integer.toString(indent));
-		}
-		transformer.transform(new DOMSource(document), new StreamResult(new FileOutputStream(
-		        filePathname)));
-	}
-
-	/**
-	 * Returns the file contents without stripping line-endings.
-	 * 
-	 * @param file
-	 *            File to read out.
-	 * @return Contents including line-endings.
-	 */
-	public static String getContent(File file) {
-		StringBuilder contents = new StringBuilder();
-
-		try {
-			BufferedReader input = new BufferedReader(new FileReader(file));
-			try {
-				String line = null; // not declared within while loop
-				while ((line = input.readLine()) != null) {
-					contents.append(line);
-					contents.append(""\n"");
-				}
-			} finally {
-				input.close();
-			}
-		} catch (IOException e) {
-			e.printStackTrace();
-		}
-
-		return contents.toString();
-	}
-
-}
+package com.crawljax.util;
+
+import java.io.BufferedReader;
+import java.io.ByteArrayOutputStream;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.FileReader;
+import java.io.FileWriter;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.io.StringReader;
+import java.io.StringWriter;
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.regex.PatternSyntaxException;
+
+import javax.xml.transform.OutputKeys;
+import javax.xml.transform.Result;
+import javax.xml.transform.Source;
+import javax.xml.transform.Transformer;
+import javax.xml.transform.TransformerConfigurationException;
+import javax.xml.transform.TransformerException;
+import javax.xml.transform.TransformerFactory;
+import javax.xml.transform.dom.DOMSource;
+import javax.xml.transform.stream.StreamResult;
+import javax.xml.xpath.XPath;
+import javax.xml.xpath.XPathConstants;
+import javax.xml.xpath.XPathExpressionException;
+import javax.xml.xpath.XPathFactory;
+
+import org.apache.commons.io.FileUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.custommonkey.xmlunit.DetailedDiff;
+import org.custommonkey.xmlunit.Diff;
+import org.custommonkey.xmlunit.Difference;
+import org.custommonkey.xmlunit.DifferenceListener;
+import org.cyberneko.html.parsers.DOMParser;
+import org.w3c.dom.Attr;
+import org.w3c.dom.Document;
+import org.w3c.dom.Element;
+import org.w3c.dom.NamedNodeMap;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+import org.xml.sax.InputSource;
+import org.xml.sax.SAXException;
+
+import com.google.common.collect.Lists;
+
+/**
+ * Utility class that contains a number of helper functions used by Crawljax and some plugins.
+ * 
+ * @author mesbah
+ * @version $Id$
+ */
+public final class Helper {
+
+	private static final int BASE_LENGTH = 3;
+
+	private static final int TEXT_CUTOFF = 50;
+
+	public static final Logger LOGGER = LoggerFactory.getLogger(Helper.class.getName());
+
+	private Helper() {
+	}
+
+	/**
+	 * Internal used function to strip the basePath from a given url.
+	 * 
+	 * @param url
+	 *            the url to examine
+	 * @return the base path with file stipped
+	 */
+	private static String getBasePath(URL url) {
+		String file = url.getFile().replaceAll(""\\*"", """");
+
+		try {
+			return url.getPath().replaceAll(file, """");
+		} catch (PatternSyntaxException pe) {
+			LOGGER.error(pe.getMessage());
+			return """";
+		}
+
+	}
+
+	/**
+	 * @param location
+	 *            Current location.
+	 * @param link
+	 *            Link to check.
+	 * @return Whether location and link are on the same domain.
+	 */
+	public static boolean isLinkExternal(String location, String link) {
+
+		if (!location.contains(""://"")) {
+			// location must always contain :// by rule, it not link is handled as not external
+			return false;
+		}
+
+		// This will jump out of the local file location
+		if (location.startsWith(""file"") && link.startsWith(""/"")) {
+			return true;
+		}
+
+		if (link.contains(""://"")) {
+			if (location.startsWith(""file"") && link.startsWith(""http"") || link.startsWith(""file"")
+			        && location.startsWith(""http"")) {
+				// Jump from file to http(s) or from http(s) to file, so external
+				return true;
+			}
+			try {
+				URL locationUrl = new URL(location);
+				try {
+					URL linkUrl = new URL(link);
+					if (linkUrl.getHost().equals(locationUrl.getHost())) {
+						String linkPath = getBasePath(linkUrl);
+						return !(linkPath.startsWith(getBasePath(locationUrl)));
+					}
+					return true;
+				} catch (MalformedURLException e) {
+					LOGGER.info(""Can not parse link "" + link + "" to check its externalOf ""
+					        + location);
+					return false;
+				}
+			} catch (MalformedURLException e) {
+				LOGGER.info(""Can not parse location "" + location + "" to check if "" + link
+				        + "" isExternal"", e);
+				return false;
+			}
+		} else {
+			// No full url specifier so internal link...
+			return false;
+		}
+	}
+
+	/**
+	 * @param url
+	 *            the URL string.
+	 * @return the base part of the URL.
+	 */
+	public static String getBaseUrl(String url) {
+		String head = url.substring(0, url.indexOf("":""));
+		String subLoc = url.substring(head.length() + BASE_LENGTH);
+		return head + ""://"" + subLoc.substring(0, subLoc.indexOf(""/""));
+	}
+
+	/**
+	 * transforms a string into a Document object. TODO This needs more optimizations. As it seems
+	 * the getDocument is called way too much times causing a lot of parsing which is slow and not
+	 * necessary.
+	 * 
+	 * @param html
+	 *            the HTML string.
+	 * @return The DOM Document version of the HTML string.
+	 * @throws IOException
+	 *             if an IO failure occurs.
+	 * @throws SAXException
+	 *             if an exception occurs while parsing the HTML string.
+	 */
+	public static Document getDocument(String html) throws SAXException, IOException {
+		DOMParser domParser = new DOMParser();
+		domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
+		domParser.setFeature(""http://xml.org/sax/features/namespaces"", false);
+		domParser.parse(new InputSource(new StringReader(html)));
+		return domParser.getDocument();
+	}
+
+	/**
+	 * @param html
+	 *            the HTML string.
+	 * @return a Document object made from the HTML string.
+	 * @throws SAXException
+	 *             if an exception occurs while parsing the HTML string.
+	 * @throws IOException
+	 *             if an IO failure occurs.
+	 */
+	public static Document getDocumentNoBalance(String html) throws SAXException, IOException {
+		DOMParser domParser = new DOMParser();
+		domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
+		domParser.setFeature(""http://cyberneko.org/html/features/balance-tags"", false);
+		domParser.parse(new InputSource(new StringReader(html)));
+		return domParser.getDocument();
+	}
+
+	/**
+	 * @param element
+	 *            The DOM Element.
+	 * @return A string representation of all the element's attributes.
+	 */
+	public static String getAllElementAttributes(Element element) {
+		return getElementAttributes(element, new ArrayList<String>());
+	}
+
+	/**
+	 * @param element
+	 *            The DOM Element.
+	 * @param exclude
+	 *            the list of exclude strings.
+	 * @return A string representation of the element's attributes excluding exclude.
+	 */
+	public static String getElementAttributes(Element element, List<String> exclude) {
+		StringBuffer buffer = new StringBuffer();
+
+		if (element != null) {
+			NamedNodeMap attributes = element.getAttributes();
+			if (attributes != null) {
+				for (int i = 0; i < attributes.getLength(); i++) {
+					Attr attr = (Attr) attributes.item(i);
+					if (!exclude.contains(attr.getNodeName())) {
+						buffer.append(attr.getNodeName() + ""="");
+						buffer.append(attr.getNodeValue() + "" "");
+					}
+				}
+			}
+		}
+
+		return buffer.toString().trim();
+	}
+
+	/**
+	 * @param element
+	 *            the element.
+	 * @return a string representation of the element including its attributes.
+	 */
+	public static String getElementString(Element element) {
+		if (element == null) {
+			return """";
+		}
+		String text = Helper.removeNewLines(Helper.getTextValue(element)).trim();
+		String info = """";
+		if (!text.equals("""")) {
+			info += ""\"""" + text + ""\"" "";
+			// Helper.removeNewLines(this.text.trim()) + "" - "";
+		}
+		if (element != null) {
+			if (element.hasAttribute(""id"")) {
+				info += ""ID: "" + element.getAttribute(""id"") + "" "";
+			}
+			info += Helper.getAllElementAttributes(element) + "" "";
+		}
+		return info;
+	}
+
+	/**
+	 * @param dom
+	 *            the DOM document.
+	 * @param xpath
+	 *            the xpath.
+	 * @return The element found on DOM having the xpath position.
+	 * @throws XPathExpressionException
+	 *             if the xpath fails.
+	 */
+	public static Element getElementByXpath(Document dom, String xpath)
+	        throws XPathExpressionException {
+		XPath xp = XPathFactory.newInstance().newXPath();
+		xp.setNamespaceContext(new HtmlNamespace());
+
+		return (Element) xp.evaluate(xpath, dom, XPathConstants.NODE);
+	}
+
+	/**
+	 * Removes all the <SCRIPT/> tags from the document.
+	 * 
+	 * @param dom
+	 *            the document object.
+	 * @return the changed dom.
+	 */
+	public static Document removeScriptTags(Document dom) {
+		return removeTags(dom, ""SCRIPT"");
+	}
+
+	/**
+	 * Removes all the given tags from the document.
+	 * 
+	 * @param dom
+	 *            the document object.
+	 * @param tagName
+	 *            the tag name, examples: script, style, meta
+	 * @return the changed dom.
+	 */
+	public static Document removeTags(Document dom, String tagName) {
+		if (dom != null) {
+			// NodeList list = dom.getElementsByTagName(""SCRIPT"");
+
+			NodeList list;
+			try {
+				list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
+
+				while (list.getLength() > 0) {
+					Node sc = list.item(0);
+
+					if (sc != null) {
+						sc.getParentNode().removeChild(sc);
+					}
+
+					list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
+					// list = dom.getElementsByTagName(""SCRIPT"");
+				}
+			} catch (XPathExpressionException e) {
+				LOGGER.error(e.getMessage(), e);
+			}
+
+			return dom;
+		}
+
+		return null;
+	}
+
+	/**
+	 * Checks the existence of the directory. If it does not exist, the method creates it.
+	 * 
+	 * @param dir
+	 *            the directory to check.
+	 * @throws IOException
+	 *             if fails.
+	 */
+	public static void directoryCheck(String dir) throws IOException {
+		final File file = new File(dir);
+
+		if (!file.exists()) {
+			FileUtils.forceMkdir(file);
+		}
+	}
+
+	/**
+	 * Checks whether the folder exists for fname, and creates it if neccessary.
+	 * 
+	 * @param fname
+	 *            folder name.
+	 * @throws IOException
+	 *             an IO exception.
+	 */
+	public static void checkFolderForFile(String fname) throws IOException {
+
+		if (fname.lastIndexOf(File.separator) > 0) {
+			String folder = fname.substring(0, fname.lastIndexOf(File.separator));
+			Helper.directoryCheck(folder);
+		}
+	}
+
+	/**
+	 * Retrieve the var value for varName from a HTTP query string (format is
+	 * ""var1=val1&var2=val2"").
+	 * 
+	 * @param varName
+	 *            the name.
+	 * @param haystack
+	 *            the haystack.
+	 * @return variable value for varName
+	 */
+	public static String getVarFromQueryString(String varName, String haystack) {
+		if (haystack == null || haystack.length() == 0) {
+			return null;
+		}
+		if (haystack.charAt(0) == '?') {
+			haystack = haystack.substring(1);
+		}
+		String[] vars = haystack.split(""&"");
+
+		for (String var : vars) {
+			String[] tuple = var.split(""="");
+			if (tuple.length == 2 && tuple[0].equals(varName)) {
+				return tuple[1];
+			}
+		}
+		return null;
+	}
+
+	/**
+	 * @param dom
+	 *            the DOM document.
+	 * @return a string representation of the DOM.
+	 */
+	public static String getDocumentToString(Document dom) {
+		try {
+			Source source = new DOMSource(dom);
+			StringWriter stringWriter = new StringWriter();
+			Result result = new StreamResult(stringWriter);
+			TransformerFactory factory = TransformerFactory.newInstance();
+			Transformer transformer = factory.newTransformer();
+			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
+			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""yes"");
+			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
+			transformer.transform(source, result);
+			return stringWriter.getBuffer().toString();
+		} catch (TransformerConfigurationException e) {
+			LOGGER.error(e.getMessage(), e);
+		} catch (TransformerException e) {
+			LOGGER.error(e.getMessage(), e);
+		}
+		return null;
+
+	}
+
+	/**
+	 * Serialize the Document object.
+	 * 
+	 * @param dom
+	 *            the document to serialize
+	 * @return the serialized dom String
+	 */
+	public static byte[] getDocumentToByteArray(Document dom) {
+		try {
+			TransformerFactory tFactory = TransformerFactory.newInstance();
+
+			Transformer transformer = tFactory.newTransformer();
+			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
+			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
+			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
+			// TODO should be fixed to read doctype declaration
+			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
+			// ""-//W3C//DTD XHTML 1.0 Transitional//EN\""
+			// \""http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"");
+			transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
+			        ""-//W3C//DTD XHTML 1.0 Strict//EN\"" ""
+			                + ""\""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"");
+
+			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
+			// ""-//W3C//DTD HTML 4.01//EN\"" \""http://www.w3.org/TR/html4/strict.dtd"");
+			DOMSource source = new DOMSource(dom);
+
+			ByteArrayOutputStream out = new ByteArrayOutputStream();
+			Result result = new StreamResult(out);
+			transformer.transform(source, result);
+
+			// System.out.println(""Injected Javascript!"");
+			return out.toByteArray();
+		} catch (TransformerConfigurationException e) {
+			LOGGER.error(e.getMessage(), e);
+		} catch (TransformerException e) {
+			LOGGER.error(e.getMessage(), e);
+		}
+		return null;
+
+	}
+
+	/**
+	 * Save a string to a file and append a newline character to that string.
+	 * 
+	 * @param filename
+	 *            The filename to save to.
+	 * @param text
+	 *            The text to save.
+	 * @param append
+	 *            Whether to append to existing file.
+	 * @throws IOException
+	 *             On error.
+	 */
+	public static void writeToFile(String filename, String text, boolean append)
+	        throws IOException {
+		FileWriter fw = new FileWriter(filename, append);
+		try {
+			fw.write(text + ""\n"");
+		} catch (IOException e) {
+			throw e;
+		} finally {
+			fw.close();
+		}
+	}
+
+	/**
+	 * @param code
+	 *            hashcode.
+	 * @return String version of hashcode.
+	 */
+	public static String hashCodeToString(long code) {
+		if (code < 0) {
+			return ""0"" + (code * -1);
+		} else {
+			return """" + code;
+		}
+	}
+
+	/**
+	 * Returns the text value of an element (title, alt or contents). Note that the result is 50
+	 * characters or less in length.
+	 * 
+	 * @param element
+	 *            The element.
+	 * @return The text value of the element.
+	 */
+	public static String getTextValue(Element element) {
+		String ret = """";
+		if (element == null) {
+			return """";
+		}
+
+		if (element.getTextContent() != null) {
+			ret = element.getTextContent();
+		} else if (element.hasAttribute(""title"")) {
+			ret = element.getAttribute(""title"");
+		} else if (element.hasAttribute(""alt"")) {
+			ret = element.getAttribute(""alt"");
+		}
+		if (ret.length() > TEXT_CUTOFF) {
+			return ret.substring(0, TEXT_CUTOFF);
+		} else {
+			return ret;
+		}
+	}
+
+	/**
+	 * Get differences between doms.
+	 * 
+	 * @param controlDom
+	 *            The control dom.
+	 * @param testDom
+	 *            The test dom.
+	 * @return The differences.
+	 */
+	public static List<Difference> getDifferences(String controlDom, String testDom) {
+		return getDifferences(controlDom, testDom, Lists.<String> newArrayList());
+	}
+
+	/**
+	 * Get differences between doms.
+	 * 
+	 * @param controlDom
+	 *            The control dom.
+	 * @param testDom
+	 *            The test dom.
+	 * @param ignoreAttributes
+	 *            The list of attributes to ignore.
+	 * @return The differences.
+	 */
+	@SuppressWarnings(""unchecked"")
+	public static List<Difference> getDifferences(String controlDom, String testDom,
+	        final List<String> ignoreAttributes) {
+		try {
+			Diff d = new Diff(Helper.getDocument(controlDom), Helper.getDocument(testDom));
+			DetailedDiff dd = new DetailedDiff(d);
+			dd.overrideDifferenceListener(new DifferenceListener() {
+
+				@Override
+				public void skippedComparison(Node control, Node test) {
+				}
+
+				@Override
+				public int differenceFound(Difference difference) {
+					if (difference.getControlNodeDetail() == null
+					        || difference.getControlNodeDetail().getNode() == null
+					        || difference.getTestNodeDetail() == null
+					        || difference.getTestNodeDetail().getNode() == null) {
+						return RETURN_ACCEPT_DIFFERENCE;
+					}
+					if (ignoreAttributes.contains(difference.getTestNodeDetail().getNode()
+					        .getNodeName())
+					        || ignoreAttributes.contains(difference.getControlNodeDetail()
+					                .getNode().getNodeName())) {
+						return RETURN_IGNORE_DIFFERENCE_NODES_IDENTICAL;
+					}
+					return RETURN_ACCEPT_DIFFERENCE;
+				}
+			});
+
+			return dd.getAllDifferences();
+		} catch (Exception e) {
+			LOGGER.error(""Error with getDifferences: "" + e.getMessage(), e);
+		}
+		return null;
+	}
+
+	/**
+	 * Removes newlines from a string.
+	 * 
+	 * @param html
+	 *            The string.
+	 * @return The new string without the newlines or tabs.
+	 */
+	public static String removeNewLines(String html) {
+		return html.replaceAll(""[\\t\\n\\x0B\\f\\r]"", """");
+	}
+
+	/**
+	 * @param string
+	 *            The original string.
+	 * @param regex
+	 *            The regular expression.
+	 * @param replace
+	 *            What to replace it with.
+	 * @return replaces regex in str by replace where the dot sign also supports newlines
+	 */
+	public static String replaceString(String string, String regex, String replace) {
+		Pattern p = Pattern.compile(regex, Pattern.DOTALL);
+		Matcher m = p.matcher(string);
+		String replaced = m.replaceAll(replace);
+		p = Pattern.compile(""  "", Pattern.DOTALL);
+		m = p.matcher(replaced);
+		return m.replaceAll("" "");
+	}
+
+	/**
+	 * Adds a slash to a path if it doesn't end with a slash.
+	 * 
+	 * @param folderName
+	 *            The path to append a possible slash.
+	 * @return The new, correct path.
+	 */
+	public static String addFolderSlashIfNeeded(String folderName) {
+		if (!folderName.equals("""") && !folderName.endsWith(""/"")) {
+			return folderName + ""/"";
+		} else {
+			return folderName;
+		}
+	}
+
+	/**
+	 * Returns the filename in a path. For example with path = ""foo/bar/crawljax.txt"" returns
+	 * ""crawljax.txt""
+	 * 
+	 * @param path
+	 * @return the filename from the path
+	 */
+	private static String getFileNameInPath(String path) {
+		String fname;
+		if (path.indexOf(""/"") != -1) {
+			fname = path.substring(path.lastIndexOf(""/"") + 1);
+		} else {
+			fname = path;
+		}
+		return fname;
+	}
+
+	/**
+	 * Retrieves the content of the filename. Also reads from JAR Searches for the resource in the
+	 * root folder in the jar
+	 * 
+	 * @param fname
+	 *            Filename.
+	 * @return The contents of the file.
+	 * @throws IOException
+	 *             On error.
+	 */
+	public static String getTemplateAsString(String fname) throws IOException {
+		// in .jar file
+		String fnameJar = getFileNameInPath(fname);
+		InputStream inStream = Helper.class.getResourceAsStream(""/"" + fnameJar);
+		if (inStream == null) {
+			// try to find file normally
+			File f = new File(fname);
+			if (f.exists()) {
+				inStream = new FileInputStream(f);
+			} else {
+				throw new IOException(""Cannot find "" + fname + "" or "" + fnameJar);
+			}
+		}
+
+		BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inStream));
+		String line;
+		StringBuilder stringBuilder = new StringBuilder();
+
+		while ((line = bufferedReader.readLine()) != null) {
+			stringBuilder.append(line + ""\n"");
+		}
+
+		bufferedReader.close();
+		return stringBuilder.toString();
+	}
+
+	/**
+	 * @param xpath
+	 *            The xpath of the element.
+	 * @return The JavaScript to get an element.
+	 */
+	public static String getJSGetElement(String xpath) {
+		String js =
+		        """"
+		                + ""function ATUSA_getElementInNodes(nodes, tagName, number){""
+		                + ""try{""
+		                + ""var pos = 1;""
+		                + ""for(i=0; i<nodes.length; i++){""
+		                + ""if(nodes[i]!=null && nodes[i].tagName!=null && ""
+		                + ""nodes[i].tagName.toLowerCase() == tagName){""
+		                + ""if(number==pos){""
+		                + ""return nodes[i];""
+		                + ""}else{""
+		                + ""pos++;""
+		                + ""}""
+		                + ""}""
+		                + ""}""
+		                + ""}catch(e){}""
+		                + ""return null;""
+		                + ""}""
+		                + ""function ATUSA_getElementByXpath(xpath){""
+		                + ""try{""
+		                + ""var elements = xpath.toLowerCase().split('/');""
+		                + ""var curNode = window.document.body;""
+		                + ""var tagName, number;""
+		                + ""for(j=0; j<elements.length; j++){""
+		                + ""if(elements[j]!=''){""
+		                + ""if(elements[j].indexOf('[')==-1){""
+		                + ""tagName = elements[j];""
+		                + ""number = 1;""
+		                + ""}else{""
+		                + ""tagName = elements[j].substring(0, elements[j].indexOf('['));""
+		                + ""number = elements[j].substring(elements[j].indexOf('[')+1, ""
+		                + ""elements[j].lastIndexOf(']'));""
+		                + ""}""
+		                + ""if(tagName!='body' && tagName!='html'){""
+		                + ""curNode = ATUSA_getElementInNodes(curNode.childNodes, tagName, number);""
+		                + ""if(curNode==null){"" + ""return null;"" + ""}"" + ""}"" + ""}"" + ""}""
+		                + ""}catch(e){return null;}"" + ""return curNode;"" + ""}""
+		                + ""try{var ATUSA_element = ATUSA_getElementByXpath('"" + xpath
+		                + ""');}catch(e){return null;}"";
+
+		return js;
+	}
+
+	/**
+	 * @param frame
+	 *            the frame element.
+	 * @return the name or id of this element if they are present, otherwise null.
+	 */
+	public static String getFrameIdentification(Element frame) {
+
+		Attr attr = frame.getAttributeNode(""id"");
+		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
+			return attr.getNodeValue();
+		}
+
+		attr = frame.getAttributeNode(""name"");
+		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
+			return attr.getNodeValue();
+		}
+
+		return null;
+
+	}
+
+	/**
+	 * Write the document object to a file.
+	 * 
+	 * @param document
+	 *            the document object.
+	 * @param filePathname
+	 *            the path name of the file to be written to.
+	 * @param method
+	 *            the output method: for instance html, xml, text
+	 * @param indent
+	 *            amount of indentation. -1 to use the default.
+	 * @throws TransformerException
+	 *             if an exception occurs.
+	 * @throws IOException
+	 *             if an IO exception occurs.
+	 */
+	public static void writeDocumentToFile(Document document, String filePathname, String method,
+	        int indent) throws TransformerException, IOException {
+
+		checkFolderForFile(filePathname);
+		Transformer transformer = TransformerFactory.newInstance().newTransformer();
+		transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
+		transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
+		transformer.setOutputProperty(OutputKeys.METHOD, method);
+
+		if (indent > -1) {
+			transformer.setOutputProperty(
+			        org.apache.xml.serializer.OutputPropertiesFactory.S_KEY_INDENT_AMOUNT,
+			        Integer.toString(indent));
+		}
+		transformer.transform(new DOMSource(document), new StreamResult(new FileOutputStream(
+		        filePathname)));
+	}
+
+	/**
+	 * Returns the file contents without stripping line-endings.
+	 * 
+	 * @param file
+	 *            File to read out.
+	 * @return Contents including line-endings.
+	 */
+	public static String getContent(File file) {
+		StringBuilder contents = new StringBuilder();
+
+		try {
+			BufferedReader input = new BufferedReader(new FileReader(file));
+			try {
+				String line = null; // not declared within while loop
+				while ((line = input.readLine()) != null) {
+					contents.append(line);
+					contents.append(""\n"");
+				}
+			} finally {
+				input.close();
+			}
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+
+		return contents.toString();
+	}
+
+}
"
08b2d85ebd395ff2948c9f1cc594a24b5aaedea7,Ali Mesbah,PrettyHTML.java,MODIFY,"prettyHTML -> [String html] | [String html, String strIndent]","diff --git a/src/main/java/com/crawljax/util/PrettyHTML.java b/src/main/java/com/crawljax/util/PrettyHTML.java
index 13b56af..b13adc9 100644
--- a/src/main/java/com/crawljax/util/PrettyHTML.java
+++ b/src/main/java/com/crawljax/util/PrettyHTML.java
@@ -1,190 +1,190 @@
-package com.crawljax.util;
-
-import java.util.Stack;
-
-/**
- * Class for making presenting HTML without changing it's structure.
- * 
- * @author Danny
- * @version $Id$
- */
-public final class PrettyHTML {
-
-	private PrettyHTML() {
-
-	}
-
-	// private static final Logger LOGGER =
-	// Logger.getLogger(PrettyHTML.class.getName());
-
-	/**
-	 * Pretty print HTML string.
-	 * 
-	 * @param html
-	 *            The HTML string.
-	 * @param strIndent
-	 *            The indentation string.
-	 * @return The pretty HTML.
-	 */
-	public static String prettyHTML(String html, String strIndent) {
-		String[] elements = html.split(""<"");
-		StringBuffer prettyHTML = new StringBuffer();
-		int indent = 0;
-		// preparsing for not closing elements
-		elements = fixElements(elements);
-
-		for (String element : elements) {
-			if (!element.equals("""")) {
-				element = element.trim();
-
-				if (!element.startsWith(""/"")) {
-					// open element
-					prettyHTML.append(repeatString(strIndent, indent));
-					String[] temp = element.split("">"");
-					prettyHTML.append(""<"" + temp[0].trim() + "">\n"");
-
-					// only indent if element is not a single element (like
-					// <img src='..' />)
-					if ((!temp[0].endsWith(""/"") || temp.length == 1)
-					        && !temp[0].startsWith(""!--"")) {
-						indent++;
-					}
-
-					// if there is text after the element, print it
-					if (temp.length > 1 && !temp[1].trim().equals("""")) {
-						prettyHTML.append(repeatString(strIndent, indent));
-						prettyHTML.append(temp[1].trim() + ""\n"");
-					}
-				} else {
-					// close element
-					indent--;
-					prettyHTML.append(repeatString(strIndent, indent));
-					prettyHTML.append(""<"" + element + ""\n"");
-				}
-				if (element.endsWith(""/>"")) {
-					indent--;
-				}
-			}
-		}
-		return prettyHTML.toString();
-
-	}
-
-	/**
-	 * @param html
-	 *            The HTML string.
-	 * @return Pretty HTML.
-	 */
-	public static String prettyHTML(String html) {
-		return prettyHTML(html, ""\t"");
-	}
-
-	/**
-	 * @param s
-	 * @param number
-	 * @return s repreated number of times
-	 */
-	private static String repeatString(String s, int number) {
-		StringBuffer ret = new StringBuffer();
-		for (int i = 0; i < number; i++) {
-			ret.append(s);
-		}
-		return ret.toString();
-	}
-
-	/**
-	 * @param openElement
-	 * @param closeElement
-	 * @return wheter element has a seperate closing element
-	 */
-	private static boolean elementsRelated(String openElement, String closeElement) {
-		openElement = openElement.split("">"")[0];
-		openElement = openElement.split("" "")[0];
-		closeElement = closeElement.split("">"")[0];
-		return closeElement.startsWith(""/"" + openElement);
-	}
-
-	/**
-	 * @param stack
-	 * @param element
-	 * @return whether the element is open
-	 */
-	private static boolean elementIsOpen(Stack<String> stack, String element) {
-		for (int i = stack.size() - 1; i >= 0; i--) {
-			if (elementsRelated(stack.get(i), element)) {
-				return true;
-			}
-		}
-		return false;
-	}
-
-	/**
-	 * @param element
-	 * @return wheter the element is a single element (<foo ... />)
-	 */
-	private static boolean isSingleElement(String element) {
-		return element.indexOf(""/>"") != -1;
-	}
-
-	/**
-	 * @param elements
-	 * @return list with elements with added closing elements if needed
-	 */
-	private static String[] fixElements(String[] elements) {
-		Stack<String> stackElements = new Stack<String>();
-		Stack<Integer> stackIndexElements = new Stack<Integer>();
-		for (int i = 0; i < elements.length; i++) {
-			elements[i] = elements[i].trim();
-			String element = elements[i];
-			if (!element.equals("""") && !element.startsWith(""!--"") && !element.endsWith(""-->"")) {
-				while (stackElements.size() > 0 && element.startsWith(""/"")
-				        && !elementsRelated(stackElements.peek(), element)) {
-					// found a close element which is not on top of stack,
-					// thus fix
-					if (elementIsOpen(stackElements, element)) {
-						// the element is open --> close element on top of
-						// stack
-						int index = stackIndexElements.peek();
-						if (!isSingleElement(elements[index])
-						        && elements[index].lastIndexOf("">"") != -1) {
-							// close this element
-							elements[index] =
-							        elements[index]
-							                .substring(0, elements[index].lastIndexOf("">""))
-							                + ""/""
-							                + elements[index].substring(elements[index]
-							                        .lastIndexOf("">""));
-						}
-						stackElements.pop();
-						stackIndexElements.pop();
-					} else {
-						// element is closing element while element is not
-						// open--> remove.
-						elements[i] = """";
-						element = """";
-						break;
-					}
-
-				}
-				if (!element.equals("""")) {
-					// open element
-					if (!element.startsWith(""/"")) {
-						// only add to stack if has an open and close element
-						if (!isSingleElement(element)) {
-							stackElements.push(element);
-							stackIndexElements.push(i);
-						}
-					} else {
-						// close element, pop from stack if possible
-						if (stackElements.size() > 0) {
-							stackElements.pop();
-							stackIndexElements.pop();
-						}
-					}
-				}
-			}
-		}
-		return elements;
-	}
-
-}
+package com.crawljax.util;
+
+import java.util.Stack;
+
+/**
+ * Class for making presenting HTML without changing it's structure.
+ * 
+ * @author Danny
+ * @version $Id$
+ */
+public final class PrettyHTML {
+
+	private PrettyHTML() {
+
+	}
+
+	// private static final Logger LOGGER =
+	// LoggerFactory.getLogger(PrettyHTML.class.getName());
+
+	/**
+	 * Pretty print HTML string.
+	 * 
+	 * @param html
+	 *            The HTML string.
+	 * @param strIndent
+	 *            The indentation string.
+	 * @return The pretty HTML.
+	 */
+	public static String prettyHTML(String html, String strIndent) {
+		String[] elements = html.split(""<"");
+		StringBuffer prettyHTML = new StringBuffer();
+		int indent = 0;
+		// preparsing for not closing elements
+		elements = fixElements(elements);
+
+		for (String element : elements) {
+			if (!element.equals("""")) {
+				element = element.trim();
+
+				if (!element.startsWith(""/"")) {
+					// open element
+					prettyHTML.append(repeatString(strIndent, indent));
+					String[] temp = element.split("">"");
+					prettyHTML.append(""<"" + temp[0].trim() + "">\n"");
+
+					// only indent if element is not a single element (like
+					// <img src='..' />)
+					if ((!temp[0].endsWith(""/"") || temp.length == 1)
+					        && !temp[0].startsWith(""!--"")) {
+						indent++;
+					}
+
+					// if there is text after the element, print it
+					if (temp.length > 1 && !temp[1].trim().equals("""")) {
+						prettyHTML.append(repeatString(strIndent, indent));
+						prettyHTML.append(temp[1].trim() + ""\n"");
+					}
+				} else {
+					// close element
+					indent--;
+					prettyHTML.append(repeatString(strIndent, indent));
+					prettyHTML.append(""<"" + element + ""\n"");
+				}
+				if (element.endsWith(""/>"")) {
+					indent--;
+				}
+			}
+		}
+		return prettyHTML.toString();
+
+	}
+
+	/**
+	 * @param html
+	 *            The HTML string.
+	 * @return Pretty HTML.
+	 */
+	public static String prettyHTML(String html) {
+		return prettyHTML(html, ""\t"");
+	}
+
+	/**
+	 * @param s
+	 * @param number
+	 * @return s repreated number of times
+	 */
+	private static String repeatString(String s, int number) {
+		StringBuffer ret = new StringBuffer();
+		for (int i = 0; i < number; i++) {
+			ret.append(s);
+		}
+		return ret.toString();
+	}
+
+	/**
+	 * @param openElement
+	 * @param closeElement
+	 * @return wheter element has a seperate closing element
+	 */
+	private static boolean elementsRelated(String openElement, String closeElement) {
+		openElement = openElement.split("">"")[0];
+		openElement = openElement.split("" "")[0];
+		closeElement = closeElement.split("">"")[0];
+		return closeElement.startsWith(""/"" + openElement);
+	}
+
+	/**
+	 * @param stack
+	 * @param element
+	 * @return whether the element is open
+	 */
+	private static boolean elementIsOpen(Stack<String> stack, String element) {
+		for (int i = stack.size() - 1; i >= 0; i--) {
+			if (elementsRelated(stack.get(i), element)) {
+				return true;
+			}
+		}
+		return false;
+	}
+
+	/**
+	 * @param element
+	 * @return wheter the element is a single element (<foo ... />)
+	 */
+	private static boolean isSingleElement(String element) {
+		return element.indexOf(""/>"") != -1;
+	}
+
+	/**
+	 * @param elements
+	 * @return list with elements with added closing elements if needed
+	 */
+	private static String[] fixElements(String[] elements) {
+		Stack<String> stackElements = new Stack<String>();
+		Stack<Integer> stackIndexElements = new Stack<Integer>();
+		for (int i = 0; i < elements.length; i++) {
+			elements[i] = elements[i].trim();
+			String element = elements[i];
+			if (!element.equals("""") && !element.startsWith(""!--"") && !element.endsWith(""-->"")) {
+				while (stackElements.size() > 0 && element.startsWith(""/"")
+				        && !elementsRelated(stackElements.peek(), element)) {
+					// found a close element which is not on top of stack,
+					// thus fix
+					if (elementIsOpen(stackElements, element)) {
+						// the element is open --> close element on top of
+						// stack
+						int index = stackIndexElements.peek();
+						if (!isSingleElement(elements[index])
+						        && elements[index].lastIndexOf("">"") != -1) {
+							// close this element
+							elements[index] =
+							        elements[index]
+							                .substring(0, elements[index].lastIndexOf("">""))
+							                + ""/""
+							                + elements[index].substring(elements[index]
+							                        .lastIndexOf("">""));
+						}
+						stackElements.pop();
+						stackIndexElements.pop();
+					} else {
+						// element is closing element while element is not
+						// open--> remove.
+						elements[i] = """";
+						element = """";
+						break;
+					}
+
+				}
+				if (!element.equals("""")) {
+					// open element
+					if (!element.startsWith(""/"")) {
+						// only add to stack if has an open and close element
+						if (!isSingleElement(element)) {
+							stackElements.push(element);
+							stackIndexElements.push(i);
+						}
+					} else {
+						// close element, pop from stack if possible
+						if (stackElements.size() > 0) {
+							stackElements.pop();
+							stackIndexElements.pop();
+						}
+					}
+				}
+			}
+		}
+		return elements;
+	}
+
+}
"
9e2de808c045212e6a52daded054749ecf0b2dd0,Ali Mesbah,CandidateElementExtractor.java,MODIFY,"extract -> [List crawlTagElements, List crawlExcludeTagElements, boolean clickOnce, StateVertix currentState] | [List crawlTagElements, List crawlExcludeTagElements, boolean clickOnce, StateVertex currentState]","diff --git a/src/main/java/com/crawljax/core/CandidateElementExtractor.java b/src/main/java/com/crawljax/core/CandidateElementExtractor.java
index f4db5de..d218d0a 100644
--- a/src/main/java/com/crawljax/core/CandidateElementExtractor.java
+++ b/src/main/java/com/crawljax/core/CandidateElementExtractor.java
@@ -22,7 +22,7 @@
 import com.crawljax.condition.eventablecondition.EventableConditionChecker;
 import com.crawljax.core.configuration.IgnoreFrameChecker;
 import com.crawljax.core.state.Identification;
-import com.crawljax.core.state.StateVertix;
+import com.crawljax.core.state.StateVertex;
 import com.crawljax.forms.FormHandler;
 import com.crawljax.util.Helper;
 import com.crawljax.util.XPathHelper;
@@ -83,7 +83,7 @@
 	 *             if the method fails.
 	 */
 	public List<CandidateElement> extract(List<TagElement> crawlTagElements,
-	        List<TagElement> crawlExcludeTagElements, boolean clickOnce, StateVertix currentState)
+	        List<TagElement> crawlExcludeTagElements, boolean clickOnce, StateVertex currentState)
 	        throws CrawljaxException {
 		List<CandidateElement> results = new ArrayList<CandidateElement>();
 
"
9e2de808c045212e6a52daded054749ecf0b2dd0,Ali Mesbah,CrawlSession.java,MODIFY,setCurrentState -> [StateVertix currentState] | [StateVertex currentState],"diff --git a/src/main/java/com/crawljax/core/CrawlSession.java b/src/main/java/com/crawljax/core/CrawlSession.java
index e0dfef6..dfe447d 100644
--- a/src/main/java/com/crawljax/core/CrawlSession.java
+++ b/src/main/java/com/crawljax/core/CrawlSession.java
@@ -9,7 +9,7 @@
 import com.crawljax.core.state.CrawlPath;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateFlowGraph;
-import com.crawljax.core.state.StateVertix;
+import com.crawljax.core.state.StateVertex;
 
 import java.util.Collection;
 import java.util.List;
@@ -38,7 +38,7 @@
 	/**
 	 * The initial State (indexState).
 	 */
-	private final StateVertix initialState;
+	private final StateVertex initialState;
 
 	/**
 	 * Variable for reading the Configuration from.
@@ -55,7 +55,7 @@
 	/**
 	 * ThreadLocal store the have a Thread<->Current State relation.
 	 */
-	private final ThreadLocal<StateVertix> tlState = new ThreadLocal<StateVertix>();
+	private final ThreadLocal<StateVertex> tlState = new ThreadLocal<StateVertex>();
 
 	/**
 	 * The main BrowserPool where the current Browser is stored.
@@ -81,7 +81,7 @@
 	 *            the time this session started in milliseconds.
 	 */
 	public CrawlSession(
-	        BrowserPool pool, StateFlowGraph stateFlowGraph, StateVertix state, long startTime) {
+	        BrowserPool pool, StateFlowGraph stateFlowGraph, StateVertex state, long startTime) {
 		this(pool, stateFlowGraph, state, startTime, null);
 	}
 
@@ -97,7 +97,7 @@
 	 * @param crawljaxConfiguration
 	 *            the configuration.
 	 */
-	public CrawlSession(BrowserPool pool, StateFlowGraph stateFlowGraph, StateVertix state,
+	public CrawlSession(BrowserPool pool, StateFlowGraph stateFlowGraph, StateVertex state,
 	        long startTime, CrawljaxConfigurationReader crawljaxConfiguration) {
 		this.crawljaxConfiguration = crawljaxConfiguration;
 		this.browserPool = pool;
@@ -124,8 +124,8 @@
 	/**
 	 * @return the currentState
 	 */
-	public StateVertix getCurrentState() {
-		StateVertix sv = tlState.get();
+	public StateVertex getCurrentState() {
+		StateVertex sv = tlState.get();
 		if (sv == null) {
 			tlState.set(getInitialState());
 		} else {
@@ -138,7 +138,7 @@
 	 * @param currentState
 	 *            the currentState to set
 	 */
-	public void setCurrentState(StateVertix currentState) {
+	public void setCurrentState(StateVertex currentState) {
 		this.tlState.set(currentState);
 	}
 
@@ -167,7 +167,7 @@
 	/**
 	 * @return the initialState
 	 */
-	public final StateVertix getInitialState() {
+	public final StateVertex getInitialState() {
 		return initialState;
 	}
 
"
9e2de808c045212e6a52daded054749ecf0b2dd0,Ali Mesbah,Crawler.java,MODIFY,spawnThreads -> [StateVertix state] | [StateVertex state],"diff --git a/src/main/java/com/crawljax/core/Crawler.java b/src/main/java/com/crawljax/core/Crawler.java
index 216f6a3..e994a8c 100644
--- a/src/main/java/com/crawljax/core/Crawler.java
+++ b/src/main/java/com/crawljax/core/Crawler.java
@@ -19,7 +19,7 @@
 import com.crawljax.core.state.Identification;
 import com.crawljax.core.state.StateFlowGraph;
 import com.crawljax.core.state.StateMachine;
-import com.crawljax.core.state.StateVertix;
+import com.crawljax.core.state.StateVertex;
 import com.crawljax.forms.FormHandler;
 import com.crawljax.forms.FormInput;
 import com.crawljax.util.ElementResolver;
@@ -256,7 +256,7 @@
 		/**
 		 * Thread safe
 		 */
-		StateVertix curState = controller.getSession().getInitialState();
+		StateVertex curState = controller.getSession().getInitialState();
 
 		for (Eventable clickable : backTrackPath) {
 
@@ -326,8 +326,8 @@
 		LOGGER.info(""Executing "" + eventable.getEventType() + "" on element: "" + eventable
 		        + ""; State: "" + this.getStateMachine().getCurrentState().getName());
 		if (this.fireEvent(eventable)) {
-			StateVertix newState =
-			        new StateVertix(getBrowser().getCurrentUrl(), controller.getSession()
+			StateVertex newState =
+			        new StateVertex(getBrowser().getCurrentUrl(), controller.getSession()
 			                .getStateFlowGraph().getNewStateName(), getBrowser().getDom(),
 			                this.controller.getStrippedDom(getBrowser()));
 			if (isDomChanged(this.getStateMachine().getCurrentState(), newState)) {
@@ -385,7 +385,7 @@
 		}
 	}
 
-	private void spawnThreads(StateVertix state) {
+	private void spawnThreads(StateVertex state) {
 		Crawler c = null;
 		do {
 			if (c != null) {
@@ -401,7 +401,7 @@
 		CandidateElement candidateElement = action.getCandidateElement();
 		EventType eventType = action.getEventType();
 
-		StateVertix orrigionalState = this.getStateMachine().getCurrentState();
+		StateVertex orrigionalState = this.getStateMachine().getCurrentState();
 
 		if (candidateElement.allConditionsSatisfied(getBrowser())) {
 			ClickResult clickResult = clickTag(new Eventable(candidateElement, eventType));
@@ -449,7 +449,7 @@
 		}
 
 		// Store the currentState to be able to 'back-track' later.
-		StateVertix orrigionalState = this.getStateMachine().getCurrentState();
+		StateVertex orrigionalState = this.getStateMachine().getCurrentState();
 
 		if (orrigionalState.searchForCandidateElements(candidateExtractor, configurationReader
 		        .getTagElements(), configurationReader.getExcludeTagElements(),
@@ -497,7 +497,7 @@
 	 * @return true if crawling must continue false otherwise.
 	 * @throws CrawljaxException
 	 */
-	private boolean newStateDetected(StateVertix orrigionalState) throws CrawljaxException {
+	private boolean newStateDetected(StateVertex orrigionalState) throws CrawljaxException {
 
 		/**
 		 * An event has been fired so we are one level deeper
@@ -663,7 +663,7 @@
 	 *            the state after the event.
 	 * @return true if the state is changed according to the compare method of the oracle.
 	 */
-	private boolean isDomChanged(final StateVertix stateBefore, final StateVertix stateAfter) {
+	private boolean isDomChanged(final StateVertex stateBefore, final StateVertex stateAfter) {
 		boolean isChanged = false;
 
 		// do not need Oracle Comparators now, because hash of stripped dom is
"
9e2de808c045212e6a52daded054749ecf0b2dd0,Ali Mesbah,CrawljaxPluginsUtil.java,MODIFY,"runOnRevisitStatePlugins -> [CrawlSession session, StateVertix currentState] | [CrawlSession session, StateVertex currentState]","diff --git a/src/main/java/com/crawljax/core/plugin/CrawljaxPluginsUtil.java b/src/main/java/com/crawljax/core/plugin/CrawljaxPluginsUtil.java
index fba21ca..628e178 100644
--- a/src/main/java/com/crawljax/core/plugin/CrawljaxPluginsUtil.java
+++ b/src/main/java/com/crawljax/core/plugin/CrawljaxPluginsUtil.java
@@ -14,7 +14,7 @@
 import com.crawljax.core.configuration.ProxyConfiguration;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateMachine;
-import com.crawljax.core.state.StateVertix;
+import com.crawljax.core.state.StateVertex;
 import com.google.common.collect.Lists;
 
 /**
@@ -166,7 +166,7 @@
 	 * @param currentState
 	 *            the state the 'back tracking' operation is currently in
 	 */
-	public static void runOnRevisitStatePlugins(CrawlSession session, StateVertix currentState) {
+	public static void runOnRevisitStatePlugins(CrawlSession session, StateVertex currentState) {
 		LOGGER.info(""Running OnRevisitStatePlugins..."");
 		for (Plugin plugin : CrawljaxPluginsUtil.PLUGINS) {
 			if (plugin instanceof OnRevisitStatePlugin) {
@@ -238,7 +238,7 @@
 		for (Plugin plugin : CrawljaxPluginsUtil.PLUGINS) {
 			if (plugin instanceof GuidedCrawlingPlugin) {
 				LOGGER.info(""Calling plugin "" + plugin.getClass().getName());
-				StateVertix currentState = session.getCurrentState();
+				StateVertex currentState = session.getCurrentState();
 				((GuidedCrawlingPlugin) plugin).guidedCrawling(currentState, controller, session,
 				        exactEventPaths, stateMachine);
 			}
"
9e2de808c045212e6a52daded054749ecf0b2dd0,Ali Mesbah,GuidedCrawlingPlugin.java,MODIFY,"guidedCrawling -> [StateVertix currentState, CrawljaxController controller, CrawlSession session, List exactEventPaths, StateMachine stateMachine] | [StateVertex currentState, CrawljaxController controller, CrawlSession session, List exactEventPaths, StateMachine stateMachine]","diff --git a/src/main/java/com/crawljax/core/plugin/GuidedCrawlingPlugin.java b/src/main/java/com/crawljax/core/plugin/GuidedCrawlingPlugin.java
index 5e6b29e..9905358 100644
--- a/src/main/java/com/crawljax/core/plugin/GuidedCrawlingPlugin.java
+++ b/src/main/java/com/crawljax/core/plugin/GuidedCrawlingPlugin.java
@@ -6,7 +6,7 @@
 import com.crawljax.core.CrawljaxController;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateMachine;
-import com.crawljax.core.state.StateVertix;
+import com.crawljax.core.state.StateVertex;
 
 /**
  * Plugin type that is called when the crawling control needs to be given to a plugin. After the
@@ -30,7 +30,7 @@
 	 * @param stateMachine
 	 *            the state machine.
 	 */
-	void guidedCrawling(StateVertix currentState, CrawljaxController controller,
+	void guidedCrawling(StateVertex currentState, CrawljaxController controller,
 	        CrawlSession session, List<Eventable> exactEventPaths, StateMachine stateMachine);
 
 }
"
9e2de808c045212e6a52daded054749ecf0b2dd0,Ali Mesbah,OnRevisitStatePlugin.java,MODIFY,"onRevisitState -> [CrawlSession session, StateVertix currentState] | [CrawlSession session, StateVertex currentState]","diff --git a/src/main/java/com/crawljax/core/plugin/OnRevisitStatePlugin.java b/src/main/java/com/crawljax/core/plugin/OnRevisitStatePlugin.java
index 0de4508..53a14f2 100644
--- a/src/main/java/com/crawljax/core/plugin/OnRevisitStatePlugin.java
+++ b/src/main/java/com/crawljax/core/plugin/OnRevisitStatePlugin.java
@@ -1,7 +1,7 @@
 package com.crawljax.core.plugin;
 
 import com.crawljax.core.CrawlSession;
-import com.crawljax.core.state.StateVertix;
+import com.crawljax.core.state.StateVertex;
 
 /**
  * Plugin type that is called every time a state is revisited by Crawljax. Example: Benchmarking.
@@ -22,6 +22,6 @@
 	 * @param currentState
 	 *            the state revisited
 	 */
-	void onRevisitState(CrawlSession session, StateVertix currentState);
+	void onRevisitState(CrawlSession session, StateVertex currentState);
 
 }
"
9e2de808c045212e6a52daded054749ecf0b2dd0,Ali Mesbah,StateFlowGraph.java,MODIFY,"addState -> [StateVertix stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index bbcead3..4be6150 100644
--- a/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -26,7 +26,7 @@
 public class StateFlowGraph {
 	private static final Logger LOGGER = LoggerFactory.getLogger(StateFlowGraph.class.getName());
 
-	private final DirectedGraph<StateVertix, Eventable> sfg;
+	private final DirectedGraph<StateVertex, Eventable> sfg;
 
 	/**
 	 * Intermediate counter for the number of states, not relaying on getAllStates.size() because of
@@ -38,7 +38,7 @@
 	 * Empty constructor.
 	 */
 	public StateFlowGraph() {
-		sfg = new DirectedMultigraph<StateVertix, Eventable>(Eventable.class);
+		sfg = new DirectedMultigraph<StateVertex, Eventable>(Eventable.class);
 	}
 
 	/**
@@ -47,7 +47,7 @@
 	 * @param initialState
 	 *            the state to start from.
 	 */
-	public StateFlowGraph(StateVertix initialState) {
+	public StateFlowGraph(StateVertex initialState) {
 		this();
 		sfg.addVertex(initialState);
 	}
@@ -66,7 +66,7 @@
 	 * @return the clone if one is detected null otherwise.
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
-	public StateVertix addState(StateVertix stateVertix) {
+	public StateVertex addState(StateVertex stateVertix) {
 		return addState(stateVertix, true);
 	}
 
@@ -87,7 +87,7 @@
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
 	@GuardedBy(""sfg"")
-	public StateVertix addState(StateVertix stateVertix, boolean correctName) {
+	public StateVertex addState(StateVertex stateVertix, boolean correctName) {
 		synchronized (sfg) {
 			if (!sfg.addVertex(stateVertix)) {
 				// Graph already contained the vertix
@@ -136,7 +136,7 @@
 	 * @see org.jgrapht.Graph#addEdge(Object, Object, Object)
 	 */
 	@GuardedBy(""sfg"")
-	public boolean addEdge(StateVertix sourceVert, StateVertix targetVert, Eventable clickable) {
+	public boolean addEdge(StateVertex sourceVert, StateVertex targetVert, Eventable clickable) {
 		synchronized (sfg) {
 			// TODO Ali; Why is this code (if-stmt) here? Its the same as what happens in sfg.addEge
 			// imo (21-01-10 Stefan).
@@ -166,7 +166,7 @@
 	 * @return a set of the outgoing edges (clickables) of the stateVertix.
 	 * @see org.jgrapht.DirectedGraph#outgoingEdgesOf(Object)
 	 */
-	public Set<Eventable> getOutgoingClickables(StateVertix stateVertix) {
+	public Set<Eventable> getOutgoingClickables(StateVertex stateVertix) {
 		return sfg.outgoingEdgesOf(stateVertix);
 	}
 
@@ -178,7 +178,7 @@
 	 * @return a set of the incoming edges (clickables) of the stateVertix.
 	 * @see org.jgrapht.DirectedGraph#incomingEdgesOf(Object)
 	 */
-	public Set<Eventable> getIncomingClickable(StateVertix stateVertix) {
+	public Set<Eventable> getIncomingClickable(StateVertex stateVertix) {
 		return sfg.incomingEdgesOf(stateVertix);
 	}
 
@@ -189,8 +189,8 @@
 	 *            the state.
 	 * @return the set of outgoing states from the stateVertix.
 	 */
-	public Set<StateVertix> getOutgoingStates(StateVertix stateVertix) {
-		final Set<StateVertix> result = new HashSet<StateVertix>();
+	public Set<StateVertex> getOutgoingStates(StateVertex stateVertix) {
+		final Set<StateVertex> result = new HashSet<StateVertex>();
 
 		for (Eventable c : getOutgoingClickables(stateVertix)) {
 			result.add(sfg.getEdgeTarget(c));
@@ -204,7 +204,7 @@
 	 *            the edge.
 	 * @return the target state of this edge.
 	 */
-	public StateVertix getTargetState(Eventable clickable) {
+	public StateVertex getTargetState(Eventable clickable) {
 		return sfg.getEdgeTarget(clickable);
 	}
 
@@ -218,7 +218,7 @@
 	 * @return true if it is possible (edge exists in graph) to go from source to target.
 	 */
 	@GuardedBy(""sfg"")
-	public boolean canGoTo(StateVertix source, StateVertix target) {
+	public boolean canGoTo(StateVertex source, StateVertex target) {
 		synchronized (sfg) {
 			return sfg.containsEdge(source, target) || sfg.containsEdge(target, source);
 		}
@@ -233,7 +233,7 @@
 	 *            the end state.
 	 * @return a list of shortest path of clickables from the state to the end
 	 */
-	public List<Eventable> getShortestPath(StateVertix start, StateVertix end) {
+	public List<Eventable> getShortestPath(StateVertex start, StateVertex end) {
 		return DijkstraShortestPath.findPathBetween(sfg, start, end);
 	}
 
@@ -242,7 +242,7 @@
 	 * 
 	 * @return all the states on the graph.
 	 */
-	public Set<StateVertix> getAllStates() {
+	public Set<StateVertex> getAllStates() {
 		return sfg.vertexSet();
 	}
 
@@ -263,10 +263,10 @@
 	 *            the StateVertix to search
 	 * @return the copy of the StateVertix in the StateFlowGraph where v.equals(u)
 	 */
-	private StateVertix getStateInGraph(StateVertix state) {
-		Set<StateVertix> states = getAllStates();
+	private StateVertex getStateInGraph(StateVertex state) {
+		Set<StateVertex> states = getAllStates();
 
-		for (StateVertix st : states) {
+		for (StateVertex st : states) {
 			if (state.equals(st)) {
 				return st;
 			}
@@ -281,7 +281,7 @@
 	public int getMeanStateStringSize() {
 		final Mean mean = new Mean();
 
-		for (StateVertix state : getAllStates()) {
+		for (StateVertex state : getAllStates()) {
 			mean.increment(state.getDomSize());
 		}
 
@@ -291,7 +291,7 @@
 	/**
 	 * @return the state-flow graph.
 	 */
-	public DirectedGraph<StateVertix, Eventable> getSfg() {
+	public DirectedGraph<StateVertex, Eventable> getSfg() {
 		return sfg;
 	}
 
@@ -300,20 +300,20 @@
 	 *            The starting state.
 	 * @return A list of the deepest states (states with no outgoing edges).
 	 */
-	public List<StateVertix> getDeepStates(StateVertix state) {
+	public List<StateVertex> getDeepStates(StateVertex state) {
 		final Set<String> visitedStates = new HashSet<String>();
-		final List<StateVertix> deepStates = new ArrayList<StateVertix>();
+		final List<StateVertex> deepStates = new ArrayList<StateVertex>();
 
 		traverse(visitedStates, deepStates, state);
 
 		return deepStates;
 	}
 
-	private void traverse(Set<String> visitedStates, List<StateVertix> deepStates,
-	        StateVertix state) {
+	private void traverse(Set<String> visitedStates, List<StateVertex> deepStates,
+	        StateVertex state) {
 		visitedStates.add(state.getName());
 
-		Set<StateVertix> outgoingSet = getOutgoingStates(state);
+		Set<StateVertex> outgoingSet = getOutgoingStates(state);
 
 		if ((outgoingSet == null) || outgoingSet.isEmpty()) {
 			deepStates.add(state);
@@ -321,7 +321,7 @@
 			if (cyclic(visitedStates, outgoingSet)) {
 				deepStates.add(state);
 			} else {
-				for (StateVertix st : outgoingSet) {
+				for (StateVertex st : outgoingSet) {
 					if (!visitedStates.contains(st.getName())) {
 						traverse(visitedStates, deepStates, st);
 					}
@@ -330,10 +330,10 @@
 		}
 	}
 
-	private boolean cyclic(Set<String> visitedStates, Set<StateVertix> outgoingSet) {
+	private boolean cyclic(Set<String> visitedStates, Set<StateVertex> outgoingSet) {
 		int i = 0;
 
-		for (StateVertix state : outgoingSet) {
+		for (StateVertex state : outgoingSet) {
 			if (visitedStates.contains(state.getName())) {
 				i++;
 			}
@@ -349,19 +349,19 @@
 	 *            the initial state.
 	 * @return a list of GraphPath lists.
 	 */
-	public List<List<GraphPath<StateVertix, Eventable>>> getAllPossiblePaths(StateVertix index) {
-		final List<List<GraphPath<StateVertix, Eventable>>> results =
-		        new ArrayList<List<GraphPath<StateVertix, Eventable>>>();
+	public List<List<GraphPath<StateVertex, Eventable>>> getAllPossiblePaths(StateVertex index) {
+		final List<List<GraphPath<StateVertex, Eventable>>> results =
+		        new ArrayList<List<GraphPath<StateVertex, Eventable>>>();
 
-		final KShortestPaths<StateVertix, Eventable> kPaths =
-		        new KShortestPaths<StateVertix, Eventable>(this.sfg, index, Integer.MAX_VALUE);
+		final KShortestPaths<StateVertex, Eventable> kPaths =
+		        new KShortestPaths<StateVertex, Eventable>(this.sfg, index, Integer.MAX_VALUE);
 		// System.out.println(sfg.toString());
 
-		for (StateVertix state : getDeepStates(index)) {
+		for (StateVertex state : getDeepStates(index)) {
 			// System.out.println(""Deep State: "" + state.getName());
 
 			try {
-				List<GraphPath<StateVertix, Eventable>> paths = kPaths.getPaths(state);
+				List<GraphPath<StateVertex, Eventable>> paths = kPaths.getPaths(state);
 				results.add(paths);
 			} catch (Exception e) {
 				// TODO Stefan; which Exception is catched here???Can this be removed?
"
9e2de808c045212e6a52daded054749ecf0b2dd0,Ali Mesbah,StateMachine.java,MODIFY,changeState -> [StateVertix nextState] | [StateVertex nextState],"diff --git a/src/main/java/com/crawljax/core/state/StateMachine.java b/src/main/java/com/crawljax/core/state/StateMachine.java
index 49f1387..6df6d14 100644
--- a/src/main/java/com/crawljax/core/state/StateMachine.java
+++ b/src/main/java/com/crawljax/core/state/StateMachine.java
@@ -31,11 +31,11 @@
 	/**
 	 * One-to-one relation with the initalState, the initalState is never changed.
 	 */
-	private final StateVertix initialState;
+	private final StateVertex initialState;
 
-	private StateVertix currentState;
+	private StateVertex currentState;
 
-	private StateVertix previousState;
+	private StateVertex previousState;
 
 	/**
 	 * The invariantChecker to use when updating the state machine.
@@ -50,7 +50,7 @@
 	 * @param indexState
 	 *            the state representing the Index vertix
 	 */
-	public StateMachine(StateFlowGraph sfg, StateVertix indexState) {
+	public StateMachine(StateFlowGraph sfg, StateVertex indexState) {
 		this(sfg, indexState, new ArrayList<Invariant>());
 	}
 
@@ -64,7 +64,7 @@
 	 * @param invariantList
 	 *            the invariants to use in the InvariantChecker.
 	 */
-	public StateMachine(StateFlowGraph sfg, StateVertix indexState, List<Invariant> invariantList) {
+	public StateMachine(StateFlowGraph sfg, StateVertex indexState, List<Invariant> invariantList) {
 		stateFlowGraph = sfg;
 		this.initialState = indexState;
 		currentState = initialState;
@@ -79,7 +79,7 @@
 	 *            the next state.
 	 * @return true if currentState is successfully changed.
 	 */
-	public boolean changeState(StateVertix nextState) {
+	public boolean changeState(StateVertex nextState) {
 		if (nextState == null) {
 			LOGGER.info(""nextState given is null"");
 			return false;
@@ -114,12 +114,12 @@
 	 *            the clickable causing the new state.
 	 * @return the clone state iff newState is a clone, else returns null
 	 */
-	private StateVertix addStateToCurrentState(StateVertix newState, Eventable eventable) {
+	private StateVertex addStateToCurrentState(StateVertex newState, Eventable eventable) {
 		LOGGER.debug(""currentState: "" + currentState.getName());
 		LOGGER.debug(""newState: "" + newState.getName());
 
 		// Add the state to the stateFlowGraph. Store the result
-		StateVertix cloneState = stateFlowGraph.addState(newState);
+		StateVertex cloneState = stateFlowGraph.addState(newState);
 
 		// Is there a clone detected?
 		if (cloneState != null) {
@@ -145,7 +145,7 @@
 	 * 
 	 * @return the current State.
 	 */
-	public StateVertix getCurrentState() {
+	public StateVertex getCurrentState() {
 		return currentState;
 	}
 
@@ -168,9 +168,9 @@
 	 *            the current Session
 	 * @return true if the new state is not found in the state machine.
 	 */
-	public boolean update(final Eventable event, StateVertix newState, EmbeddedBrowser browser,
+	public boolean update(final Eventable event, StateVertex newState, EmbeddedBrowser browser,
 	        CrawlSession session) {
-		StateVertix cloneState = this.addStateToCurrentState(newState, event);
+		StateVertex cloneState = this.addStateToCurrentState(newState, event);
 
 		if (cloneState != null) {
 			newState = cloneState;
"
5e6e1a6f08e8815a4faf34161b20b865b9f907e8,Ali Mesbah,StateFlowGraph.java,MODIFY,"addState -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index 4be6150..aaca56f 100644
--- a/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -1,29 +1,31 @@
 package com.crawljax.core.state;
 
-import net.jcip.annotations.GuardedBy;
-
-import org.apache.commons.math.stat.descriptive.moment.Mean;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-import org.jgrapht.DirectedGraph;
-import org.jgrapht.GraphPath;
-import org.jgrapht.alg.DijkstraShortestPath;
-import org.jgrapht.alg.KShortestPaths;
-import org.jgrapht.graph.DirectedMultigraph;
-
+import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 import java.util.concurrent.atomic.AtomicInteger;
 
+import net.jcip.annotations.GuardedBy;
+
+import org.apache.commons.math.stat.descriptive.moment.Mean;
+import org.jgrapht.DirectedGraph;
+import org.jgrapht.GraphPath;
+import org.jgrapht.alg.DijkstraShortestPath;
+import org.jgrapht.alg.KShortestPaths;
+import org.jgrapht.graph.DirectedMultigraph;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
 /**
- * The State-Flow Graph is a directed graph with states on the vertices and clickables on the edges.
- * 
- * @author mesbah
- * @version $Id$
+ * The State-Flow Graph is a multi-edge directed graph with states (StateVetex) on the vertices and
+ * clickables (Eventable) on the edges.
  */
-public class StateFlowGraph {
+public class StateFlowGraph implements Serializable {
+
+	private static final long serialVersionUID = 923403417983488L;
+
 	private static final Logger LOGGER = LoggerFactory.getLogger(StateFlowGraph.class.getName());
 
 	private final DirectedGraph<StateVertex, Eventable> sfg;
"
262b2d4fcada61b6cc5b71cf9440f0da1a0f380b,Arie van Deursen,StateFlowGraph.java,MODIFY,"addState -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index bbcead3..aaca56f 100644
--- a/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -1,32 +1,34 @@
 package com.crawljax.core.state;
 
-import net.jcip.annotations.GuardedBy;
-
-import org.apache.commons.math.stat.descriptive.moment.Mean;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-import org.jgrapht.DirectedGraph;
-import org.jgrapht.GraphPath;
-import org.jgrapht.alg.DijkstraShortestPath;
-import org.jgrapht.alg.KShortestPaths;
-import org.jgrapht.graph.DirectedMultigraph;
-
+import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 import java.util.concurrent.atomic.AtomicInteger;
 
+import net.jcip.annotations.GuardedBy;
+
+import org.apache.commons.math.stat.descriptive.moment.Mean;
+import org.jgrapht.DirectedGraph;
+import org.jgrapht.GraphPath;
+import org.jgrapht.alg.DijkstraShortestPath;
+import org.jgrapht.alg.KShortestPaths;
+import org.jgrapht.graph.DirectedMultigraph;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
 /**
- * The State-Flow Graph is a directed graph with states on the vertices and clickables on the edges.
- * 
- * @author mesbah
- * @version $Id$
+ * The State-Flow Graph is a multi-edge directed graph with states (StateVetex) on the vertices and
+ * clickables (Eventable) on the edges.
  */
-public class StateFlowGraph {
+public class StateFlowGraph implements Serializable {
+
+	private static final long serialVersionUID = 923403417983488L;
+
 	private static final Logger LOGGER = LoggerFactory.getLogger(StateFlowGraph.class.getName());
 
-	private final DirectedGraph<StateVertix, Eventable> sfg;
+	private final DirectedGraph<StateVertex, Eventable> sfg;
 
 	/**
 	 * Intermediate counter for the number of states, not relaying on getAllStates.size() because of
@@ -38,7 +40,7 @@
 	 * Empty constructor.
 	 */
 	public StateFlowGraph() {
-		sfg = new DirectedMultigraph<StateVertix, Eventable>(Eventable.class);
+		sfg = new DirectedMultigraph<StateVertex, Eventable>(Eventable.class);
 	}
 
 	/**
@@ -47,7 +49,7 @@
 	 * @param initialState
 	 *            the state to start from.
 	 */
-	public StateFlowGraph(StateVertix initialState) {
+	public StateFlowGraph(StateVertex initialState) {
 		this();
 		sfg.addVertex(initialState);
 	}
@@ -66,7 +68,7 @@
 	 * @return the clone if one is detected null otherwise.
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
-	public StateVertix addState(StateVertix stateVertix) {
+	public StateVertex addState(StateVertex stateVertix) {
 		return addState(stateVertix, true);
 	}
 
@@ -87,7 +89,7 @@
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
 	@GuardedBy(""sfg"")
-	public StateVertix addState(StateVertix stateVertix, boolean correctName) {
+	public StateVertex addState(StateVertex stateVertix, boolean correctName) {
 		synchronized (sfg) {
 			if (!sfg.addVertex(stateVertix)) {
 				// Graph already contained the vertix
@@ -136,7 +138,7 @@
 	 * @see org.jgrapht.Graph#addEdge(Object, Object, Object)
 	 */
 	@GuardedBy(""sfg"")
-	public boolean addEdge(StateVertix sourceVert, StateVertix targetVert, Eventable clickable) {
+	public boolean addEdge(StateVertex sourceVert, StateVertex targetVert, Eventable clickable) {
 		synchronized (sfg) {
 			// TODO Ali; Why is this code (if-stmt) here? Its the same as what happens in sfg.addEge
 			// imo (21-01-10 Stefan).
@@ -166,7 +168,7 @@
 	 * @return a set of the outgoing edges (clickables) of the stateVertix.
 	 * @see org.jgrapht.DirectedGraph#outgoingEdgesOf(Object)
 	 */
-	public Set<Eventable> getOutgoingClickables(StateVertix stateVertix) {
+	public Set<Eventable> getOutgoingClickables(StateVertex stateVertix) {
 		return sfg.outgoingEdgesOf(stateVertix);
 	}
 
@@ -178,7 +180,7 @@
 	 * @return a set of the incoming edges (clickables) of the stateVertix.
 	 * @see org.jgrapht.DirectedGraph#incomingEdgesOf(Object)
 	 */
-	public Set<Eventable> getIncomingClickable(StateVertix stateVertix) {
+	public Set<Eventable> getIncomingClickable(StateVertex stateVertix) {
 		return sfg.incomingEdgesOf(stateVertix);
 	}
 
@@ -189,8 +191,8 @@
 	 *            the state.
 	 * @return the set of outgoing states from the stateVertix.
 	 */
-	public Set<StateVertix> getOutgoingStates(StateVertix stateVertix) {
-		final Set<StateVertix> result = new HashSet<StateVertix>();
+	public Set<StateVertex> getOutgoingStates(StateVertex stateVertix) {
+		final Set<StateVertex> result = new HashSet<StateVertex>();
 
 		for (Eventable c : getOutgoingClickables(stateVertix)) {
 			result.add(sfg.getEdgeTarget(c));
@@ -204,7 +206,7 @@
 	 *            the edge.
 	 * @return the target state of this edge.
 	 */
-	public StateVertix getTargetState(Eventable clickable) {
+	public StateVertex getTargetState(Eventable clickable) {
 		return sfg.getEdgeTarget(clickable);
 	}
 
@@ -218,7 +220,7 @@
 	 * @return true if it is possible (edge exists in graph) to go from source to target.
 	 */
 	@GuardedBy(""sfg"")
-	public boolean canGoTo(StateVertix source, StateVertix target) {
+	public boolean canGoTo(StateVertex source, StateVertex target) {
 		synchronized (sfg) {
 			return sfg.containsEdge(source, target) || sfg.containsEdge(target, source);
 		}
@@ -233,7 +235,7 @@
 	 *            the end state.
 	 * @return a list of shortest path of clickables from the state to the end
 	 */
-	public List<Eventable> getShortestPath(StateVertix start, StateVertix end) {
+	public List<Eventable> getShortestPath(StateVertex start, StateVertex end) {
 		return DijkstraShortestPath.findPathBetween(sfg, start, end);
 	}
 
@@ -242,7 +244,7 @@
 	 * 
 	 * @return all the states on the graph.
 	 */
-	public Set<StateVertix> getAllStates() {
+	public Set<StateVertex> getAllStates() {
 		return sfg.vertexSet();
 	}
 
@@ -263,10 +265,10 @@
 	 *            the StateVertix to search
 	 * @return the copy of the StateVertix in the StateFlowGraph where v.equals(u)
 	 */
-	private StateVertix getStateInGraph(StateVertix state) {
-		Set<StateVertix> states = getAllStates();
+	private StateVertex getStateInGraph(StateVertex state) {
+		Set<StateVertex> states = getAllStates();
 
-		for (StateVertix st : states) {
+		for (StateVertex st : states) {
 			if (state.equals(st)) {
 				return st;
 			}
@@ -281,7 +283,7 @@
 	public int getMeanStateStringSize() {
 		final Mean mean = new Mean();
 
-		for (StateVertix state : getAllStates()) {
+		for (StateVertex state : getAllStates()) {
 			mean.increment(state.getDomSize());
 		}
 
@@ -291,7 +293,7 @@
 	/**
 	 * @return the state-flow graph.
 	 */
-	public DirectedGraph<StateVertix, Eventable> getSfg() {
+	public DirectedGraph<StateVertex, Eventable> getSfg() {
 		return sfg;
 	}
 
@@ -300,20 +302,20 @@
 	 *            The starting state.
 	 * @return A list of the deepest states (states with no outgoing edges).
 	 */
-	public List<StateVertix> getDeepStates(StateVertix state) {
+	public List<StateVertex> getDeepStates(StateVertex state) {
 		final Set<String> visitedStates = new HashSet<String>();
-		final List<StateVertix> deepStates = new ArrayList<StateVertix>();
+		final List<StateVertex> deepStates = new ArrayList<StateVertex>();
 
 		traverse(visitedStates, deepStates, state);
 
 		return deepStates;
 	}
 
-	private void traverse(Set<String> visitedStates, List<StateVertix> deepStates,
-	        StateVertix state) {
+	private void traverse(Set<String> visitedStates, List<StateVertex> deepStates,
+	        StateVertex state) {
 		visitedStates.add(state.getName());
 
-		Set<StateVertix> outgoingSet = getOutgoingStates(state);
+		Set<StateVertex> outgoingSet = getOutgoingStates(state);
 
 		if ((outgoingSet == null) || outgoingSet.isEmpty()) {
 			deepStates.add(state);
@@ -321,7 +323,7 @@
 			if (cyclic(visitedStates, outgoingSet)) {
 				deepStates.add(state);
 			} else {
-				for (StateVertix st : outgoingSet) {
+				for (StateVertex st : outgoingSet) {
 					if (!visitedStates.contains(st.getName())) {
 						traverse(visitedStates, deepStates, st);
 					}
@@ -330,10 +332,10 @@
 		}
 	}
 
-	private boolean cyclic(Set<String> visitedStates, Set<StateVertix> outgoingSet) {
+	private boolean cyclic(Set<String> visitedStates, Set<StateVertex> outgoingSet) {
 		int i = 0;
 
-		for (StateVertix state : outgoingSet) {
+		for (StateVertex state : outgoingSet) {
 			if (visitedStates.contains(state.getName())) {
 				i++;
 			}
@@ -349,19 +351,19 @@
 	 *            the initial state.
 	 * @return a list of GraphPath lists.
 	 */
-	public List<List<GraphPath<StateVertix, Eventable>>> getAllPossiblePaths(StateVertix index) {
-		final List<List<GraphPath<StateVertix, Eventable>>> results =
-		        new ArrayList<List<GraphPath<StateVertix, Eventable>>>();
+	public List<List<GraphPath<StateVertex, Eventable>>> getAllPossiblePaths(StateVertex index) {
+		final List<List<GraphPath<StateVertex, Eventable>>> results =
+		        new ArrayList<List<GraphPath<StateVertex, Eventable>>>();
 
-		final KShortestPaths<StateVertix, Eventable> kPaths =
-		        new KShortestPaths<StateVertix, Eventable>(this.sfg, index, Integer.MAX_VALUE);
+		final KShortestPaths<StateVertex, Eventable> kPaths =
+		        new KShortestPaths<StateVertex, Eventable>(this.sfg, index, Integer.MAX_VALUE);
 		// System.out.println(sfg.toString());
 
-		for (StateVertix state : getDeepStates(index)) {
+		for (StateVertex state : getDeepStates(index)) {
 			// System.out.println(""Deep State: "" + state.getName());
 
 			try {
-				List<GraphPath<StateVertix, Eventable>> paths = kPaths.getPaths(state);
+				List<GraphPath<StateVertex, Eventable>> paths = kPaths.getPaths(state);
 				results.add(paths);
 			} catch (Exception e) {
 				// TODO Stefan; which Exception is catched here???Can this be removed?
"
3c8ae28665d84358f399e8b6bf9c817d653cb999,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index d97ab0c..22df7a8 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -11,8 +11,6 @@
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
 import org.openqa.selenium.ElementNotVisibleException;
 import org.openqa.selenium.JavascriptExecutor;
 import org.openqa.selenium.NoSuchElementException;
@@ -30,6 +28,8 @@
 import org.openqa.selenium.remote.HttpCommandExecutor;
 import org.openqa.selenium.remote.RemoteWebDriver;
 import org.openqa.selenium.support.ui.Select;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 import org.w3c.dom.DOMException;
 import org.w3c.dom.Document;
 import org.w3c.dom.Element;
@@ -57,7 +57,8 @@
  */
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
 	private long crawlWaitEvent;
-	private static final Logger LOGGER = LoggerFactory.getLogger(WebDriverBackedEmbeddedBrowser.class);
+	private static final Logger LOGGER = LoggerFactory
+	        .getLogger(WebDriverBackedEmbeddedBrowser.class);
 	private final WebDriver browser;
 
 	private List<String> filterAttributes;
@@ -255,6 +256,7 @@
 	 * @param url
 	 *            The URL.
 	 */
+	@Override
 	public void goToUrl(String url) {
 		try {
 			browser.navigate().to(url);
@@ -414,6 +416,7 @@
 	 *            The input.
 	 * @return true if succeeds.
 	 */
+	@Override
 	public boolean input(Identification identification, String text) {
 		try {
 			WebElement field = browser.findElement(identification.getWebDriverBy());
@@ -440,6 +443,7 @@
 	 *            The eventable.
 	 * @return true if it is able to fire the event successfully on the element.
 	 */
+	@Override
 	public synchronized boolean fireEvent(Eventable eventable) {
 		try {
 
@@ -489,6 +493,7 @@
 	 * @throws CrawljaxException
 	 *             when javascript execution failed.
 	 */
+	@Override
 	public Object executeJavaScript(String code) throws CrawljaxException {
 		try {
 			JavascriptExecutor js = (JavascriptExecutor) browser;
@@ -506,6 +511,7 @@
 	 *            The element to search for.
 	 * @return true if the element is visible
 	 */
+	@Override
 	public boolean isVisible(Identification identification) {
 		try {
 			WebElement el = browser.findElement(identification.getWebDriverBy());
@@ -523,6 +529,7 @@
 	/**
 	 * @return The current browser url.
 	 */
+	@Override
 	public String getCurrentUrl() {
 		try {
 			return browser.getCurrentUrl();
@@ -656,6 +663,7 @@
 	 * @return the dom without the iframe contents.
 	 * @see com.crawljax.browser.EmbeddedBrowser#getDomWithoutIframeContent()
 	 */
+	@Override
 	public String getDomWithoutIframeContent() {
 		try {
 			String dom = browser.getPageSource();
@@ -674,6 +682,7 @@
 	 *            the input to be filled.
 	 * @return FormInput with random value assigned if possible
 	 */
+	@Override
 	public FormInput getInputWithRandomValue(FormInput input) {
 
 		WebElement webElement;
@@ -747,6 +756,7 @@
 	 *            the identification of the element.
 	 * @return true if the element can be found in the DOM tree.
 	 */
+	@Override
 	public boolean elementExists(Identification identification) {
 		try {
 			WebElement el = browser.findElement(identification.getWebDriverBy());
@@ -764,6 +774,7 @@
 	 *            the identification of the element.
 	 * @return the found element.
 	 */
+	@Override
 	public WebElement getWebElement(Identification identification) {
 		try {
 			return browser.findElement(identification.getWebDriverBy());
"
3c8ae28665d84358f399e8b6bf9c817d653cb999,Alex Nederlof,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/src/main/java/com/crawljax/core/CrawlQueue.java b/src/main/java/com/crawljax/core/CrawlQueue.java
index 52dc64f..45dbed6 100644
--- a/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -3,18 +3,18 @@
  */
 package com.crawljax.core;
 
-import net.jcip.annotations.GuardedBy;
-
 import java.util.Collection;
 import java.util.Stack;
 import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.TimeUnit;
 
+import net.jcip.annotations.GuardedBy;
+
 /**
  * This class implements a BlockingQueue with Runnable as its Generic type and extends Stack with
  * also Runnable as generic type. This class is used in the ThreadPoolExecutor and its used to store
  * separate threads in a Queue like fashion (FILO).
- *
+ * 
  * @author Stefan Lenselink <S.R.Lenselink@student.tudelft.nl>
  * @version $Id$
  */
"
3c8ae28665d84358f399e8b6bf9c817d653cb999,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/src/main/java/com/crawljax/core/CrawljaxController.java b/src/main/java/com/crawljax/core/CrawljaxController.java
index 61d1efd..5b010f4 100644
--- a/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -1,5 +1,14 @@
 package com.crawljax.core;
 
+import java.util.List;
+import java.util.concurrent.TimeUnit;
+
+import net.jcip.annotations.GuardedBy;
+
+import org.apache.commons.configuration.ConfigurationException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
 import com.crawljax.browser.BrowserPool;
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.browserwaiter.WaitConditionChecker;
@@ -14,24 +23,16 @@
 import com.crawljax.core.state.StateFlowGraph;
 import com.crawljax.oraclecomparator.StateComparator;
 
-import net.jcip.annotations.GuardedBy;
-
-import org.apache.commons.configuration.ConfigurationException;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-
-import java.util.List;
-import java.util.concurrent.TimeUnit;
-
 /**
  * The Crawljax Controller class is the core of Crawljax.
- *
+ * 
  * @author mesbah
  * @version $Id$
  */
 public class CrawljaxController implements CrawlQueueManager {
 
-	private static final Logger LOGGER = LoggerFactory.getLogger(CrawljaxController.class.getName());
+	private static final Logger LOGGER = LoggerFactory.getLogger(CrawljaxController.class
+	        .getName());
 
 	private CrawlSession session;
 
@@ -97,8 +98,8 @@
 		CrawljaxPluginsUtil.loadPlugins(configurationReader.getPlugins());
 
 		if (configurationReader.getProxyConfiguration() != null) {
-			CrawljaxPluginsUtil.runProxyServerPlugins(
-			        configurationReader.getProxyConfiguration());
+			CrawljaxPluginsUtil
+			        .runProxyServerPlugins(configurationReader.getProxyConfiguration());
 		}
 
 		LOGGER.info(""Embedded browser implementation: "" + configurationReader.getBrowser());
@@ -106,17 +107,17 @@
 		LOGGER.info(""Number of threads: ""
 		        + configurationReader.getThreadConfigurationReader().getNumberThreads());
 
-		LOGGER.info(
-		        ""Crawl depth: "" + configurationReader.getCrawlSpecificationReader().getDepth());
+		LOGGER.info(""Crawl depth: ""
+		        + configurationReader.getCrawlSpecificationReader().getDepth());
 		LOGGER.info(""Crawljax initialized!"");
 
-		return new CrawlerExecutor(
-		        configurationReader.getThreadConfigurationReader().getNumberThreads());
+		return new CrawlerExecutor(configurationReader.getThreadConfigurationReader()
+		        .getNumberThreads());
 	}
 
 	/**
 	 * Run Crawljax.
-	 *
+	 * 
 	 * @throws CrawljaxException
 	 *             If the browser cannot be instantiated.
 	 * @throws ConfigurationException
@@ -127,9 +128,8 @@
 
 		startCrawl = System.currentTimeMillis();
 
-		LOGGER.info(
-		        ""Start crawling with "" + configurationReader.getAllIncludedCrawlElements().size()
-		                + "" crawl elements"");
+		LOGGER.info(""Start crawling with ""
+		        + configurationReader.getAllIncludedCrawlElements().size() + "" crawl elements"");
 
 		// Create the initailCrawler
 		initialCrawler = new InitialCrawler(this);
@@ -143,15 +143,15 @@
 		} catch (InterruptedException e) {
 			LOGGER.error(e.getMessage(), e);
 		}
-		
+
 		if (workQueue.isAborted()) {
 			LOGGER.warn(""It apears to be that the workQueue was Aborted, ""
 			        + ""not running postcrawling plugins and not closing the browsers"");
 			return;
 		}
-		
+
 		long timeCrawlCalc = System.currentTimeMillis() - startCrawl;
-		
+
 		/**
 		 * Close all the opened browsers, this is run in separate thread to have the post crawl
 		 * plugins to execute in the meanwhile.
@@ -176,13 +176,13 @@
 		} catch (InterruptedException e) {
 			LOGGER.error(""could not wait for browsers to close."", e);
 		}
-		
+
 	}
 
 	/**
 	 * Retrieve the current session, there is only one session active at a time. So this method by
 	 * it self is Thread-Safe but actions on the session are NOT!
-	 *
+	 * 
 	 * @return the session
 	 */
 	public CrawlSession getSession() {
@@ -191,10 +191,11 @@
 
 	/**
 	 * Add work (Crawler) to the Queue of work that need to be done. The class is thread-safe.
-	 *
+	 * 
 	 * @param work
 	 *            the work (Crawler) to add to the Queue
 	 */
+	@Override
 	public final void addWorkToQueue(Crawler work) {
 		workQueue.execute(work);
 	}
@@ -202,18 +203,19 @@
 	/**
 	 * Removes this Crawler from the workQueue if it is present, thus causing it not to be run if it
 	 * has not already started.
-	 *
+	 * 
 	 * @param crawler
 	 *            the Crawler to remove
 	 * @return true if the crawler was removed
 	 */
+	@Override
 	public boolean removeWorkFromQueue(Crawler crawler) {
 		return workQueue.remove(crawler);
 	}
 
 	/**
 	 * Wait for a given condition. This call is thread safe as the underlying object is thread-safe.
-	 *
+	 * 
 	 * @param browser
 	 *            the browser which requires a wait condition
 	 */
@@ -226,7 +228,7 @@
 	 * because ThreadLocal is not ThreadSafe??? get the stripped version of the dom currently in the
 	 * browser. This call is thread safe, must be synchronised because there is thread-intefearing
 	 * bug in the stateComparator.
-	 *
+	 * 
 	 * @param browser
 	 *            the browser instance.
 	 * @return a stripped string of the DOM tree taken from the browser.
@@ -246,7 +248,7 @@
 
 	/**
 	 * Retrieve the initial Crawler used.
-	 *
+	 * 
 	 * @return the initialCrawler used to initiate the Crawling run.
 	 */
 	public final Crawler getInitialCrawler() {
@@ -256,7 +258,7 @@
 	/**
 	 * Format the time the current crawl run has taken into a more readable format. Taking now as
 	 * the end time of the crawling.
-	 *
+	 * 
 	 * @return the formatted time in X min, X sec layout.
 	 */
 	private String formatRunningTime() {
@@ -265,25 +267,29 @@
 
 	/**
 	 * Format the time the current crawl run has taken into a more readable format.
-	 *
+	 * 
 	 * @param timeCrawlCalc
 	 *            the time to display
 	 * @return the formatted time in X min, X sec layout.
 	 */
 	private String formatRunningTime(long timeCrawlCalc) {
-		return String.format(""%d min, %d sec"", TimeUnit.MILLISECONDS.toMinutes(timeCrawlCalc),
-		        TimeUnit.MILLISECONDS.toSeconds(timeCrawlCalc) - TimeUnit.MINUTES.toSeconds(
-		                TimeUnit.MILLISECONDS.toMinutes(timeCrawlCalc)));
+		return String.format(
+		        ""%d min, %d sec"",
+		        TimeUnit.MILLISECONDS.toMinutes(timeCrawlCalc),
+		        TimeUnit.MILLISECONDS.toSeconds(timeCrawlCalc)
+		                - TimeUnit.MINUTES.toSeconds(TimeUnit.MILLISECONDS
+		                        .toMinutes(timeCrawlCalc)));
 	}
 
 	/**
 	 * Terminate the crawling, Stop all threads this will cause the controller which is sleeping to
 	 * reactive and do the final work....
-	 *
+	 * 
 	 * @param isAbort
 	 *            if set true the terminate must be as an abort not allowing running PostCrawling
 	 *            plugins.
 	 */
+	@Override
 	@GuardedBy(""this"")
 	public final synchronized void terminate(boolean isAbort) {
 		LOGGER.warn(""After "" + this.formatRunningTime()
@@ -313,7 +319,7 @@
 	/**
 	 * The current element checker in use. This call is thread-safe because it returns a final
 	 * field.
-	 *
+	 * 
 	 * @return the elementChecker used to register the checked elements.
 	 */
 	public final ExtractorManager getElementChecker() {
@@ -338,7 +344,7 @@
 	 * Return the used CrawlQueueManager, this method is designed for extension purposes. Being able
 	 * to move the {@link #addWorkToQueue(Crawler)} and {@link #removeWorkFromQueue(Crawler)} out of
 	 * this class using the interface.
-	 *
+	 * 
 	 * @return the crawlQueueManager that is used.
 	 */
 	public CrawlQueueManager getCrawlQueueManager() {
@@ -354,7 +360,7 @@
 
 	/**
 	 * Install a new CrawlSession.
-	 *
+	 * 
 	 * @param session
 	 *            set the new value for the session
 	 */
"
3c8ae28665d84358f399e8b6bf9c817d653cb999,Alex Nederlof,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 225ec9e..1a759f0 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -95,39 +95,37 @@
 		crawlActions.click(""input"").withAttribute(""type"", ""button"");
 	}
 
-        
 	/**
-         * Guifre Ruiz: This method can be used to crawl more tags and, therefore,
-         * more pages in the target. However, it slow down a bit the process.
-         */ 
-        public void clickMoreElements() {
-            crawlActions.click(""a"");
-            crawlActions.click(""button"");
-            crawlActions.click(""td"");
-            crawlActions.click(""span"");
-            crawlActions.click(""div"");
-            crawlActions.click(""tr"");
-            crawlActions.click(""table"");
-            crawlActions.click(""tbody"");
-            crawlActions.click(""ol"");
-            crawlActions.click(""center"");
-            crawlActions.click(""li"");
-            crawlActions.click(""radio"");
-            crawlActions.click(""non"");
-            crawlActions.click(""meta"");
-            crawlActions.click(""refresh"");
-            crawlActions.click(""xhr"");
-            crawlActions.click(""relative"");
-            crawlActions.click(""link"");
-            crawlActions.click(""self"");
-            crawlActions.click(""form"");
-            crawlActions.click(""input"");
-            crawlActions.click(""option"");
-            crawlActions.click(""img"");
-            crawlActions.click(""p"");    
-        }
+	 * Guifre Ruiz: This method can be used to crawl more tags and, therefore, more pages in the
+	 * target. However, it slow down a bit the process.
+	 */
+	public void clickMoreElements() {
+		crawlActions.click(""a"");
+		crawlActions.click(""button"");
+		crawlActions.click(""td"");
+		crawlActions.click(""span"");
+		crawlActions.click(""div"");
+		crawlActions.click(""tr"");
+		crawlActions.click(""table"");
+		crawlActions.click(""tbody"");
+		crawlActions.click(""ol"");
+		crawlActions.click(""center"");
+		crawlActions.click(""li"");
+		crawlActions.click(""radio"");
+		crawlActions.click(""non"");
+		crawlActions.click(""meta"");
+		crawlActions.click(""refresh"");
+		crawlActions.click(""xhr"");
+		crawlActions.click(""relative"");
+		crawlActions.click(""link"");
+		crawlActions.click(""self"");
+		crawlActions.click(""form"");
+		crawlActions.click(""input"");
+		crawlActions.click(""option"");
+		crawlActions.click(""img"");
+		crawlActions.click(""p"");
+	}
 
-        
 	/**
 	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
 	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}.
"
3c8ae28665d84358f399e8b6bf9c817d653cb999,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 24c101f..e7c8ebf 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -3,9 +3,9 @@
 import java.util.ArrayList;
 import java.util.List;
 
+import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.browser.EmbeddedBrowserBuilder;
 import com.crawljax.browser.WebDriverBrowserBuilder;
-import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.util.Helper;
"
3c8ae28665d84358f399e8b6bf9c817d653cb999,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index cf51040..46ae2c7 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -3,13 +3,12 @@
  */
 package com.crawljax.forms;
 
-import com.crawljax.browser.EmbeddedBrowser;
-import com.crawljax.condition.eventablecondition.EventableCondition;
-import com.crawljax.core.CandidateElement;
-import com.crawljax.core.configuration.InputSpecification;
-import com.crawljax.core.exception.BrowserConnectionException;
-import com.crawljax.util.Helper;
-import com.crawljax.util.XPathHelper;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+
+import javax.xml.xpath.XPathExpressionException;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -19,12 +18,13 @@
 import org.w3c.dom.NodeList;
 import org.xml.sax.SAXException;
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.List;
-
-import javax.xml.xpath.XPathExpressionException;
+import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.condition.eventablecondition.EventableCondition;
+import com.crawljax.core.CandidateElement;
+import com.crawljax.core.configuration.InputSpecification;
+import com.crawljax.core.exception.BrowserConnectionException;
+import com.crawljax.util.Helper;
+import com.crawljax.util.XPathHelper;
 
 /**
  * Handles form values and fills in the form input elements with random values of the defined
@@ -148,7 +148,7 @@
 					}
 				}
 			} catch (Exception e) {
-				//TODO Stefan; refactor this catch
+				// TODO Stefan; refactor this catch
 				if (e instanceof BrowserConnectionException) {
 					throw (BrowserConnectionException) e;
 				}
"
3c8ae28665d84358f399e8b6bf9c817d653cb999,Alex Nederlof,AttributeInjector.java,MODIFY,"removeInjectedAttributes -> [HTMLElement element, String attrName] | [Vector injectedElements, String attrName]","diff --git a/src/main/java/com/crawljax/util/AttributeInjector.java b/src/main/java/com/crawljax/util/AttributeInjector.java
index bbb5a37..4e76dd0 100644
--- a/src/main/java/com/crawljax/util/AttributeInjector.java
+++ b/src/main/java/com/crawljax/util/AttributeInjector.java
@@ -142,7 +142,7 @@
 			element.removeAttribute(attrName);
 			// check if the attr was appended to the src value
 			// String srcAttrValue = element.getAttribute(""src"");
-			//			
+			//
 			// if(srcAttrValue.matches("".*"" + attrName + ""=.*""))
 			// {
 			// int index = srcAttrValue.indexOf(attrName);
"
3c8ae28665d84358f399e8b6bf9c817d653cb999,Alex Nederlof,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/src/main/java/com/crawljax/util/ElementResolver.java b/src/main/java/com/crawljax/util/ElementResolver.java
index 65a531d..605a685 100644
--- a/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/src/main/java/com/crawljax/util/ElementResolver.java
@@ -1,8 +1,8 @@
 package com.crawljax.util;
 
-import com.crawljax.browser.EmbeddedBrowser;
-import com.crawljax.core.state.Element;
-import com.crawljax.core.state.Eventable;
+import java.io.IOException;
+
+import javax.xml.xpath.XPathExpressionException;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -11,9 +11,9 @@
 import org.w3c.dom.NodeList;
 import org.xml.sax.SAXException;
 
-import java.io.IOException;
-
-import javax.xml.xpath.XPathExpressionException;
+import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.core.state.Element;
+import com.crawljax.core.state.Eventable;
 
 /**
  * class for finding and checking elements.
@@ -58,7 +58,7 @@
 	public String resolve(boolean logging) {
 		Document dom = null;
 		try {
-	        dom = Helper.getDocument(browser.getDom());
+			dom = Helper.getDocument(browser.getDom());
 		} catch (SAXException e) {
 			LOGGER.error(e.getMessage(), e);
 			return """";
@@ -66,7 +66,7 @@
 			LOGGER.error(e.getMessage(), e);
 			return """";
 		}
-		
+
 		try {
 			String xpathEventable = eventable.getIdentification().getValue();
 			Node nodeSameXpath = Helper.getElementByXpath(dom, xpathEventable);
"
3c8ae28665d84358f399e8b6bf9c817d653cb999,Alex Nederlof,Helper.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/src/main/java/com/crawljax/util/Helper.java b/src/main/java/com/crawljax/util/Helper.java
index e4815b8..a238623 100644
--- a/src/main/java/com/crawljax/util/Helper.java
+++ b/src/main/java/com/crawljax/util/Helper.java
@@ -35,13 +35,13 @@
 import javax.xml.xpath.XPathFactory;
 
 import org.apache.commons.io.FileUtils;
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
 import org.custommonkey.xmlunit.DetailedDiff;
 import org.custommonkey.xmlunit.Diff;
 import org.custommonkey.xmlunit.Difference;
 import org.custommonkey.xmlunit.DifferenceListener;
 import org.cyberneko.html.parsers.DOMParser;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
 import org.w3c.dom.Attr;
 import org.w3c.dom.Document;
 import org.w3c.dom.Element;
"
ba877d01152f4ea7eb17bf338e8c8b9e4e18a267,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 72ec044..22df7a8 100644
--- a/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -1,874 +1,886 @@
-package com.crawljax.browser;
-
-import java.io.File;
-import java.io.IOException;
-import java.net.MalformedURLException;
-import java.net.URL;
-import java.util.ArrayList;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-
-import org.apache.log4j.Logger;
-import org.openqa.selenium.ElementNotVisibleException;
-import org.openqa.selenium.JavascriptExecutor;
-import org.openqa.selenium.NoSuchElementException;
-import org.openqa.selenium.NoSuchFrameException;
-import org.openqa.selenium.OutputType;
-import org.openqa.selenium.Platform;
-import org.openqa.selenium.TakesScreenshot;
-import org.openqa.selenium.WebDriver;
-import org.openqa.selenium.WebDriverException;
-import org.openqa.selenium.WebElement;
-import org.openqa.selenium.internal.WrapsDriver;
-import org.openqa.selenium.io.FileHandler;
-import org.openqa.selenium.remote.Augmenter;
-import org.openqa.selenium.remote.DesiredCapabilities;
-import org.openqa.selenium.remote.HttpCommandExecutor;
-import org.openqa.selenium.remote.RemoteWebDriver;
-import org.openqa.selenium.support.ui.Select;
-import org.w3c.dom.DOMException;
-import org.w3c.dom.Document;
-import org.w3c.dom.Element;
-import org.w3c.dom.NodeList;
-import org.xml.sax.SAXException;
-
-import com.crawljax.core.CrawljaxException;
-import com.crawljax.core.configuration.AcceptAllFramesChecker;
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
-import com.crawljax.core.configuration.IgnoreFrameChecker;
-import com.crawljax.core.exception.BrowserConnectionException;
-import com.crawljax.core.state.Eventable;
-import com.crawljax.core.state.Identification;
-import com.crawljax.forms.FormHandler;
-import com.crawljax.forms.FormInput;
-import com.crawljax.forms.InputValue;
-import com.crawljax.forms.RandomInputValueGenerator;
-import com.crawljax.util.Helper;
-
-/**
- * @author mesbah
- * @author Frank Groeneveld
- * @version $Id: WebDriverBackedEmbeddedBrowser.java 387 2010-07-13 13:55:49Z slenselink@google.com
- *          $
- */
-public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
-	private long crawlWaitEvent;
-	private static final Logger LOGGER = Logger.getLogger(WebDriverBackedEmbeddedBrowser.class);
-	private final WebDriver browser;
-
-	private List<String> filterAttributes;
-	private long crawlWaitReload;
-	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
-
-	/**
-	 * Constructor without configuration values, these must be updated using the
-	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
-		this.browser = driver;
-	}
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent) {
-		this(driver);
-		this.filterAttributes = filterAttributes;
-		this.crawlWaitEvent = crawlWaitEvent;
-		this.crawlWaitReload = crawlWaitReload;
-	}
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
-		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
-		this.ignoreFrameChecker = ignoreFrameChecker;
-	}
-
-	/**
-	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param hubUrl
-	 *            Url of the server.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
-		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
-		        filterAttributes, crawlWaitEvent, crawlWaitReload);
-	}
-
-	/**
-	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param hubUrl
-	 *            Url of the server.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-	        IgnoreFrameChecker ignoreFrameChecker) {
-		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
-		        filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
-	}
-
-	/**
-	 * Create a WebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
-		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
-		        crawlWaitReload);
-	}
-
-	/**
-	 * Create a WebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-	        IgnoreFrameChecker ignoreFrameChecker) {
-		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
-		        crawlWaitReload, ignoreFrameChecker);
-	}
-
-	/**
-	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param hubUrl
-	 *            Url of the server.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl) {
-		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl));
-	}
-
-	/**
-	 * Private used static method for creation of a RemoteWebDriver. Taking care of the default
-	 * Capabilities and using the HttpCommandExecutor.
-	 * 
-	 * @param hubUrl
-	 *            the url of the hub to use.
-	 * @return the RemoteWebDriver instance.
-	 */
-	private static RemoteWebDriver buildRemoteWebDriver(String hubUrl) {
-		DesiredCapabilities capabilities = new DesiredCapabilities();
-		capabilities.setPlatform(Platform.ANY);
-		URL url;
-		try {
-			url = new URL(hubUrl);
-		} catch (MalformedURLException e) {
-			LOGGER.error(""The given hub url of the remote server is malformed can not continue!"",
-			        e);
-			return null;
-		}
-		HttpCommandExecutor executor = null;
-		try {
-			executor = new HttpCommandExecutor(url);
-		} catch (Exception e) {
-			// TODO Stefan; refactor this catch, this will definitely result in NullPointers, why
-			// not throw RuntimeExcption direct?
-			LOGGER.error(""Received unknown exception while creating the ""
-			        + ""HttpCommandExecutor, can not continue!"", e);
-			return null;
-		}
-		return new RemoteWebDriver(executor, capabilities);
-	}
-
-	/**
-	 * Create a WebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @return The EmbeddedBrowser.
-	 */
-	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver) {
-		return new WebDriverBackedEmbeddedBrowser(driver);
-	}
-
-	/**
-	 * @param url
-	 *            The URL.
-	 */
-	public void goToUrl(String url) {
-		try {
-			browser.navigate().to(url);
-			Thread.sleep(this.crawlWaitReload);
-			handlePopups();
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return;
-		} catch (InterruptedException e) {
-			LOGGER.error(""goToUrl got interrupted while waiting for the page to be loaded"", e);
-			return;
-		}
-	}
-
-	/**
-	 * alert, prompt, and confirm behave as if the OK button is always clicked.
-	 */
-	private void handlePopups() {
-		try {
-			executeJavaScript(""window.alert = function(msg){return true;};""
-			        + ""window.confirm = function(msg){return true;};""
-			        + ""window.prompt = function(msg){return true;};"");
-		} catch (CrawljaxException e) {
-			LOGGER.error(""Handling of PopUp windows failed"", e);
-		}
-	}
-
-	/**
-	 * Fires the event and waits for a specified time.
-	 * 
-	 * @param webElement
-	 *            the element to fire event on.
-	 * @param eventable
-	 *            The HTML event type (onclick, onmouseover, ...).
-	 * @return true if firing event is successful.
-	 */
-	protected boolean fireEventWait(WebElement webElement, Eventable eventable) {
-		switch (eventable.getEventType()) {
-			case click:
-				try {
-					webElement.click();
-				} catch (ElementNotVisibleException e1) {
-					LOGGER.info(""Element not visible, so cannot be clicked: ""
-					        + webElement.getTagName().toUpperCase() + "" "" + webElement.getText());
-					return false;
-				} catch (WebDriverException e) {
-					throwIfConnectionException(e);
-					return false;
-				}
-				break;
-			case hover:
-				// todo
-				break;
-
-			default:
-				LOGGER.info(""EventType "" + eventable.getEventType()
-				        + "" not supported in WebDriver."");
-				return false;
-		}
-
-		try {
-			Thread.sleep(this.crawlWaitEvent);
-		} catch (InterruptedException e) {
-			LOGGER.error(""fireEventWait got interrupted during wait process"", e);
-			return false;
-		}
-		return true;
-	}
-
-	@Override
-	public void close() {
-		LOGGER.info(""Closing the browser..."");
-		try {
-			// close browser and close every associated window.
-			browser.quit();
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	@Override
-	public String getDom() {
-
-		try {
-			String dom = toUniformDOM(Helper.getDocumentToString(getDomTreeWithFrames()));
-			LOGGER.debug(dom);
-			return dom;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			LOGGER.warn(e.getMessage(), e);
-			return """";
-		} catch (CrawljaxException e) {
-			LOGGER.warn(e.getMessage(), e);
-			return """";
-		}
-	}
-
-	/**
-	 * @param html
-	 *            The html string.
-	 * @return uniform version of dom with predefined attributes stripped
-	 */
-	private String toUniformDOM(String html) {
-
-		Pattern p =
-		        Pattern.compile(""<SCRIPT(.*?)</SCRIPT>"", Pattern.DOTALL
-		                | Pattern.CASE_INSENSITIVE);
-		Matcher m = p.matcher(html);
-		String htmlFormatted = m.replaceAll("""");
-
-		p = Pattern.compile(""<\\?xml:(.*?)>"");
-		m = p.matcher(html);
-		htmlFormatted = m.replaceAll("""");
-
-		// html = html.replace(""<?xml:namespace prefix = gwt >"", """");
-
-		// TODO (Stefan), Following lines are a serious performance bottle neck...
-		// Document doc = Helper.getDocument(htmlFormatted);
-		// htmlFormatted = Helper.getDocumentToString(doc);
-
-		htmlFormatted = filterAttributes(htmlFormatted);
-		return htmlFormatted;
-	}
-
-	/**
-	 * Filters attributes from the HTML string.
-	 * 
-	 * @param html
-	 *            The HTML to filter.
-	 * @return The filtered HTML string.
-	 */
-	private String filterAttributes(String html) {
-		if (this.filterAttributes != null) {
-			for (String attribute : this.filterAttributes) {
-				String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
-				Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
-				Matcher m = p.matcher(html);
-				html = m.replaceAll("""");
-			}
-		}
-		return html;
-	}
-
-	@Override
-	public void goBack() {
-		try {
-			browser.navigate().back();
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	/**
-	 * @param identification
-	 *            The identification object.
-	 * @param text
-	 *            The input.
-	 * @return true if succeeds.
-	 */
-	public boolean input(Identification identification, String text) {
-		try {
-			WebElement field = browser.findElement(identification.getWebDriverBy());
-			if (field != null) {
-				// first clear the field
-				field.clear();
-				// then fill in
-				field.sendKeys(text);
-
-				// this.activeElement = field;
-				return true;
-			}
-			return false;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return false;
-		}
-	}
-
-	/**
-	 * Fires an event on an element using its identification.
-	 * 
-	 * @param eventable
-	 *            The eventable.
-	 * @return true if it is able to fire the event successfully on the element.
-	 */
-	public synchronized boolean fireEvent(Eventable eventable) {
-		try {
-
-			boolean handleChanged = false;
-			boolean result = false;
-
-			if (eventable.getRelatedFrame() != null && !eventable.getRelatedFrame().equals("""")) {
-				LOGGER.debug(""switching to frame: "" + eventable.getRelatedFrame());
-				try {
-
-					switchToFrame(eventable.getRelatedFrame());
-				} catch (NoSuchFrameException e) {
-					LOGGER.debug(""Frame not found, possibily while back-tracking.."", e);
-					// TODO Stefan, This exception is catched to prevent stopping from working
-					// This was the case on the Gmail case; find out if not switching (catching)
-					// Results in good performance...
-				}
-				handleChanged = true;
-			}
-
-			WebElement webElement =
-			        browser.findElement(eventable.getIdentification().getWebDriverBy());
-
-			if (webElement != null) {
-				result = fireEventWait(webElement, eventable);
-			}
-
-			if (handleChanged) {
-				browser.switchTo().defaultContent();
-			}
-			return result;
-		} catch (NoSuchElementException e) {
-			LOGGER.warn(""Could not fire eventable: "" + eventable.toString());
-			return false;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return false;
-		}
-	}
-
-	/**
-	 * Execute JavaScript in the browser.
-	 * 
-	 * @param code
-	 *            The code to execute.
-	 * @return The return value of the JavaScript.
-	 * @throws CrawljaxException
-	 *             when javascript execution failed.
-	 */
-	public Object executeJavaScript(String code) throws CrawljaxException {
-		try {
-			JavascriptExecutor js = (JavascriptExecutor) browser;
-			return js.executeScript(code);
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			throw new CrawljaxException(e);
-		}
-	}
-
-	/**
-	 * Determines whether the corresponding element is visible.
-	 * 
-	 * @param identification
-	 *            The element to search for.
-	 * @return true if the element is visible
-	 */
-	public boolean isVisible(Identification identification) {
-		try {
-			WebElement el = browser.findElement(identification.getWebDriverBy());
-			if (el != null) {
-				return el.isDisplayed();
-			}
-
-			return false;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return false;
-		}
-	}
-
-	/**
-	 * @return The current browser url.
-	 */
-	public String getCurrentUrl() {
-		try {
-			return browser.getCurrentUrl();
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	@Override
-	public void closeOtherWindows() {
-		try {
-			String current = browser.getWindowHandle();
-			for (String handle : browser.getWindowHandles()) {
-				if (!handle.equals(browser.getWindowHandle())) {
-
-					browser.switchTo().window(handle);
-					LOGGER.info(""Closing other window with title \"""" + browser.getTitle() + ""\"""");
-					browser.close();
-					// browser.switchTo().defaultContent();
-					browser.switchTo().window(current);
-				}
-			}
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	/**
-	 * @return a Document object containing the contents of iframes as well.
-	 * @throws CrawljaxException
-	 *             if an exception is thrown.
-	 */
-	private Document getDomTreeWithFrames() throws CrawljaxException {
-
-		try {
-			Document document = Helper.getDocument(browser.getPageSource());
-			appendFrameContent(document.getDocumentElement(), document, """");
-			return document;
-		} catch (SAXException e) {
-			throw new CrawljaxException(e.getMessage(), e);
-		} catch (IOException e) {
-			throw new CrawljaxException(e.getMessage(), e);
-		}
-
-	}
-
-	private void appendFrameContent(Element orig, Document document, String topFrame) {
-
-		NodeList frameNodes = orig.getElementsByTagName(""IFRAME"");
-
-		List<Element> nodeList = new ArrayList<Element>();
-
-		for (int i = 0; i < frameNodes.getLength(); i++) {
-			Element frameElement = (Element) frameNodes.item(i);
-			nodeList.add(frameElement);
-		}
-
-		// Added support for FRAMES
-		frameNodes = orig.getElementsByTagName(""FRAME"");
-		for (int i = 0; i < frameNodes.getLength(); i++) {
-			Element frameElement = (Element) frameNodes.item(i);
-			nodeList.add(frameElement);
-		}
-
-		for (int i = 0; i < nodeList.size(); i++) {
-			String frameIdentification = """";
-
-			if (topFrame != null && !topFrame.equals("""")) {
-				frameIdentification += topFrame + ""."";
-			}
-
-			Element frameElement = nodeList.get(i);
-
-			String nameId = Helper.getFrameIdentification(frameElement);
-
-			if (nameId != null
-			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
-				frameIdentification += nameId;
-
-				String handle = browser.getWindowHandle();
-
-				LOGGER.debug(""The current H: "" + handle);
-
-				switchToFrame(frameIdentification);
-
-				String toAppend = browser.getPageSource();
-
-				LOGGER.debug(""frame dom: "" + toAppend);
-
-				browser.switchTo().defaultContent();
-
-				try {
-					Element toAppendElement = Helper.getDocument(toAppend).getDocumentElement();
-					Element importedElement =
-					        (Element) document.importNode(toAppendElement, true);
-					frameElement.appendChild(importedElement);
-
-					appendFrameContent(importedElement, document, frameIdentification);
-				} catch (DOMException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				} catch (SAXException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				} catch (IOException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				}
-			}
-		}
-	}
-
-	private void switchToFrame(String frameIdentification) {
-		LOGGER.debug(""frame identification: "" + frameIdentification);
-
-		if (frameIdentification.contains(""."")) {
-			String[] frames = frameIdentification.split(""\\."");
-
-			for (String frameId : frames) {
-				LOGGER.debug(""switching to frame: "" + frameId);
-				browser.switchTo().frame(frameId);
-			}
-
-		} else {
-			browser.switchTo().frame(frameIdentification);
-		}
-
-	}
-
-	/**
-	 * @return the dom without the iframe contents.
-	 * @see com.crawljax.browser.EmbeddedBrowser#getDomWithoutIframeContent()
-	 */
-	public String getDomWithoutIframeContent() {
-		try {
-			String dom = browser.getPageSource();
-			// logger.debug(""driver.source: "" + dom);
-			String result = toUniformDOM(dom);
-			// logger.debug(""driver.source toUniformDom: "" + result);
-			return result;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return """";
-		}
-	}
-
-	/**
-	 * @param input
-	 *            the input to be filled.
-	 * @return FormInput with random value assigned if possible
-	 */
-	public FormInput getInputWithRandomValue(FormInput input) {
-
-		WebElement webElement;
-		try {
-			webElement = browser.findElement(input.getIdentification().getWebDriverBy());
-			if (!(webElement.isDisplayed())) {
-
-				return null;
-			}
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return null;
-		}
-
-		Set<InputValue> values = new HashSet<InputValue>();
-
-		// create some random value
-
-		if (input.getType().toLowerCase().startsWith(""text"")) {
-			values.add(new InputValue(new RandomInputValueGenerator()
-			        .getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
-		} else if (input.getType().equalsIgnoreCase(""checkbox"")
-		        || input.getType().equalsIgnoreCase(""radio"") && !webElement.isSelected()) {
-			if (new RandomInputValueGenerator().getCheck()) {
-				values.add(new InputValue(""1"", true));
-			} else {
-				values.add(new InputValue(""0"", false));
-
-			}
-		} else if (input.getType().equalsIgnoreCase(""select"")) {
-			try {
-				Select select = new Select(webElement);
-				WebElement option =
-				        (WebElement) new RandomInputValueGenerator().getRandomOption(select
-				                .getOptions());
-				values.add(new InputValue(option.getText(), true));
-			} catch (WebDriverException e) {
-				throwIfConnectionException(e);
-				return null;
-			}
-		}
-
-		if (values.size() == 0) {
-			return null;
-		}
-		input.setInputValues(values);
-		return input;
-
-	}
-
-	@Override
-	public String getFrameDom(String iframeIdentification) {
-		try {
-
-			switchToFrame(iframeIdentification);
-
-			// make a copy of the dom before changing into the top page
-			String frameDom = browser.getPageSource();
-
-			browser.switchTo().defaultContent();
-
-			return frameDom;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return """";
-		}
-	}
-
-	/**
-	 * @param identification
-	 *            the identification of the element.
-	 * @return true if the element can be found in the DOM tree.
-	 */
-	public boolean elementExists(Identification identification) {
-		try {
-			WebElement el = browser.findElement(identification.getWebDriverBy());
-			// TODO Stefan; I think el will never be null as a NoSuchElementExcpetion will be
-			// thrown, catched below.
-			return el != null;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return false;
-		}
-	}
-
-	/**
-	 * @param identification
-	 *            the identification of the element.
-	 * @return the found element.
-	 */
-	public WebElement getWebElement(Identification identification) {
-		try {
-			return browser.findElement(identification.getWebDriverBy());
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	/**
-	 * @return the period to wait after an event.
-	 */
-	protected long getCrawlWaitEvent() {
-		return crawlWaitEvent;
-	}
-
-	/**
-	 * @return the list of attributes to be filtered from DOM.
-	 */
-	protected List<String> getFilterAttributes() {
-		return filterAttributes;
-	}
-
-	/**
-	 * @return the period to waint after a reload.
-	 */
-	protected long getCrawlWaitReload() {
-		return crawlWaitReload;
-	}
-
-	private void takeScreenShotOnBrowser(WebDriver driver, File file) throws CrawljaxException {
-		if (driver instanceof TakesScreenshot) {
-			File tmpfile = ((TakesScreenshot) driver).getScreenshotAs(OutputType.FILE);
-
-			try {
-				FileHandler.copy(tmpfile, file);
-			} catch (IOException e) {
-				throw new CrawljaxException(e);
-			}
-
-			removeCanvasGeneratedByFirefoxDriverForScreenshots();
-		} else if (driver instanceof RemoteWebDriver) {
-			WebDriver augmentedWebdriver = new Augmenter().augment(driver);
-			takeScreenShotOnBrowser(augmentedWebdriver, file);
-		} else if (driver instanceof WrapsDriver) {
-			takeScreenShotOnBrowser(((WrapsDriver) driver).getWrappedDriver(), file);
-		} else {
-			throw new CrawljaxException(""Your current WebDriver doesn't support screenshots."");
-		}
-	}
-
-	@Override
-	public void saveScreenShot(File file) throws CrawljaxException {
-		try {
-			takeScreenShotOnBrowser(browser, file);
-		} catch (WebDriverException e) {
-			throw wrapWebDriverExceptionIfConnectionException(e);
-		}
-	}
-
-	private void removeCanvasGeneratedByFirefoxDriverForScreenshots() {
-		String js = """";
-		js += ""var canvas = document.getElementById('fxdriver-screenshot-canvas');"";
-		js += ""if(canvas != null){"";
-		js += ""canvas.parentNode.removeChild(canvas);"";
-		js += ""}"";
-		try {
-			executeJavaScript(js);
-		} catch (CrawljaxException e) {
-			LOGGER.error(""Removing of Canvas Generated By FirefoxDriver failed,""
-			        + "" most likely leaving it in the browser"", e);
-		}
-	}
-
-	/**
-	 * @return the WebDriver used as an EmbeddedBrowser.
-	 */
-	public WebDriver getBrowser() {
-		return browser;
-	}
-
-	@Override
-	public void updateConfiguration(CrawljaxConfigurationReader configuration) {
-		// Retrieve the config values used
-		this.filterAttributes = configuration.getFilterAttributeNames();
-		this.crawlWaitReload =
-		        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
-		this.crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
-		this.ignoreFrameChecker = configuration.getCrawlSpecificationReader();
-	}
-
-	private boolean exceptionIsConnectionException(WebDriverException exception) {
-		return exception != null && exception.getCause() != null
-		        && exception.getCause() instanceof IOException;
-	}
-
-	private RuntimeException wrapWebDriverExceptionIfConnectionException(
-	        WebDriverException exception) {
-		if (exceptionIsConnectionException(exception)) {
-			return new BrowserConnectionException(exception);
-		}
-		return exception;
-	}
-
-	private void throwIfConnectionException(WebDriverException exception) {
-		if (exceptionIsConnectionException(exception)) {
-			throw wrapWebDriverExceptionIfConnectionException(exception);
-		}
-	}
-}
\ No newline at end of file
+package com.crawljax.browser;
+
+import java.io.File;
+import java.io.IOException;
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+
+import org.openqa.selenium.ElementNotVisibleException;
+import org.openqa.selenium.JavascriptExecutor;
+import org.openqa.selenium.NoSuchElementException;
+import org.openqa.selenium.NoSuchFrameException;
+import org.openqa.selenium.OutputType;
+import org.openqa.selenium.Platform;
+import org.openqa.selenium.TakesScreenshot;
+import org.openqa.selenium.WebDriver;
+import org.openqa.selenium.WebDriverException;
+import org.openqa.selenium.WebElement;
+import org.openqa.selenium.internal.WrapsDriver;
+import org.openqa.selenium.io.FileHandler;
+import org.openqa.selenium.remote.Augmenter;
+import org.openqa.selenium.remote.DesiredCapabilities;
+import org.openqa.selenium.remote.HttpCommandExecutor;
+import org.openqa.selenium.remote.RemoteWebDriver;
+import org.openqa.selenium.support.ui.Select;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.w3c.dom.DOMException;
+import org.w3c.dom.Document;
+import org.w3c.dom.Element;
+import org.w3c.dom.NodeList;
+import org.xml.sax.SAXException;
+
+import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.configuration.AcceptAllFramesChecker;
+import com.crawljax.core.configuration.CrawljaxConfigurationReader;
+import com.crawljax.core.configuration.IgnoreFrameChecker;
+import com.crawljax.core.exception.BrowserConnectionException;
+import com.crawljax.core.state.Eventable;
+import com.crawljax.core.state.Identification;
+import com.crawljax.forms.FormHandler;
+import com.crawljax.forms.FormInput;
+import com.crawljax.forms.InputValue;
+import com.crawljax.forms.RandomInputValueGenerator;
+import com.crawljax.util.Helper;
+
+/**
+ * @author mesbah
+ * @author Frank Groeneveld
+ * @version $Id: WebDriverBackedEmbeddedBrowser.java 387 2010-07-13 13:55:49Z slenselink@google.com
+ *          $
+ */
+public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
+	private long crawlWaitEvent;
+	private static final Logger LOGGER = LoggerFactory
+	        .getLogger(WebDriverBackedEmbeddedBrowser.class);
+	private final WebDriver browser;
+
+	private List<String> filterAttributes;
+	private long crawlWaitReload;
+	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
+
+	/**
+	 * Constructor without configuration values, these must be updated using the
+	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
+		this.browser = driver;
+	}
+
+	/**
+	 * Constructor.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
+	        long crawlWaitReload, long crawlWaitEvent) {
+		this(driver);
+		this.filterAttributes = filterAttributes;
+		this.crawlWaitEvent = crawlWaitEvent;
+		this.crawlWaitReload = crawlWaitReload;
+	}
+
+	/**
+	 * Constructor.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
+	        long crawlWaitReload, long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
+		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
+		this.ignoreFrameChecker = ignoreFrameChecker;
+	}
+
+	/**
+	 * Create a RemoteWebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param hubUrl
+	 *            Url of the server.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
+		        filterAttributes, crawlWaitEvent, crawlWaitReload);
+	}
+
+	/**
+	 * Create a RemoteWebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param hubUrl
+	 *            Url of the server.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
+	        IgnoreFrameChecker ignoreFrameChecker) {
+		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
+		        filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
+	}
+
+	/**
+	 * Create a WebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
+		        crawlWaitReload);
+	}
+
+	/**
+	 * Create a WebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
+	        IgnoreFrameChecker ignoreFrameChecker) {
+		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
+		        crawlWaitReload, ignoreFrameChecker);
+	}
+
+	/**
+	 * Create a RemoteWebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param hubUrl
+	 *            Url of the server.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl) {
+		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl));
+	}
+
+	/**
+	 * Private used static method for creation of a RemoteWebDriver. Taking care of the default
+	 * Capabilities and using the HttpCommandExecutor.
+	 * 
+	 * @param hubUrl
+	 *            the url of the hub to use.
+	 * @return the RemoteWebDriver instance.
+	 */
+	private static RemoteWebDriver buildRemoteWebDriver(String hubUrl) {
+		DesiredCapabilities capabilities = new DesiredCapabilities();
+		capabilities.setPlatform(Platform.ANY);
+		URL url;
+		try {
+			url = new URL(hubUrl);
+		} catch (MalformedURLException e) {
+			LOGGER.error(""The given hub url of the remote server is malformed can not continue!"",
+			        e);
+			return null;
+		}
+		HttpCommandExecutor executor = null;
+		try {
+			executor = new HttpCommandExecutor(url);
+		} catch (Exception e) {
+			// TODO Stefan; refactor this catch, this will definitely result in NullPointers, why
+			// not throw RuntimeExcption direct?
+			LOGGER.error(""Received unknown exception while creating the ""
+			        + ""HttpCommandExecutor, can not continue!"", e);
+			return null;
+		}
+		return new RemoteWebDriver(executor, capabilities);
+	}
+
+	/**
+	 * Create a WebDriver backed EmbeddedBrowser.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @return The EmbeddedBrowser.
+	 */
+	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver) {
+		return new WebDriverBackedEmbeddedBrowser(driver);
+	}
+
+	/**
+	 * @param url
+	 *            The URL.
+	 */
+	@Override
+	public void goToUrl(String url) {
+		try {
+			browser.navigate().to(url);
+			Thread.sleep(this.crawlWaitReload);
+			handlePopups();
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return;
+		} catch (InterruptedException e) {
+			LOGGER.error(""goToUrl got interrupted while waiting for the page to be loaded"", e);
+			return;
+		}
+	}
+
+	/**
+	 * alert, prompt, and confirm behave as if the OK button is always clicked.
+	 */
+	private void handlePopups() {
+		try {
+			executeJavaScript(""window.alert = function(msg){return true;};""
+			        + ""window.confirm = function(msg){return true;};""
+			        + ""window.prompt = function(msg){return true;};"");
+		} catch (CrawljaxException e) {
+			LOGGER.error(""Handling of PopUp windows failed"", e);
+		}
+	}
+
+	/**
+	 * Fires the event and waits for a specified time.
+	 * 
+	 * @param webElement
+	 *            the element to fire event on.
+	 * @param eventable
+	 *            The HTML event type (onclick, onmouseover, ...).
+	 * @return true if firing event is successful.
+	 */
+	protected boolean fireEventWait(WebElement webElement, Eventable eventable) {
+		switch (eventable.getEventType()) {
+			case click:
+				try {
+					webElement.click();
+				} catch (ElementNotVisibleException e1) {
+					LOGGER.info(""Element not visible, so cannot be clicked: ""
+					        + webElement.getTagName().toUpperCase() + "" "" + webElement.getText());
+					return false;
+				} catch (WebDriverException e) {
+					throwIfConnectionException(e);
+					return false;
+				}
+				break;
+			case hover:
+				// todo
+				break;
+
+			default:
+				LOGGER.info(""EventType "" + eventable.getEventType()
+				        + "" not supported in WebDriver."");
+				return false;
+		}
+
+		try {
+			Thread.sleep(this.crawlWaitEvent);
+		} catch (InterruptedException e) {
+			LOGGER.error(""fireEventWait got interrupted during wait process"", e);
+			return false;
+		}
+		return true;
+	}
+
+	@Override
+	public void close() {
+		LOGGER.info(""Closing the browser..."");
+		try {
+			// close browser and close every associated window.
+			browser.quit();
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	@Override
+	public String getDom() {
+
+		try {
+			String dom = toUniformDOM(Helper.getDocumentToString(getDomTreeWithFrames()));
+			LOGGER.debug(dom);
+			return dom;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			LOGGER.warn(e.getMessage(), e);
+			return """";
+		} catch (CrawljaxException e) {
+			LOGGER.warn(e.getMessage(), e);
+			return """";
+		}
+	}
+
+	/**
+	 * @param html
+	 *            The html string.
+	 * @return uniform version of dom with predefined attributes stripped
+	 */
+	private String toUniformDOM(String html) {
+
+		Pattern p =
+		        Pattern.compile(""<SCRIPT(.*?)</SCRIPT>"", Pattern.DOTALL
+		                | Pattern.CASE_INSENSITIVE);
+		Matcher m = p.matcher(html);
+		String htmlFormatted = m.replaceAll("""");
+
+		p = Pattern.compile(""<\\?xml:(.*?)>"");
+		m = p.matcher(html);
+		htmlFormatted = m.replaceAll("""");
+
+		// html = html.replace(""<?xml:namespace prefix = gwt >"", """");
+
+		// TODO (Stefan), Following lines are a serious performance bottle neck...
+		// Document doc = Helper.getDocument(htmlFormatted);
+		// htmlFormatted = Helper.getDocumentToString(doc);
+
+		htmlFormatted = filterAttributes(htmlFormatted);
+		return htmlFormatted;
+	}
+
+	/**
+	 * Filters attributes from the HTML string.
+	 * 
+	 * @param html
+	 *            The HTML to filter.
+	 * @return The filtered HTML string.
+	 */
+	private String filterAttributes(String html) {
+		if (this.filterAttributes != null) {
+			for (String attribute : this.filterAttributes) {
+				String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
+				Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
+				Matcher m = p.matcher(html);
+				html = m.replaceAll("""");
+			}
+		}
+		return html;
+	}
+
+	@Override
+	public void goBack() {
+		try {
+			browser.navigate().back();
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	/**
+	 * @param identification
+	 *            The identification object.
+	 * @param text
+	 *            The input.
+	 * @return true if succeeds.
+	 */
+	@Override
+	public boolean input(Identification identification, String text) {
+		try {
+			WebElement field = browser.findElement(identification.getWebDriverBy());
+			if (field != null) {
+				// first clear the field
+				field.clear();
+				// then fill in
+				field.sendKeys(text);
+
+				// this.activeElement = field;
+				return true;
+			}
+			return false;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return false;
+		}
+	}
+
+	/**
+	 * Fires an event on an element using its identification.
+	 * 
+	 * @param eventable
+	 *            The eventable.
+	 * @return true if it is able to fire the event successfully on the element.
+	 */
+	@Override
+	public synchronized boolean fireEvent(Eventable eventable) {
+		try {
+
+			boolean handleChanged = false;
+			boolean result = false;
+
+			if (eventable.getRelatedFrame() != null && !eventable.getRelatedFrame().equals("""")) {
+				LOGGER.debug(""switching to frame: "" + eventable.getRelatedFrame());
+				try {
+
+					switchToFrame(eventable.getRelatedFrame());
+				} catch (NoSuchFrameException e) {
+					LOGGER.debug(""Frame not found, possibily while back-tracking.."", e);
+					// TODO Stefan, This exception is catched to prevent stopping from working
+					// This was the case on the Gmail case; find out if not switching (catching)
+					// Results in good performance...
+				}
+				handleChanged = true;
+			}
+
+			WebElement webElement =
+			        browser.findElement(eventable.getIdentification().getWebDriverBy());
+
+			if (webElement != null) {
+				result = fireEventWait(webElement, eventable);
+			}
+
+			if (handleChanged) {
+				browser.switchTo().defaultContent();
+			}
+			return result;
+		} catch (NoSuchElementException e) {
+			LOGGER.warn(""Could not fire eventable: "" + eventable.toString());
+			return false;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return false;
+		}
+	}
+
+	/**
+	 * Execute JavaScript in the browser.
+	 * 
+	 * @param code
+	 *            The code to execute.
+	 * @return The return value of the JavaScript.
+	 * @throws CrawljaxException
+	 *             when javascript execution failed.
+	 */
+	@Override
+	public Object executeJavaScript(String code) throws CrawljaxException {
+		try {
+			JavascriptExecutor js = (JavascriptExecutor) browser;
+			return js.executeScript(code);
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			throw new CrawljaxException(e);
+		}
+	}
+
+	/**
+	 * Determines whether the corresponding element is visible.
+	 * 
+	 * @param identification
+	 *            The element to search for.
+	 * @return true if the element is visible
+	 */
+	@Override
+	public boolean isVisible(Identification identification) {
+		try {
+			WebElement el = browser.findElement(identification.getWebDriverBy());
+			if (el != null) {
+				return el.isDisplayed();
+			}
+
+			return false;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return false;
+		}
+	}
+
+	/**
+	 * @return The current browser url.
+	 */
+	@Override
+	public String getCurrentUrl() {
+		try {
+			return browser.getCurrentUrl();
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	@Override
+	public void closeOtherWindows() {
+		try {
+			String current = browser.getWindowHandle();
+			for (String handle : browser.getWindowHandles()) {
+				if (!handle.equals(browser.getWindowHandle())) {
+
+					browser.switchTo().window(handle);
+					LOGGER.info(""Closing other window with title \"""" + browser.getTitle() + ""\"""");
+					browser.close();
+					// browser.switchTo().defaultContent();
+					browser.switchTo().window(current);
+				}
+			}
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	/**
+	 * @return a Document object containing the contents of iframes as well.
+	 * @throws CrawljaxException
+	 *             if an exception is thrown.
+	 */
+	private Document getDomTreeWithFrames() throws CrawljaxException {
+
+		try {
+			Document document = Helper.getDocument(browser.getPageSource());
+			appendFrameContent(document.getDocumentElement(), document, """");
+			return document;
+		} catch (SAXException e) {
+			throw new CrawljaxException(e.getMessage(), e);
+		} catch (IOException e) {
+			throw new CrawljaxException(e.getMessage(), e);
+		}
+
+	}
+
+	private void appendFrameContent(Element orig, Document document, String topFrame) {
+
+		NodeList frameNodes = orig.getElementsByTagName(""IFRAME"");
+
+		List<Element> nodeList = new ArrayList<Element>();
+
+		for (int i = 0; i < frameNodes.getLength(); i++) {
+			Element frameElement = (Element) frameNodes.item(i);
+			nodeList.add(frameElement);
+		}
+
+		// Added support for FRAMES
+		frameNodes = orig.getElementsByTagName(""FRAME"");
+		for (int i = 0; i < frameNodes.getLength(); i++) {
+			Element frameElement = (Element) frameNodes.item(i);
+			nodeList.add(frameElement);
+		}
+
+		for (int i = 0; i < nodeList.size(); i++) {
+			String frameIdentification = """";
+
+			if (topFrame != null && !topFrame.equals("""")) {
+				frameIdentification += topFrame + ""."";
+			}
+
+			Element frameElement = nodeList.get(i);
+
+			String nameId = Helper.getFrameIdentification(frameElement);
+
+			if (nameId != null
+			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
+				frameIdentification += nameId;
+
+				String handle = browser.getWindowHandle();
+
+				LOGGER.debug(""The current H: "" + handle);
+
+				switchToFrame(frameIdentification);
+
+				String toAppend = browser.getPageSource();
+
+				LOGGER.debug(""frame dom: "" + toAppend);
+
+				browser.switchTo().defaultContent();
+
+				try {
+					Element toAppendElement = Helper.getDocument(toAppend).getDocumentElement();
+					Element importedElement =
+					        (Element) document.importNode(toAppendElement, true);
+					frameElement.appendChild(importedElement);
+
+					appendFrameContent(importedElement, document, frameIdentification);
+				} catch (DOMException e) {
+					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
+					        + "" continuing..."", e);
+				} catch (SAXException e) {
+					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
+					        + "" continuing..."", e);
+				} catch (IOException e) {
+					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
+					        + "" continuing..."", e);
+				}
+			}
+		}
+	}
+
+	private void switchToFrame(String frameIdentification) {
+		LOGGER.debug(""frame identification: "" + frameIdentification);
+
+		if (frameIdentification.contains(""."")) {
+			String[] frames = frameIdentification.split(""\\."");
+
+			for (String frameId : frames) {
+				LOGGER.debug(""switching to frame: "" + frameId);
+				browser.switchTo().frame(frameId);
+			}
+
+		} else {
+			browser.switchTo().frame(frameIdentification);
+		}
+
+	}
+
+	/**
+	 * @return the dom without the iframe contents.
+	 * @see com.crawljax.browser.EmbeddedBrowser#getDomWithoutIframeContent()
+	 */
+	@Override
+	public String getDomWithoutIframeContent() {
+		try {
+			String dom = browser.getPageSource();
+			// logger.debug(""driver.source: "" + dom);
+			String result = toUniformDOM(dom);
+			// logger.debug(""driver.source toUniformDom: "" + result);
+			return result;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return """";
+		}
+	}
+
+	/**
+	 * @param input
+	 *            the input to be filled.
+	 * @return FormInput with random value assigned if possible
+	 */
+	@Override
+	public FormInput getInputWithRandomValue(FormInput input) {
+
+		WebElement webElement;
+		try {
+			webElement = browser.findElement(input.getIdentification().getWebDriverBy());
+			if (!(webElement.isDisplayed())) {
+
+				return null;
+			}
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return null;
+		}
+
+		Set<InputValue> values = new HashSet<InputValue>();
+
+		// create some random value
+
+		if (input.getType().toLowerCase().startsWith(""text"")) {
+			values.add(new InputValue(new RandomInputValueGenerator()
+			        .getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
+		} else if (input.getType().equalsIgnoreCase(""checkbox"")
+		        || input.getType().equalsIgnoreCase(""radio"") && !webElement.isSelected()) {
+			if (new RandomInputValueGenerator().getCheck()) {
+				values.add(new InputValue(""1"", true));
+			} else {
+				values.add(new InputValue(""0"", false));
+
+			}
+		} else if (input.getType().equalsIgnoreCase(""select"")) {
+			try {
+				Select select = new Select(webElement);
+				WebElement option =
+				        (WebElement) new RandomInputValueGenerator().getRandomOption(select
+				                .getOptions());
+				values.add(new InputValue(option.getText(), true));
+			} catch (WebDriverException e) {
+				throwIfConnectionException(e);
+				return null;
+			}
+		}
+
+		if (values.size() == 0) {
+			return null;
+		}
+		input.setInputValues(values);
+		return input;
+
+	}
+
+	@Override
+	public String getFrameDom(String iframeIdentification) {
+		try {
+
+			switchToFrame(iframeIdentification);
+
+			// make a copy of the dom before changing into the top page
+			String frameDom = browser.getPageSource();
+
+			browser.switchTo().defaultContent();
+
+			return frameDom;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return """";
+		}
+	}
+
+	/**
+	 * @param identification
+	 *            the identification of the element.
+	 * @return true if the element can be found in the DOM tree.
+	 */
+	@Override
+	public boolean elementExists(Identification identification) {
+		try {
+			WebElement el = browser.findElement(identification.getWebDriverBy());
+			// TODO Stefan; I think el will never be null as a NoSuchElementExcpetion will be
+			// thrown, catched below.
+			return el != null;
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return false;
+		}
+	}
+
+	/**
+	 * @param identification
+	 *            the identification of the element.
+	 * @return the found element.
+	 */
+	@Override
+	public WebElement getWebElement(Identification identification) {
+		try {
+			return browser.findElement(identification.getWebDriverBy());
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	/**
+	 * @return the period to wait after an event.
+	 */
+	protected long getCrawlWaitEvent() {
+		return crawlWaitEvent;
+	}
+
+	/**
+	 * @return the list of attributes to be filtered from DOM.
+	 */
+	protected List<String> getFilterAttributes() {
+		return filterAttributes;
+	}
+
+	/**
+	 * @return the period to waint after a reload.
+	 */
+	protected long getCrawlWaitReload() {
+		return crawlWaitReload;
+	}
+
+	private void takeScreenShotOnBrowser(WebDriver driver, File file) throws CrawljaxException {
+		if (driver instanceof TakesScreenshot) {
+			File tmpfile = ((TakesScreenshot) driver).getScreenshotAs(OutputType.FILE);
+
+			try {
+				FileHandler.copy(tmpfile, file);
+			} catch (IOException e) {
+				throw new CrawljaxException(e);
+			}
+
+			removeCanvasGeneratedByFirefoxDriverForScreenshots();
+		} else if (driver instanceof RemoteWebDriver) {
+			WebDriver augmentedWebdriver = new Augmenter().augment(driver);
+			takeScreenShotOnBrowser(augmentedWebdriver, file);
+		} else if (driver instanceof WrapsDriver) {
+			takeScreenShotOnBrowser(((WrapsDriver) driver).getWrappedDriver(), file);
+		} else {
+			throw new CrawljaxException(""Your current WebDriver doesn't support screenshots."");
+		}
+	}
+
+	@Override
+	public void saveScreenShot(File file) throws CrawljaxException {
+		try {
+			takeScreenShotOnBrowser(browser, file);
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
+
+	private void removeCanvasGeneratedByFirefoxDriverForScreenshots() {
+		String js = """";
+		js += ""var canvas = document.getElementById('fxdriver-screenshot-canvas');"";
+		js += ""if(canvas != null){"";
+		js += ""canvas.parentNode.removeChild(canvas);"";
+		js += ""}"";
+		try {
+			executeJavaScript(js);
+		} catch (CrawljaxException e) {
+			LOGGER.error(""Removing of Canvas Generated By FirefoxDriver failed,""
+			        + "" most likely leaving it in the browser"", e);
+		}
+	}
+
+	/**
+	 * @return the WebDriver used as an EmbeddedBrowser.
+	 */
+	public WebDriver getBrowser() {
+		return browser;
+	}
+
+	@Override
+	public void updateConfiguration(CrawljaxConfigurationReader configuration) {
+		// Retrieve the config values used
+		this.filterAttributes = configuration.getFilterAttributeNames();
+		this.crawlWaitReload =
+		        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
+		this.crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
+		this.ignoreFrameChecker = configuration.getCrawlSpecificationReader();
+	}
+
+	private boolean exceptionIsConnectionException(WebDriverException exception) {
+		return exception != null && exception.getCause() != null
+		        && exception.getCause() instanceof IOException;
+	}
+
+	private RuntimeException wrapWebDriverExceptionIfConnectionException(
+	        WebDriverException exception) {
+		if (exceptionIsConnectionException(exception)) {
+			return new BrowserConnectionException(exception);
+		}
+		return exception;
+	}
+
+	private void throwIfConnectionException(WebDriverException exception) {
+		if (exceptionIsConnectionException(exception)) {
+			throw wrapWebDriverExceptionIfConnectionException(exception);
+		}
+	}
+}
"
ba877d01152f4ea7eb17bf338e8c8b9e4e18a267,Alex Nederlof,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/src/main/java/com/crawljax/core/CrawlQueue.java b/src/main/java/com/crawljax/core/CrawlQueue.java
index 52dc64f..45dbed6 100644
--- a/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -3,18 +3,18 @@
  */
 package com.crawljax.core;
 
-import net.jcip.annotations.GuardedBy;
-
 import java.util.Collection;
 import java.util.Stack;
 import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.TimeUnit;
 
+import net.jcip.annotations.GuardedBy;
+
 /**
  * This class implements a BlockingQueue with Runnable as its Generic type and extends Stack with
  * also Runnable as generic type. This class is used in the ThreadPoolExecutor and its used to store
  * separate threads in a Queue like fashion (FILO).
- *
+ * 
  * @author Stefan Lenselink <S.R.Lenselink@student.tudelft.nl>
  * @version $Id$
  */
"
ba877d01152f4ea7eb17bf338e8c8b9e4e18a267,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/src/main/java/com/crawljax/core/CrawljaxController.java b/src/main/java/com/crawljax/core/CrawljaxController.java
index 7a3b33b..5b010f4 100644
--- a/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -1,5 +1,14 @@
 package com.crawljax.core;
 
+import java.util.List;
+import java.util.concurrent.TimeUnit;
+
+import net.jcip.annotations.GuardedBy;
+
+import org.apache.commons.configuration.ConfigurationException;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
 import com.crawljax.browser.BrowserPool;
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.browserwaiter.WaitConditionChecker;
@@ -14,23 +23,16 @@
 import com.crawljax.core.state.StateFlowGraph;
 import com.crawljax.oraclecomparator.StateComparator;
 
-import net.jcip.annotations.GuardedBy;
-
-import org.apache.commons.configuration.ConfigurationException;
-import org.apache.log4j.Logger;
-
-import java.util.List;
-import java.util.concurrent.TimeUnit;
-
 /**
  * The Crawljax Controller class is the core of Crawljax.
- *
+ * 
  * @author mesbah
  * @version $Id$
  */
 public class CrawljaxController implements CrawlQueueManager {
 
-	private static final Logger LOGGER = Logger.getLogger(CrawljaxController.class.getName());
+	private static final Logger LOGGER = LoggerFactory.getLogger(CrawljaxController.class
+	        .getName());
 
 	private CrawlSession session;
 
@@ -96,8 +98,8 @@
 		CrawljaxPluginsUtil.loadPlugins(configurationReader.getPlugins());
 
 		if (configurationReader.getProxyConfiguration() != null) {
-			CrawljaxPluginsUtil.runProxyServerPlugins(
-			        configurationReader.getProxyConfiguration());
+			CrawljaxPluginsUtil
+			        .runProxyServerPlugins(configurationReader.getProxyConfiguration());
 		}
 
 		LOGGER.info(""Embedded browser implementation: "" + configurationReader.getBrowser());
@@ -105,17 +107,17 @@
 		LOGGER.info(""Number of threads: ""
 		        + configurationReader.getThreadConfigurationReader().getNumberThreads());
 
-		LOGGER.info(
-		        ""Crawl depth: "" + configurationReader.getCrawlSpecificationReader().getDepth());
+		LOGGER.info(""Crawl depth: ""
+		        + configurationReader.getCrawlSpecificationReader().getDepth());
 		LOGGER.info(""Crawljax initialized!"");
 
-		return new CrawlerExecutor(
-		        configurationReader.getThreadConfigurationReader().getNumberThreads());
+		return new CrawlerExecutor(configurationReader.getThreadConfigurationReader()
+		        .getNumberThreads());
 	}
 
 	/**
 	 * Run Crawljax.
-	 *
+	 * 
 	 * @throws CrawljaxException
 	 *             If the browser cannot be instantiated.
 	 * @throws ConfigurationException
@@ -126,9 +128,8 @@
 
 		startCrawl = System.currentTimeMillis();
 
-		LOGGER.info(
-		        ""Start crawling with "" + configurationReader.getAllIncludedCrawlElements().size()
-		                + "" crawl elements"");
+		LOGGER.info(""Start crawling with ""
+		        + configurationReader.getAllIncludedCrawlElements().size() + "" crawl elements"");
 
 		// Create the initailCrawler
 		initialCrawler = new InitialCrawler(this);
@@ -142,15 +143,15 @@
 		} catch (InterruptedException e) {
 			LOGGER.error(e.getMessage(), e);
 		}
-		
+
 		if (workQueue.isAborted()) {
 			LOGGER.warn(""It apears to be that the workQueue was Aborted, ""
 			        + ""not running postcrawling plugins and not closing the browsers"");
 			return;
 		}
-		
+
 		long timeCrawlCalc = System.currentTimeMillis() - startCrawl;
-		
+
 		/**
 		 * Close all the opened browsers, this is run in separate thread to have the post crawl
 		 * plugins to execute in the meanwhile.
@@ -175,13 +176,13 @@
 		} catch (InterruptedException e) {
 			LOGGER.error(""could not wait for browsers to close."", e);
 		}
-		
+
 	}
 
 	/**
 	 * Retrieve the current session, there is only one session active at a time. So this method by
 	 * it self is Thread-Safe but actions on the session are NOT!
-	 *
+	 * 
 	 * @return the session
 	 */
 	public CrawlSession getSession() {
@@ -190,10 +191,11 @@
 
 	/**
 	 * Add work (Crawler) to the Queue of work that need to be done. The class is thread-safe.
-	 *
+	 * 
 	 * @param work
 	 *            the work (Crawler) to add to the Queue
 	 */
+	@Override
 	public final void addWorkToQueue(Crawler work) {
 		workQueue.execute(work);
 	}
@@ -201,18 +203,19 @@
 	/**
 	 * Removes this Crawler from the workQueue if it is present, thus causing it not to be run if it
 	 * has not already started.
-	 *
+	 * 
 	 * @param crawler
 	 *            the Crawler to remove
 	 * @return true if the crawler was removed
 	 */
+	@Override
 	public boolean removeWorkFromQueue(Crawler crawler) {
 		return workQueue.remove(crawler);
 	}
 
 	/**
 	 * Wait for a given condition. This call is thread safe as the underlying object is thread-safe.
-	 *
+	 * 
 	 * @param browser
 	 *            the browser which requires a wait condition
 	 */
@@ -225,7 +228,7 @@
 	 * because ThreadLocal is not ThreadSafe??? get the stripped version of the dom currently in the
 	 * browser. This call is thread safe, must be synchronised because there is thread-intefearing
 	 * bug in the stateComparator.
-	 *
+	 * 
 	 * @param browser
 	 *            the browser instance.
 	 * @return a stripped string of the DOM tree taken from the browser.
@@ -245,7 +248,7 @@
 
 	/**
 	 * Retrieve the initial Crawler used.
-	 *
+	 * 
 	 * @return the initialCrawler used to initiate the Crawling run.
 	 */
 	public final Crawler getInitialCrawler() {
@@ -255,7 +258,7 @@
 	/**
 	 * Format the time the current crawl run has taken into a more readable format. Taking now as
 	 * the end time of the crawling.
-	 *
+	 * 
 	 * @return the formatted time in X min, X sec layout.
 	 */
 	private String formatRunningTime() {
@@ -264,25 +267,29 @@
 
 	/**
 	 * Format the time the current crawl run has taken into a more readable format.
-	 *
+	 * 
 	 * @param timeCrawlCalc
 	 *            the time to display
 	 * @return the formatted time in X min, X sec layout.
 	 */
 	private String formatRunningTime(long timeCrawlCalc) {
-		return String.format(""%d min, %d sec"", TimeUnit.MILLISECONDS.toMinutes(timeCrawlCalc),
-		        TimeUnit.MILLISECONDS.toSeconds(timeCrawlCalc) - TimeUnit.MINUTES.toSeconds(
-		                TimeUnit.MILLISECONDS.toMinutes(timeCrawlCalc)));
+		return String.format(
+		        ""%d min, %d sec"",
+		        TimeUnit.MILLISECONDS.toMinutes(timeCrawlCalc),
+		        TimeUnit.MILLISECONDS.toSeconds(timeCrawlCalc)
+		                - TimeUnit.MINUTES.toSeconds(TimeUnit.MILLISECONDS
+		                        .toMinutes(timeCrawlCalc)));
 	}
 
 	/**
 	 * Terminate the crawling, Stop all threads this will cause the controller which is sleeping to
 	 * reactive and do the final work....
-	 *
+	 * 
 	 * @param isAbort
 	 *            if set true the terminate must be as an abort not allowing running PostCrawling
 	 *            plugins.
 	 */
+	@Override
 	@GuardedBy(""this"")
 	public final synchronized void terminate(boolean isAbort) {
 		LOGGER.warn(""After "" + this.formatRunningTime()
@@ -312,7 +319,7 @@
 	/**
 	 * The current element checker in use. This call is thread-safe because it returns a final
 	 * field.
-	 *
+	 * 
 	 * @return the elementChecker used to register the checked elements.
 	 */
 	public final ExtractorManager getElementChecker() {
@@ -337,7 +344,7 @@
 	 * Return the used CrawlQueueManager, this method is designed for extension purposes. Being able
 	 * to move the {@link #addWorkToQueue(Crawler)} and {@link #removeWorkFromQueue(Crawler)} out of
 	 * this class using the interface.
-	 *
+	 * 
 	 * @return the crawlQueueManager that is used.
 	 */
 	public CrawlQueueManager getCrawlQueueManager() {
@@ -353,7 +360,7 @@
 
 	/**
 	 * Install a new CrawlSession.
-	 *
+	 * 
 	 * @param session
 	 *            set the new value for the session
 	 */
"
ba877d01152f4ea7eb17bf338e8c8b9e4e18a267,Alex Nederlof,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 225ec9e..1a759f0 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -95,39 +95,37 @@
 		crawlActions.click(""input"").withAttribute(""type"", ""button"");
 	}
 
-        
 	/**
-         * Guifre Ruiz: This method can be used to crawl more tags and, therefore,
-         * more pages in the target. However, it slow down a bit the process.
-         */ 
-        public void clickMoreElements() {
-            crawlActions.click(""a"");
-            crawlActions.click(""button"");
-            crawlActions.click(""td"");
-            crawlActions.click(""span"");
-            crawlActions.click(""div"");
-            crawlActions.click(""tr"");
-            crawlActions.click(""table"");
-            crawlActions.click(""tbody"");
-            crawlActions.click(""ol"");
-            crawlActions.click(""center"");
-            crawlActions.click(""li"");
-            crawlActions.click(""radio"");
-            crawlActions.click(""non"");
-            crawlActions.click(""meta"");
-            crawlActions.click(""refresh"");
-            crawlActions.click(""xhr"");
-            crawlActions.click(""relative"");
-            crawlActions.click(""link"");
-            crawlActions.click(""self"");
-            crawlActions.click(""form"");
-            crawlActions.click(""input"");
-            crawlActions.click(""option"");
-            crawlActions.click(""img"");
-            crawlActions.click(""p"");    
-        }
+	 * Guifre Ruiz: This method can be used to crawl more tags and, therefore, more pages in the
+	 * target. However, it slow down a bit the process.
+	 */
+	public void clickMoreElements() {
+		crawlActions.click(""a"");
+		crawlActions.click(""button"");
+		crawlActions.click(""td"");
+		crawlActions.click(""span"");
+		crawlActions.click(""div"");
+		crawlActions.click(""tr"");
+		crawlActions.click(""table"");
+		crawlActions.click(""tbody"");
+		crawlActions.click(""ol"");
+		crawlActions.click(""center"");
+		crawlActions.click(""li"");
+		crawlActions.click(""radio"");
+		crawlActions.click(""non"");
+		crawlActions.click(""meta"");
+		crawlActions.click(""refresh"");
+		crawlActions.click(""xhr"");
+		crawlActions.click(""relative"");
+		crawlActions.click(""link"");
+		crawlActions.click(""self"");
+		crawlActions.click(""form"");
+		crawlActions.click(""input"");
+		crawlActions.click(""option"");
+		crawlActions.click(""img"");
+		crawlActions.click(""p"");
+	}
 
-        
 	/**
 	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
 	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}.
"
ba877d01152f4ea7eb17bf338e8c8b9e4e18a267,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 24c101f..e7c8ebf 100644
--- a/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -3,9 +3,9 @@
 import java.util.ArrayList;
 import java.util.List;
 
+import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.browser.EmbeddedBrowserBuilder;
 import com.crawljax.browser.WebDriverBrowserBuilder;
-import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.util.Helper;
"
ba877d01152f4ea7eb17bf338e8c8b9e4e18a267,Alex Nederlof,StateFlowGraph.java,MODIFY,"addState -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index a38fa43..aaca56f 100644
--- a/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -1,31 +1,34 @@
 package com.crawljax.core.state;
 
-import net.jcip.annotations.GuardedBy;
-
-import org.apache.commons.math.stat.descriptive.moment.Mean;
-import org.apache.log4j.Logger;
-import org.jgrapht.DirectedGraph;
-import org.jgrapht.GraphPath;
-import org.jgrapht.alg.DijkstraShortestPath;
-import org.jgrapht.alg.KShortestPaths;
-import org.jgrapht.graph.DirectedMultigraph;
-
+import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
 import java.util.concurrent.atomic.AtomicInteger;
 
-/**
- * The State-Flow Graph is a directed graph with states on the vertices and clickables on the edges.
- * 
- * @author mesbah
- * @version $Id$
- */
-public class StateFlowGraph {
-	private static final Logger LOGGER = Logger.getLogger(StateFlowGraph.class.getName());
+import net.jcip.annotations.GuardedBy;
 
-	private final DirectedGraph<StateVertix, Eventable> sfg;
+import org.apache.commons.math.stat.descriptive.moment.Mean;
+import org.jgrapht.DirectedGraph;
+import org.jgrapht.GraphPath;
+import org.jgrapht.alg.DijkstraShortestPath;
+import org.jgrapht.alg.KShortestPaths;
+import org.jgrapht.graph.DirectedMultigraph;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
+/**
+ * The State-Flow Graph is a multi-edge directed graph with states (StateVetex) on the vertices and
+ * clickables (Eventable) on the edges.
+ */
+public class StateFlowGraph implements Serializable {
+
+	private static final long serialVersionUID = 923403417983488L;
+
+	private static final Logger LOGGER = LoggerFactory.getLogger(StateFlowGraph.class.getName());
+
+	private final DirectedGraph<StateVertex, Eventable> sfg;
 
 	/**
 	 * Intermediate counter for the number of states, not relaying on getAllStates.size() because of
@@ -37,7 +40,7 @@
 	 * Empty constructor.
 	 */
 	public StateFlowGraph() {
-		sfg = new DirectedMultigraph<StateVertix, Eventable>(Eventable.class);
+		sfg = new DirectedMultigraph<StateVertex, Eventable>(Eventable.class);
 	}
 
 	/**
@@ -46,7 +49,7 @@
 	 * @param initialState
 	 *            the state to start from.
 	 */
-	public StateFlowGraph(StateVertix initialState) {
+	public StateFlowGraph(StateVertex initialState) {
 		this();
 		sfg.addVertex(initialState);
 	}
@@ -65,7 +68,7 @@
 	 * @return the clone if one is detected null otherwise.
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
-	public StateVertix addState(StateVertix stateVertix) {
+	public StateVertex addState(StateVertex stateVertix) {
 		return addState(stateVertix, true);
 	}
 
@@ -86,7 +89,7 @@
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
 	@GuardedBy(""sfg"")
-	public StateVertix addState(StateVertix stateVertix, boolean correctName) {
+	public StateVertex addState(StateVertex stateVertix, boolean correctName) {
 		synchronized (sfg) {
 			if (!sfg.addVertex(stateVertix)) {
 				// Graph already contained the vertix
@@ -135,7 +138,7 @@
 	 * @see org.jgrapht.Graph#addEdge(Object, Object, Object)
 	 */
 	@GuardedBy(""sfg"")
-	public boolean addEdge(StateVertix sourceVert, StateVertix targetVert, Eventable clickable) {
+	public boolean addEdge(StateVertex sourceVert, StateVertex targetVert, Eventable clickable) {
 		synchronized (sfg) {
 			// TODO Ali; Why is this code (if-stmt) here? Its the same as what happens in sfg.addEge
 			// imo (21-01-10 Stefan).
@@ -165,7 +168,7 @@
 	 * @return a set of the outgoing edges (clickables) of the stateVertix.
 	 * @see org.jgrapht.DirectedGraph#outgoingEdgesOf(Object)
 	 */
-	public Set<Eventable> getOutgoingClickables(StateVertix stateVertix) {
+	public Set<Eventable> getOutgoingClickables(StateVertex stateVertix) {
 		return sfg.outgoingEdgesOf(stateVertix);
 	}
 
@@ -177,7 +180,7 @@
 	 * @return a set of the incoming edges (clickables) of the stateVertix.
 	 * @see org.jgrapht.DirectedGraph#incomingEdgesOf(Object)
 	 */
-	public Set<Eventable> getIncomingClickable(StateVertix stateVertix) {
+	public Set<Eventable> getIncomingClickable(StateVertex stateVertix) {
 		return sfg.incomingEdgesOf(stateVertix);
 	}
 
@@ -188,8 +191,8 @@
 	 *            the state.
 	 * @return the set of outgoing states from the stateVertix.
 	 */
-	public Set<StateVertix> getOutgoingStates(StateVertix stateVertix) {
-		final Set<StateVertix> result = new HashSet<StateVertix>();
+	public Set<StateVertex> getOutgoingStates(StateVertex stateVertix) {
+		final Set<StateVertex> result = new HashSet<StateVertex>();
 
 		for (Eventable c : getOutgoingClickables(stateVertix)) {
 			result.add(sfg.getEdgeTarget(c));
@@ -203,7 +206,7 @@
 	 *            the edge.
 	 * @return the target state of this edge.
 	 */
-	public StateVertix getTargetState(Eventable clickable) {
+	public StateVertex getTargetState(Eventable clickable) {
 		return sfg.getEdgeTarget(clickable);
 	}
 
@@ -217,7 +220,7 @@
 	 * @return true if it is possible (edge exists in graph) to go from source to target.
 	 */
 	@GuardedBy(""sfg"")
-	public boolean canGoTo(StateVertix source, StateVertix target) {
+	public boolean canGoTo(StateVertex source, StateVertex target) {
 		synchronized (sfg) {
 			return sfg.containsEdge(source, target) || sfg.containsEdge(target, source);
 		}
@@ -232,7 +235,7 @@
 	 *            the end state.
 	 * @return a list of shortest path of clickables from the state to the end
 	 */
-	public List<Eventable> getShortestPath(StateVertix start, StateVertix end) {
+	public List<Eventable> getShortestPath(StateVertex start, StateVertex end) {
 		return DijkstraShortestPath.findPathBetween(sfg, start, end);
 	}
 
@@ -241,7 +244,7 @@
 	 * 
 	 * @return all the states on the graph.
 	 */
-	public Set<StateVertix> getAllStates() {
+	public Set<StateVertex> getAllStates() {
 		return sfg.vertexSet();
 	}
 
@@ -262,10 +265,10 @@
 	 *            the StateVertix to search
 	 * @return the copy of the StateVertix in the StateFlowGraph where v.equals(u)
 	 */
-	private StateVertix getStateInGraph(StateVertix state) {
-		Set<StateVertix> states = getAllStates();
+	private StateVertex getStateInGraph(StateVertex state) {
+		Set<StateVertex> states = getAllStates();
 
-		for (StateVertix st : states) {
+		for (StateVertex st : states) {
 			if (state.equals(st)) {
 				return st;
 			}
@@ -280,7 +283,7 @@
 	public int getMeanStateStringSize() {
 		final Mean mean = new Mean();
 
-		for (StateVertix state : getAllStates()) {
+		for (StateVertex state : getAllStates()) {
 			mean.increment(state.getDomSize());
 		}
 
@@ -290,7 +293,7 @@
 	/**
 	 * @return the state-flow graph.
 	 */
-	public DirectedGraph<StateVertix, Eventable> getSfg() {
+	public DirectedGraph<StateVertex, Eventable> getSfg() {
 		return sfg;
 	}
 
@@ -299,20 +302,20 @@
 	 *            The starting state.
 	 * @return A list of the deepest states (states with no outgoing edges).
 	 */
-	public List<StateVertix> getDeepStates(StateVertix state) {
+	public List<StateVertex> getDeepStates(StateVertex state) {
 		final Set<String> visitedStates = new HashSet<String>();
-		final List<StateVertix> deepStates = new ArrayList<StateVertix>();
+		final List<StateVertex> deepStates = new ArrayList<StateVertex>();
 
 		traverse(visitedStates, deepStates, state);
 
 		return deepStates;
 	}
 
-	private void traverse(Set<String> visitedStates, List<StateVertix> deepStates,
-	        StateVertix state) {
+	private void traverse(Set<String> visitedStates, List<StateVertex> deepStates,
+	        StateVertex state) {
 		visitedStates.add(state.getName());
 
-		Set<StateVertix> outgoingSet = getOutgoingStates(state);
+		Set<StateVertex> outgoingSet = getOutgoingStates(state);
 
 		if ((outgoingSet == null) || outgoingSet.isEmpty()) {
 			deepStates.add(state);
@@ -320,7 +323,7 @@
 			if (cyclic(visitedStates, outgoingSet)) {
 				deepStates.add(state);
 			} else {
-				for (StateVertix st : outgoingSet) {
+				for (StateVertex st : outgoingSet) {
 					if (!visitedStates.contains(st.getName())) {
 						traverse(visitedStates, deepStates, st);
 					}
@@ -329,10 +332,10 @@
 		}
 	}
 
-	private boolean cyclic(Set<String> visitedStates, Set<StateVertix> outgoingSet) {
+	private boolean cyclic(Set<String> visitedStates, Set<StateVertex> outgoingSet) {
 		int i = 0;
 
-		for (StateVertix state : outgoingSet) {
+		for (StateVertex state : outgoingSet) {
 			if (visitedStates.contains(state.getName())) {
 				i++;
 			}
@@ -348,19 +351,19 @@
 	 *            the initial state.
 	 * @return a list of GraphPath lists.
 	 */
-	public List<List<GraphPath<StateVertix, Eventable>>> getAllPossiblePaths(StateVertix index) {
-		final List<List<GraphPath<StateVertix, Eventable>>> results =
-		        new ArrayList<List<GraphPath<StateVertix, Eventable>>>();
+	public List<List<GraphPath<StateVertex, Eventable>>> getAllPossiblePaths(StateVertex index) {
+		final List<List<GraphPath<StateVertex, Eventable>>> results =
+		        new ArrayList<List<GraphPath<StateVertex, Eventable>>>();
 
-		final KShortestPaths<StateVertix, Eventable> kPaths =
-		        new KShortestPaths<StateVertix, Eventable>(this.sfg, index, Integer.MAX_VALUE);
+		final KShortestPaths<StateVertex, Eventable> kPaths =
+		        new KShortestPaths<StateVertex, Eventable>(this.sfg, index, Integer.MAX_VALUE);
 		// System.out.println(sfg.toString());
 
-		for (StateVertix state : getDeepStates(index)) {
+		for (StateVertex state : getDeepStates(index)) {
 			// System.out.println(""Deep State: "" + state.getName());
 
 			try {
-				List<GraphPath<StateVertix, Eventable>> paths = kPaths.getPaths(state);
+				List<GraphPath<StateVertex, Eventable>> paths = kPaths.getPaths(state);
 				results.add(paths);
 			} catch (Exception e) {
 				// TODO Stefan; which Exception is catched here???Can this be removed?
"
ba877d01152f4ea7eb17bf338e8c8b9e4e18a267,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/src/main/java/com/crawljax/forms/FormHandler.java b/src/main/java/com/crawljax/forms/FormHandler.java
index 439d088..46ae2c7 100644
--- a/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/src/main/java/com/crawljax/forms/FormHandler.java
@@ -3,6 +3,21 @@
  */
 package com.crawljax.forms;
 
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
+
+import javax.xml.xpath.XPathExpressionException;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.w3c.dom.Document;
+import org.w3c.dom.Element;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+import org.xml.sax.SAXException;
+
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.CandidateElement;
@@ -11,20 +26,6 @@
 import com.crawljax.util.Helper;
 import com.crawljax.util.XPathHelper;
 
-import org.apache.log4j.Logger;
-import org.w3c.dom.Document;
-import org.w3c.dom.Element;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-import org.xml.sax.SAXException;
-
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.List;
-
-import javax.xml.xpath.XPathExpressionException;
-
 /**
  * Handles form values and fills in the form input elements with random values of the defined
  * values.
@@ -33,7 +34,7 @@
  * @version $Id$
  */
 public class FormHandler {
-	private static final Logger LOGGER = Logger.getLogger(FormHandler.class.getName());
+	private static final Logger LOGGER = LoggerFactory.getLogger(FormHandler.class.getName());
 
 	private boolean randomFieldValue = false;
 	private final EmbeddedBrowser browser;
@@ -147,7 +148,7 @@
 					}
 				}
 			} catch (Exception e) {
-				//TODO Stefan; refactor this catch
+				// TODO Stefan; refactor this catch
 				if (e instanceof BrowserConnectionException) {
 					throw (BrowserConnectionException) e;
 				}
"
ba877d01152f4ea7eb17bf338e8c8b9e4e18a267,Alex Nederlof,AttributeInjector.java,MODIFY,"removeInjectedAttributes -> [HTMLElement element, String attrName] | [Vector injectedElements, String attrName]","diff --git a/src/main/java/com/crawljax/util/AttributeInjector.java b/src/main/java/com/crawljax/util/AttributeInjector.java
index bbb5a37..4e76dd0 100644
--- a/src/main/java/com/crawljax/util/AttributeInjector.java
+++ b/src/main/java/com/crawljax/util/AttributeInjector.java
@@ -142,7 +142,7 @@
 			element.removeAttribute(attrName);
 			// check if the attr was appended to the src value
 			// String srcAttrValue = element.getAttribute(""src"");
-			//			
+			//
 			// if(srcAttrValue.matches("".*"" + attrName + ""=.*""))
 			// {
 			// int index = srcAttrValue.indexOf(attrName);
"
ba877d01152f4ea7eb17bf338e8c8b9e4e18a267,Alex Nederlof,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/src/main/java/com/crawljax/util/ElementResolver.java b/src/main/java/com/crawljax/util/ElementResolver.java
index c50af37..605a685 100644
--- a/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/src/main/java/com/crawljax/util/ElementResolver.java
@@ -1,151 +1,152 @@
-package com.crawljax.util;
-
-import com.crawljax.browser.EmbeddedBrowser;
-import com.crawljax.core.state.Element;
-import com.crawljax.core.state.Eventable;
-
-import org.apache.log4j.Logger;
-import org.w3c.dom.Document;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-import org.xml.sax.SAXException;
-
-import java.io.IOException;
-
-import javax.xml.xpath.XPathExpressionException;
-
-/**
- * class for finding and checking elements.
- * 
- * @author danny
- * @version $Id$
- */
-public class ElementResolver {
-	private static final Logger LOGGER = Logger.getLogger(ElementResolver.class.getName());
-
-	// private ElementResolverSettings settings = new
-	// ElementResolverSettings();
-
-	private final EmbeddedBrowser browser;
-	private final Eventable eventable;
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param eventable
-	 *            Eventable.
-	 * @param browser
-	 *            The browser.
-	 */
-	public ElementResolver(Eventable eventable, EmbeddedBrowser browser) {
-		this.browser = browser;
-		this.eventable = eventable;
-	}
-
-	/**
-	 * @return equivalent xpath of element equivalent to Eventable
-	 */
-	public String resolve() {
-		return resolve(false);
-	}
-
-	/**
-	 * @param logging
-	 *            Whether to do logging.
-	 * @return equivalent xpath of element equivalent to Eventable
-	 */
-	public String resolve(boolean logging) {
-		Document dom = null;
-		try {
-	        dom = Helper.getDocument(browser.getDom());
-		} catch (SAXException e) {
-			LOGGER.error(e.getMessage(), e);
-			return """";
-		} catch (IOException e) {
-			LOGGER.error(e.getMessage(), e);
-			return """";
-		}
-		
-		try {
-			String xpathEventable = eventable.getIdentification().getValue();
-			Node nodeSameXpath = Helper.getElementByXpath(dom, xpathEventable);
-			if (nodeSameXpath != null) {
-				Element elementSameXpath = new Element(nodeSameXpath);
-				if (logging) {
-					LOGGER.info(""Try element with same xpath expression"");
-				}
-				if (equivalent(elementSameXpath, logging)) {
-					return xpathEventable;
-				}
-			}
-
-			if (logging) {
-				LOGGER.info(""Search other candidate elements"");
-			}
-			NodeList candidateElements =
-			        XPathHelper.evaluateXpathExpression(dom, ""//""
-			                + eventable.getElement().getTag().toUpperCase());
-			if (logging) {
-				LOGGER.info(""Candidates: "" + candidateElements.getLength());
-			}
-			for (int i = 0; i < candidateElements.getLength(); i++) {
-				Element candidateElement = new Element(candidateElements.item(i));
-				if (equivalent(candidateElement, logging)) {
-					return XPathHelper.getXPathExpression(candidateElements.item(i));
-				}
-			}
-
-		} catch (XPathExpressionException e) {
-			LOGGER.error(e.getMessage(), e);
-		}
-		if (logging) {
-			LOGGER.info(""No equivalent element found"");
-		}
-		return null;
-	}
-
-	/**
-	 * Comparator against other element.
-	 * 
-	 * @param otherElement
-	 *            The other element.
-	 * @param logging
-	 *            Whether to do logging.
-	 * @return Whether the elements are equal.
-	 */
-	public boolean equivalent(Element otherElement, boolean logging) {
-		if (eventable.getElement().equals(otherElement)) {
-			if (logging) {
-				LOGGER.info(""Element equal"");
-			}
-			return true;
-		}
-
-		if (eventable.getElement().equalAttributes(otherElement)) {
-			if (logging) {
-				LOGGER.info(""Element attributes equal"");
-			}
-			return true;
-		}
-
-		if (eventable.getElement().equalId(otherElement)) {
-			if (logging) {
-				LOGGER.info(""Element ID equal"");
-			}
-			return true;
-		}
-
-		if (!eventable.getElement().getText().equals("""")
-		        && eventable.getElement().equalText(otherElement)) {
-
-			if (logging) {
-				LOGGER.info(""Element text equal"");
-			}
-
-			return true;
-		}
-
-		return false;
-	}
-
-}
+package com.crawljax.util;
+
+import java.io.IOException;
+
+import javax.xml.xpath.XPathExpressionException;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.w3c.dom.Document;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+import org.xml.sax.SAXException;
+
+import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.core.state.Element;
+import com.crawljax.core.state.Eventable;
+
+/**
+ * class for finding and checking elements.
+ * 
+ * @author danny
+ * @version $Id$
+ */
+public class ElementResolver {
+	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class.getName());
+
+	// private ElementResolverSettings settings = new
+	// ElementResolverSettings();
+
+	private final EmbeddedBrowser browser;
+	private final Eventable eventable;
+
+	/**
+	 * Constructor.
+	 * 
+	 * @param eventable
+	 *            Eventable.
+	 * @param browser
+	 *            The browser.
+	 */
+	public ElementResolver(Eventable eventable, EmbeddedBrowser browser) {
+		this.browser = browser;
+		this.eventable = eventable;
+	}
+
+	/**
+	 * @return equivalent xpath of element equivalent to Eventable
+	 */
+	public String resolve() {
+		return resolve(false);
+	}
+
+	/**
+	 * @param logging
+	 *            Whether to do logging.
+	 * @return equivalent xpath of element equivalent to Eventable
+	 */
+	public String resolve(boolean logging) {
+		Document dom = null;
+		try {
+			dom = Helper.getDocument(browser.getDom());
+		} catch (SAXException e) {
+			LOGGER.error(e.getMessage(), e);
+			return """";
+		} catch (IOException e) {
+			LOGGER.error(e.getMessage(), e);
+			return """";
+		}
+
+		try {
+			String xpathEventable = eventable.getIdentification().getValue();
+			Node nodeSameXpath = Helper.getElementByXpath(dom, xpathEventable);
+			if (nodeSameXpath != null) {
+				Element elementSameXpath = new Element(nodeSameXpath);
+				if (logging) {
+					LOGGER.info(""Try element with same xpath expression"");
+				}
+				if (equivalent(elementSameXpath, logging)) {
+					return xpathEventable;
+				}
+			}
+
+			if (logging) {
+				LOGGER.info(""Search other candidate elements"");
+			}
+			NodeList candidateElements =
+			        XPathHelper.evaluateXpathExpression(dom, ""//""
+			                + eventable.getElement().getTag().toUpperCase());
+			if (logging) {
+				LOGGER.info(""Candidates: "" + candidateElements.getLength());
+			}
+			for (int i = 0; i < candidateElements.getLength(); i++) {
+				Element candidateElement = new Element(candidateElements.item(i));
+				if (equivalent(candidateElement, logging)) {
+					return XPathHelper.getXPathExpression(candidateElements.item(i));
+				}
+			}
+
+		} catch (XPathExpressionException e) {
+			LOGGER.error(e.getMessage(), e);
+		}
+		if (logging) {
+			LOGGER.info(""No equivalent element found"");
+		}
+		return null;
+	}
+
+	/**
+	 * Comparator against other element.
+	 * 
+	 * @param otherElement
+	 *            The other element.
+	 * @param logging
+	 *            Whether to do logging.
+	 * @return Whether the elements are equal.
+	 */
+	public boolean equivalent(Element otherElement, boolean logging) {
+		if (eventable.getElement().equals(otherElement)) {
+			if (logging) {
+				LOGGER.info(""Element equal"");
+			}
+			return true;
+		}
+
+		if (eventable.getElement().equalAttributes(otherElement)) {
+			if (logging) {
+				LOGGER.info(""Element attributes equal"");
+			}
+			return true;
+		}
+
+		if (eventable.getElement().equalId(otherElement)) {
+			if (logging) {
+				LOGGER.info(""Element ID equal"");
+			}
+			return true;
+		}
+
+		if (!eventable.getElement().getText().equals("""")
+		        && eventable.getElement().equalText(otherElement)) {
+
+			if (logging) {
+				LOGGER.info(""Element text equal"");
+			}
+
+			return true;
+		}
+
+		return false;
+	}
+
+}
"
ba877d01152f4ea7eb17bf338e8c8b9e4e18a267,Alex Nederlof,Helper.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/src/main/java/com/crawljax/util/Helper.java b/src/main/java/com/crawljax/util/Helper.java
index 16e21e5..a238623 100644
--- a/src/main/java/com/crawljax/util/Helper.java
+++ b/src/main/java/com/crawljax/util/Helper.java
@@ -1,797 +1,798 @@
-package com.crawljax.util;
-
-import java.io.BufferedReader;
-import java.io.ByteArrayOutputStream;
-import java.io.File;
-import java.io.FileInputStream;
-import java.io.FileOutputStream;
-import java.io.FileReader;
-import java.io.FileWriter;
-import java.io.IOException;
-import java.io.InputStream;
-import java.io.InputStreamReader;
-import java.io.StringReader;
-import java.io.StringWriter;
-import java.net.MalformedURLException;
-import java.net.URL;
-import java.util.ArrayList;
-import java.util.List;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
-import java.util.regex.PatternSyntaxException;
-
-import javax.xml.transform.OutputKeys;
-import javax.xml.transform.Result;
-import javax.xml.transform.Source;
-import javax.xml.transform.Transformer;
-import javax.xml.transform.TransformerConfigurationException;
-import javax.xml.transform.TransformerException;
-import javax.xml.transform.TransformerFactory;
-import javax.xml.transform.dom.DOMSource;
-import javax.xml.transform.stream.StreamResult;
-import javax.xml.xpath.XPath;
-import javax.xml.xpath.XPathConstants;
-import javax.xml.xpath.XPathExpressionException;
-import javax.xml.xpath.XPathFactory;
-
-import org.apache.commons.io.FileUtils;
-import org.apache.log4j.Logger;
-import org.custommonkey.xmlunit.DetailedDiff;
-import org.custommonkey.xmlunit.Diff;
-import org.custommonkey.xmlunit.Difference;
-import org.custommonkey.xmlunit.DifferenceListener;
-import org.cyberneko.html.parsers.DOMParser;
-import org.w3c.dom.Attr;
-import org.w3c.dom.Document;
-import org.w3c.dom.Element;
-import org.w3c.dom.NamedNodeMap;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-import org.xml.sax.InputSource;
-import org.xml.sax.SAXException;
-
-import com.google.common.collect.Lists;
-
-/**
- * Utility class that contains a number of helper functions used by Crawljax and some plugins.
- * 
- * @author mesbah
- * @version $Id$
- */
-public final class Helper {
-
-	private static final int BASE_LENGTH = 3;
-
-	private static final int TEXT_CUTOFF = 50;
-
-	public static final Logger LOGGER = Logger.getLogger(Helper.class.getName());
-
-	private Helper() {
-	}
-
-	/**
-	 * Internal used function to strip the basePath from a given url.
-	 * 
-	 * @param url
-	 *            the url to examine
-	 * @return the base path with file stipped
-	 */
-	private static String getBasePath(URL url) {
-		String file = url.getFile().replaceAll(""\\*"", """");
-
-		try {
-			return url.getPath().replaceAll(file, """");
-		} catch (PatternSyntaxException pe) {
-			LOGGER.error(pe.getMessage());
-			return """";
-		}
-
-	}
-
-	/**
-	 * @param location
-	 *            Current location.
-	 * @param link
-	 *            Link to check.
-	 * @return Whether location and link are on the same domain.
-	 */
-	public static boolean isLinkExternal(String location, String link) {
-
-		if (!location.contains(""://"")) {
-			// location must always contain :// by rule, it not link is handled as not external
-			return false;
-		}
-
-		// This will jump out of the local file location
-		if (location.startsWith(""file"") && link.startsWith(""/"")) {
-			return true;
-		}
-
-		if (link.contains(""://"")) {
-			if (location.startsWith(""file"") && link.startsWith(""http"") || link.startsWith(""file"")
-			        && location.startsWith(""http"")) {
-				// Jump from file to http(s) or from http(s) to file, so external
-				return true;
-			}
-			try {
-				URL locationUrl = new URL(location);
-				try {
-					URL linkUrl = new URL(link);
-					if (linkUrl.getHost().equals(locationUrl.getHost())) {
-						String linkPath = getBasePath(linkUrl);
-						return !(linkPath.startsWith(getBasePath(locationUrl)));
-					}
-					return true;
-				} catch (MalformedURLException e) {
-					LOGGER.info(""Can not parse link "" + link + "" to check its externalOf ""
-					        + location);
-					return false;
-				}
-			} catch (MalformedURLException e) {
-				LOGGER.info(""Can not parse location "" + location + "" to check if "" + link
-				        + "" isExternal"", e);
-				return false;
-			}
-		} else {
-			// No full url specifier so internal link...
-			return false;
-		}
-	}
-
-	/**
-	 * @param url
-	 *            the URL string.
-	 * @return the base part of the URL.
-	 */
-	public static String getBaseUrl(String url) {
-		String head = url.substring(0, url.indexOf("":""));
-		String subLoc = url.substring(head.length() + BASE_LENGTH);
-		return head + ""://"" + subLoc.substring(0, subLoc.indexOf(""/""));
-	}
-
-	/**
-	 * transforms a string into a Document object. TODO This needs more optimizations. As it seems
-	 * the getDocument is called way too much times causing a lot of parsing which is slow and not
-	 * necessary.
-	 * 
-	 * @param html
-	 *            the HTML string.
-	 * @return The DOM Document version of the HTML string.
-	 * @throws IOException
-	 *             if an IO failure occurs.
-	 * @throws SAXException
-	 *             if an exception occurs while parsing the HTML string.
-	 */
-	public static Document getDocument(String html) throws SAXException, IOException {
-		DOMParser domParser = new DOMParser();
-		domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
-		domParser.setFeature(""http://xml.org/sax/features/namespaces"", false);
-		domParser.parse(new InputSource(new StringReader(html)));
-		return domParser.getDocument();
-	}
-
-	/**
-	 * @param html
-	 *            the HTML string.
-	 * @return a Document object made from the HTML string.
-	 * @throws SAXException
-	 *             if an exception occurs while parsing the HTML string.
-	 * @throws IOException
-	 *             if an IO failure occurs.
-	 */
-	public static Document getDocumentNoBalance(String html) throws SAXException, IOException {
-		DOMParser domParser = new DOMParser();
-		domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
-		domParser.setFeature(""http://cyberneko.org/html/features/balance-tags"", false);
-		domParser.parse(new InputSource(new StringReader(html)));
-		return domParser.getDocument();
-	}
-
-	/**
-	 * @param element
-	 *            The DOM Element.
-	 * @return A string representation of all the element's attributes.
-	 */
-	public static String getAllElementAttributes(Element element) {
-		return getElementAttributes(element, new ArrayList<String>());
-	}
-
-	/**
-	 * @param element
-	 *            The DOM Element.
-	 * @param exclude
-	 *            the list of exclude strings.
-	 * @return A string representation of the element's attributes excluding exclude.
-	 */
-	public static String getElementAttributes(Element element, List<String> exclude) {
-		StringBuffer buffer = new StringBuffer();
-
-		if (element != null) {
-			NamedNodeMap attributes = element.getAttributes();
-			if (attributes != null) {
-				for (int i = 0; i < attributes.getLength(); i++) {
-					Attr attr = (Attr) attributes.item(i);
-					if (!exclude.contains(attr.getNodeName())) {
-						buffer.append(attr.getNodeName() + ""="");
-						buffer.append(attr.getNodeValue() + "" "");
-					}
-				}
-			}
-		}
-
-		return buffer.toString().trim();
-	}
-
-	/**
-	 * @param element
-	 *            the element.
-	 * @return a string representation of the element including its attributes.
-	 */
-	public static String getElementString(Element element) {
-		if (element == null) {
-			return """";
-		}
-		String text = Helper.removeNewLines(Helper.getTextValue(element)).trim();
-		String info = """";
-		if (!text.equals("""")) {
-			info += ""\"""" + text + ""\"" "";
-			// Helper.removeNewLines(this.text.trim()) + "" - "";
-		}
-		if (element != null) {
-			if (element.hasAttribute(""id"")) {
-				info += ""ID: "" + element.getAttribute(""id"") + "" "";
-			}
-			info += Helper.getAllElementAttributes(element) + "" "";
-		}
-		return info;
-	}
-
-	/**
-	 * @param dom
-	 *            the DOM document.
-	 * @param xpath
-	 *            the xpath.
-	 * @return The element found on DOM having the xpath position.
-	 * @throws XPathExpressionException
-	 *             if the xpath fails.
-	 */
-	public static Element getElementByXpath(Document dom, String xpath)
-	        throws XPathExpressionException {
-		XPath xp = XPathFactory.newInstance().newXPath();
-		xp.setNamespaceContext(new HtmlNamespace());
-
-		return (Element) xp.evaluate(xpath, dom, XPathConstants.NODE);
-	}
-
-	/**
-	 * Removes all the <SCRIPT/> tags from the document.
-	 * 
-	 * @param dom
-	 *            the document object.
-	 * @return the changed dom.
-	 */
-	public static Document removeScriptTags(Document dom) {
-		return removeTags(dom, ""SCRIPT"");
-	}
-
-	/**
-	 * Removes all the given tags from the document.
-	 * 
-	 * @param dom
-	 *            the document object.
-	 * @param tagName
-	 *            the tag name, examples: script, style, meta
-	 * @return the changed dom.
-	 */
-	public static Document removeTags(Document dom, String tagName) {
-		if (dom != null) {
-			// NodeList list = dom.getElementsByTagName(""SCRIPT"");
-
-			NodeList list;
-			try {
-				list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
-
-				while (list.getLength() > 0) {
-					Node sc = list.item(0);
-
-					if (sc != null) {
-						sc.getParentNode().removeChild(sc);
-					}
-
-					list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
-					// list = dom.getElementsByTagName(""SCRIPT"");
-				}
-			} catch (XPathExpressionException e) {
-				LOGGER.error(e.getMessage(), e);
-			}
-
-			return dom;
-		}
-
-		return null;
-	}
-
-	/**
-	 * Checks the existence of the directory. If it does not exist, the method creates it.
-	 * 
-	 * @param dir
-	 *            the directory to check.
-	 * @throws IOException
-	 *             if fails.
-	 */
-	public static void directoryCheck(String dir) throws IOException {
-		final File file = new File(dir);
-
-		if (!file.exists()) {
-			FileUtils.forceMkdir(file);
-		}
-	}
-
-	/**
-	 * Checks whether the folder exists for fname, and creates it if neccessary.
-	 * 
-	 * @param fname
-	 *            folder name.
-	 * @throws IOException
-	 *             an IO exception.
-	 */
-	public static void checkFolderForFile(String fname) throws IOException {
-
-		if (fname.lastIndexOf(File.separator) > 0) {
-			String folder = fname.substring(0, fname.lastIndexOf(File.separator));
-			Helper.directoryCheck(folder);
-		}
-	}
-
-	/**
-	 * Retrieve the var value for varName from a HTTP query string (format is
-	 * ""var1=val1&var2=val2"").
-	 * 
-	 * @param varName
-	 *            the name.
-	 * @param haystack
-	 *            the haystack.
-	 * @return variable value for varName
-	 */
-	public static String getVarFromQueryString(String varName, String haystack) {
-		if (haystack == null || haystack.length() == 0) {
-			return null;
-		}
-		if (haystack.charAt(0) == '?') {
-			haystack = haystack.substring(1);
-		}
-		String[] vars = haystack.split(""&"");
-
-		for (String var : vars) {
-			String[] tuple = var.split(""="");
-			if (tuple.length == 2 && tuple[0].equals(varName)) {
-				return tuple[1];
-			}
-		}
-		return null;
-	}
-
-	/**
-	 * @param dom
-	 *            the DOM document.
-	 * @return a string representation of the DOM.
-	 */
-	public static String getDocumentToString(Document dom) {
-		try {
-			Source source = new DOMSource(dom);
-			StringWriter stringWriter = new StringWriter();
-			Result result = new StreamResult(stringWriter);
-			TransformerFactory factory = TransformerFactory.newInstance();
-			Transformer transformer = factory.newTransformer();
-			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
-			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""yes"");
-			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
-			transformer.transform(source, result);
-			return stringWriter.getBuffer().toString();
-		} catch (TransformerConfigurationException e) {
-			LOGGER.error(e.getMessage(), e);
-		} catch (TransformerException e) {
-			LOGGER.error(e.getMessage(), e);
-		}
-		return null;
-
-	}
-
-	/**
-	 * Serialize the Document object.
-	 * 
-	 * @param dom
-	 *            the document to serialize
-	 * @return the serialized dom String
-	 */
-	public static byte[] getDocumentToByteArray(Document dom) {
-		try {
-			TransformerFactory tFactory = TransformerFactory.newInstance();
-
-			Transformer transformer = tFactory.newTransformer();
-			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
-			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
-			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
-			// TODO should be fixed to read doctype declaration
-			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			// ""-//W3C//DTD XHTML 1.0 Transitional//EN\""
-			// \""http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"");
-			transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			        ""-//W3C//DTD XHTML 1.0 Strict//EN\"" ""
-			                + ""\""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"");
-
-			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			// ""-//W3C//DTD HTML 4.01//EN\"" \""http://www.w3.org/TR/html4/strict.dtd"");
-			DOMSource source = new DOMSource(dom);
-
-			ByteArrayOutputStream out = new ByteArrayOutputStream();
-			Result result = new StreamResult(out);
-			transformer.transform(source, result);
-
-			// System.out.println(""Injected Javascript!"");
-			return out.toByteArray();
-		} catch (TransformerConfigurationException e) {
-			LOGGER.error(e.getMessage(), e);
-		} catch (TransformerException e) {
-			LOGGER.error(e.getMessage(), e);
-		}
-		return null;
-
-	}
-
-	/**
-	 * Save a string to a file and append a newline character to that string.
-	 * 
-	 * @param filename
-	 *            The filename to save to.
-	 * @param text
-	 *            The text to save.
-	 * @param append
-	 *            Whether to append to existing file.
-	 * @throws IOException
-	 *             On error.
-	 */
-	public static void writeToFile(String filename, String text, boolean append)
-	        throws IOException {
-		FileWriter fw = new FileWriter(filename, append);
-		try {
-			fw.write(text + ""\n"");
-		} catch (IOException e) {
-			throw e;
-		} finally {
-			fw.close();
-		}
-	}
-
-	/**
-	 * @param code
-	 *            hashcode.
-	 * @return String version of hashcode.
-	 */
-	public static String hashCodeToString(long code) {
-		if (code < 0) {
-			return ""0"" + (code * -1);
-		} else {
-			return """" + code;
-		}
-	}
-
-	/**
-	 * Returns the text value of an element (title, alt or contents). Note that the result is 50
-	 * characters or less in length.
-	 * 
-	 * @param element
-	 *            The element.
-	 * @return The text value of the element.
-	 */
-	public static String getTextValue(Element element) {
-		String ret = """";
-		if (element == null) {
-			return """";
-		}
-
-		if (element.getTextContent() != null) {
-			ret = element.getTextContent();
-		} else if (element.hasAttribute(""title"")) {
-			ret = element.getAttribute(""title"");
-		} else if (element.hasAttribute(""alt"")) {
-			ret = element.getAttribute(""alt"");
-		}
-		if (ret.length() > TEXT_CUTOFF) {
-			return ret.substring(0, TEXT_CUTOFF);
-		} else {
-			return ret;
-		}
-	}
-
-	/**
-	 * Get differences between doms.
-	 * 
-	 * @param controlDom
-	 *            The control dom.
-	 * @param testDom
-	 *            The test dom.
-	 * @return The differences.
-	 */
-	public static List<Difference> getDifferences(String controlDom, String testDom) {
-		return getDifferences(controlDom, testDom, Lists.<String> newArrayList());
-	}
-
-	/**
-	 * Get differences between doms.
-	 * 
-	 * @param controlDom
-	 *            The control dom.
-	 * @param testDom
-	 *            The test dom.
-	 * @param ignoreAttributes
-	 *            The list of attributes to ignore.
-	 * @return The differences.
-	 */
-	@SuppressWarnings(""unchecked"")
-	public static List<Difference> getDifferences(String controlDom, String testDom,
-	        final List<String> ignoreAttributes) {
-		try {
-			Diff d = new Diff(Helper.getDocument(controlDom), Helper.getDocument(testDom));
-			DetailedDiff dd = new DetailedDiff(d);
-			dd.overrideDifferenceListener(new DifferenceListener() {
-
-				@Override
-				public void skippedComparison(Node control, Node test) {
-				}
-
-				@Override
-				public int differenceFound(Difference difference) {
-					if (difference.getControlNodeDetail() == null
-					        || difference.getControlNodeDetail().getNode() == null
-					        || difference.getTestNodeDetail() == null
-					        || difference.getTestNodeDetail().getNode() == null) {
-						return RETURN_ACCEPT_DIFFERENCE;
-					}
-					if (ignoreAttributes.contains(difference.getTestNodeDetail().getNode()
-					        .getNodeName())
-					        || ignoreAttributes.contains(difference.getControlNodeDetail()
-					                .getNode().getNodeName())) {
-						return RETURN_IGNORE_DIFFERENCE_NODES_IDENTICAL;
-					}
-					return RETURN_ACCEPT_DIFFERENCE;
-				}
-			});
-
-			return dd.getAllDifferences();
-		} catch (Exception e) {
-			LOGGER.error(""Error with getDifferences: "" + e.getMessage(), e);
-		}
-		return null;
-	}
-
-	/**
-	 * Removes newlines from a string.
-	 * 
-	 * @param html
-	 *            The string.
-	 * @return The new string without the newlines or tabs.
-	 */
-	public static String removeNewLines(String html) {
-		return html.replaceAll(""[\\t\\n\\x0B\\f\\r]"", """");
-	}
-
-	/**
-	 * @param string
-	 *            The original string.
-	 * @param regex
-	 *            The regular expression.
-	 * @param replace
-	 *            What to replace it with.
-	 * @return replaces regex in str by replace where the dot sign also supports newlines
-	 */
-	public static String replaceString(String string, String regex, String replace) {
-		Pattern p = Pattern.compile(regex, Pattern.DOTALL);
-		Matcher m = p.matcher(string);
-		String replaced = m.replaceAll(replace);
-		p = Pattern.compile(""  "", Pattern.DOTALL);
-		m = p.matcher(replaced);
-		return m.replaceAll("" "");
-	}
-
-	/**
-	 * Adds a slash to a path if it doesn't end with a slash.
-	 * 
-	 * @param folderName
-	 *            The path to append a possible slash.
-	 * @return The new, correct path.
-	 */
-	public static String addFolderSlashIfNeeded(String folderName) {
-		if (!folderName.equals("""") && !folderName.endsWith(""/"")) {
-			return folderName + ""/"";
-		} else {
-			return folderName;
-		}
-	}
-
-	/**
-	 * Returns the filename in a path. For example with path = ""foo/bar/crawljax.txt"" returns
-	 * ""crawljax.txt""
-	 * 
-	 * @param path
-	 * @return the filename from the path
-	 */
-	private static String getFileNameInPath(String path) {
-		String fname;
-		if (path.indexOf(""/"") != -1) {
-			fname = path.substring(path.lastIndexOf(""/"") + 1);
-		} else {
-			fname = path;
-		}
-		return fname;
-	}
-
-	/**
-	 * Retrieves the content of the filename. Also reads from JAR Searches for the resource in the
-	 * root folder in the jar
-	 * 
-	 * @param fname
-	 *            Filename.
-	 * @return The contents of the file.
-	 * @throws IOException
-	 *             On error.
-	 */
-	public static String getTemplateAsString(String fname) throws IOException {
-		// in .jar file
-		String fnameJar = getFileNameInPath(fname);
-		InputStream inStream = Helper.class.getResourceAsStream(""/"" + fnameJar);
-		if (inStream == null) {
-			// try to find file normally
-			File f = new File(fname);
-			if (f.exists()) {
-				inStream = new FileInputStream(f);
-			} else {
-				throw new IOException(""Cannot find "" + fname + "" or "" + fnameJar);
-			}
-		}
-
-		BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inStream));
-		String line;
-		StringBuilder stringBuilder = new StringBuilder();
-
-		while ((line = bufferedReader.readLine()) != null) {
-			stringBuilder.append(line + ""\n"");
-		}
-
-		bufferedReader.close();
-		return stringBuilder.toString();
-	}
-
-	/**
-	 * @param xpath
-	 *            The xpath of the element.
-	 * @return The JavaScript to get an element.
-	 */
-	public static String getJSGetElement(String xpath) {
-		String js =
-		        """"
-		                + ""function ATUSA_getElementInNodes(nodes, tagName, number){""
-		                + ""try{""
-		                + ""var pos = 1;""
-		                + ""for(i=0; i<nodes.length; i++){""
-		                + ""if(nodes[i]!=null && nodes[i].tagName!=null && ""
-		                + ""nodes[i].tagName.toLowerCase() == tagName){""
-		                + ""if(number==pos){""
-		                + ""return nodes[i];""
-		                + ""}else{""
-		                + ""pos++;""
-		                + ""}""
-		                + ""}""
-		                + ""}""
-		                + ""}catch(e){}""
-		                + ""return null;""
-		                + ""}""
-		                + ""function ATUSA_getElementByXpath(xpath){""
-		                + ""try{""
-		                + ""var elements = xpath.toLowerCase().split('/');""
-		                + ""var curNode = window.document.body;""
-		                + ""var tagName, number;""
-		                + ""for(j=0; j<elements.length; j++){""
-		                + ""if(elements[j]!=''){""
-		                + ""if(elements[j].indexOf('[')==-1){""
-		                + ""tagName = elements[j];""
-		                + ""number = 1;""
-		                + ""}else{""
-		                + ""tagName = elements[j].substring(0, elements[j].indexOf('['));""
-		                + ""number = elements[j].substring(elements[j].indexOf('[')+1, ""
-		                + ""elements[j].lastIndexOf(']'));""
-		                + ""}""
-		                + ""if(tagName!='body' && tagName!='html'){""
-		                + ""curNode = ATUSA_getElementInNodes(curNode.childNodes, tagName, number);""
-		                + ""if(curNode==null){"" + ""return null;"" + ""}"" + ""}"" + ""}"" + ""}""
-		                + ""}catch(e){return null;}"" + ""return curNode;"" + ""}""
-		                + ""try{var ATUSA_element = ATUSA_getElementByXpath('"" + xpath
-		                + ""');}catch(e){return null;}"";
-
-		return js;
-	}
-
-	/**
-	 * @param frame
-	 *            the frame element.
-	 * @return the name or id of this element if they are present, otherwise null.
-	 */
-	public static String getFrameIdentification(Element frame) {
-
-		Attr attr = frame.getAttributeNode(""id"");
-		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
-			return attr.getNodeValue();
-		}
-
-		attr = frame.getAttributeNode(""name"");
-		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
-			return attr.getNodeValue();
-		}
-
-		return null;
-
-	}
-
-	/**
-	 * Write the document object to a file.
-	 * 
-	 * @param document
-	 *            the document object.
-	 * @param filePathname
-	 *            the path name of the file to be written to.
-	 * @param method
-	 *            the output method: for instance html, xml, text
-	 * @param indent
-	 *            amount of indentation. -1 to use the default.
-	 * @throws TransformerException
-	 *             if an exception occurs.
-	 * @throws IOException
-	 *             if an IO exception occurs.
-	 */
-	public static void writeDocumentToFile(Document document, String filePathname, String method,
-	        int indent) throws TransformerException, IOException {
-
-		checkFolderForFile(filePathname);
-		Transformer transformer = TransformerFactory.newInstance().newTransformer();
-		transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
-		transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
-		transformer.setOutputProperty(OutputKeys.METHOD, method);
-
-		if (indent > -1) {
-			transformer.setOutputProperty(
-			        org.apache.xml.serializer.OutputPropertiesFactory.S_KEY_INDENT_AMOUNT,
-			        Integer.toString(indent));
-		}
-		transformer.transform(new DOMSource(document), new StreamResult(new FileOutputStream(
-		        filePathname)));
-	}
-
-	/**
-	 * Returns the file contents without stripping line-endings.
-	 * 
-	 * @param file
-	 *            File to read out.
-	 * @return Contents including line-endings.
-	 */
-	public static String getContent(File file) {
-		StringBuilder contents = new StringBuilder();
-
-		try {
-			BufferedReader input = new BufferedReader(new FileReader(file));
-			try {
-				String line = null; // not declared within while loop
-				while ((line = input.readLine()) != null) {
-					contents.append(line);
-					contents.append(""\n"");
-				}
-			} finally {
-				input.close();
-			}
-		} catch (IOException e) {
-			e.printStackTrace();
-		}
-
-		return contents.toString();
-	}
-
-}
+package com.crawljax.util;
+
+import java.io.BufferedReader;
+import java.io.ByteArrayOutputStream;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.FileReader;
+import java.io.FileWriter;
+import java.io.IOException;
+import java.io.InputStream;
+import java.io.InputStreamReader;
+import java.io.StringReader;
+import java.io.StringWriter;
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.util.ArrayList;
+import java.util.List;
+import java.util.regex.Matcher;
+import java.util.regex.Pattern;
+import java.util.regex.PatternSyntaxException;
+
+import javax.xml.transform.OutputKeys;
+import javax.xml.transform.Result;
+import javax.xml.transform.Source;
+import javax.xml.transform.Transformer;
+import javax.xml.transform.TransformerConfigurationException;
+import javax.xml.transform.TransformerException;
+import javax.xml.transform.TransformerFactory;
+import javax.xml.transform.dom.DOMSource;
+import javax.xml.transform.stream.StreamResult;
+import javax.xml.xpath.XPath;
+import javax.xml.xpath.XPathConstants;
+import javax.xml.xpath.XPathExpressionException;
+import javax.xml.xpath.XPathFactory;
+
+import org.apache.commons.io.FileUtils;
+import org.custommonkey.xmlunit.DetailedDiff;
+import org.custommonkey.xmlunit.Diff;
+import org.custommonkey.xmlunit.Difference;
+import org.custommonkey.xmlunit.DifferenceListener;
+import org.cyberneko.html.parsers.DOMParser;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.w3c.dom.Attr;
+import org.w3c.dom.Document;
+import org.w3c.dom.Element;
+import org.w3c.dom.NamedNodeMap;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+import org.xml.sax.InputSource;
+import org.xml.sax.SAXException;
+
+import com.google.common.collect.Lists;
+
+/**
+ * Utility class that contains a number of helper functions used by Crawljax and some plugins.
+ * 
+ * @author mesbah
+ * @version $Id$
+ */
+public final class Helper {
+
+	private static final int BASE_LENGTH = 3;
+
+	private static final int TEXT_CUTOFF = 50;
+
+	public static final Logger LOGGER = LoggerFactory.getLogger(Helper.class.getName());
+
+	private Helper() {
+	}
+
+	/**
+	 * Internal used function to strip the basePath from a given url.
+	 * 
+	 * @param url
+	 *            the url to examine
+	 * @return the base path with file stipped
+	 */
+	private static String getBasePath(URL url) {
+		String file = url.getFile().replaceAll(""\\*"", """");
+
+		try {
+			return url.getPath().replaceAll(file, """");
+		} catch (PatternSyntaxException pe) {
+			LOGGER.error(pe.getMessage());
+			return """";
+		}
+
+	}
+
+	/**
+	 * @param location
+	 *            Current location.
+	 * @param link
+	 *            Link to check.
+	 * @return Whether location and link are on the same domain.
+	 */
+	public static boolean isLinkExternal(String location, String link) {
+
+		if (!location.contains(""://"")) {
+			// location must always contain :// by rule, it not link is handled as not external
+			return false;
+		}
+
+		// This will jump out of the local file location
+		if (location.startsWith(""file"") && link.startsWith(""/"")) {
+			return true;
+		}
+
+		if (link.contains(""://"")) {
+			if (location.startsWith(""file"") && link.startsWith(""http"") || link.startsWith(""file"")
+			        && location.startsWith(""http"")) {
+				// Jump from file to http(s) or from http(s) to file, so external
+				return true;
+			}
+			try {
+				URL locationUrl = new URL(location);
+				try {
+					URL linkUrl = new URL(link);
+					if (linkUrl.getHost().equals(locationUrl.getHost())) {
+						String linkPath = getBasePath(linkUrl);
+						return !(linkPath.startsWith(getBasePath(locationUrl)));
+					}
+					return true;
+				} catch (MalformedURLException e) {
+					LOGGER.info(""Can not parse link "" + link + "" to check its externalOf ""
+					        + location);
+					return false;
+				}
+			} catch (MalformedURLException e) {
+				LOGGER.info(""Can not parse location "" + location + "" to check if "" + link
+				        + "" isExternal"", e);
+				return false;
+			}
+		} else {
+			// No full url specifier so internal link...
+			return false;
+		}
+	}
+
+	/**
+	 * @param url
+	 *            the URL string.
+	 * @return the base part of the URL.
+	 */
+	public static String getBaseUrl(String url) {
+		String head = url.substring(0, url.indexOf("":""));
+		String subLoc = url.substring(head.length() + BASE_LENGTH);
+		return head + ""://"" + subLoc.substring(0, subLoc.indexOf(""/""));
+	}
+
+	/**
+	 * transforms a string into a Document object. TODO This needs more optimizations. As it seems
+	 * the getDocument is called way too much times causing a lot of parsing which is slow and not
+	 * necessary.
+	 * 
+	 * @param html
+	 *            the HTML string.
+	 * @return The DOM Document version of the HTML string.
+	 * @throws IOException
+	 *             if an IO failure occurs.
+	 * @throws SAXException
+	 *             if an exception occurs while parsing the HTML string.
+	 */
+	public static Document getDocument(String html) throws SAXException, IOException {
+		DOMParser domParser = new DOMParser();
+		domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
+		domParser.setFeature(""http://xml.org/sax/features/namespaces"", false);
+		domParser.parse(new InputSource(new StringReader(html)));
+		return domParser.getDocument();
+	}
+
+	/**
+	 * @param html
+	 *            the HTML string.
+	 * @return a Document object made from the HTML string.
+	 * @throws SAXException
+	 *             if an exception occurs while parsing the HTML string.
+	 * @throws IOException
+	 *             if an IO failure occurs.
+	 */
+	public static Document getDocumentNoBalance(String html) throws SAXException, IOException {
+		DOMParser domParser = new DOMParser();
+		domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
+		domParser.setFeature(""http://cyberneko.org/html/features/balance-tags"", false);
+		domParser.parse(new InputSource(new StringReader(html)));
+		return domParser.getDocument();
+	}
+
+	/**
+	 * @param element
+	 *            The DOM Element.
+	 * @return A string representation of all the element's attributes.
+	 */
+	public static String getAllElementAttributes(Element element) {
+		return getElementAttributes(element, new ArrayList<String>());
+	}
+
+	/**
+	 * @param element
+	 *            The DOM Element.
+	 * @param exclude
+	 *            the list of exclude strings.
+	 * @return A string representation of the element's attributes excluding exclude.
+	 */
+	public static String getElementAttributes(Element element, List<String> exclude) {
+		StringBuffer buffer = new StringBuffer();
+
+		if (element != null) {
+			NamedNodeMap attributes = element.getAttributes();
+			if (attributes != null) {
+				for (int i = 0; i < attributes.getLength(); i++) {
+					Attr attr = (Attr) attributes.item(i);
+					if (!exclude.contains(attr.getNodeName())) {
+						buffer.append(attr.getNodeName() + ""="");
+						buffer.append(attr.getNodeValue() + "" "");
+					}
+				}
+			}
+		}
+
+		return buffer.toString().trim();
+	}
+
+	/**
+	 * @param element
+	 *            the element.
+	 * @return a string representation of the element including its attributes.
+	 */
+	public static String getElementString(Element element) {
+		if (element == null) {
+			return """";
+		}
+		String text = Helper.removeNewLines(Helper.getTextValue(element)).trim();
+		String info = """";
+		if (!text.equals("""")) {
+			info += ""\"""" + text + ""\"" "";
+			// Helper.removeNewLines(this.text.trim()) + "" - "";
+		}
+		if (element != null) {
+			if (element.hasAttribute(""id"")) {
+				info += ""ID: "" + element.getAttribute(""id"") + "" "";
+			}
+			info += Helper.getAllElementAttributes(element) + "" "";
+		}
+		return info;
+	}
+
+	/**
+	 * @param dom
+	 *            the DOM document.
+	 * @param xpath
+	 *            the xpath.
+	 * @return The element found on DOM having the xpath position.
+	 * @throws XPathExpressionException
+	 *             if the xpath fails.
+	 */
+	public static Element getElementByXpath(Document dom, String xpath)
+	        throws XPathExpressionException {
+		XPath xp = XPathFactory.newInstance().newXPath();
+		xp.setNamespaceContext(new HtmlNamespace());
+
+		return (Element) xp.evaluate(xpath, dom, XPathConstants.NODE);
+	}
+
+	/**
+	 * Removes all the <SCRIPT/> tags from the document.
+	 * 
+	 * @param dom
+	 *            the document object.
+	 * @return the changed dom.
+	 */
+	public static Document removeScriptTags(Document dom) {
+		return removeTags(dom, ""SCRIPT"");
+	}
+
+	/**
+	 * Removes all the given tags from the document.
+	 * 
+	 * @param dom
+	 *            the document object.
+	 * @param tagName
+	 *            the tag name, examples: script, style, meta
+	 * @return the changed dom.
+	 */
+	public static Document removeTags(Document dom, String tagName) {
+		if (dom != null) {
+			// NodeList list = dom.getElementsByTagName(""SCRIPT"");
+
+			NodeList list;
+			try {
+				list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
+
+				while (list.getLength() > 0) {
+					Node sc = list.item(0);
+
+					if (sc != null) {
+						sc.getParentNode().removeChild(sc);
+					}
+
+					list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
+					// list = dom.getElementsByTagName(""SCRIPT"");
+				}
+			} catch (XPathExpressionException e) {
+				LOGGER.error(e.getMessage(), e);
+			}
+
+			return dom;
+		}
+
+		return null;
+	}
+
+	/**
+	 * Checks the existence of the directory. If it does not exist, the method creates it.
+	 * 
+	 * @param dir
+	 *            the directory to check.
+	 * @throws IOException
+	 *             if fails.
+	 */
+	public static void directoryCheck(String dir) throws IOException {
+		final File file = new File(dir);
+
+		if (!file.exists()) {
+			FileUtils.forceMkdir(file);
+		}
+	}
+
+	/**
+	 * Checks whether the folder exists for fname, and creates it if neccessary.
+	 * 
+	 * @param fname
+	 *            folder name.
+	 * @throws IOException
+	 *             an IO exception.
+	 */
+	public static void checkFolderForFile(String fname) throws IOException {
+
+		if (fname.lastIndexOf(File.separator) > 0) {
+			String folder = fname.substring(0, fname.lastIndexOf(File.separator));
+			Helper.directoryCheck(folder);
+		}
+	}
+
+	/**
+	 * Retrieve the var value for varName from a HTTP query string (format is
+	 * ""var1=val1&var2=val2"").
+	 * 
+	 * @param varName
+	 *            the name.
+	 * @param haystack
+	 *            the haystack.
+	 * @return variable value for varName
+	 */
+	public static String getVarFromQueryString(String varName, String haystack) {
+		if (haystack == null || haystack.length() == 0) {
+			return null;
+		}
+		if (haystack.charAt(0) == '?') {
+			haystack = haystack.substring(1);
+		}
+		String[] vars = haystack.split(""&"");
+
+		for (String var : vars) {
+			String[] tuple = var.split(""="");
+			if (tuple.length == 2 && tuple[0].equals(varName)) {
+				return tuple[1];
+			}
+		}
+		return null;
+	}
+
+	/**
+	 * @param dom
+	 *            the DOM document.
+	 * @return a string representation of the DOM.
+	 */
+	public static String getDocumentToString(Document dom) {
+		try {
+			Source source = new DOMSource(dom);
+			StringWriter stringWriter = new StringWriter();
+			Result result = new StreamResult(stringWriter);
+			TransformerFactory factory = TransformerFactory.newInstance();
+			Transformer transformer = factory.newTransformer();
+			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
+			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""yes"");
+			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
+			transformer.transform(source, result);
+			return stringWriter.getBuffer().toString();
+		} catch (TransformerConfigurationException e) {
+			LOGGER.error(e.getMessage(), e);
+		} catch (TransformerException e) {
+			LOGGER.error(e.getMessage(), e);
+		}
+		return null;
+
+	}
+
+	/**
+	 * Serialize the Document object.
+	 * 
+	 * @param dom
+	 *            the document to serialize
+	 * @return the serialized dom String
+	 */
+	public static byte[] getDocumentToByteArray(Document dom) {
+		try {
+			TransformerFactory tFactory = TransformerFactory.newInstance();
+
+			Transformer transformer = tFactory.newTransformer();
+			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
+			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
+			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
+			// TODO should be fixed to read doctype declaration
+			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
+			// ""-//W3C//DTD XHTML 1.0 Transitional//EN\""
+			// \""http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"");
+			transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
+			        ""-//W3C//DTD XHTML 1.0 Strict//EN\"" ""
+			                + ""\""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"");
+
+			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
+			// ""-//W3C//DTD HTML 4.01//EN\"" \""http://www.w3.org/TR/html4/strict.dtd"");
+			DOMSource source = new DOMSource(dom);
+
+			ByteArrayOutputStream out = new ByteArrayOutputStream();
+			Result result = new StreamResult(out);
+			transformer.transform(source, result);
+
+			// System.out.println(""Injected Javascript!"");
+			return out.toByteArray();
+		} catch (TransformerConfigurationException e) {
+			LOGGER.error(e.getMessage(), e);
+		} catch (TransformerException e) {
+			LOGGER.error(e.getMessage(), e);
+		}
+		return null;
+
+	}
+
+	/**
+	 * Save a string to a file and append a newline character to that string.
+	 * 
+	 * @param filename
+	 *            The filename to save to.
+	 * @param text
+	 *            The text to save.
+	 * @param append
+	 *            Whether to append to existing file.
+	 * @throws IOException
+	 *             On error.
+	 */
+	public static void writeToFile(String filename, String text, boolean append)
+	        throws IOException {
+		FileWriter fw = new FileWriter(filename, append);
+		try {
+			fw.write(text + ""\n"");
+		} catch (IOException e) {
+			throw e;
+		} finally {
+			fw.close();
+		}
+	}
+
+	/**
+	 * @param code
+	 *            hashcode.
+	 * @return String version of hashcode.
+	 */
+	public static String hashCodeToString(long code) {
+		if (code < 0) {
+			return ""0"" + (code * -1);
+		} else {
+			return """" + code;
+		}
+	}
+
+	/**
+	 * Returns the text value of an element (title, alt or contents). Note that the result is 50
+	 * characters or less in length.
+	 * 
+	 * @param element
+	 *            The element.
+	 * @return The text value of the element.
+	 */
+	public static String getTextValue(Element element) {
+		String ret = """";
+		if (element == null) {
+			return """";
+		}
+
+		if (element.getTextContent() != null) {
+			ret = element.getTextContent();
+		} else if (element.hasAttribute(""title"")) {
+			ret = element.getAttribute(""title"");
+		} else if (element.hasAttribute(""alt"")) {
+			ret = element.getAttribute(""alt"");
+		}
+		if (ret.length() > TEXT_CUTOFF) {
+			return ret.substring(0, TEXT_CUTOFF);
+		} else {
+			return ret;
+		}
+	}
+
+	/**
+	 * Get differences between doms.
+	 * 
+	 * @param controlDom
+	 *            The control dom.
+	 * @param testDom
+	 *            The test dom.
+	 * @return The differences.
+	 */
+	public static List<Difference> getDifferences(String controlDom, String testDom) {
+		return getDifferences(controlDom, testDom, Lists.<String> newArrayList());
+	}
+
+	/**
+	 * Get differences between doms.
+	 * 
+	 * @param controlDom
+	 *            The control dom.
+	 * @param testDom
+	 *            The test dom.
+	 * @param ignoreAttributes
+	 *            The list of attributes to ignore.
+	 * @return The differences.
+	 */
+	@SuppressWarnings(""unchecked"")
+	public static List<Difference> getDifferences(String controlDom, String testDom,
+	        final List<String> ignoreAttributes) {
+		try {
+			Diff d = new Diff(Helper.getDocument(controlDom), Helper.getDocument(testDom));
+			DetailedDiff dd = new DetailedDiff(d);
+			dd.overrideDifferenceListener(new DifferenceListener() {
+
+				@Override
+				public void skippedComparison(Node control, Node test) {
+				}
+
+				@Override
+				public int differenceFound(Difference difference) {
+					if (difference.getControlNodeDetail() == null
+					        || difference.getControlNodeDetail().getNode() == null
+					        || difference.getTestNodeDetail() == null
+					        || difference.getTestNodeDetail().getNode() == null) {
+						return RETURN_ACCEPT_DIFFERENCE;
+					}
+					if (ignoreAttributes.contains(difference.getTestNodeDetail().getNode()
+					        .getNodeName())
+					        || ignoreAttributes.contains(difference.getControlNodeDetail()
+					                .getNode().getNodeName())) {
+						return RETURN_IGNORE_DIFFERENCE_NODES_IDENTICAL;
+					}
+					return RETURN_ACCEPT_DIFFERENCE;
+				}
+			});
+
+			return dd.getAllDifferences();
+		} catch (Exception e) {
+			LOGGER.error(""Error with getDifferences: "" + e.getMessage(), e);
+		}
+		return null;
+	}
+
+	/**
+	 * Removes newlines from a string.
+	 * 
+	 * @param html
+	 *            The string.
+	 * @return The new string without the newlines or tabs.
+	 */
+	public static String removeNewLines(String html) {
+		return html.replaceAll(""[\\t\\n\\x0B\\f\\r]"", """");
+	}
+
+	/**
+	 * @param string
+	 *            The original string.
+	 * @param regex
+	 *            The regular expression.
+	 * @param replace
+	 *            What to replace it with.
+	 * @return replaces regex in str by replace where the dot sign also supports newlines
+	 */
+	public static String replaceString(String string, String regex, String replace) {
+		Pattern p = Pattern.compile(regex, Pattern.DOTALL);
+		Matcher m = p.matcher(string);
+		String replaced = m.replaceAll(replace);
+		p = Pattern.compile(""  "", Pattern.DOTALL);
+		m = p.matcher(replaced);
+		return m.replaceAll("" "");
+	}
+
+	/**
+	 * Adds a slash to a path if it doesn't end with a slash.
+	 * 
+	 * @param folderName
+	 *            The path to append a possible slash.
+	 * @return The new, correct path.
+	 */
+	public static String addFolderSlashIfNeeded(String folderName) {
+		if (!folderName.equals("""") && !folderName.endsWith(""/"")) {
+			return folderName + ""/"";
+		} else {
+			return folderName;
+		}
+	}
+
+	/**
+	 * Returns the filename in a path. For example with path = ""foo/bar/crawljax.txt"" returns
+	 * ""crawljax.txt""
+	 * 
+	 * @param path
+	 * @return the filename from the path
+	 */
+	private static String getFileNameInPath(String path) {
+		String fname;
+		if (path.indexOf(""/"") != -1) {
+			fname = path.substring(path.lastIndexOf(""/"") + 1);
+		} else {
+			fname = path;
+		}
+		return fname;
+	}
+
+	/**
+	 * Retrieves the content of the filename. Also reads from JAR Searches for the resource in the
+	 * root folder in the jar
+	 * 
+	 * @param fname
+	 *            Filename.
+	 * @return The contents of the file.
+	 * @throws IOException
+	 *             On error.
+	 */
+	public static String getTemplateAsString(String fname) throws IOException {
+		// in .jar file
+		String fnameJar = getFileNameInPath(fname);
+		InputStream inStream = Helper.class.getResourceAsStream(""/"" + fnameJar);
+		if (inStream == null) {
+			// try to find file normally
+			File f = new File(fname);
+			if (f.exists()) {
+				inStream = new FileInputStream(f);
+			} else {
+				throw new IOException(""Cannot find "" + fname + "" or "" + fnameJar);
+			}
+		}
+
+		BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inStream));
+		String line;
+		StringBuilder stringBuilder = new StringBuilder();
+
+		while ((line = bufferedReader.readLine()) != null) {
+			stringBuilder.append(line + ""\n"");
+		}
+
+		bufferedReader.close();
+		return stringBuilder.toString();
+	}
+
+	/**
+	 * @param xpath
+	 *            The xpath of the element.
+	 * @return The JavaScript to get an element.
+	 */
+	public static String getJSGetElement(String xpath) {
+		String js =
+		        """"
+		                + ""function ATUSA_getElementInNodes(nodes, tagName, number){""
+		                + ""try{""
+		                + ""var pos = 1;""
+		                + ""for(i=0; i<nodes.length; i++){""
+		                + ""if(nodes[i]!=null && nodes[i].tagName!=null && ""
+		                + ""nodes[i].tagName.toLowerCase() == tagName){""
+		                + ""if(number==pos){""
+		                + ""return nodes[i];""
+		                + ""}else{""
+		                + ""pos++;""
+		                + ""}""
+		                + ""}""
+		                + ""}""
+		                + ""}catch(e){}""
+		                + ""return null;""
+		                + ""}""
+		                + ""function ATUSA_getElementByXpath(xpath){""
+		                + ""try{""
+		                + ""var elements = xpath.toLowerCase().split('/');""
+		                + ""var curNode = window.document.body;""
+		                + ""var tagName, number;""
+		                + ""for(j=0; j<elements.length; j++){""
+		                + ""if(elements[j]!=''){""
+		                + ""if(elements[j].indexOf('[')==-1){""
+		                + ""tagName = elements[j];""
+		                + ""number = 1;""
+		                + ""}else{""
+		                + ""tagName = elements[j].substring(0, elements[j].indexOf('['));""
+		                + ""number = elements[j].substring(elements[j].indexOf('[')+1, ""
+		                + ""elements[j].lastIndexOf(']'));""
+		                + ""}""
+		                + ""if(tagName!='body' && tagName!='html'){""
+		                + ""curNode = ATUSA_getElementInNodes(curNode.childNodes, tagName, number);""
+		                + ""if(curNode==null){"" + ""return null;"" + ""}"" + ""}"" + ""}"" + ""}""
+		                + ""}catch(e){return null;}"" + ""return curNode;"" + ""}""
+		                + ""try{var ATUSA_element = ATUSA_getElementByXpath('"" + xpath
+		                + ""');}catch(e){return null;}"";
+
+		return js;
+	}
+
+	/**
+	 * @param frame
+	 *            the frame element.
+	 * @return the name or id of this element if they are present, otherwise null.
+	 */
+	public static String getFrameIdentification(Element frame) {
+
+		Attr attr = frame.getAttributeNode(""id"");
+		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
+			return attr.getNodeValue();
+		}
+
+		attr = frame.getAttributeNode(""name"");
+		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
+			return attr.getNodeValue();
+		}
+
+		return null;
+
+	}
+
+	/**
+	 * Write the document object to a file.
+	 * 
+	 * @param document
+	 *            the document object.
+	 * @param filePathname
+	 *            the path name of the file to be written to.
+	 * @param method
+	 *            the output method: for instance html, xml, text
+	 * @param indent
+	 *            amount of indentation. -1 to use the default.
+	 * @throws TransformerException
+	 *             if an exception occurs.
+	 * @throws IOException
+	 *             if an IO exception occurs.
+	 */
+	public static void writeDocumentToFile(Document document, String filePathname, String method,
+	        int indent) throws TransformerException, IOException {
+
+		checkFolderForFile(filePathname);
+		Transformer transformer = TransformerFactory.newInstance().newTransformer();
+		transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
+		transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
+		transformer.setOutputProperty(OutputKeys.METHOD, method);
+
+		if (indent > -1) {
+			transformer.setOutputProperty(
+			        org.apache.xml.serializer.OutputPropertiesFactory.S_KEY_INDENT_AMOUNT,
+			        Integer.toString(indent));
+		}
+		transformer.transform(new DOMSource(document), new StreamResult(new FileOutputStream(
+		        filePathname)));
+	}
+
+	/**
+	 * Returns the file contents without stripping line-endings.
+	 * 
+	 * @param file
+	 *            File to read out.
+	 * @return Contents including line-endings.
+	 */
+	public static String getContent(File file) {
+		StringBuilder contents = new StringBuilder();
+
+		try {
+			BufferedReader input = new BufferedReader(new FileReader(file));
+			try {
+				String line = null; // not declared within while loop
+				while ((line = input.readLine()) != null) {
+					contents.append(line);
+					contents.append(""\n"");
+				}
+			} finally {
+				input.close();
+			}
+		} catch (IOException e) {
+			e.printStackTrace();
+		}
+
+		return contents.toString();
+	}
+
+}
"
ba877d01152f4ea7eb17bf338e8c8b9e4e18a267,Alex Nederlof,PrettyHTML.java,MODIFY,"prettyHTML -> [String html] | [String html, String strIndent]","diff --git a/src/main/java/com/crawljax/util/PrettyHTML.java b/src/main/java/com/crawljax/util/PrettyHTML.java
index 13b56af..b13adc9 100644
--- a/src/main/java/com/crawljax/util/PrettyHTML.java
+++ b/src/main/java/com/crawljax/util/PrettyHTML.java
@@ -1,190 +1,190 @@
-package com.crawljax.util;
-
-import java.util.Stack;
-
-/**
- * Class for making presenting HTML without changing it's structure.
- * 
- * @author Danny
- * @version $Id$
- */
-public final class PrettyHTML {
-
-	private PrettyHTML() {
-
-	}
-
-	// private static final Logger LOGGER =
-	// Logger.getLogger(PrettyHTML.class.getName());
-
-	/**
-	 * Pretty print HTML string.
-	 * 
-	 * @param html
-	 *            The HTML string.
-	 * @param strIndent
-	 *            The indentation string.
-	 * @return The pretty HTML.
-	 */
-	public static String prettyHTML(String html, String strIndent) {
-		String[] elements = html.split(""<"");
-		StringBuffer prettyHTML = new StringBuffer();
-		int indent = 0;
-		// preparsing for not closing elements
-		elements = fixElements(elements);
-
-		for (String element : elements) {
-			if (!element.equals("""")) {
-				element = element.trim();
-
-				if (!element.startsWith(""/"")) {
-					// open element
-					prettyHTML.append(repeatString(strIndent, indent));
-					String[] temp = element.split("">"");
-					prettyHTML.append(""<"" + temp[0].trim() + "">\n"");
-
-					// only indent if element is not a single element (like
-					// <img src='..' />)
-					if ((!temp[0].endsWith(""/"") || temp.length == 1)
-					        && !temp[0].startsWith(""!--"")) {
-						indent++;
-					}
-
-					// if there is text after the element, print it
-					if (temp.length > 1 && !temp[1].trim().equals("""")) {
-						prettyHTML.append(repeatString(strIndent, indent));
-						prettyHTML.append(temp[1].trim() + ""\n"");
-					}
-				} else {
-					// close element
-					indent--;
-					prettyHTML.append(repeatString(strIndent, indent));
-					prettyHTML.append(""<"" + element + ""\n"");
-				}
-				if (element.endsWith(""/>"")) {
-					indent--;
-				}
-			}
-		}
-		return prettyHTML.toString();
-
-	}
-
-	/**
-	 * @param html
-	 *            The HTML string.
-	 * @return Pretty HTML.
-	 */
-	public static String prettyHTML(String html) {
-		return prettyHTML(html, ""\t"");
-	}
-
-	/**
-	 * @param s
-	 * @param number
-	 * @return s repreated number of times
-	 */
-	private static String repeatString(String s, int number) {
-		StringBuffer ret = new StringBuffer();
-		for (int i = 0; i < number; i++) {
-			ret.append(s);
-		}
-		return ret.toString();
-	}
-
-	/**
-	 * @param openElement
-	 * @param closeElement
-	 * @return wheter element has a seperate closing element
-	 */
-	private static boolean elementsRelated(String openElement, String closeElement) {
-		openElement = openElement.split("">"")[0];
-		openElement = openElement.split("" "")[0];
-		closeElement = closeElement.split("">"")[0];
-		return closeElement.startsWith(""/"" + openElement);
-	}
-
-	/**
-	 * @param stack
-	 * @param element
-	 * @return whether the element is open
-	 */
-	private static boolean elementIsOpen(Stack<String> stack, String element) {
-		for (int i = stack.size() - 1; i >= 0; i--) {
-			if (elementsRelated(stack.get(i), element)) {
-				return true;
-			}
-		}
-		return false;
-	}
-
-	/**
-	 * @param element
-	 * @return wheter the element is a single element (<foo ... />)
-	 */
-	private static boolean isSingleElement(String element) {
-		return element.indexOf(""/>"") != -1;
-	}
-
-	/**
-	 * @param elements
-	 * @return list with elements with added closing elements if needed
-	 */
-	private static String[] fixElements(String[] elements) {
-		Stack<String> stackElements = new Stack<String>();
-		Stack<Integer> stackIndexElements = new Stack<Integer>();
-		for (int i = 0; i < elements.length; i++) {
-			elements[i] = elements[i].trim();
-			String element = elements[i];
-			if (!element.equals("""") && !element.startsWith(""!--"") && !element.endsWith(""-->"")) {
-				while (stackElements.size() > 0 && element.startsWith(""/"")
-				        && !elementsRelated(stackElements.peek(), element)) {
-					// found a close element which is not on top of stack,
-					// thus fix
-					if (elementIsOpen(stackElements, element)) {
-						// the element is open --> close element on top of
-						// stack
-						int index = stackIndexElements.peek();
-						if (!isSingleElement(elements[index])
-						        && elements[index].lastIndexOf("">"") != -1) {
-							// close this element
-							elements[index] =
-							        elements[index]
-							                .substring(0, elements[index].lastIndexOf("">""))
-							                + ""/""
-							                + elements[index].substring(elements[index]
-							                        .lastIndexOf("">""));
-						}
-						stackElements.pop();
-						stackIndexElements.pop();
-					} else {
-						// element is closing element while element is not
-						// open--> remove.
-						elements[i] = """";
-						element = """";
-						break;
-					}
-
-				}
-				if (!element.equals("""")) {
-					// open element
-					if (!element.startsWith(""/"")) {
-						// only add to stack if has an open and close element
-						if (!isSingleElement(element)) {
-							stackElements.push(element);
-							stackIndexElements.push(i);
-						}
-					} else {
-						// close element, pop from stack if possible
-						if (stackElements.size() > 0) {
-							stackElements.pop();
-							stackIndexElements.pop();
-						}
-					}
-				}
-			}
-		}
-		return elements;
-	}
-
-}
+package com.crawljax.util;
+
+import java.util.Stack;
+
+/**
+ * Class for making presenting HTML without changing it's structure.
+ * 
+ * @author Danny
+ * @version $Id$
+ */
+public final class PrettyHTML {
+
+	private PrettyHTML() {
+
+	}
+
+	// private static final Logger LOGGER =
+	// LoggerFactory.getLogger(PrettyHTML.class.getName());
+
+	/**
+	 * Pretty print HTML string.
+	 * 
+	 * @param html
+	 *            The HTML string.
+	 * @param strIndent
+	 *            The indentation string.
+	 * @return The pretty HTML.
+	 */
+	public static String prettyHTML(String html, String strIndent) {
+		String[] elements = html.split(""<"");
+		StringBuffer prettyHTML = new StringBuffer();
+		int indent = 0;
+		// preparsing for not closing elements
+		elements = fixElements(elements);
+
+		for (String element : elements) {
+			if (!element.equals("""")) {
+				element = element.trim();
+
+				if (!element.startsWith(""/"")) {
+					// open element
+					prettyHTML.append(repeatString(strIndent, indent));
+					String[] temp = element.split("">"");
+					prettyHTML.append(""<"" + temp[0].trim() + "">\n"");
+
+					// only indent if element is not a single element (like
+					// <img src='..' />)
+					if ((!temp[0].endsWith(""/"") || temp.length == 1)
+					        && !temp[0].startsWith(""!--"")) {
+						indent++;
+					}
+
+					// if there is text after the element, print it
+					if (temp.length > 1 && !temp[1].trim().equals("""")) {
+						prettyHTML.append(repeatString(strIndent, indent));
+						prettyHTML.append(temp[1].trim() + ""\n"");
+					}
+				} else {
+					// close element
+					indent--;
+					prettyHTML.append(repeatString(strIndent, indent));
+					prettyHTML.append(""<"" + element + ""\n"");
+				}
+				if (element.endsWith(""/>"")) {
+					indent--;
+				}
+			}
+		}
+		return prettyHTML.toString();
+
+	}
+
+	/**
+	 * @param html
+	 *            The HTML string.
+	 * @return Pretty HTML.
+	 */
+	public static String prettyHTML(String html) {
+		return prettyHTML(html, ""\t"");
+	}
+
+	/**
+	 * @param s
+	 * @param number
+	 * @return s repreated number of times
+	 */
+	private static String repeatString(String s, int number) {
+		StringBuffer ret = new StringBuffer();
+		for (int i = 0; i < number; i++) {
+			ret.append(s);
+		}
+		return ret.toString();
+	}
+
+	/**
+	 * @param openElement
+	 * @param closeElement
+	 * @return wheter element has a seperate closing element
+	 */
+	private static boolean elementsRelated(String openElement, String closeElement) {
+		openElement = openElement.split("">"")[0];
+		openElement = openElement.split("" "")[0];
+		closeElement = closeElement.split("">"")[0];
+		return closeElement.startsWith(""/"" + openElement);
+	}
+
+	/**
+	 * @param stack
+	 * @param element
+	 * @return whether the element is open
+	 */
+	private static boolean elementIsOpen(Stack<String> stack, String element) {
+		for (int i = stack.size() - 1; i >= 0; i--) {
+			if (elementsRelated(stack.get(i), element)) {
+				return true;
+			}
+		}
+		return false;
+	}
+
+	/**
+	 * @param element
+	 * @return wheter the element is a single element (<foo ... />)
+	 */
+	private static boolean isSingleElement(String element) {
+		return element.indexOf(""/>"") != -1;
+	}
+
+	/**
+	 * @param elements
+	 * @return list with elements with added closing elements if needed
+	 */
+	private static String[] fixElements(String[] elements) {
+		Stack<String> stackElements = new Stack<String>();
+		Stack<Integer> stackIndexElements = new Stack<Integer>();
+		for (int i = 0; i < elements.length; i++) {
+			elements[i] = elements[i].trim();
+			String element = elements[i];
+			if (!element.equals("""") && !element.startsWith(""!--"") && !element.endsWith(""-->"")) {
+				while (stackElements.size() > 0 && element.startsWith(""/"")
+				        && !elementsRelated(stackElements.peek(), element)) {
+					// found a close element which is not on top of stack,
+					// thus fix
+					if (elementIsOpen(stackElements, element)) {
+						// the element is open --> close element on top of
+						// stack
+						int index = stackIndexElements.peek();
+						if (!isSingleElement(elements[index])
+						        && elements[index].lastIndexOf("">"") != -1) {
+							// close this element
+							elements[index] =
+							        elements[index]
+							                .substring(0, elements[index].lastIndexOf("">""))
+							                + ""/""
+							                + elements[index].substring(elements[index]
+							                        .lastIndexOf("">""));
+						}
+						stackElements.pop();
+						stackIndexElements.pop();
+					} else {
+						// element is closing element while element is not
+						// open--> remove.
+						elements[i] = """";
+						element = """";
+						break;
+					}
+
+				}
+				if (!element.equals("""")) {
+					// open element
+					if (!element.startsWith(""/"")) {
+						// only add to stack if has an open and close element
+						if (!isSingleElement(element)) {
+							stackElements.push(element);
+							stackIndexElements.push(i);
+						}
+					} else {
+						// close element, pop from stack if possible
+						if (stackElements.size() > 0) {
+							stackElements.pop();
+							stackIndexElements.pop();
+						}
+					}
+				}
+			}
+		}
+		return elements;
+	}
+
+}
"
da97d9e7d7d15c6300647e68590d31c19bab0b83,Alex Nederlof,CrawlOverview.java,MODIFY,saveScreenshot -> [StateVertix currentState] | [StateVertex currentState],"diff --git a/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java b/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java
index b9cf697..d0a3b01 100644
--- a/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java
+++ b/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java
@@ -38,7 +38,7 @@
 import com.crawljax.core.plugin.PreStateCrawlingPlugin;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateFlowGraph;
-import com.crawljax.core.state.StateVertix;
+import com.crawljax.core.state.StateVertex;
 import com.google.common.collect.Maps;
 
 /**
@@ -96,7 +96,7 @@
 		StateFlowGraph sfg = session.getStateFlowGraph();
 		try {
 			writeIndexFile();
-			for (StateVertix state : sfg.getAllStates()) {
+			for (StateVertex state : sfg.getAllStates()) {
 				List<RenderedCandidateElement> rendered = stateCandidatesMap.get(state.getName());
 				writeHtmlForState(state, rendered);
 			}
@@ -107,7 +107,7 @@
 		LOG.info(""Overview report generated: {}"", outputBuilder.getIndexFile().getAbsolutePath());
 	}
 
-	private void saveScreenshot(StateVertix currentState) {
+	private void saveScreenshot(StateVertex currentState) {
 		if (!visitedStates.contains(currentState.getName())) {
 			LOG.debug(""Saving screenshot for state {}"", currentState.getName());
 			File screenShot = outputBuilder.newScreenShotFile(currentState.getName());
@@ -120,7 +120,7 @@
 		}
 	}
 
-	private Eventable getEventableByCandidateElementInState(StateVertix state,
+	private Eventable getEventableByCandidateElementInState(StateVertex state,
 	        RenderedCandidateElement element) {
 		StateFlowGraph sfg = session.getStateFlowGraph();
 		for (Eventable eventable : sfg.getOutgoingClickables(state)) {
@@ -134,21 +134,21 @@
 		return null;
 	}
 
-	private int getStateNumber(StateVertix state) {
+	private int getStateNumber(StateVertex state) {
 		if (state.getName().equals(""index"")) {
 			return 0;
 		}
 		return Integer.parseInt(state.getName().replace(""state"", """"));
 	}
 
-	private List<Map<String, String>> getElements(StateFlowGraph sfg, StateVertix state,
+	private List<Map<String, String>> getElements(StateFlowGraph sfg, StateVertex state,
 	        List<RenderedCandidateElement> rendered) {
 		List<Map<String, String>> elements = new ArrayList<Map<String, String>>();
 
 		if (rendered != null) {
 			for (RenderedCandidateElement element : rendered) {
 				Eventable eventable = getEventableByCandidateElementInState(state, element);
-				StateVertix toState = null;
+				StateVertex toState = null;
 				Map<String, String> elementMap = new HashMap<String, String>();
 				if (eventable != null) {
 					toState = sfg.getTargetState(eventable);
@@ -189,8 +189,8 @@
 		List<Map<String, String>> eventables = new ArrayList<Map<String, String>>();
 		for (Eventable eventable : sfg.getAllEdges()) {
 			Map<String, String> eventableMap = new HashMap<String, String>();
-			eventableMap.put(""from"", eventable.getSourceStateVertix().getName());
-			eventableMap.put(""to"", eventable.getTargetStateVertix().getName());
+			eventableMap.put(""from"", eventable.getSourceStateVertex().getName());
+			eventableMap.put(""to"", eventable.getTargetStateVertex().getName());
 			eventables.add(eventableMap);
 		}
 		return eventables;
@@ -198,13 +198,13 @@
 
 	private List<Map<String, String>> getStates(StateFlowGraph sfg) {
 		List<Map<String, String>> states = new ArrayList<Map<String, String>>();
-		for (StateVertix stateVertix : sfg.getAllStates()) {
-			Map<String, String> stateVertixMap = new HashMap<String, String>();
-			stateVertixMap.put(""name"", stateVertix.getName());
-			stateVertixMap.put(""url"", stateVertix.getUrl());
-			stateVertixMap.put(""id"", stateVertix.getName().replace(""state"", ""S""));
-			stateVertixMap.put(""screenshot"", stateVertix.getName() + "".png"");
-			states.add(stateVertixMap);
+		for (StateVertex StateVertex : sfg.getAllStates()) {
+			Map<String, String> StateVertexMap = new HashMap<String, String>();
+			StateVertexMap.put(""name"", StateVertex.getName());
+			StateVertexMap.put(""url"", StateVertex.getUrl());
+			StateVertexMap.put(""id"", StateVertex.getName().replace(""state"", ""S""));
+			StateVertexMap.put(""screenshot"", StateVertex.getName() + "".png"");
+			states.add(StateVertexMap);
 		}
 		return states;
 	}
@@ -227,7 +227,7 @@
 		writeToFile(template, context, fileHTML, ""index"");
 	}
 
-	private void writeHtmlForState(StateVertix state, List<RenderedCandidateElement> rendered)
+	private void writeHtmlForState(StateVertex state, List<RenderedCandidateElement> rendered)
 	        throws Exception {
 		LOG.debug(""Writing state file for state {}"", state.getName());
 		StateFlowGraph sfg = session.getStateFlowGraph();
@@ -256,7 +256,7 @@
 		writer.close();
 	}
 
-	private void findElementAndAddToMap(StateVertix state, CandidateElement element) {
+	private void findElementAndAddToMap(StateVertex state, CandidateElement element) {
 		// find element
 
 		WebElement webElement;
"
2f12df379f4d398c173fbc42ab5777532230b4a1,alireza,CrawljaxPluginsUtil.java,MODIFY,"runDomChangeNotifierPlugins -> [StateVertex stateBefore, Eventable e, StateVertex stateAfter] | [StateVertex stateBefore, Eventable e, StateVertex stateAfter, EmbeddedBrowser browser]","diff --git a/core/src/main/java/com/crawljax/core/plugin/CrawljaxPluginsUtil.java b/core/src/main/java/com/crawljax/core/plugin/CrawljaxPluginsUtil.java
index 22461f2..12c4c94 100644
--- a/core/src/main/java/com/crawljax/core/plugin/CrawljaxPluginsUtil.java
+++ b/core/src/main/java/com/crawljax/core/plugin/CrawljaxPluginsUtil.java
@@ -290,7 +290,7 @@
 	 *  
 	 *        
 	 */
-	public static boolean runDomChangeNotifierPlugins(final StateVertex stateBefore,final Eventable e, final StateVertex stateAfter) {
+	public static boolean runDomChangeNotifierPlugins(final StateVertex stateBefore,final Eventable e, final StateVertex stateAfter, final EmbeddedBrowser browser) {
 		LOGGER.info(""Checking for DomChangeNotifierPlugin..."");
 		Plugin latest = null;
 		for (Plugin plugin : CrawljaxPluginsUtil.PLUGINS) {
@@ -302,7 +302,7 @@
 		
 		if (latest != null){
 			LOGGER.info(""Calling plugin "" + latest.getClass().getName());
-			return ((DomChangeNotifierPlugin) latest).isDomChanged(stateBefore.getDom(), e ,stateAfter.getDom());
+			return ((DomChangeNotifierPlugin) latest).isDomChanged(stateBefore.getDom(), e ,stateAfter.getDom(), browser);
 		}
 		
 		LOGGER.info(""No DomChangeNotifierPlugin found. Performing default DOM comparison..."");
"
2f12df379f4d398c173fbc42ab5777532230b4a1,alireza,DomChangeNotifierPlugin.java,MODIFY,"isDomChanged -> [String domBefore, Eventable e, String domAfter] | [String domBefore, Eventable e, String domAfter, EmbeddedBrowser browser]","diff --git a/core/src/main/java/com/crawljax/core/plugin/DomChangeNotifierPlugin.java b/core/src/main/java/com/crawljax/core/plugin/DomChangeNotifierPlugin.java
index 0f5a150..13cee59 100644
--- a/core/src/main/java/com/crawljax/core/plugin/DomChangeNotifierPlugin.java
+++ b/core/src/main/java/com/crawljax/core/plugin/DomChangeNotifierPlugin.java
@@ -9,6 +9,7 @@
  */
 package com.crawljax.core.plugin;
 
+import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.core.state.Eventable;
 
 public interface DomChangeNotifierPlugin extends Plugin {
@@ -24,7 +25,7 @@
 	 *            the state after the event.
 	 * @return true if the state is changed according to the compare method of the oracle.
 	 */
-	 boolean isDomChanged(final String domBefore,final Eventable e, final String domAfter);
+	 boolean isDomChanged(final String domBefore,final Eventable e, final String domAfter, EmbeddedBrowser browser);
 	 
 	 
 	 
"
708ae7da0eaf1d4b20dc62afc3256c5f61c237e8,Alex Nederlof,OutputBuilder.java,MODIFY,writeStatistics -> [] | [Statistics stats],"diff --git a/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java b/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
index 4ca60b1..96c142a 100644
--- a/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
+++ b/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
@@ -14,6 +14,8 @@
 import org.apache.velocity.runtime.RuntimeConstants;
 import org.apache.velocity.runtime.resource.loader.ClasspathResourceLoader;
 
+import com.crawljax.plugins.crawloverview.model.Statistics;
+
 class OutputBuilder {
 
 	private final static String SCREENSHOT_FOLDER_NAME = ""screenshots"";
@@ -80,9 +82,16 @@
 		writeFile(context, file, ""state.html"");
 	}
 
-	void writeStatistics() {
+	void writeStatistics(Statistics stats) {
 		File file = new File(outputDir, ""statistics.html"");
-		writeFile(new VelocityContext(), file, ""statistics.html"");
+		VelocityContext context = new VelocityContext();
+		context.put(""stats"", stats);
+		writeFile(context, file, ""statistics.html"");
+
+		file = new File(outputDir, ""urls.html"");
+		context = new VelocityContext();
+		context.put(""urls"", stats.getStateStats().getUrls());
+		writeFile(context, file, ""urls.html"");
 	}
 
 	private void writeFile(VelocityContext context, File outFile, String template) {
"
708ae7da0eaf1d4b20dc62afc3256c5f61c237e8,Alex Nederlof,OutPutModel.java,MODIFY,close -> [] | [CrawlSession session],"diff --git a/src/main/java/com/crawljax/plugins/crawloverview/model/OutPutModel.java b/src/main/java/com/crawljax/plugins/crawloverview/model/OutPutModel.java
index 6cfb4e3..7410121 100644
--- a/src/main/java/com/crawljax/plugins/crawloverview/model/OutPutModel.java
+++ b/src/main/java/com/crawljax/plugins/crawloverview/model/OutPutModel.java
@@ -7,6 +7,7 @@
 import java.util.Map;
 import java.util.Set;
 
+import com.crawljax.core.CrawlSession;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateVertex;
 import com.fasterxml.jackson.annotation.JsonAutoDetect.Visibility;
@@ -37,8 +38,10 @@
 	/**
 	 * Makes the final calculations.
 	 */
-	public void close() {
+	public Statistics close(CrawlSession session) {
 		checkEdgesAndCountFans();
+		StateStatistics stateStats = new StateStatistics(states);
+		return new Statistics(session, stateStats);
 	}
 
 	public Collection<State> getStates() {
"
1cb7cc9f72b9592ae9ef120e7b0a3e714585a56e,Alex Nederlof,StateWriter.java,MODIFY,"getEventableByCandidateElementInState -> [State state, RenderedCandidateElement element] | [State state, CandidateElementPosition element]","diff --git a/src/main/java/com/crawljax/plugins/crawloverview/StateWriter.java b/src/main/java/com/crawljax/plugins/crawloverview/StateWriter.java
index eda2ef9..701c9f4 100644
--- a/src/main/java/com/crawljax/plugins/crawloverview/StateWriter.java
+++ b/src/main/java/com/crawljax/plugins/crawloverview/StateWriter.java
@@ -1,19 +1,19 @@
 package com.crawljax.plugins.crawloverview;
 
-import java.util.ArrayList;
 import java.util.HashMap;
 import java.util.List;
 import java.util.Map;
 
 import org.apache.velocity.VelocityContext;
-import org.openqa.selenium.Point;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateFlowGraph;
 import com.crawljax.core.state.StateVertex;
+import com.crawljax.plugins.crawloverview.model.CandidateElementPosition;
 import com.crawljax.plugins.crawloverview.model.State;
+import com.google.common.collect.Lists;
 
 public class StateWriter {
 
@@ -50,17 +50,20 @@
 	}
 
 	private List<Map<String, String>> getElements(StateFlowGraph sfg, State state) {
-		List<Map<String, String>> elements = new ArrayList<Map<String, String>>();
+		List<CandidateElementPosition> candidateElements = state.getCandidateElements();
 
-		for (RenderedCandidateElement element : state.getCandidateElements()) {
+		List<Map<String, String>> elements =
+		        Lists.newArrayListWithCapacity(candidateElements.size());
+
+		for (CandidateElementPosition element : candidateElements) {
 			Eventable eventable = getEventableByCandidateElementInState(state, element);
 			StateVertex toState = null;
 			Map<String, String> elementMap = new HashMap<String, String>();
-			Point offset = state.getScreenShotOffset();
-			elementMap.put(""left"", """" + (element.getLocation().x - 3 + offset.getY()));
-			elementMap.put(""top"", """" + (element.getLocation().y - 3 + offset.getX()));
-			elementMap.put(""width"", """" + (element.getSize().width + 2));
-			elementMap.put(""height"", """" + (element.getSize().height + 2));
+			elementMap
+			        .put(""left"", """" + (element.getLeft() - 3 + state.getScreenshotOffsetLeft()));
+			elementMap.put(""top"", """" + (element.getTop() - 3 + state.getScreenshotOffsetTop()));
+			elementMap.put(""width"", """" + (element.getWidth() + 2));
+			elementMap.put(""height"", """" + (element.getHeight() + 2));
 			if (eventable != null) {
 				toState = sfg.getTargetState(eventable);
 			}
@@ -89,13 +92,13 @@
 	}
 
 	private Eventable getEventableByCandidateElementInState(State state,
-	        RenderedCandidateElement element) {
+	        CandidateElementPosition element) {
 		StateVertex vertex = visitedStates.get(state.getName());
 		for (Eventable eventable : sfg.getOutgoingClickables(vertex)) {
 			// TODO Check if element.getIdentification().getValue() is correct replacement for
 			// element.getXpath()
 			if (eventable.getIdentification().getValue()
-			        .equals(element.getIdentification().getValue())) {
+			        .equals(element.getXpath())) {
 				return eventable;
 			}
 		}
"
46e40abb43a82db40870dd04208bf740b25cc55e,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index 5b010f4..b88f139 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -66,7 +66,7 @@
 	 * @throws ConfigurationException
 	 *             if the configuration fails.
 	 */
-	public CrawljaxController(final CrawljaxConfiguration config) throws ConfigurationException {
+	public CrawljaxController(final CrawljaxConfiguration config) throws CrawljaxException {
 		configurationReader = new CrawljaxConfigurationReader(config);
 		CrawlSpecificationReader crawlerReader =
 		        configurationReader.getCrawlSpecificationReader();
@@ -91,7 +91,7 @@
 	 *             if the configuration fails.
 	 * @NotThreadSafe
 	 */
-	private CrawlerExecutor init() throws ConfigurationException {
+	private CrawlerExecutor init() {
 		LOGGER.info(""Starting Crawljax..."");
 
 		LOGGER.info(""Used plugins:"");
@@ -124,7 +124,7 @@
 	 *             if crawljax configuration fails.
 	 * @NotThreadSafe
 	 */
-	public final void run() throws CrawljaxException, ConfigurationException {
+	public final void run() throws CrawljaxException {
 
 		startCrawl = System.currentTimeMillis();
 
"
77db30faa7988845d6e2eacb77109654557053eb,Ali Mesbah,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index 5b010f4..b88f139 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -66,7 +66,7 @@
 	 * @throws ConfigurationException
 	 *             if the configuration fails.
 	 */
-	public CrawljaxController(final CrawljaxConfiguration config) throws ConfigurationException {
+	public CrawljaxController(final CrawljaxConfiguration config) throws CrawljaxException {
 		configurationReader = new CrawljaxConfigurationReader(config);
 		CrawlSpecificationReader crawlerReader =
 		        configurationReader.getCrawlSpecificationReader();
@@ -91,7 +91,7 @@
 	 *             if the configuration fails.
 	 * @NotThreadSafe
 	 */
-	private CrawlerExecutor init() throws ConfigurationException {
+	private CrawlerExecutor init() {
 		LOGGER.info(""Starting Crawljax..."");
 
 		LOGGER.info(""Used plugins:"");
@@ -124,7 +124,7 @@
 	 *             if crawljax configuration fails.
 	 * @NotThreadSafe
 	 */
-	public final void run() throws CrawljaxException, ConfigurationException {
+	public final void run() throws CrawljaxException {
 
 		startCrawl = System.currentTimeMillis();
 
"
bee0de0e4afeeb5920253e144589c86d5108c84a,Alex Nederlof,AttributeInjector.java,MODIFY,"removeInjectedAttributes -> [HTMLElement element, String attrName] | [Vector injectedElements, String attrName]","diff --git a/core/src/main/java/com/crawljax/util/AttributeInjector.java b/core/src/main/java/com/crawljax/util/AttributeInjector.java
index 4e76dd0..8bc9fc6 100644
--- a/core/src/main/java/com/crawljax/util/AttributeInjector.java
+++ b/core/src/main/java/com/crawljax/util/AttributeInjector.java
@@ -3,6 +3,9 @@
 import java.util.Vector;
 
 import org.apache.commons.lang.StringUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.w3c.dom.DOMException;
 import org.w3c.dom.NamedNodeMap;
 import org.w3c.dom.Node;
 import org.w3c.dom.html.HTMLElement;
@@ -14,38 +17,8 @@
  */
 public final class AttributeInjector {
 
-	private AttributeInjector() {
+	private static final Logger LOG = LoggerFactory.getLogger(AttributeInjector.class);
 
-	}
-
-	/**
-	 * Inject a unique attribute into element.
-	 * 
-	 * @param element
-	 * @param isActive
-	 */
-	/*
-	 * public static HTMLElement injectUniqueAttributeInNode(
-	 * com.jniwrapper.win32.ie.dom.HTMLElement element, String attrName, String value, boolean
-	 * injectParents) { if (element == null) return null; element.setAttribute(attrName, value); if
-	 * (injectParents) return injectUniqueAttributeInNode(element.getOffsetParent(), attrName,
-	 * value, injectParents); return element; }
-	 */
-
-	/*
-	 * public static HTMLElement injectUniqueAttributeInNode(watij.elements.HtmlElement element,
-	 * String attrName, String value, boolean injectParents) { if (element == null) return null; try
-	 * { // use reflection to get the 'real' DOM element HTMLElement realElement =
-	 * getInternalBrowserElement(element); return injectUniqueAttributeInNode(realElement, attrName,
-	 * value, injectParents); } catch (Exception e) { e.printStackTrace(); } return null; }
-	 */
-
-	/*
-	 * public static HTMLElement getInternalBrowserElement(watij.elements.HtmlElement element)
-	 * throws Exception { IEHtmlElement ieHtml = (IEHtmlElement) element; Method ieMethod =
-	 * ieHtml.getClass().getDeclaredMethod(""htmlElement""); ieMethod.setAccessible(true); HTMLElement
-	 * HTMLe = (HTMLElement) ieMethod.invoke(ieHtml); return HTMLe; }
-	 */
 	/**
 	 * Find the corresponding 'real' DOM element in the browser for element and inject the unique
 	 * attribute.
@@ -71,13 +44,6 @@
 		return element;
 	}
 
-	/*
-	 * public static HTMLElement append(watij.elements.HtmlElement element, String attrName, String
-	 * value) { try { HTMLElement realElement = getInternalBrowserElement(element); return
-	 * append(realElement, attrName, value); } catch (Exception e) { e.printStackTrace(); } return
-	 * null; }
-	 */
-
 	/**
 	 * Return true iff the node contains the injected attribute.
 	 * 
@@ -140,18 +106,12 @@
 	public static void removeInjectedAttributes(HTMLElement element, String attrName) {
 		try {
 			element.removeAttribute(attrName);
-			// check if the attr was appended to the src value
-			// String srcAttrValue = element.getAttribute(""src"");
-			//
-			// if(srcAttrValue.matches("".*"" + attrName + ""=.*""))
-			// {
-			// int index = srcAttrValue.indexOf(attrName);
-			// srcAttrValue = srcAttrValue.substring(0, index-1);
-			// element.setAttribute(""src"", srcAttrValue);
-			// }
-
-		} catch (Exception exc) {
-			System.out.println(""Element was removed from DOM"");
+		} catch (DOMException exc) {
+			LOG.warn(""Element {} was removed from DOM"", element.getId());
 		}
 	}
+
+	private AttributeInjector() {
+	}
+
 }
"
c41bb14243d0c7d7d665966abfd352ff3e0baa13,Alex Nederlof,BeanToReadableMap.java,MODIFY,"toMap -> [Object o, Filter filters] | [Object o]","diff --git a/src/main/java/com/crawljax/plugins/crawloverview/BeanToReadableMap.java b/src/main/java/com/crawljax/plugins/crawloverview/BeanToReadableMap.java
index d28de3d..6242e3c 100644
--- a/src/main/java/com/crawljax/plugins/crawloverview/BeanToReadableMap.java
+++ b/src/main/java/com/crawljax/plugins/crawloverview/BeanToReadableMap.java
@@ -6,11 +6,8 @@
 import java.util.Collection;
 import java.util.Map.Entry;
 
-import org.apache.commons.lang.StringEscapeUtils;
 import org.apache.commons.lang3.tuple.ImmutablePair;
-import org.apache.velocity.app.event.implement.EscapeHtmlReference;
 
-import com.crawljax.core.configuration.CrawlElement;
 import com.google.common.collect.ImmutableMap;
 import com.google.common.collect.ImmutableMap.Builder;
 
@@ -18,7 +15,7 @@
  * Parses a Java bean to a map containing the getter name as the key and the field value as the
  * value. All instances of {@link Collection} are converted to html lists.
  */
-public class BeanToReadableMap {
+class BeanToReadableMap {
 
 	public static interface Filter {
 
"
e11726168366287efdda108ba886cd69f6e58c36,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index b88f139..bfe18b8 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -22,6 +22,7 @@
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateFlowGraph;
 import com.crawljax.oraclecomparator.StateComparator;
+import com.google.common.collect.ImmutableList;
 
 /**
  * The Crawljax Controller class is the core of Crawljax.
@@ -49,7 +50,7 @@
 
 	private final CrawljaxConfigurationReader configurationReader;
 
-	private final List<Invariant> invariantList;
+	private final ImmutableList<Invariant> invariantList;
 
 	/**
 	 * Central thread starting engine.
@@ -102,13 +103,13 @@
 			        .runProxyServerPlugins(configurationReader.getProxyConfiguration());
 		}
 
-		LOGGER.info(""Embedded browser implementation: "" + configurationReader.getBrowser());
+		LOGGER.info(""Embedded browser implementation: {}"", configurationReader.getBrowser());
 
-		LOGGER.info(""Number of threads: ""
-		        + configurationReader.getThreadConfigurationReader().getNumberThreads());
+		LOGGER.info(""Number of threads: {}"", configurationReader.getThreadConfigurationReader()
+		        .getNumberThreads());
 
-		LOGGER.info(""Crawl depth: ""
-		        + configurationReader.getCrawlSpecificationReader().getDepth());
+		LOGGER.info(""Crawl depth: {}"", configurationReader.getCrawlSpecificationReader()
+		        .getDepth());
 		LOGGER.info(""Crawljax initialized!"");
 
 		return new CrawlerExecutor(configurationReader.getThreadConfigurationReader()
@@ -128,8 +129,8 @@
 
 		startCrawl = System.currentTimeMillis();
 
-		LOGGER.info(""Start crawling with ""
-		        + configurationReader.getAllIncludedCrawlElements().size() + "" crawl elements"");
+		LOGGER.info(""Start crawling with {} crawl elements"", configurationReader
+		        .getAllIncludedCrawlElements().size());
 
 		// Create the initailCrawler
 		initialCrawler = new InitialCrawler(this);
@@ -354,7 +355,7 @@
 	/**
 	 * @return the invariantList
 	 */
-	public final List<Invariant> getInvariantList() {
+	public final ImmutableList<Invariant> getInvariantList() {
 		return invariantList;
 	}
 
"
3c78f4b7fd09c2f7f843aaf7ea40cdd524e68c8f,Alex Nederlof,BeanToReadableMap.java,MODIFY,"toMap -> [Object o, Filter filters] | [Object o]","diff --git a/src/main/java/com/crawljax/plugins/crawloverview/BeanToReadableMap.java b/src/main/java/com/crawljax/plugins/crawloverview/BeanToReadableMap.java
index 6242e3c..89f5311 100644
--- a/src/main/java/com/crawljax/plugins/crawloverview/BeanToReadableMap.java
+++ b/src/main/java/com/crawljax/plugins/crawloverview/BeanToReadableMap.java
@@ -9,7 +9,7 @@
 import org.apache.commons.lang3.tuple.ImmutablePair;
 
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.ImmutableMap.Builder;
+import com.google.common.collect.ImmutableSortedMap;
 
 /**
  * Parses a Java bean to a map containing the getter name as the key and the field value as the
@@ -34,8 +34,8 @@
 		return toMap(o, EMPTY_FILTERS);
 	}
 
-	public static ImmutableMap<String, String> toMap(Object o, Filter... filters) {
-		Builder<String, String> builder = ImmutableMap.builder();
+	public static ImmutableSortedMap<String, String> toMap(Object o, Filter... filters) {
+		ImmutableSortedMap.Builder<String, String> builder = ImmutableSortedMap.naturalOrder();
 		for (Method method : o.getClass().getMethods()) {
 			if (isGetter(method)) {
 				builder.put(addmethodToMap(o, method, filters));
"
97700f4d6bf9b52e3303dc6bfc3f02b9ee417f50,Alex Nederlof,BeanToReadableMap.java,MODIFY,"toMap -> [Object o, Filter filters] | [Object o]","diff --git a/src/main/java/com/crawljax/plugins/crawloverview/BeanToReadableMap.java b/src/main/java/com/crawljax/plugins/crawloverview/BeanToReadableMap.java
index 89f5311..106685a 100644
--- a/src/main/java/com/crawljax/plugins/crawloverview/BeanToReadableMap.java
+++ b/src/main/java/com/crawljax/plugins/crawloverview/BeanToReadableMap.java
@@ -9,42 +9,34 @@
 import org.apache.commons.lang3.tuple.ImmutablePair;
 
 import com.google.common.collect.ImmutableMap;
-import com.google.common.collect.ImmutableSortedMap;
+import com.google.common.collect.ImmutableMap.Builder;
 
 /**
  * Parses a Java bean to a map containing the getter name as the key and the field value as the
  * value. All instances of {@link Collection} are converted to html lists.
+ * <p>
+ * The getter name is parsed from Camel case to a readable format. Both keys and values are HTML
+ * escaped for safety.
+ * </p>
  */
 class BeanToReadableMap {
 
-	public static interface Filter {
-
-		Entry<String, String> filter(String key, String value);
-
-	}
-
 	private static final String CAMEL_REGEX = String.format(""%s|%s|%s"",
 	        ""(?<=[A-Z])(?=[A-Z][a-z])"",
 	        ""(?<=[^A-Z])(?=[A-Z])"",
 	        ""(?<=[A-Za-z])(?=[^A-Za-z])"");
 
-	private static final Filter[] EMPTY_FILTERS = new Filter[] {};
-
 	public static ImmutableMap<String, String> toMap(Object o) {
-		return toMap(o, EMPTY_FILTERS);
-	}
-
-	public static ImmutableSortedMap<String, String> toMap(Object o, Filter... filters) {
-		ImmutableSortedMap.Builder<String, String> builder = ImmutableSortedMap.naturalOrder();
+		Builder<String, String> builder = ImmutableMap.builder();
 		for (Method method : o.getClass().getMethods()) {
 			if (isGetter(method)) {
-				builder.put(addmethodToMap(o, method, filters));
+				builder.put(addMethodToMap(o, method));
 			}
 		}
 		return builder.build();
 	}
 
-	private static Entry<String, String> addmethodToMap(Object o, Method method, Filter[] filters) {
+	private static Entry<String, String> addMethodToMap(Object o, Method method) {
 		try {
 			Object[] noArgs = null;
 			Object result = method.invoke(o, noArgs);
"
8a20f558eae445e2c8fff909a1f5fa8250c1cacc,Ali Mesbah,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index b88f139..bfe18b8 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -22,6 +22,7 @@
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateFlowGraph;
 import com.crawljax.oraclecomparator.StateComparator;
+import com.google.common.collect.ImmutableList;
 
 /**
  * The Crawljax Controller class is the core of Crawljax.
@@ -49,7 +50,7 @@
 
 	private final CrawljaxConfigurationReader configurationReader;
 
-	private final List<Invariant> invariantList;
+	private final ImmutableList<Invariant> invariantList;
 
 	/**
 	 * Central thread starting engine.
@@ -102,13 +103,13 @@
 			        .runProxyServerPlugins(configurationReader.getProxyConfiguration());
 		}
 
-		LOGGER.info(""Embedded browser implementation: "" + configurationReader.getBrowser());
+		LOGGER.info(""Embedded browser implementation: {}"", configurationReader.getBrowser());
 
-		LOGGER.info(""Number of threads: ""
-		        + configurationReader.getThreadConfigurationReader().getNumberThreads());
+		LOGGER.info(""Number of threads: {}"", configurationReader.getThreadConfigurationReader()
+		        .getNumberThreads());
 
-		LOGGER.info(""Crawl depth: ""
-		        + configurationReader.getCrawlSpecificationReader().getDepth());
+		LOGGER.info(""Crawl depth: {}"", configurationReader.getCrawlSpecificationReader()
+		        .getDepth());
 		LOGGER.info(""Crawljax initialized!"");
 
 		return new CrawlerExecutor(configurationReader.getThreadConfigurationReader()
@@ -128,8 +129,8 @@
 
 		startCrawl = System.currentTimeMillis();
 
-		LOGGER.info(""Start crawling with ""
-		        + configurationReader.getAllIncludedCrawlElements().size() + "" crawl elements"");
+		LOGGER.info(""Start crawling with {} crawl elements"", configurationReader
+		        .getAllIncludedCrawlElements().size());
 
 		// Create the initailCrawler
 		initialCrawler = new InitialCrawler(this);
@@ -354,7 +355,7 @@
 	/**
 	 * @return the invariantList
 	 */
-	public final List<Invariant> getInvariantList() {
+	public final ImmutableList<Invariant> getInvariantList() {
 		return invariantList;
 	}
 
"
8a20f558eae445e2c8fff909a1f5fa8250c1cacc,Ali Mesbah,AttributeInjector.java,MODIFY,"removeInjectedAttributes -> [HTMLElement element, String attrName] | [Vector injectedElements, String attrName]","diff --git a/core/src/main/java/com/crawljax/util/AttributeInjector.java b/core/src/main/java/com/crawljax/util/AttributeInjector.java
index 4e76dd0..8bc9fc6 100644
--- a/core/src/main/java/com/crawljax/util/AttributeInjector.java
+++ b/core/src/main/java/com/crawljax/util/AttributeInjector.java
@@ -3,6 +3,9 @@
 import java.util.Vector;
 
 import org.apache.commons.lang.StringUtils;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.w3c.dom.DOMException;
 import org.w3c.dom.NamedNodeMap;
 import org.w3c.dom.Node;
 import org.w3c.dom.html.HTMLElement;
@@ -14,38 +17,8 @@
  */
 public final class AttributeInjector {
 
-	private AttributeInjector() {
+	private static final Logger LOG = LoggerFactory.getLogger(AttributeInjector.class);
 
-	}
-
-	/**
-	 * Inject a unique attribute into element.
-	 * 
-	 * @param element
-	 * @param isActive
-	 */
-	/*
-	 * public static HTMLElement injectUniqueAttributeInNode(
-	 * com.jniwrapper.win32.ie.dom.HTMLElement element, String attrName, String value, boolean
-	 * injectParents) { if (element == null) return null; element.setAttribute(attrName, value); if
-	 * (injectParents) return injectUniqueAttributeInNode(element.getOffsetParent(), attrName,
-	 * value, injectParents); return element; }
-	 */
-
-	/*
-	 * public static HTMLElement injectUniqueAttributeInNode(watij.elements.HtmlElement element,
-	 * String attrName, String value, boolean injectParents) { if (element == null) return null; try
-	 * { // use reflection to get the 'real' DOM element HTMLElement realElement =
-	 * getInternalBrowserElement(element); return injectUniqueAttributeInNode(realElement, attrName,
-	 * value, injectParents); } catch (Exception e) { e.printStackTrace(); } return null; }
-	 */
-
-	/*
-	 * public static HTMLElement getInternalBrowserElement(watij.elements.HtmlElement element)
-	 * throws Exception { IEHtmlElement ieHtml = (IEHtmlElement) element; Method ieMethod =
-	 * ieHtml.getClass().getDeclaredMethod(""htmlElement""); ieMethod.setAccessible(true); HTMLElement
-	 * HTMLe = (HTMLElement) ieMethod.invoke(ieHtml); return HTMLe; }
-	 */
 	/**
 	 * Find the corresponding 'real' DOM element in the browser for element and inject the unique
 	 * attribute.
@@ -71,13 +44,6 @@
 		return element;
 	}
 
-	/*
-	 * public static HTMLElement append(watij.elements.HtmlElement element, String attrName, String
-	 * value) { try { HTMLElement realElement = getInternalBrowserElement(element); return
-	 * append(realElement, attrName, value); } catch (Exception e) { e.printStackTrace(); } return
-	 * null; }
-	 */
-
 	/**
 	 * Return true iff the node contains the injected attribute.
 	 * 
@@ -140,18 +106,12 @@
 	public static void removeInjectedAttributes(HTMLElement element, String attrName) {
 		try {
 			element.removeAttribute(attrName);
-			// check if the attr was appended to the src value
-			// String srcAttrValue = element.getAttribute(""src"");
-			//
-			// if(srcAttrValue.matches("".*"" + attrName + ""=.*""))
-			// {
-			// int index = srcAttrValue.indexOf(attrName);
-			// srcAttrValue = srcAttrValue.substring(0, index-1);
-			// element.setAttribute(""src"", srcAttrValue);
-			// }
-
-		} catch (Exception exc) {
-			System.out.println(""Element was removed from DOM"");
+		} catch (DOMException exc) {
+			LOG.warn(""Element {} was removed from DOM"", element.getId());
 		}
 	}
+
+	private AttributeInjector() {
+	}
+
 }
"
517c7f33c199c92df142cf45518d4f1cef55a223,Alex Nederlof,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 1a759f0..3a06c39 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -153,19 +153,6 @@
 	}
 
 	/**
-	 * Crawljax will the HTML elements while crawling if and only if all the specified conditions
-	 * are satisfied. IMPORTANT: only works with click()!!! For example:
-	 * when(onContactPageCondition) will only click the HTML element if it is on the contact page
-	 * 
-	 * @param conditions
-	 *            the condition to be met.
-	 * @return this CrawlActions
-	 */
-	public CrawlActions when(Condition... conditions) {
-		return crawlActions.when(conditions);
-	}
-
-	/**
 	 * @return the initial url of the site to crawl
 	 */
 	protected String getUrl() {
"
d0d9fdcc6515e2159cb3139d313a0d6150704b87,Alex Nederlof,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 3a06c39..bd571d4 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -1,6 +1,5 @@
 package com.crawljax.core.configuration;
 
-import java.util.ArrayList;
 import java.util.List;
 
 import com.crawljax.condition.Condition;
@@ -11,6 +10,8 @@
 import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.oraclecomparator.Comparator;
 import com.crawljax.oraclecomparator.OracleComparator;
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.Lists;
 
 /**
  * Specifies the crawl options for a single crawl session. The user must specify which HTML elements
@@ -53,7 +54,12 @@
 
 	private final String url;
 
-	private List<EventType> crawlEvents = new ArrayList<EventType>();
+	private final List<EventType> crawlEvents = Lists.newLinkedList();
+	private final List<String> ignoredFrameIdentifiers = Lists.newLinkedList();
+	private final List<Invariant> invariants = Lists.newLinkedList();
+	private final List<OracleComparator> oracleComparators = Lists.newLinkedList();
+	private final List<WaitCondition> waitConditions = Lists.newLinkedList();
+	private final List<CrawlCondition> crawlConditions = Lists.newLinkedList();
 
 	private int depth = 2;
 	private int maximumStates = 0;
@@ -66,13 +72,8 @@
 	private InputSpecification inputSpecification = new InputSpecification();
 
 	private boolean testInvariantsWhileCrawling = true;
-	private final List<Invariant> invariants = new ArrayList<Invariant>();
 
-	private final List<OracleComparator> oracleComparators = new ArrayList<OracleComparator>();
-	private final List<WaitCondition> waitConditions = new ArrayList<WaitCondition>();
-	private final List<CrawlCondition> crawlConditions = new ArrayList<CrawlCondition>();
 	private boolean clicklOnce = true;
-	private final List<String> ignoredFrameIdentifiers = new ArrayList<String>();
 	private boolean disableCrawlFrames = false;
 
 	/**
@@ -260,8 +261,8 @@
 	/**
 	 * @return the events that should be fired (e.g. onclick)
 	 */
-	protected List<EventType> getCrawlEvents() {
-		return crawlEvents;
+	protected ImmutableList<EventType> getCrawlEvents() {
+		return ImmutableList.copyOf(crawlEvents);
 	}
 
 	/**
@@ -289,8 +290,8 @@
 	/**
 	 * @return the oracleComparators
 	 */
-	protected List<OracleComparator> getOracleComparators() {
-		return oracleComparators;
+	protected ImmutableList<OracleComparator> getOracleComparators() {
+		return ImmutableList.copyOf(oracleComparators);
 	}
 
 	/**
@@ -323,8 +324,8 @@
 	/**
 	 * @return the invariants
 	 */
-	protected List<Invariant> getInvariants() {
-		return invariants;
+	protected ImmutableList<Invariant> getInvariants() {
+		return ImmutableList.copyOf(invariants);
 	}
 
 	/**
@@ -367,8 +368,8 @@
 	/**
 	 * @return the waitConditions
 	 */
-	protected List<WaitCondition> getWaitConditions() {
-		return waitConditions;
+	protected ImmutableList<WaitCondition> getWaitConditions() {
+		return ImmutableList.copyOf(waitConditions);
 	}
 
 	/**
@@ -398,8 +399,8 @@
 	/**
 	 * @return the crawlConditions
 	 */
-	protected List<CrawlCondition> getCrawlConditions() {
-		return crawlConditions;
+	protected ImmutableList<CrawlCondition> getCrawlConditions() {
+		return ImmutableList.copyOf(crawlConditions);
 	}
 
 	/**
@@ -444,8 +445,8 @@
 	 * @param crawlEvents
 	 *            the crawlEvents to set
 	 */
-	public void setCrawlEvents(List<EventType> crawlEvents) {
-		this.crawlEvents = crawlEvents;
+	public void addCrawlEvents(List<EventType> crawlEvents) {
+		this.crawlEvents.addAll(crawlEvents);
 	}
 
 	/**
@@ -459,8 +460,8 @@
 	/**
 	 * @return the list of ignored frames
 	 */
-	protected List<String> ignoredFrameIdentifiers() {
-		return ignoredFrameIdentifiers;
+	protected ImmutableList<String> ignoredFrameIdentifiers() {
+		return ImmutableList.copyOf(ignoredFrameIdentifiers);
 	}
 
 	/**
"
d0d9fdcc6515e2159cb3139d313a0d6150704b87,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index e7c8ebf..40820d7 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -9,6 +9,9 @@
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.util.Helper;
+import com.google.common.base.Preconditions;
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableList.Builder;
 
 /**
  * Specifies the settings Crawljax. The methods in this class fall into two categories:Oz
@@ -65,6 +68,7 @@
 	 *            Which contains all the crawl settings.
 	 */
 	public void setCrawlSpecification(CrawlSpecification crawlSpecification) {
+		Preconditions.checkNotNull(crawlSpecification);
 		this.crawlSpecification = crawlSpecification;
 	}
 
@@ -72,11 +76,7 @@
 	 * @return The inputSpecification which contains information the data for setting input fields.
 	 */
 	protected InputSpecification getInputSpecification() {
-		if (crawlSpecification != null) {
-			return crawlSpecification.getInputSpecification();
-		} else {
-			return null;
-		}
+		return crawlSpecification.getInputSpecification();
 	}
 
 	/**
@@ -114,40 +114,32 @@
 	/**
 	 * @return All the included crawlTags.
 	 */
-	protected List<CrawlElement> getAllIncludedCrawlElements() {
+	protected ImmutableList<CrawlElement> getAllIncludedCrawlElements() {
 		// first add elements for forms so that form action crawlTags are only
-		// clicked
-		// and not by another random crawlTag
-		List<CrawlElement> crawlTags = getInputSpecification().getCrawlElements();
-		if (getCrawlSpecification() != null) {
-
-			for (CrawlElement crawlTag : getCrawlSpecification().crawlActions()
-			        .getCrawlElements()) {
-				crawlTags.add(crawlTag);
-			}
-		}
-		return crawlTags;
+		// clicked and not by another random crawlTag
+		return ImmutableList.<CrawlElement> builder()
+		        .addAll(getInputSpecification().getCrawlElements())
+		        .addAll(crawlSpecification.crawlActions().getCrawlElements())
+		        .build();
 	}
 
 	/**
 	 * @return All the added crawlTags.
 	 */
 	protected List<CrawlElement> getAllCrawlElements() {
-		List<CrawlElement> crawlTags = getAllIncludedCrawlElements();
-		if (getCrawlSpecification() != null) {
-			for (CrawlElement crawlTag : getCrawlSpecification().crawlActions()
-			        .getCrawlElementsExcluded()) {
-				crawlTags.add(crawlTag);
-			}
-		}
-		return crawlTags;
+		return ImmutableList.<CrawlElement> builder()
+		        .addAll(getInputSpecification().getCrawlElements())
+		        .addAll(crawlSpecification.crawlActions().getCrawlElements())
+		        .addAll(getCrawlSpecification().crawlActions()
+		                .getCrawlElementsExcluded())
+		        .build();
 	}
 
 	/**
 	 * @return The eventableConditions.
 	 */
 	protected List<EventableCondition> getEventableConditions() {
-		List<EventableCondition> eventableConditions = new ArrayList<EventableCondition>();
+		Builder<EventableCondition> eventableConditions = ImmutableList.builder();
 		for (CrawlElement crawlTag : getAllCrawlElements()) {
 			EventableCondition eventableCondition = crawlTag.getEventableCondition();
 			if (eventableCondition != null) {
@@ -155,7 +147,7 @@
 			}
 		}
 
-		return eventableConditions;
+		return eventableConditions.build();
 	}
 
 	/**
"
4401355c180dddf7e6824f48c1dd59b3c56c81f9,Alex Nederlof,CandidateElementExtractor.java,MODIFY,"extractElements -> [Document dom, List crawlTagElements, List crawlExcludeTagElements, boolean clickOnce, List results, String relatedFrame] | [Document dom, List crawlTagElements, List crawlExcludeTagElements, boolean clickOnce, Builder results, String relatedFrame]","diff --git a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
index d218d0a..6f42e00 100644
--- a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
+++ b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
@@ -2,6 +2,7 @@
 
 import java.io.IOException;
 import java.util.ArrayList;
+import java.util.Collections;
 import java.util.List;
 import java.util.Set;
 import java.util.regex.Matcher;
@@ -26,18 +27,16 @@
 import com.crawljax.forms.FormHandler;
 import com.crawljax.util.Helper;
 import com.crawljax.util.XPathHelper;
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableList.Builder;
 
 /**
  * This class extracts candidate elements from the DOM tree, based on the tags provided by the user.
  * Elements can also be excluded.
- * 
- * @author mesbah
- * @version $Id$
  */
 public class CandidateElementExtractor {
 
-	private static final Logger LOGGER = LoggerFactory.getLogger(CandidateElementExtractor.class
-	        .getName());
+	private static final Logger LOG = LoggerFactory.getLogger(CandidateElementExtractor.class);
 
 	private final ExtractorManager checkedElements;
 	private final EmbeddedBrowser browser;
@@ -82,17 +81,17 @@
 	 * @throws CrawljaxException
 	 *             if the method fails.
 	 */
-	public List<CandidateElement> extract(List<TagElement> crawlTagElements,
+	public ImmutableList<CandidateElement> extract(List<TagElement> crawlTagElements,
 	        List<TagElement> crawlExcludeTagElements, boolean clickOnce, StateVertex currentState)
 	        throws CrawljaxException {
-		List<CandidateElement> results = new ArrayList<CandidateElement>();
+		Builder<CandidateElement> results = ImmutableList.builder();
 
 		if (!checkedElements.checkCrawlCondition(browser)) {
-			LOGGER.info(""State "" + currentState.getName()
+			LOG.info(""State "" + currentState.getName()
 			        + "" dit not satisfy the CrawlConditions."");
-			return results;
+			return results.build();
 		}
-		LOGGER.info(""Looking in state: "" + currentState.getName()
+		LOG.info(""Looking in state: "" + currentState.getName()
 		        + "" for candidate elements with "");
 
 		try {
@@ -100,46 +99,26 @@
 			extractElements(dom, crawlTagElements, crawlExcludeTagElements, clickOnce, results,
 			        """");
 		} catch (SAXException e) {
-			LOGGER.error(e.getMessage(), e);
+			LOG.error(e.getMessage(), e);
 			throw new CrawljaxException(e.getMessage(), e);
 		} catch (IOException e) {
-			LOGGER.error(e.getMessage(), e);
+			LOG.error(e.getMessage(), e);
 			throw new CrawljaxException(e.getMessage(), e);
 		}
-
-		LOGGER.info(""Found "" + results.size() + "" new candidate elements to analyze!"");
-		return results;
+		ImmutableList<CandidateElement> found = results.build();
+		LOG.info(""Found "" + found.size() + "" new candidate elements to analyze!"");
+		return found;
 	}
 
 	private void extractElements(Document dom, List<TagElement> crawlTagElements,
 	        List<TagElement> crawlExcludeTagElements, boolean clickOnce,
-	        List<CandidateElement> results, String relatedFrame) {
+	        Builder<CandidateElement> results, String relatedFrame) {
 
 		for (TagElement tag : crawlTagElements) {
-			LOGGER.info(""TAG: "" + tag.toString());
+			LOG.info(""TAG: "" + tag.toString());
 
-			List<Element> foundElements;
-
-			try {
-				foundElements =
-				        getNodeListForTagElement(dom, tag,
-				                checkedElements.getEventableConditionChecker(),
-				                crawlExcludeTagElements);
-			} catch (XPathExpressionException e) {
-				LOGGER.error(""Catched XPathExpression during NodeList For Tag Element retrieval"",
-				        e);
-				return;
-			} catch (SAXException e) {
-				LOGGER.error(""Catched SAXException during NodeList For Tag Element retrieval"", e);
-				return;
-			} catch (IOException e) {
-				LOGGER.error(""Catched IOException during NodeList For Tag Element retrieval"", e);
-				return;
-			} catch (CrawljaxException e) {
-				LOGGER.error(
-				        ""Catched CrawljaxException during NodeList For Tag Element retrieval"", e);
-				return;
-			}
+			List<Element> foundElements =
+			        getElementsFromNodelist(dom, crawlExcludeTagElements, tag);
 
 			getFramesCandidates(dom, crawlTagElements, crawlExcludeTagElements, clickOnce,
 			        results, relatedFrame);
@@ -148,51 +127,79 @@
 			        results, relatedFrame);
 
 			for (Element sourceElement : foundElements) {
-				EventableCondition eventableCondition =
-				        checkedElements.getEventableConditionChecker().getEventableCondition(
-				                tag.getId());
-				String xpath = XPathHelper.getXPathExpression(sourceElement);
-				// get multiple candidate elements when there are input
-				// fields connected to this element
+				evaluateElement(clickOnce, results, relatedFrame, tag, sourceElement);
+			}
+		}
+	}
 
-				List<CandidateElement> candidateElements = new ArrayList<CandidateElement>();
-				if (eventableCondition != null
-				        && eventableCondition.getLinkedInputFields() != null
-				        && eventableCondition.getLinkedInputFields().size() > 0) {
-					// add multiple candidate elements, for every input
-					// value combination
-					candidateElements =
-					        formHandler.getCandidateElementsForInputs(sourceElement,
-					                eventableCondition);
-				} else {
-					// just add default element
-					candidateElements.add(new CandidateElement(sourceElement, new Identification(
-					        Identification.How.xpath, xpath), relatedFrame));
+	private List<Element> getElementsFromNodelist(Document dom,
+	        List<TagElement> crawlExcludeTagElements, TagElement tag) {
+		try {
+			return getNodeListForTagElement(dom, tag,
+			        checkedElements.getEventableConditionChecker(),
+			        crawlExcludeTagElements);
+		} catch (XPathExpressionException e) {
+			LOG.error(""Catched XPathExpression during NodeList For Tag Element retrieval"",
+			        e);
+			return Collections.emptyList();
+		} catch (SAXException e) {
+			LOG.error(""Catched SAXException during NodeList For Tag Element retrieval"", e);
+			return Collections.emptyList();
+		} catch (IOException e) {
+			LOG.error(""Catched IOException during NodeList For Tag Element retrieval"", e);
+			return Collections.emptyList();
+		} catch (CrawljaxException e) {
+			LOG.error(
+			        ""Catched CrawljaxException during NodeList For Tag Element retrieval"", e);
+			return Collections.emptyList();
+		}
+	}
+
+	private void evaluateElement(boolean clickOnce, Builder<CandidateElement> results,
+	        String relatedFrame, TagElement tag, Element sourceElement) {
+		EventableCondition eventableCondition =
+		        checkedElements.getEventableConditionChecker().getEventableCondition(
+		                tag.getId());
+		String xpath = XPathHelper.getXPathExpression(sourceElement);
+		// get multiple candidate elements when there are input
+		// fields connected to this element
+
+		List<CandidateElement> candidateElements = new ArrayList<CandidateElement>();
+		if (eventableCondition != null
+		        && eventableCondition.getLinkedInputFields() != null
+		        && eventableCondition.getLinkedInputFields().size() > 0) {
+			// add multiple candidate elements, for every input
+			// value combination
+			candidateElements =
+			        formHandler.getCandidateElementsForInputs(sourceElement,
+			                eventableCondition);
+		} else {
+			// just add default element
+			candidateElements.add(new CandidateElement(sourceElement, new Identification(
+			        Identification.How.xpath, xpath), relatedFrame));
+		}
+
+		for (CandidateElement candidateElement : candidateElements) {
+			if (!clickOnce || checkedElements.markChecked(candidateElement)) {
+				LOG.info(""Found new candidate element: ""
+				        + candidateElement.getUniqueString());
+
+				if (eventableCondition != null) {
+					candidateElement.setEventableCondition(eventableCondition);
 				}
-
-				for (CandidateElement candidateElement : candidateElements) {
-					if (!clickOnce || checkedElements.markChecked(candidateElement)) {
-						LOGGER.info(""Found new candidate element: ""
-						        + candidateElement.getUniqueString());
-
-						if (eventableCondition != null) {
-							candidateElement.setEventableCondition(eventableCondition);
-						}
-						results.add(candidateElement);
-						/**
-						 * TODO add element to checkedElements after the event is fired! also add
-						 * string without 'atusa' attribute to make sure an form action element is
-						 * only clicked for its defined values
-						 */
-					}
-				}
+				results.add(candidateElement);
+				/**
+				 * TODO add element to checkedElements after the event is fired! also add string
+				 * without 'atusa' attribute to make sure an form action element is only clicked for
+				 * its defined values
+				 */
 			}
 		}
 	}
 
 	private void getIFramesCandidates(Document dom, List<TagElement> crawlTagElements,
 	        List<TagElement> crawlExcludeTagElements, boolean clickOnce,
-	        List<CandidateElement> results, String relatedFrame) {
+	        Builder<CandidateElement> results, String relatedFrame) {
 
 		NodeList frameNodes = dom.getElementsByTagName(""IFRAME"");
 
@@ -214,7 +221,7 @@
 			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
 				frameIdentification += nameId;
 
-				LOGGER.debug(""iframe Identification: "" + frameIdentification);
+				LOG.debug(""iframe Identification: "" + frameIdentification);
 
 				try {
 					Document frameDom =
@@ -222,10 +229,10 @@
 					extractElements(frameDom, crawlTagElements, crawlExcludeTagElements,
 					        clickOnce, results, frameIdentification);
 				} catch (SAXException e) {
-					LOGGER.info(""Got exception while inspecting an iframe:"" + frameIdentification
+					LOG.info(""Got exception while inspecting an iframe:"" + frameIdentification
 					        + "" continuing..."", e);
 				} catch (IOException e) {
-					LOGGER.info(""Got exception while inspecting an iframe:"" + frameIdentification
+					LOG.info(""Got exception while inspecting an iframe:"" + frameIdentification
 					        + "" continuing..."", e);
 				}
 			}
@@ -235,7 +242,7 @@
 	// adds support for FRAME tags
 	private void getFramesCandidates(Document dom, List<TagElement> crawlTagElements,
 	        List<TagElement> crawlExcludeTagElements, boolean clickOnce,
-	        List<CandidateElement> results, String relatedFrame) {
+	        Builder<CandidateElement> results, String relatedFrame) {
 
 		NodeList frameNodes = dom.getElementsByTagName(""FRAME"");
 
@@ -257,7 +264,7 @@
 			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
 				frameIdentification += nameId;
 
-				LOGGER.debug(""frame Identification: "" + frameIdentification);
+				LOG.debug(""frame Identification: "" + frameIdentification);
 
 				try {
 					Document frameDom =
@@ -265,10 +272,10 @@
 					extractElements(frameDom, crawlTagElements, crawlExcludeTagElements,
 					        clickOnce, results, frameIdentification);
 				} catch (SAXException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
+					LOG.info(""Got exception while inspecting a frame:"" + frameIdentification
 					        + "" continuing..."", e);
 				} catch (IOException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
+					LOG.info(""Got exception while inspecting a frame:"" + frameIdentification
 					        + "" continuing..."", e);
 				}
 			}
@@ -336,7 +343,7 @@
 					String href = element.getAttribute(""href"");
 					boolean isExternal = Helper.isLinkExternal(browser.getCurrentUrl(), href);
 					boolean isEmail = isEmail(href);
-					LOGGER.debug(""HREF: "" + href + ""isExternal= "" + isExternal);
+					LOG.debug(""HREF: "" + href + ""isExternal= "" + isExternal);
 
 					if (!(isExternal || isEmail || isPDForPS(href))) {
 						result.add(element);
@@ -430,12 +437,12 @@
 				}
 
 				if (matchesXPath) {
-					LOGGER.info(""Excluded element because of xpath: "" + element);
+					LOG.info(""Excluded element because of xpath: "" + element);
 					return true;
 				}
 				if (!filterElement(tag.getAttributes(), element)
 				        && tag.getAttributes().size() > 0) {
-					LOGGER.info(""Excluded element because of attributes: "" + element);
+					LOG.info(""Excluded element because of attributes: "" + element);
 					return true;
 				}
 			}
@@ -461,7 +468,7 @@
 		NodeList nodes = XPathHelper.evaluateXpathExpression(dom, xpath);
 
 		if (nodes.getLength() > 0) {
-			LOGGER.debug(""Element: "" + Helper.getAllElementAttributes(element) + "" is invisible!"");
+			LOG.debug(""Element: "" + Helper.getAllElementAttributes(element) + "" is invisible!"");
 
 			return false;
 		}
@@ -478,7 +485,7 @@
 			return false;
 		}
 		for (TagAttribute attr : attributes) {
-			LOGGER.debug(""Checking element "" + Helper.getElementString(element)
+			LOG.debug(""Checking element "" + Helper.getElementString(element)
 			        + ""AttributeName: "" + attr.getName() + "" value: "" + attr.getValue());
 
 			if (attr.matchesValue(element.getAttribute(attr.getName()))) {
"
4401355c180dddf7e6824f48c1dd59b3c56c81f9,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 40820d7..0d95586 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -26,8 +26,6 @@
  * EXAMPLE: CrawljaxConfiguration crawljaxConfig = new CrawljaxConfiguration(); CrawlSpecification
  * crawler = new CrawlSpecification(""http://www.google.com""); crawler.click(""a"");
  * crawljaxConfig.setCrawlSpecification(crawler);
- * 
- * @version $Id$
  */
 public final class CrawljaxConfiguration {
 
@@ -138,7 +136,7 @@
 	/**
 	 * @return The eventableConditions.
 	 */
-	protected List<EventableCondition> getEventableConditions() {
+	protected ImmutableList<EventableCondition> getEventableConditions() {
 		Builder<EventableCondition> eventableConditions = ImmutableList.builder();
 		for (CrawlElement crawlTag : getAllCrawlElements()) {
 			EventableCondition eventableCondition = crawlTag.getEventableCondition();
"
03a222614c956a580c05ac10e4753d44eab3a4bb,Ali Mesbah,CrawlSpecification.java,MODIFY,"addOracleComparator -> [String id, Comparator oracleComparator, Condition preConditions] | [String id, Comparator oracleComparator]","diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 1a759f0..bd571d4 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -1,6 +1,5 @@
 package com.crawljax.core.configuration;
 
-import java.util.ArrayList;
 import java.util.List;
 
 import com.crawljax.condition.Condition;
@@ -11,6 +10,8 @@
 import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.oraclecomparator.Comparator;
 import com.crawljax.oraclecomparator.OracleComparator;
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.Lists;
 
 /**
  * Specifies the crawl options for a single crawl session. The user must specify which HTML elements
@@ -53,7 +54,12 @@
 
 	private final String url;
 
-	private List<EventType> crawlEvents = new ArrayList<EventType>();
+	private final List<EventType> crawlEvents = Lists.newLinkedList();
+	private final List<String> ignoredFrameIdentifiers = Lists.newLinkedList();
+	private final List<Invariant> invariants = Lists.newLinkedList();
+	private final List<OracleComparator> oracleComparators = Lists.newLinkedList();
+	private final List<WaitCondition> waitConditions = Lists.newLinkedList();
+	private final List<CrawlCondition> crawlConditions = Lists.newLinkedList();
 
 	private int depth = 2;
 	private int maximumStates = 0;
@@ -66,13 +72,8 @@
 	private InputSpecification inputSpecification = new InputSpecification();
 
 	private boolean testInvariantsWhileCrawling = true;
-	private final List<Invariant> invariants = new ArrayList<Invariant>();
 
-	private final List<OracleComparator> oracleComparators = new ArrayList<OracleComparator>();
-	private final List<WaitCondition> waitConditions = new ArrayList<WaitCondition>();
-	private final List<CrawlCondition> crawlConditions = new ArrayList<CrawlCondition>();
 	private boolean clicklOnce = true;
-	private final List<String> ignoredFrameIdentifiers = new ArrayList<String>();
 	private boolean disableCrawlFrames = false;
 
 	/**
@@ -153,19 +154,6 @@
 	}
 
 	/**
-	 * Crawljax will the HTML elements while crawling if and only if all the specified conditions
-	 * are satisfied. IMPORTANT: only works with click()!!! For example:
-	 * when(onContactPageCondition) will only click the HTML element if it is on the contact page
-	 * 
-	 * @param conditions
-	 *            the condition to be met.
-	 * @return this CrawlActions
-	 */
-	public CrawlActions when(Condition... conditions) {
-		return crawlActions.when(conditions);
-	}
-
-	/**
 	 * @return the initial url of the site to crawl
 	 */
 	protected String getUrl() {
@@ -273,8 +261,8 @@
 	/**
 	 * @return the events that should be fired (e.g. onclick)
 	 */
-	protected List<EventType> getCrawlEvents() {
-		return crawlEvents;
+	protected ImmutableList<EventType> getCrawlEvents() {
+		return ImmutableList.copyOf(crawlEvents);
 	}
 
 	/**
@@ -302,8 +290,8 @@
 	/**
 	 * @return the oracleComparators
 	 */
-	protected List<OracleComparator> getOracleComparators() {
-		return oracleComparators;
+	protected ImmutableList<OracleComparator> getOracleComparators() {
+		return ImmutableList.copyOf(oracleComparators);
 	}
 
 	/**
@@ -336,8 +324,8 @@
 	/**
 	 * @return the invariants
 	 */
-	protected List<Invariant> getInvariants() {
-		return invariants;
+	protected ImmutableList<Invariant> getInvariants() {
+		return ImmutableList.copyOf(invariants);
 	}
 
 	/**
@@ -380,8 +368,8 @@
 	/**
 	 * @return the waitConditions
 	 */
-	protected List<WaitCondition> getWaitConditions() {
-		return waitConditions;
+	protected ImmutableList<WaitCondition> getWaitConditions() {
+		return ImmutableList.copyOf(waitConditions);
 	}
 
 	/**
@@ -411,8 +399,8 @@
 	/**
 	 * @return the crawlConditions
 	 */
-	protected List<CrawlCondition> getCrawlConditions() {
-		return crawlConditions;
+	protected ImmutableList<CrawlCondition> getCrawlConditions() {
+		return ImmutableList.copyOf(crawlConditions);
 	}
 
 	/**
@@ -457,8 +445,8 @@
 	 * @param crawlEvents
 	 *            the crawlEvents to set
 	 */
-	public void setCrawlEvents(List<EventType> crawlEvents) {
-		this.crawlEvents = crawlEvents;
+	public void addCrawlEvents(List<EventType> crawlEvents) {
+		this.crawlEvents.addAll(crawlEvents);
 	}
 
 	/**
@@ -472,8 +460,8 @@
 	/**
 	 * @return the list of ignored frames
 	 */
-	protected List<String> ignoredFrameIdentifiers() {
-		return ignoredFrameIdentifiers;
+	protected ImmutableList<String> ignoredFrameIdentifiers() {
+		return ImmutableList.copyOf(ignoredFrameIdentifiers);
 	}
 
 	/**
"
03a222614c956a580c05ac10e4753d44eab3a4bb,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index e7c8ebf..0d95586 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -9,6 +9,9 @@
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.util.Helper;
+import com.google.common.base.Preconditions;
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableList.Builder;
 
 /**
  * Specifies the settings Crawljax. The methods in this class fall into two categories:Oz
@@ -23,8 +26,6 @@
  * EXAMPLE: CrawljaxConfiguration crawljaxConfig = new CrawljaxConfiguration(); CrawlSpecification
  * crawler = new CrawlSpecification(""http://www.google.com""); crawler.click(""a"");
  * crawljaxConfig.setCrawlSpecification(crawler);
- * 
- * @version $Id$
  */
 public final class CrawljaxConfiguration {
 
@@ -65,6 +66,7 @@
 	 *            Which contains all the crawl settings.
 	 */
 	public void setCrawlSpecification(CrawlSpecification crawlSpecification) {
+		Preconditions.checkNotNull(crawlSpecification);
 		this.crawlSpecification = crawlSpecification;
 	}
 
@@ -72,11 +74,7 @@
 	 * @return The inputSpecification which contains information the data for setting input fields.
 	 */
 	protected InputSpecification getInputSpecification() {
-		if (crawlSpecification != null) {
-			return crawlSpecification.getInputSpecification();
-		} else {
-			return null;
-		}
+		return crawlSpecification.getInputSpecification();
 	}
 
 	/**
@@ -114,40 +112,32 @@
 	/**
 	 * @return All the included crawlTags.
 	 */
-	protected List<CrawlElement> getAllIncludedCrawlElements() {
+	protected ImmutableList<CrawlElement> getAllIncludedCrawlElements() {
 		// first add elements for forms so that form action crawlTags are only
-		// clicked
-		// and not by another random crawlTag
-		List<CrawlElement> crawlTags = getInputSpecification().getCrawlElements();
-		if (getCrawlSpecification() != null) {
-
-			for (CrawlElement crawlTag : getCrawlSpecification().crawlActions()
-			        .getCrawlElements()) {
-				crawlTags.add(crawlTag);
-			}
-		}
-		return crawlTags;
+		// clicked and not by another random crawlTag
+		return ImmutableList.<CrawlElement> builder()
+		        .addAll(getInputSpecification().getCrawlElements())
+		        .addAll(crawlSpecification.crawlActions().getCrawlElements())
+		        .build();
 	}
 
 	/**
 	 * @return All the added crawlTags.
 	 */
 	protected List<CrawlElement> getAllCrawlElements() {
-		List<CrawlElement> crawlTags = getAllIncludedCrawlElements();
-		if (getCrawlSpecification() != null) {
-			for (CrawlElement crawlTag : getCrawlSpecification().crawlActions()
-			        .getCrawlElementsExcluded()) {
-				crawlTags.add(crawlTag);
-			}
-		}
-		return crawlTags;
+		return ImmutableList.<CrawlElement> builder()
+		        .addAll(getInputSpecification().getCrawlElements())
+		        .addAll(crawlSpecification.crawlActions().getCrawlElements())
+		        .addAll(getCrawlSpecification().crawlActions()
+		                .getCrawlElementsExcluded())
+		        .build();
 	}
 
 	/**
 	 * @return The eventableConditions.
 	 */
-	protected List<EventableCondition> getEventableConditions() {
-		List<EventableCondition> eventableConditions = new ArrayList<EventableCondition>();
+	protected ImmutableList<EventableCondition> getEventableConditions() {
+		Builder<EventableCondition> eventableConditions = ImmutableList.builder();
 		for (CrawlElement crawlTag : getAllCrawlElements()) {
 			EventableCondition eventableCondition = crawlTag.getEventableCondition();
 			if (eventableCondition != null) {
@@ -155,7 +145,7 @@
 			}
 		}
 
-		return eventableConditions;
+		return eventableConditions.build();
 	}
 
 	/**
"
26fda01f44e2f5e3f000d7baa5c1171b32ae8664,Alex Nederlof,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 3693671..c29dd03 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -22,14 +22,13 @@
 /**
  * Utility class that contains methods used by Crawljax and some plugin to deal with XPath
  * resolving, constructing etc.
- * 
- * @author mesbah
- * @version $Id$
  */
 public final class XPathHelper {
-	/**
-     * 
-     */
+
+	private static final Pattern TAG_PATTERN = Pattern
+	        .compile(""(/(?:[-a-zA-Z]+::)?+)([a-zA-Z]+)"");
+	private static final Pattern ID_PATTERN = Pattern.compile(""(@[a-zA-Z]+)"");
+
 	private static final String FULL_XPATH_CACHE = ""FULL_XPATH_CACHE"";
 	private static final int MAX_SEARCH_LOOPS = 10000;
 
@@ -183,21 +182,16 @@
 	 */
 	public static String formatXPath(String xpath) {
 		String formatted = xpath;
-		Pattern p = Pattern.compile(""(/(?:[-a-zA-Z]+::)?+)([a-zA-Z]+)"");
-		Matcher m = p.matcher(formatted);
+		Matcher tagMatcher = TAG_PATTERN.matcher(formatted);
+		tagMatcher.find();
+		formatted =
+		        tagMatcher.replaceFirst(tagMatcher.group(1) + tagMatcher.group(2).toUpperCase());
 
-		for (int i = 0; m.find(i); i++) {
-			i = m.start();
-			formatted = m.replaceFirst(m.group(1) + m.group(2).toUpperCase());
-			m = p.matcher(formatted);
-		}
-		p = Pattern.compile(""(@[a-zA-Z]+)"");
-		m = p.matcher(formatted);
-
-		for (int i = 0; m.find(i); i++) {
-			i = m.start();
-			formatted = m.replaceFirst(m.group().toLowerCase());
-			m = p.matcher(formatted);
+		Matcher IdMatcher = ID_PATTERN.matcher(formatted);
+		for (int i = 0; IdMatcher.find(i); i++) {
+			i = IdMatcher.start();
+			formatted = IdMatcher.replaceFirst(IdMatcher.group().toLowerCase());
+			IdMatcher = ID_PATTERN.matcher(formatted);
 		}
 		return formatted;
 	}
@@ -223,10 +217,10 @@
 	 * @return string without the before [
 	 */
 	private static String stripEndSquareBrackets(String string) {
-		if (string.indexOf(""["") == -1) {
-			return string;
+		if (string.contains(""["")) {
+			return string.substring(0, string.indexOf('['));
 		} else {
-			return string.substring(0, string.indexOf(""[""));
+			return string;
 		}
 	}
 
"
e2461f32bd8a959eae11839430974c31ad3b0242,Alex Nederlof,CandidateElementExtractor.java,MODIFY,"extract -> [List crawlTagElements, List crawlExcludeTagElements, boolean clickOnce, StateVertex currentState] | [StateVertex currentState]","diff --git a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
index e10565d..ad61c8c 100644
--- a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
+++ b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
@@ -21,6 +21,7 @@
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.condition.eventablecondition.EventableConditionChecker;
+import com.crawljax.core.configuration.CrawljaxConfigurationReader;
 import com.crawljax.core.configuration.IgnoreFrameChecker;
 import com.crawljax.core.state.Identification;
 import com.crawljax.core.state.StateVertex;
@@ -44,6 +45,11 @@
 	private final FormHandler formHandler;
 	private final IgnoreFrameChecker ignoreFrameChecker;
 
+	private final ImmutableList<TagElement> excludeTagElements;
+	private final ImmutableList<TagElement> includedTagElements;
+
+	private final boolean clickOnce;
+
 	/**
 	 * Create a new CandidateElementExtractor.
 	 * 
@@ -54,15 +60,19 @@
 	 *            the current browser instance used in the Crawler
 	 * @param formHandler
 	 *            the form handler.
-	 * @param ignoreFrameChecker
+	 * @param configurationReader
 	 *            the checker used to determine if a certain frame must be ignored.
 	 */
 	public CandidateElementExtractor(ExtractorManager checker, EmbeddedBrowser browser,
-	        FormHandler formHandler, IgnoreFrameChecker ignoreFrameChecker) {
+	        FormHandler formHandler, CrawljaxConfigurationReader configurationReader) {
 		checkedElements = checker;
 		this.browser = browser;
 		this.formHandler = formHandler;
-		this.ignoreFrameChecker = ignoreFrameChecker;
+		this.excludeTagElements = configurationReader.getExcludeTagElements();
+		this.includedTagElements = configurationReader.getTagElements();
+		this.ignoreFrameChecker = configurationReader.getCrawlSpecificationReader();
+		clickOnce = configurationReader.getCrawlSpecificationReader().getClickOnce();
+
 	}
 
 	/**
@@ -81,22 +91,19 @@
 	 * @throws CrawljaxException
 	 *             if the method fails.
 	 */
-	public ImmutableList<CandidateElement> extract(List<TagElement> crawlTagElements,
-	        List<TagElement> crawlExcludeTagElements, boolean clickOnce, StateVertex currentState)
+	public ImmutableList<CandidateElement> extract(StateVertex currentState)
 	        throws CrawljaxException {
 		Builder<CandidateElement> results = ImmutableList.builder();
 
 		if (!checkedElements.checkCrawlCondition(browser)) {
-			LOG.info(""State "" + currentState.getName()
-			        + "" dit not satisfy the CrawlConditions."");
+			LOG.info(""State {} did not satisfy the CrawlConditions."", currentState.getName());
 			return results.build();
 		}
 		LOG.info(""Looking in state: {} for candidate elements with "", currentState.getName());
 
 		try {
 			Document dom = Helper.getDocument(browser.getDomWithoutIframeContent());
-			extractElements(dom, crawlTagElements, crawlExcludeTagElements, clickOnce, results,
-			        """");
+			extractElements(dom, results, """");
 		} catch (SAXException e) {
 			LOG.error(e.getMessage(), e);
 			throw new CrawljaxException(e.getMessage(), e);
@@ -109,34 +116,67 @@
 		return found;
 	}
 
-	private void extractElements(Document dom, List<TagElement> crawlTagElements,
-	        List<TagElement> crawlExcludeTagElements, boolean clickOnce,
-	        Builder<CandidateElement> results, String relatedFrame) {
+	private void extractElements(Document dom, Builder<CandidateElement> results,
+	        String relatedFrame) {
 
-		for (TagElement tag : crawlTagElements) {
-			LOG.debug(""TAG: "" + tag.toString());
+		for (TagElement tag : includedTagElements) {
+			LOG.debug(""Extracting TAG: {}"", tag);
 
-			List<Element> foundElements =
-			        getElementsFromNodelist(dom, crawlExcludeTagElements, tag);
+			addFramesCandidates(dom, results, relatedFrame);
 
-			getFramesCandidates(dom, crawlTagElements, crawlExcludeTagElements, clickOnce,
-			        results, relatedFrame);
+			addIFramesCandidates(dom, results, relatedFrame);
 
-			getIFramesCandidates(dom, crawlTagElements, crawlExcludeTagElements, clickOnce,
-			        results, relatedFrame);
-
+			List<Element> foundElements = getElementsFromNodelist(dom, tag);
 			for (Element sourceElement : foundElements) {
 				evaluateElement(clickOnce, results, relatedFrame, tag, sourceElement);
 			}
 		}
 	}
 
-	private List<Element> getElementsFromNodelist(Document dom,
-	        List<TagElement> crawlExcludeTagElements, TagElement tag) {
+	private void addFramesCandidates(Document dom, Builder<CandidateElement> results,
+	        String relatedFrame) {
+
+		NodeList frameNodes = dom.getElementsByTagName(""FRAME"");
+
+		for (int i = 0; frameNodes != null && i < frameNodes.getLength(); i++) {
+
+			String frameIdentification = """";
+
+			if (relatedFrame != null && !relatedFrame.equals("""")) {
+				frameIdentification += relatedFrame + ""."";
+			}
+
+			Element frameElement = (Element) frameNodes.item(i);
+
+			String nameId = Helper.getFrameIdentification(frameElement);
+
+			// TODO Stefan; Here the IgnoreFrameChecker is used, also in
+			// WebDriverBackedEmbeddedBrowser. We must get this in 1 place.
+			if (nameId != null
+			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
+				frameIdentification += nameId;
+
+				LOG.debug(""frame Identification: {}"", frameIdentification);
+
+				try {
+					Document frameDom =
+					        Helper.getDocument(browser.getFrameDom(frameIdentification));
+					extractElements(frameDom, results, frameIdentification);
+				} catch (SAXException e) {
+					LOG.info(""Got exception while inspecting a frame: {} continuing..."",
+					        frameIdentification, e);
+				} catch (IOException e) {
+					LOG.info(""Got exception while inspecting a frame: {} continuing..."",
+					        frameIdentification, e);
+				}
+			}
+		}
+	}
+
+	private List<Element> getElementsFromNodelist(Document dom, TagElement tag) {
 		try {
 			return getNodeListForTagElement(dom, tag,
-			        checkedElements.getEventableConditionChecker(),
-			        crawlExcludeTagElements);
+			        checkedElements.getEventableConditionChecker());
 		} catch (XPathExpressionException e) {
 			LOG.error(""Catched XPathExpression during NodeList For Tag Element retrieval"",
 			        e);
@@ -192,9 +232,8 @@
 		}
 	}
 
-	private void getIFramesCandidates(Document dom, List<TagElement> crawlTagElements,
-	        List<TagElement> crawlExcludeTagElements, boolean clickOnce,
-	        Builder<CandidateElement> results, String relatedFrame) {
+	private void addIFramesCandidates(Document dom, Builder<CandidateElement> results,
+	        String relatedFrame) {
 
 		NodeList frameNodes = dom.getElementsByTagName(""IFRAME"");
 
@@ -221,8 +260,7 @@
 				try {
 					Document frameDom =
 					        Helper.getDocument(browser.getFrameDom(frameIdentification));
-					extractElements(frameDom, crawlTagElements, crawlExcludeTagElements,
-					        clickOnce, results, frameIdentification);
+					extractElements(frameDom, results, frameIdentification);
 				} catch (SAXException e) {
 					LOG.info(""Got exception while inspecting an iframe:"" + frameIdentification
 					        + "" continuing..."", e);
@@ -234,49 +272,6 @@
 		}
 	}
 
-	// adds support for FRAME tags
-	private void getFramesCandidates(Document dom, List<TagElement> crawlTagElements,
-	        List<TagElement> crawlExcludeTagElements, boolean clickOnce,
-	        Builder<CandidateElement> results, String relatedFrame) {
-
-		NodeList frameNodes = dom.getElementsByTagName(""FRAME"");
-
-		for (int i = 0; frameNodes != null && i < frameNodes.getLength(); i++) {
-
-			String frameIdentification = """";
-
-			if (relatedFrame != null && !relatedFrame.equals("""")) {
-				frameIdentification += relatedFrame + ""."";
-			}
-
-			Element frameElement = (Element) frameNodes.item(i);
-
-			String nameId = Helper.getFrameIdentification(frameElement);
-
-			// TODO Stefan; Here the IgnoreFrameChecker is used, also in
-			// WebDriverBackedEmbeddedBrowser. We must get this in 1 place.
-			if (nameId != null
-			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
-				frameIdentification += nameId;
-
-				LOG.debug(""frame Identification: "" + frameIdentification);
-
-				try {
-					Document frameDom =
-					        Helper.getDocument(browser.getFrameDom(frameIdentification));
-					extractElements(frameDom, crawlTagElements, crawlExcludeTagElements,
-					        clickOnce, results, frameIdentification);
-				} catch (SAXException e) {
-					LOG.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				} catch (IOException e) {
-					LOG.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				}
-			}
-		}
-	}
-
 	/**
 	 * Returns a list of Elements form the DOM tree, matching the tag element.
 	 * 
@@ -286,8 +281,8 @@
 	 * @throws XPathExpressionException
 	 */
 	private List<Element> getNodeListForTagElement(Document dom, TagElement tagElement,
-	        EventableConditionChecker eventableConditionChecker,
-	        List<TagElement> crawlExcludeTagElements) throws SAXException, IOException,
+	        EventableConditionChecker eventableConditionChecker) throws SAXException,
+	        IOException,
 	        CrawljaxException, XPathExpressionException {
 
 		List<Element> result = new ArrayList<Element>();
@@ -351,12 +346,12 @@
 			}
 		}
 
-		if ((crawlExcludeTagElements == null) || (crawlExcludeTagElements.size() == 0)) {
+		if (excludeTagElements.isEmpty()) {
 			return result;
 		} else {
 			List<Element> resultExcluded = new ArrayList<Element>();
 			for (Element e : result) {
-				if (!isExcluded(dom, e, eventableConditionChecker, crawlExcludeTagElements)) {
+				if (!isExcluded(dom, e, eventableConditionChecker)) {
 					resultExcluded.add(e);
 				}
 			}
@@ -404,16 +399,16 @@
 	 *         candidates.
 	 */
 	private boolean isExcluded(Document dom, Element element,
-	        EventableConditionChecker eventableConditionChecker, List<TagElement> excluded) {
+	        EventableConditionChecker eventableConditionChecker) {
 
 		Node parent = element.getParentNode();
 
 		if (parent instanceof Element
-		        && isExcluded(dom, (Element) parent, eventableConditionChecker, excluded)) {
+		        && isExcluded(dom, (Element) parent, eventableConditionChecker)) {
 			return true;
 		}
 
-		for (TagElement tag : excluded) {
+		for (TagElement tag : excludeTagElements) {
 
 			if (element.getTagName().equalsIgnoreCase(tag.getName())) {
 				boolean matchesXPath = false;
"
da6fca0a9f4aa4aeb1f10528863aef52b1f451e2,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 22df7a8..5d04db3 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -47,7 +47,7 @@
 import com.crawljax.forms.FormInput;
 import com.crawljax.forms.InputValue;
 import com.crawljax.forms.RandomInputValueGenerator;
-import com.crawljax.util.Helper;
+import com.crawljax.util.DomUtils;
 
 /**
  * @author mesbah
@@ -341,15 +341,11 @@
 	public String getDom() {
 
 		try {
-			String dom = toUniformDOM(Helper.getDocumentToString(getDomTreeWithFrames()));
+			String dom = toUniformDOM(DomUtils.getDocumentToString(getDomTreeWithFrames()));
 			LOGGER.debug(dom);
 			return dom;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			LOGGER.warn(e.getMessage(), e);
-			return """";
-		} catch (CrawljaxException e) {
-			LOGGER.warn(e.getMessage(), e);
+		} catch (WebDriverException | CrawljaxException e) {
+			LOGGER.warn(""Could not get the dom"", e);
 			return """";
 		}
 	}
@@ -565,7 +561,7 @@
 	private Document getDomTreeWithFrames() throws CrawljaxException {
 
 		try {
-			Document document = Helper.getDocument(browser.getPageSource());
+			Document document = DomUtils.getDocument(browser.getPageSource());
 			appendFrameContent(document.getDocumentElement(), document, """");
 			return document;
 		} catch (SAXException e) {
@@ -603,7 +599,7 @@
 
 			Element frameElement = nodeList.get(i);
 
-			String nameId = Helper.getFrameIdentification(frameElement);
+			String nameId = DomUtils.getFrameIdentification(frameElement);
 
 			if (nameId != null
 			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
@@ -622,7 +618,7 @@
 				browser.switchTo().defaultContent();
 
 				try {
-					Element toAppendElement = Helper.getDocument(toAppend).getDocumentElement();
+					Element toAppendElement = DomUtils.getDocument(toAppend).getDocumentElement();
 					Element importedElement =
 					        (Element) document.importNode(toAppendElement, true);
 					frameElement.appendChild(importedElement);
"
da6fca0a9f4aa4aeb1f10528863aef52b1f451e2,Alex Nederlof,CandidateElementExtractor.java,MODIFY,"addFramesCandidates -> [Document dom, Builder results, String relatedFrame] | [Document dom, Builder results, String relatedFrame, NodeList frameNodes]","diff --git a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
index 1bdc8a7..609c3a7 100644
--- a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
+++ b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
@@ -2,7 +2,6 @@
 
 import java.io.IOException;
 import java.util.ArrayList;
-import java.util.Collections;
 import java.util.List;
 import java.util.Set;
 import java.util.regex.Matcher;
@@ -26,10 +25,13 @@
 import com.crawljax.core.state.Identification;
 import com.crawljax.core.state.StateVertex;
 import com.crawljax.forms.FormHandler;
-import com.crawljax.util.Helper;
+import com.crawljax.util.DomUtils;
+import com.crawljax.util.UrlUtils;
 import com.crawljax.util.XPathHelper;
+import com.google.common.base.Strings;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableList.Builder;
+import com.google.common.collect.ImmutableSet;
 
 /**
  * This class extracts candidate elements from the DOM tree, based on the tags provided by the user.
@@ -102,7 +104,7 @@
 		LOG.info(""Looking in state: {} for candidate elements with "", currentState.getName());
 
 		try {
-			Document dom = Helper.getDocument(browser.getDomWithoutIframeContent());
+			Document dom = DomUtils.getDocument(browser.getDomWithoutIframeContent());
 			extractElements(dom, results, """");
 		} catch (SAXException | IOException e) {
 			LOG.error(e.getMessage(), e);
@@ -115,34 +117,36 @@
 
 	private void extractElements(Document dom, Builder<CandidateElement> results,
 	        String relatedFrame) {
-
+		LOG.debug(""Extracting elements for related frame '{}'"", relatedFrame);
 		for (TagElement tag : includedTagElements) {
 			LOG.debug(""Extracting TAG: {}"", tag);
 
-			addFramesCandidates(dom, results, relatedFrame);
+			NodeList frameNodes = dom.getElementsByTagName(""FRAME"");
+			addFramesCandidates(dom, results, relatedFrame, frameNodes);
 
-			addIFramesCandidates(dom, results, relatedFrame);
+			NodeList iFrameNodes = dom.getElementsByTagName(""IFRAME"");
+			addFramesCandidates(dom, results, relatedFrame, iFrameNodes);
 
 			eveluateElements(dom, tag, results, relatedFrame);
 		}
 	}
 
 	private void addFramesCandidates(Document dom, Builder<CandidateElement> results,
-	        String relatedFrame) {
+	        String relatedFrame, NodeList frameNodes) {
 
-		NodeList frameNodes = dom.getElementsByTagName(""FRAME"");
+		if (frameNodes == null) {
+			return;
+		}
 
-		for (int i = 0; frameNodes != null && i < frameNodes.getLength(); i++) {
+		String frameIdentification = """";
 
-			String frameIdentification = """";
-
-			if (relatedFrame != null && !relatedFrame.equals("""")) {
-				frameIdentification += relatedFrame + ""."";
-			}
-
+		if (!Strings.isNullOrEmpty(relatedFrame)) {
+			frameIdentification = relatedFrame + ""."";
+		}
+		for (int i = 0; i < frameNodes.getLength(); i++) {
 			Element frameElement = (Element) frameNodes.item(i);
 
-			String nameId = Helper.getFrameIdentification(frameElement);
+			String nameId = DomUtils.getFrameIdentification(frameElement);
 
 			// TODO Stefan; Here the IgnoreFrameChecker is used, also in
 			// WebDriverBackedEmbeddedBrowser. We must get this in 1 place.
@@ -154,7 +158,7 @@
 
 				try {
 					Document frameDom =
-					        Helper.getDocument(browser.getFrameDom(frameIdentification));
+					        DomUtils.getDocument(browser.getFrameDom(frameIdentification));
 					extractElements(frameDom, results, frameIdentification);
 				} catch (SAXException | IOException e) {
 					LOG.info(""Got exception while inspecting a frame: {} continuing..."",
@@ -171,14 +175,114 @@
 			        checkedElements.getEventableConditionChecker());
 
 			for (Element sourceElement : nodeListForTagElement) {
-				evaluateElement(clickOnce, results, relatedFrame, tag, sourceElement);
+				evaluateElement(results, relatedFrame, tag, sourceElement);
 			}
-		} catch (XPathExpressionException | SAXException | IOException e) {
-			LOG.error(""Catched exception during NodeList For Tag Element retrieval"", e);
+		} catch (CrawljaxException e) {
+			LOG.warn(""Catched exception during NodeList For Tag Element retrieval"", e);
 		}
 	}
 
-	private void evaluateElement(boolean clickOnce, Builder<CandidateElement> results,
+	/**
+	 * Returns a list of Elements form the DOM tree, matching the tag element.
+	 */
+	private ImmutableList<Element> getNodeListForTagElement(Document dom, TagElement tagElement,
+	        EventableConditionChecker eventableConditionChecker) {
+
+		Builder<Element> result = ImmutableList.builder();
+
+		if (tagElement.getName() == null) {
+			return result.build();
+		}
+
+		EventableCondition eventableCondition =
+		        eventableConditionChecker.getEventableCondition(tagElement.getId());
+		// TODO Stefan; this part of the code should be re-factored, Hack-ed it this way to prevent
+		// performance problems.
+		ImmutableList<String> expressions = getFullXpathForGivenXpath(dom, eventableCondition);
+
+		NodeList nodeList = dom.getElementsByTagName(tagElement.getName());
+		ImmutableSet<TagAttribute> attributes = tagElement.getAttributes();
+
+		for (int k = 0; k < nodeList.getLength(); k++) {
+
+			Element element = (Element) nodeList.item(k);
+			LOG.debug(""Considering element {}"", DomUtils.getElementString(element));
+			boolean matchesXpath =
+			        elementMatchesXpath(eventableConditionChecker, eventableCondition,
+			                expressions, element);
+
+			// TODO Stefan This is a possible Thread-Interleaving problem, as
+			// isChecked can return
+			// false and when needed to add it can return true.
+			// check if element is a candidate
+			String id = element.getNodeName() + "": "" + DomUtils.getAllElementAttributes(element);
+			try {
+				if (matchesXpath
+				        && !checkedElements.isChecked(id)
+				        && isElementVisible(dom, element)
+				        && !filterElement(attributes, element)
+				        && !isExcluded(dom, element, eventableConditionChecker)) {
+					addElement(element, result, tagElement);
+				}
+			} catch (XPathExpressionException e) {
+				LOG.info(""Could not read XPath"", e);
+			}
+		}
+		return result.build();
+	}
+
+	private boolean elementMatchesXpath(EventableConditionChecker eventableConditionChecker,
+	        EventableCondition eventableCondition, ImmutableList<String> expressions,
+	        Element element) {
+		boolean matchesXpath = true;
+		if (eventableCondition != null && eventableCondition.getInXPath() != null) {
+			try {
+				matchesXpath =
+				        eventableConditionChecker.checkXPathUnderXPaths(
+				                XPathHelper.getXPathExpression(element), expressions);
+			} catch (RuntimeException e) {
+				matchesXpath = false;
+			}
+		}
+		return matchesXpath;
+	}
+
+	private ImmutableList<String> getFullXpathForGivenXpath(Document dom,
+	        EventableCondition eventableCondition) {
+		if (eventableCondition != null && eventableCondition.getInXPath() != null) {
+			try {
+				ImmutableList<String> result = XPathHelper.getXpathForXPathExpressions(dom,
+				        eventableCondition.getInXPath());
+				LOG.debug(""Xpath {} resolved to xpaths in document: {}"",
+				        eventableCondition.getInXPath(), result);
+				return result;
+			} catch (XPathExpressionException e) {
+				LOG.debug(""Could not load XPath expressions for {}"", eventableCondition, e);
+			}
+		}
+		return ImmutableList.<String> of();
+	}
+
+	private void addElement(Element element, Builder<Element> builder, TagElement tagElement) {
+
+		if (""A"".equalsIgnoreCase(tagElement.getName())) {
+			String href = element.getAttribute(""href"");
+			boolean isExternal = UrlUtils.isLinkExternal(browser.getCurrentUrl(), href);
+			LOG.debug(""HREF: {} isExternal= {}"", href, isExternal);
+
+			if (!(isExternal || isEmail(href) || isPDForPS(href))) {
+				LOG.debug(""Adding element {}"", element);
+				builder.add(element);
+				checkedElements.increaseElementsCounter();
+			}
+		} else {
+			builder.add(element);
+			LOG.debug(""Adding element {}"", element);
+			checkedElements.increaseElementsCounter();
+		}
+	}
+
+	private void evaluateElement(Builder<CandidateElement> results,
 	        String relatedFrame, TagElement tag, Element sourceElement) {
 		EventableCondition eventableCondition =
 		        checkedElements.getEventableConditionChecker().getEventableCondition(
@@ -220,131 +324,6 @@
 		}
 	}
 
-	private void addIFramesCandidates(Document dom, Builder<CandidateElement> results,
-	        String relatedFrame) {
-
-		NodeList frameNodes = dom.getElementsByTagName(""IFRAME"");
-
-		for (int i = 0; frameNodes != null && i < frameNodes.getLength(); i++) {
-
-			String frameIdentification = """";
-
-			if (relatedFrame != null && !relatedFrame.equals("""")) {
-				frameIdentification += relatedFrame + ""."";
-			}
-
-			Element frameElement = (Element) frameNodes.item(i);
-
-			String nameId = Helper.getFrameIdentification(frameElement);
-
-			// TODO Stefan; Here the IgnoreFrameChecker is used, also in
-			// WebDriverBackedEmbeddedBrowser. We must get this in 1 place.
-			if (nameId != null
-			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
-				frameIdentification += nameId;
-
-				LOG.debug(""iframe Identification: "" + frameIdentification);
-
-				try {
-					Document frameDom =
-					        Helper.getDocument(browser.getFrameDom(frameIdentification));
-					extractElements(frameDom, results, frameIdentification);
-				} catch (SAXException | IOException e) {
-					LOG.info(""Got exception while inspecting an iframe:"" + frameIdentification
-					        + "" continuing..."", e);
-				}
-			}
-		}
-	}
-
-	/**
-	 * Returns a list of Elements form the DOM tree, matching the tag element.
-	 * 
-	 * @throws CrawljaxException
-	 * @throws IOException
-	 * @throws SAXException
-	 * @throws XPathExpressionException
-	 */
-	private List<Element> getNodeListForTagElement(Document dom, TagElement tagElement,
-	        EventableConditionChecker eventableConditionChecker) throws SAXException,
-	        IOException,
-	        CrawljaxException, XPathExpressionException {
-
-		List<Element> result = new ArrayList<Element>();
-
-		if (tagElement.getName() == null) {
-			return result;
-		}
-
-		EventableCondition eventableCondition =
-		        eventableConditionChecker.getEventableCondition(tagElement.getId());
-		// TODO Stefan; this part of the code should be re-factored, Hack-ed it this way to prevent
-		// performance problems.
-		boolean matchesXpath = true;
-		List<String> expressions = null;
-		if (eventableCondition != null && eventableCondition.getInXPath() != null) {
-
-			expressions =
-			        XPathHelper.getXpathForXPathExpressions(dom, eventableCondition.getInXPath());
-		}
-
-		NodeList nodeList = dom.getElementsByTagName(tagElement.getName());
-		Set<TagAttribute> attributes = tagElement.getAttributes();
-
-		for (int k = 0; k < nodeList.getLength(); k++) {
-
-			Element element = (Element) nodeList.item(k);
-			if (eventableCondition != null && eventableCondition.getInXPath() != null) {
-				try {
-					matchesXpath =
-					        eventableConditionChecker.checkXPathUnderXPaths(
-					                XPathHelper.getXPathExpression(element), expressions);
-				} catch (Exception e) {
-					matchesXpath = false;
-					// xpath could not be found or determined, so dont allow
-					// element
-				}
-			}
-
-			// TODO Stefan This is a possible Thread-Interleaving problem, as
-			// isChecked can return
-			// false and when needed to add it can return true.
-			// check if element is a candidate
-			if (matchesXpath
-			        && !checkedElements.isChecked(element.getNodeName() + "": ""
-			                + Helper.getAllElementAttributes(element))
-			        && isElementVisible(dom, element) && !filterElement(attributes, element)) {
-				if (""A"".equalsIgnoreCase(tagElement.getName())) {
-					String href = element.getAttribute(""href"");
-					boolean isExternal = Helper.isLinkExternal(browser.getCurrentUrl(), href);
-					boolean isEmail = isEmail(href);
-					LOG.debug(""HREF: "" + href + ""isExternal= "" + isExternal);
-
-					if (!(isExternal || isEmail || isPDForPS(href))) {
-						result.add(element);
-						checkedElements.increaseElementsCounter();
-					}
-				} else {
-					result.add(element);
-					checkedElements.increaseElementsCounter();
-				}
-			}
-		}
-
-		if (excludeTagElements.isEmpty()) {
-			return result;
-		} else {
-			List<Element> resultExcluded = new ArrayList<Element>();
-			for (Element e : result) {
-				if (!isExcluded(dom, e, eventableConditionChecker)) {
-					resultExcluded.add(e);
-				}
-			}
-
-			return resultExcluded;
-		}
-	}
-
 	/**
 	 * @param email
 	 *            the string to check
@@ -405,9 +384,7 @@
 					                .checkXpathStartsWithXpathEventableCondition(dom,
 					                        eventableCondition,
 					                        XPathHelper.getXPathExpression(element));
-				} catch (CrawljaxException e) {
-					// xpath could not be found or determined, so dont filter
-					// element because of xpath
+				} catch (CrawljaxException | XPathExpressionException e) {
 					matchesXPath = false;
 				}
 
@@ -443,7 +420,7 @@
 		NodeList nodes = XPathHelper.evaluateXpathExpression(dom, xpath);
 
 		if (nodes.getLength() > 0) {
-			LOG.debug(""Element: "" + Helper.getAllElementAttributes(element) + "" is invisible!"");
+			LOG.debug(""Element: "" + DomUtils.getAllElementAttributes(element) + "" is invisible!"");
 
 			return false;
 		}
@@ -460,7 +437,7 @@
 			return false;
 		}
 		for (TagAttribute attr : attributes) {
-			LOG.debug(""Checking element "" + Helper.getElementString(element)
+			LOG.debug(""Checking element "" + DomUtils.getElementString(element)
 			        + ""AttributeName: "" + attr.getName() + "" value: "" + attr.getValue());
 
 			if (attr.matchesValue(element.getAttribute(attr.getName()))) {
"
da6fca0a9f4aa4aeb1f10528863aef52b1f451e2,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 0d95586..bccbdce 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -8,7 +8,7 @@
 import com.crawljax.browser.WebDriverBrowserBuilder;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.plugin.Plugin;
-import com.crawljax.util.Helper;
+import com.crawljax.util.DomUtils;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableList.Builder;
@@ -199,7 +199,7 @@
 	 * @return The path of the outputFolder with a trailing slash.
 	 */
 	protected String getOutputFolder() {
-		return Helper.addFolderSlashIfNeeded(outputFolder);
+		return DomUtils.addFolderSlashIfNeeded(outputFolder);
 	}
 
 	/**
@@ -207,7 +207,7 @@
 	 *            The (absolute) path of the output folder.
 	 */
 	public void setOutputFolder(String path) {
-		this.outputFolder = Helper.addFolderSlashIfNeeded(path);
+		this.outputFolder = DomUtils.addFolderSlashIfNeeded(path);
 	}
 
 	/**
"
da6fca0a9f4aa4aeb1f10528863aef52b1f451e2,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index 46ae2c7..7e8e0bf 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -23,7 +23,7 @@
 import com.crawljax.core.CandidateElement;
 import com.crawljax.core.configuration.InputSpecification;
 import com.crawljax.core.exception.BrowserConnectionException;
-import com.crawljax.util.Helper;
+import com.crawljax.util.DomUtils;
 import com.crawljax.util.XPathHelper;
 
 /**
@@ -88,7 +88,7 @@
 					if (text.equals("""")) {
 						return;
 					}
-					String js = Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
+					String js = DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
 					js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
 					browser.executeJavaScript(js);
 				}
@@ -97,7 +97,7 @@
 				if (input.getType().equals(""checkbox"")) {
 					for (InputValue inputValue : input.getInputValues()) {
 						String js =
-						        Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
+						        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
 						boolean check;
 						if (!randomFieldValue) {
 							check = inputValue.isChecked();
@@ -122,7 +122,7 @@
 					for (InputValue inputValue : input.getInputValues()) {
 						if (inputValue.isChecked()) {
 							String js =
-							        Helper.getJSGetElement(XPathHelper
+							        DomUtils.getJSGetElement(XPathHelper
 							                .getXPathExpression(element));
 							js += ""try{ATUSA_element.checked=true;}catch(e){}"";
 							browser.executeJavaScript(js);
@@ -135,7 +135,7 @@
 					for (InputValue inputValue : input.getInputValues()) {
 						// if(browser.getDriver()==null){
 						String js =
-						        Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
+						        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
 						js +=
 						        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
 						                + ""if(ATUSA_element.options[i].value=='""
@@ -200,7 +200,7 @@
 		List<FormInput> formInputs = new ArrayList<FormInput>();
 		Document dom;
 		try {
-			dom = Helper.getDocument(browser.getDom());
+			dom = DomUtils.getDocument(browser.getDom());
 			List<Node> nodes = getInputElements(dom);
 			for (Node node : nodes) {
 				FormInput formInput =
@@ -239,7 +239,7 @@
 		Document dom;
 
 		try {
-			dom = Helper.getDocument(browser.getDomWithoutIframeContent());
+			dom = DomUtils.getDocument(browser.getDomWithoutIframeContent());
 			for (FormInput input : formInputs) {
 				LOGGER.debug(""Filling in: "" + input);
 				setInputElementValue(formInputValueHelper.getBelongingNode(input, dom), input);
"
da6fca0a9f4aa4aeb1f10528863aef52b1f451e2,Alex Nederlof,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index 605a685..3600c9b 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -58,7 +58,7 @@
 	public String resolve(boolean logging) {
 		Document dom = null;
 		try {
-			dom = Helper.getDocument(browser.getDom());
+			dom = DomUtils.getDocument(browser.getDom());
 		} catch (SAXException e) {
 			LOGGER.error(e.getMessage(), e);
 			return """";
@@ -69,7 +69,7 @@
 
 		try {
 			String xpathEventable = eventable.getIdentification().getValue();
-			Node nodeSameXpath = Helper.getElementByXpath(dom, xpathEventable);
+			Node nodeSameXpath = DomUtils.getElementByXpath(dom, xpathEventable);
 			if (nodeSameXpath != null) {
 				Element elementSameXpath = new Element(nodeSameXpath);
 				if (logging) {
"
da6fca0a9f4aa4aeb1f10528863aef52b1f451e2,Alex Nederlof,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index c29dd03..65233d8 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -19,6 +19,9 @@
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
 
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableList.Builder;
+
 /**
  * Utility class that contains methods used by Crawljax and some plugin to deal with XPath
  * resolving, constructing etc.
@@ -120,7 +123,7 @@
 	 */
 	public static NodeList evaluateXpathExpression(String domStr, String xpathExpr)
 	        throws Exception {
-		Document dom = Helper.getDocument(domStr);
+		Document dom = DomUtils.getDocument(domStr);
 
 		return evaluateXpathExpression(dom, xpathExpr);
 	}
@@ -157,22 +160,19 @@
 	 * @param xpathExpression
 	 *            The expression to find the element.
 	 * @return list of XPaths retrieved by xpathExpression.
+	 * @throws XPathExpressionException
 	 */
-	public static List<String> getXpathForXPathExpressions(Document dom, String xpathExpression) {
-		NodeList nodeList;
-		try {
-			nodeList = XPathHelper.evaluateXpathExpression(dom, xpathExpression);
-		} catch (XPathExpressionException e) {
-			return null;
-		}
-		List<String> result = new ArrayList<String>();
+	public static ImmutableList<String> getXpathForXPathExpressions(Document dom,
+	        String xpathExpression) throws XPathExpressionException {
+		NodeList nodeList = XPathHelper.evaluateXpathExpression(dom, xpathExpression);
+		Builder<String> result = ImmutableList.builder();
 		if (nodeList.getLength() > 0) {
 			for (int i = 0; i < nodeList.getLength(); i++) {
 				Node n = nodeList.item(i);
 				result.add(getXPathExpression(n));
 			}
 		}
-		return result;
+		return result.build();
 	}
 
 	/**
"
ad1fb7385b4c3f1d5c3f33f12d2207fbb4b0bff3,Alex Nederlof,JarRunner.java,MODIFY,"readConfigAndRun -> [CommandLine commandLine, String urlValue] | [CommandLine commandLine, String urlValue, String outputDir]","diff --git a/cli/src/main/java/com/crawljax/cli/JarRunner.java b/cli/src/main/java/com/crawljax/cli/JarRunner.java
index a568de2..770dd70 100644
--- a/cli/src/main/java/com/crawljax/cli/JarRunner.java
+++ b/cli/src/main/java/com/crawljax/cli/JarRunner.java
@@ -1,5 +1,6 @@
 package com.crawljax.cli;
 
+import java.io.File;
 import java.io.IOException;
 import java.io.PrintWriter;
 
@@ -18,6 +19,8 @@
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlSpecification;
 import com.crawljax.core.configuration.CrawljaxConfiguration;
+import com.crawljax.core.configuration.ThreadConfiguration;
+import com.crawljax.plugins.crawloverview.CrawlOverview;
 import com.google.common.base.Charsets;
 import com.google.common.io.Resources;
 
@@ -28,7 +31,7 @@
 	public static final String MAXSTATES = ""maxstates"";
 	public static final String DEPTH = ""depth"";
 	public static final String BROWSER = ""browser"";
-	public static final String URL = ""url"";
+	public static final String PARALLEL = ""parallel"";
 
 	private static final int SPACES_AFTER_OPTION = 3;
 	private static final int SPACES_BEFORE_OPTION = 5;
@@ -42,7 +45,7 @@
 	 */
 	public static void main(String[] args) {
 		try {
-			if (args.length < 1) {
+			if (args.length < 2) {
 				printHelp(getOptions());
 				System.exit(1);
 			}
@@ -58,26 +61,40 @@
 	 * 
 	 * @return Options expected from command-line.
 	 */
+	@SuppressWarnings(""static-access"")
 	private static Options getOptions() {
 		Options options = new Options();
-
 		options.addOption(new Option(HELP, ""print this message""));
 		options.addOption(new Option(VERSION, ""print the version information and exit""));
 
-		options.addOption(OptionBuilder.withArgName(""URL"").hasArg()
-		        .withDescription(""url to crawl"").create(URL));
-
-		options.addOption(OptionBuilder.withLongOpt(BROWSER)
-		        .withDescription(""browser type: firefox, chrome, ie, htmlunit"").hasArg()
-		        .withArgName(""TYPE"").create());
+		options.addOption(
+		        OptionBuilder
+		                .withLongOpt(BROWSER)
+		                .withDescription(
+		                        ""browser type: firefox, chrome, ie, htmlunit. Default is Firefox"")
+		                .hasArg()
+		                .withArgName(""TYPE"").create());
 
 		options.addOption(OptionBuilder.withLongOpt(DEPTH)
-		        .withDescription(""crawl depth level"").hasArg().withArgName(""LEVEL"").create());
+		        .withDescription(""crawl depth level. Default is 2"")
+		        .hasArg()
+		        .withArgName(""LEVEL"").create());
 
-		options.addOption(OptionBuilder.withLongOpt(MAXSTATES)
-		        .withDescription(""max number of states to crawl"").hasArg()
-		        .withArgName(""STATES"").create());
+		options.addOption(
+		        OptionBuilder
+		                .withLongOpt(MAXSTATES)
+		                .withDescription(
+		                        ""max number of states to crawl. Default is 0 (unlimited)"")
+		                .hasArg()
+		                .withArgName(""STATES"").create());
 
+		options.addOption(
+		        OptionBuilder
+		                .withLongOpt(PARALLEL)
+		                .withDescription(
+		                        ""Number of browsers to use for crawling. Default is 1"")
+		                .hasArg()
+		                .withArgName(""PARALLEL"").create());
 		return options;
 	}
 
@@ -88,7 +105,8 @@
 	 * @throws IOException
 	 */
 	public static void printHelp(Options options) throws IOException {
-		String cmlSyntax = ""java -jar crawljax-cli-"" + getCrawljaxVersion() + "".jar"";
+		String cmlSyntax =
+		        ""java -jar crawljax-cli-"" + getCrawljaxVersion() + "".jar theUrl theOutputDir"";
 		final PrintWriter writer = new PrintWriter(System.out);
 		final HelpFormatter helpFormatter = new HelpFormatter();
 		helpFormatter.printHelp(writer, ROW_WIDTH, cmlSyntax, """", options,
@@ -112,18 +130,18 @@
 		Options options = getOptions();
 		final CommandLine commandLine = new GnuParser().parse(options, args);
 
-		String urlValue = commandLine.getOptionValue(URL);
-
+		String url = commandLine.getArgs()[0];
+		String outputDir = commandLine.getArgs()[1];
 		if (commandLine.hasOption(HELP)) {
 			printHelp(options);
 		} else if (commandLine.hasOption(VERSION)) {
 			System.out.println(""crawljax version \"""" + getCrawljaxVersion() + ""\"""");
-		} else if (urlIsInvalid(urlValue)) {
-			System.err.println(""provide a valid URL. -url=http://example.com"");
+		} else if (urlIsInvalid(url)) {
+			System.err.println(""provide a valid URL like http://example.com"");
 			printHelp(options);
 			System.exit(1);
 		} else {
-			readConfigAndRun(commandLine, urlValue);
+			readConfigAndRun(commandLine, url, outputDir);
 		}
 	}
 
@@ -137,9 +155,11 @@
 		return urlValue == null || !new UrlValidator(schemes).isValid(urlValue);
 	}
 
-	private static void readConfigAndRun(final CommandLine commandLine, String urlValue) {
+	private static void readConfigAndRun(final CommandLine commandLine, String urlValue,
+	        String outputDir) {
 		CrawlSpecification crawlSpec = new CrawlSpecification(urlValue);
 		CrawljaxConfiguration config = new CrawljaxConfiguration();
+		config.addPlugin(new CrawlOverview(new File(outputDir)));
 		config.setCrawlSpecification(crawlSpec);
 
 		if (commandLine.hasOption(BROWSER)) {
@@ -157,6 +177,15 @@
 			crawlSpec.setMaximumStates(Integer.parseInt(maxstates));
 		}
 
+		if (commandLine.hasOption(PARALLEL)) {
+			int parallel = Integer.parseInt(commandLine.getOptionValue(PARALLEL));
+			ThreadConfiguration threadConfiguration = new ThreadConfiguration(5, 10, true);
+			threadConfiguration.setNumberThreads(parallel + 2);
+			threadConfiguration.setNumberBrowsers(parallel);
+			threadConfiguration.setBrowserBooting(true);
+			config.setThreadConfiguration(threadConfiguration);
+		}
+
 		// run Crawljax
 		crawlSpec.clickDefaultElements();
 		CrawljaxController crawljax = new CrawljaxController(config);
"
8e3c168b476a5a509506e94f2f11057c341bedcd,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 5d04db3..f14cb5e 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -342,7 +342,7 @@
 
 		try {
 			String dom = toUniformDOM(DomUtils.getDocumentToString(getDomTreeWithFrames()));
-			LOGGER.debug(dom);
+			LOGGER.trace(dom);
 			return dom;
 		} catch (WebDriverException | CrawljaxException e) {
 			LOGGER.warn(""Could not get the dom"", e);
@@ -561,11 +561,9 @@
 	private Document getDomTreeWithFrames() throws CrawljaxException {
 
 		try {
-			Document document = DomUtils.getDocument(browser.getPageSource());
+			Document document = DomUtils.asDocument(browser.getPageSource());
 			appendFrameContent(document.getDocumentElement(), document, """");
 			return document;
-		} catch (SAXException e) {
-			throw new CrawljaxException(e.getMessage(), e);
 		} catch (IOException e) {
 			throw new CrawljaxException(e.getMessage(), e);
 		}
@@ -618,19 +616,13 @@
 				browser.switchTo().defaultContent();
 
 				try {
-					Element toAppendElement = DomUtils.getDocument(toAppend).getDocumentElement();
+					Element toAppendElement = DomUtils.asDocument(toAppend).getDocumentElement();
 					Element importedElement =
 					        (Element) document.importNode(toAppendElement, true);
 					frameElement.appendChild(importedElement);
 
 					appendFrameContent(importedElement, document, frameIdentification);
-				} catch (DOMException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				} catch (SAXException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				} catch (IOException e) {
+				} catch (DOMException | IOException e) {
 					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
 					        + "" continuing..."", e);
 				}
"
8e3c168b476a5a509506e94f2f11057c341bedcd,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index bccbdce..6b50bed 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -144,7 +144,6 @@
 				eventableConditions.add(eventableCondition);
 			}
 		}
-
 		return eventableConditions.build();
 	}
 
"
8e3c168b476a5a509506e94f2f11057c341bedcd,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index 7e8e0bf..ac9c003 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -16,7 +16,6 @@
 import org.w3c.dom.Element;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
-import org.xml.sax.SAXException;
 
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.eventablecondition.EventableCondition;
@@ -62,7 +61,7 @@
 	}
 
 	private static final String[] ALLOWED_INPUT_TYPES =
-	        { ""text"", ""radio"", ""checkbox"", ""password"" };
+	{ ""text"", ""radio"", ""checkbox"", ""password"" };
 
 	/**
 	 * Fills in the element with the InputValues for input TODO: improve this by using WebDriver
@@ -200,7 +199,7 @@
 		List<FormInput> formInputs = new ArrayList<FormInput>();
 		Document dom;
 		try {
-			dom = DomUtils.getDocument(browser.getDom());
+			dom = DomUtils.asDocument(browser.getDom());
 			List<Node> nodes = getInputElements(dom);
 			for (Node node : nodes) {
 				FormInput formInput =
@@ -209,11 +208,7 @@
 					formInputs.add(formInput);
 				}
 			}
-		} catch (Exception e) {
-			// TODO Stefan; refactor this Exception
-			if (e instanceof BrowserConnectionException) {
-				throw (BrowserConnectionException) e;
-			}
+		} catch (IOException e) {
 			LOGGER.error(e.getMessage(), e);
 		}
 		return formInputs;
@@ -236,19 +231,13 @@
 	 *            form input list.
 	 */
 	public void handleFormElements(List<FormInput> formInputs) {
-		Document dom;
-
 		try {
-			dom = DomUtils.getDocument(browser.getDomWithoutIframeContent());
+			Document dom = DomUtils.asDocument(browser.getDomWithoutIframeContent());
 			for (FormInput input : formInputs) {
 				LOGGER.debug(""Filling in: "" + input);
 				setInputElementValue(formInputValueHelper.getBelongingNode(input, dom), input);
 			}
-		} catch (SAXException e) {
-			LOGGER.error(e.getMessage(), e);
-		} catch (IOException e) {
-			LOGGER.error(e.getMessage(), e);
-		} catch (XPathExpressionException e) {
+		} catch (IOException | XPathExpressionException e) {
 			LOGGER.error(e.getMessage(), e);
 		}
 
"
8e3c168b476a5a509506e94f2f11057c341bedcd,Alex Nederlof,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index 3600c9b..a0b29d5 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -53,15 +53,13 @@
 	/**
 	 * @param logging
 	 *            Whether to do logging.
-	 * @return equivalent xpath of element equivalent to Eventable
+	 * @return equivalent xpath of element equivalent to Eventable or an empty string if the DOM
+	 *         cannot be read.
 	 */
 	public String resolve(boolean logging) {
 		Document dom = null;
 		try {
-			dom = DomUtils.getDocument(browser.getDom());
-		} catch (SAXException e) {
-			LOGGER.error(e.getMessage(), e);
-			return """";
+			dom = DomUtils.asDocument(browser.getDom());
 		} catch (IOException e) {
 			LOGGER.error(e.getMessage(), e);
 			return """";
"
8e3c168b476a5a509506e94f2f11057c341bedcd,Alex Nederlof,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 65233d8..5e1218c 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -3,6 +3,7 @@
  */
 package com.crawljax.util;
 
+import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
@@ -112,19 +113,13 @@
 	/**
 	 * Returns the list of nodes which match the expression xpathExpr in the String domStr.
 	 * 
-	 * @param domStr
-	 *            the string of the document to search in
-	 * @param xpathExpr
-	 *            the xpath query
-	 * @author cor-paul
 	 * @return the list of nodes which match the query
-	 * @throws Exception
-	 *             On erorr.
+	 * @throws XPathExpressionException
+	 * @throws IOException
 	 */
 	public static NodeList evaluateXpathExpression(String domStr, String xpathExpr)
-	        throws Exception {
-		Document dom = DomUtils.getDocument(domStr);
-
+	        throws XPathExpressionException, IOException {
+		Document dom = DomUtils.asDocument(domStr);
 		return evaluateXpathExpression(dom, xpathExpr);
 	}
 
@@ -147,7 +142,6 @@
 		XPathExpression expr = xpath.compile(xpathExpr);
 		Object result = expr.evaluate(dom, XPathConstants.NODESET);
 		NodeList nodes = (NodeList) result;
-
 		return nodes;
 	}
 
@@ -181,19 +175,26 @@
 	 * @return formatted xpath with tag names in uppercase and attributes in lowercase
 	 */
 	public static String formatXPath(String xpath) {
-		String formatted = xpath;
-		Matcher tagMatcher = TAG_PATTERN.matcher(formatted);
-		tagMatcher.find();
-		formatted =
-		        tagMatcher.replaceFirst(tagMatcher.group(1) + tagMatcher.group(2).toUpperCase());
-
-		Matcher IdMatcher = ID_PATTERN.matcher(formatted);
-		for (int i = 0; IdMatcher.find(i); i++) {
-			i = IdMatcher.start();
-			formatted = IdMatcher.replaceFirst(IdMatcher.group().toLowerCase());
-			IdMatcher = ID_PATTERN.matcher(formatted);
+		Matcher m = TAG_PATTERN.matcher(xpath);
+		StringBuffer sb = new StringBuffer();
+		while (m.find()) {
+			String text = m.group();
+			System.out.println(""Found group "" + text);
+			m.appendReplacement(sb, Matcher.quoteReplacement(text.toUpperCase()));
 		}
-		return formatted;
+		m.appendTail(sb);
+
+		m = ID_PATTERN.matcher(sb.toString());
+		sb = new StringBuffer();
+		while (m.find()) {
+			String text = m.group();
+			m.appendReplacement(sb, Matcher.quoteReplacement(text.toLowerCase()));
+		}
+		m.appendTail(sb);
+
+		System.out.println(xpath + "" became "" + sb.toString());
+
+		return sb.toString();
 	}
 
 	/**
"
fbab3ce2d013497b779b99eca69afb794928d37c,Alex Nederlof,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 5e1218c..5529735 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -1,6 +1,3 @@
-/**
- * Created Dec 13, 2007
- */
 package com.crawljax.util;
 
 import java.io.IOException;
@@ -20,6 +17,7 @@
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
 
+import com.google.common.base.Strings;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableList.Builder;
 
@@ -30,15 +28,13 @@
 public final class XPathHelper {
 
 	private static final Pattern TAG_PATTERN = Pattern
-	        .compile(""(/(?:[-a-zA-Z]+::)?+)([a-zA-Z]+)"");
+	        .compile(""(?<=[/|::])[a-zA-z]+(?=([/|\\[]|$))"");
+
 	private static final Pattern ID_PATTERN = Pattern.compile(""(@[a-zA-Z]+)"");
 
 	private static final String FULL_XPATH_CACHE = ""FULL_XPATH_CACHE"";
 	private static final int MAX_SEARCH_LOOPS = 10000;
 
-	private XPathHelper() {
-	}
-
 	/**
 	 * Reverse Engineers an XPath Expression of a given Node in the DOM.
 	 * 
@@ -175,25 +171,30 @@
 	 * @return formatted xpath with tag names in uppercase and attributes in lowercase
 	 */
 	public static String formatXPath(String xpath) {
-		Matcher m = TAG_PATTERN.matcher(xpath);
-		StringBuffer sb = new StringBuffer();
-		while (m.find()) {
-			String text = m.group();
-			System.out.println(""Found group "" + text);
-			m.appendReplacement(sb, Matcher.quoteReplacement(text.toUpperCase()));
-		}
-		m.appendTail(sb);
+		String formatted = capitalizeTagNames(xpath);
+		formatted = lowerCaseAttributes(formatted);
+		return formatted;
+	}
 
-		m = ID_PATTERN.matcher(sb.toString());
-		sb = new StringBuffer();
+	private static String lowerCaseAttributes(String formatted) {
+		Matcher m = ID_PATTERN.matcher(formatted);
+		StringBuffer sb = new StringBuffer();
 		while (m.find()) {
 			String text = m.group();
 			m.appendReplacement(sb, Matcher.quoteReplacement(text.toLowerCase()));
 		}
 		m.appendTail(sb);
+		return sb.toString();
+	}
 
-		System.out.println(xpath + "" became "" + sb.toString());
-
+	private static String capitalizeTagNames(String xpath) {
+		Matcher m = TAG_PATTERN.matcher(xpath);
+		StringBuffer sb = new StringBuffer();
+		while (m.find()) {
+			String text = m.group();
+			m.appendReplacement(sb, Matcher.quoteReplacement(text.toUpperCase()));
+		}
+		m.appendTail(sb);
 		return sb.toString();
 	}
 
@@ -244,19 +245,18 @@
 		int number;
 		// System.out.println(xpath);
 		for (String element : elements) {
-			if (!element.equals("""") && !element.startsWith(""@"") && element.indexOf(""()"") == -1) {
+			if (!element.isEmpty() && !element.startsWith(""@"") && !element.contains(""()"")) {
 				if (element.indexOf(""["") != -1) {
 					try {
 						number =
 						        Integer.parseInt(element.substring(element.indexOf(""["") + 1,
 						                element.indexOf(""]"")));
-					} catch (Exception e) {
+					} catch (NumberFormatException e) {
 						return -1;
 					}
 				} else {
 					number = 1;
 				}
-				// System.out.println(""number: "" + number);
 				for (int i = 0; i < number; i++) {
 					// find new open element
 					temp = dom.indexOf(""<"" + stripEndSquareBrackets(element), pos);
@@ -306,25 +306,20 @@
 			if (dom.indexOf(openElement, pos) == -1 && dom.indexOf(closeElement, pos) == -1) {
 				return -1;
 			}
-			// System.out.println(""hierzo: "" + dom.substring(pos));
 			if (dom.indexOf(openElement, pos) < dom.indexOf(closeElement, pos)
 			        && dom.indexOf(openElement, pos) != -1) {
 				openElements++;
 				pos = dom.indexOf(openElement, pos) + 1;
-				// System.out.println(""open: "" + dom.substring(pos-1));
 			} else {
 
 				openElements--;
 				pos = dom.indexOf(closeElement, pos) + 1;
-				// System.out.println(""close: "" + dom.substring(pos-1));
 			}
-			// System.out.println(openElements);
 			if (openElements == 0) {
 				break;
 			}
 			i++;
 		}
-		// System.out.println(""Finished: "" + dom.substring(pos-1));
 		return pos - 1;
 
 	}
@@ -348,14 +343,14 @@
 	 *         text()
 	 */
 	public static String stripXPathToElement(String xpath) {
-		if (xpath != null && !xpath.equals("""")) {
-			if (xpath.toLowerCase().indexOf(""/text()"") != -1) {
+		if (!Strings.isNullOrEmpty(xpath)) {
+			if (xpath.toLowerCase().contains(""/text()"")) {
 				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/text()""));
 			}
-			if (xpath.toLowerCase().indexOf(""/comment()"") != -1) {
+			if (xpath.toLowerCase().contains(""/comment()"")) {
 				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/comment()""));
 			}
-			if (xpath.indexOf(""@"") != -1) {
+			if (xpath.contains(""@"")) {
 				xpath = xpath.substring(0, xpath.indexOf(""@"") - 1);
 			}
 		}
@@ -363,4 +358,7 @@
 		return xpath;
 	}
 
+	private XPathHelper() {
+	}
+
 }
"
dded41ae315c31c54b643804ba2e481220baf1fd,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index bfe18b8..77394ed 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -1,6 +1,5 @@
 package com.crawljax.core;
 
-import java.util.List;
 import java.util.concurrent.TimeUnit;
 
 import net.jcip.annotations.GuardedBy;
"
d4fe5d1942b71f951beed4cc2dde154fa0b1c175,Alex Nederlof,EmbeddedBrowser.java,MODIFY,goToUrl -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
index e8685dc..f9e541a 100644
--- a/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
@@ -1,6 +1,7 @@
 package com.crawljax.browser;
 
 import java.io.File;
+import java.net.URL;
 
 import org.openqa.selenium.WebElement;
 
@@ -28,7 +29,7 @@
 	 * @param url
 	 *            the URL.
 	 */
-	void goToUrl(String url);
+	void goToUrl(URL url);
 
 	/**
 	 * fires the event.
"
d4fe5d1942b71f951beed4cc2dde154fa0b1c175,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index f14cb5e..2c59e55 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -257,7 +257,7 @@
 	 *            The URL.
 	 */
 	@Override
-	public void goToUrl(String url) {
+	public void goToUrl(URL url) {
 		try {
 			browser.navigate().to(url);
 			Thread.sleep(this.crawlWaitReload);
"
d4fe5d1942b71f951beed4cc2dde154fa0b1c175,Alex Nederlof,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 56127d5..7485d52 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -1,12 +1,16 @@
 package com.crawljax.core.configuration;
 
+import java.net.MalformedURLException;
+import java.net.URL;
 import java.util.List;
+import java.util.concurrent.TimeUnit;
 
 import com.crawljax.condition.Condition;
 import com.crawljax.condition.browserwaiter.ExpectedCondition;
 import com.crawljax.condition.browserwaiter.WaitCondition;
 import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.invariant.Invariant;
+import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlActions.ExcludeByParentBuilder;
 import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.oraclecomparator.Comparator;
@@ -43,20 +47,14 @@
  * //restrict the scope of the crawling<br />
  * crawler.setCrawlMaximumStates(15);<br />
  * crawler.setCrawlDepth(2);
- * 
- * @author DannyRoest@gmail.com (Danny Roest)
- * @version $Id$
- */
-/**
- * @author alex
  */
 public class CrawlSpecification {
 
-	private static final int DEFAULT_MAXIMUMRUNTIME = 3600;
-	private static final int DEFAULT_WAITTIMEAFTERRELOADURL = 500;
-	private static final int DEFAULT_WAITTIMEAFTEREVENT = 500;
+	private static final long DEFAULT_MAXIMUMRUNTIME = TimeUnit.HOURS.toMillis(1);
+	private static final long DEFAULT_WAITTIMEAFTERRELOADURL = 500;
+	private static final long DEFAULT_WAITTIMEAFTEREVENT = 500;
 
-	private final String url;
+	private final URL url;
 
 	private final List<EventType> crawlEvents = Lists.newLinkedList();
 	private final List<String> ignoredFrameIdentifiers = Lists.newLinkedList();
@@ -67,9 +65,10 @@
 
 	private int depth = 2;
 	private int maximumStates = 0;
-	private int maximumRuntime = DEFAULT_MAXIMUMRUNTIME; // in seconds
-	private int waitTimeAfterReloadUrl = DEFAULT_WAITTIMEAFTERRELOADURL; // in milliseconds
-	private int waitTimeAfterEvent = DEFAULT_WAITTIMEAFTEREVENT; // in milliseconds
+	private long maximumRuntime = DEFAULT_MAXIMUMRUNTIME;
+	private long waitTimeAfterReloadUrl = DEFAULT_WAITTIMEAFTERRELOADURL;
+	private long waitTimeAfterEvent = DEFAULT_WAITTIMEAFTEREVENT;
+
 	private final CrawlActions crawlActions = new CrawlActions();
 
 	private boolean randomInputInForms = true;
@@ -84,11 +83,20 @@
 	 * @param url
 	 *            the site to crawl
 	 */
-	public CrawlSpecification(String url) {
+	public CrawlSpecification(URL url) {
 		this.crawlEvents.add(EventType.click);
 		this.url = url;
 	}
 
+	public CrawlSpecification(String url) {
+		this.crawlEvents.add(EventType.click);
+		try {
+			this.url = new URL(url);
+		} catch (MalformedURLException e) {
+			throw new CrawljaxException(""Invalid URL: "" + url);
+		}
+	}
+
 	/**
 	 * Specifies that Crawljax should click all the default clickable elements. These include: All
 	 * anchor tags All buttons
@@ -101,34 +109,38 @@
 	}
 
 	/**
-	 * Guifre Ruiz: This method can be used to crawl more tags and, therefore, more pages in the
-	 * target. However, it slow down a bit the process.
+	 * Click {@link #clickDefaultElements()}, {@link #clickTableElements()} and click
+	 * <code>""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"",
+		        ""refresh"", ""xhr"", ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"",
+		        ""p""</code>
 	 */
 	public void clickMoreElements() {
-		crawlActions.click(""a"");
-		crawlActions.click(""button"");
-		crawlActions.click(""td"");
-		crawlActions.click(""span"");
-		crawlActions.click(""div"");
-		crawlActions.click(""tr"");
-		crawlActions.click(""table"");
-		crawlActions.click(""tbody"");
-		crawlActions.click(""ol"");
-		crawlActions.click(""center"");
-		crawlActions.click(""li"");
-		crawlActions.click(""radio"");
-		crawlActions.click(""non"");
-		crawlActions.click(""meta"");
-		crawlActions.click(""refresh"");
-		crawlActions.click(""xhr"");
-		crawlActions.click(""relative"");
-		crawlActions.click(""link"");
-		crawlActions.click(""self"");
-		crawlActions.click(""form"");
-		crawlActions.click(""input"");
-		crawlActions.click(""option"");
-		crawlActions.click(""img"");
-		crawlActions.click(""p"");
+		clickDefaultElements();
+		clickTableElements();
+		click(""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"",
+		        ""refresh"", ""xhr"", ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"",
+		        ""p"");
+	}
+
+	/**
+	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
+	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}.
+	 * 
+	 * @param tagName
+	 *            the tag name of the elements to be included
+	 * @return this CrawlElement
+	 */
+	public void click(String... tagNames) {
+		for (String tagName : tagNames) {
+			crawlActions.click(tagName);
+		}
+	}
+
+	/**
+	 * Clicks <code>""td"", ""tr"", ""table"", ""tbody""</code>
+	 */
+	public void clickTableElements() {
+		click(""td"", ""tr"", ""table"", ""tbody"");
 	}
 
 	/**
@@ -167,7 +179,7 @@
 	/**
 	 * @return the initial url of the site to crawl
 	 */
-	protected String getUrl() {
+	protected URL getUrl() {
 		return url;
 	}
 
@@ -207,9 +219,9 @@
 	}
 
 	/**
-	 * @return the crawlMaximumRuntime
+	 * @return the crawlMaximumRuntime in millis
 	 */
-	protected int getMaximumRuntime() {
+	protected long getMaximumRuntime() {
 		return maximumRuntime;
 	}
 
@@ -220,8 +232,8 @@
 	 * @param seconds
 	 *            the crawlMaximumRuntime to set
 	 */
-	public void setMaximumRuntime(int seconds) {
-		this.maximumRuntime = seconds;
+	public void setMaximumRuntime(long time, TimeUnit timeUnit) {
+		this.maximumRuntime = timeUnit.toSeconds(time);
 	}
 
 	/**
@@ -242,7 +254,7 @@
 	/**
 	 * @return the number of milliseconds to wait after reloading the url
 	 */
-	protected int getWaitTimeAfterReloadUrl() {
+	protected long getWaitTimeAfterReloadUrl() {
 		return waitTimeAfterReloadUrl;
 	}
 
@@ -250,14 +262,14 @@
 	 * @param milliseconds
 	 *            the number of milliseconds to wait after reloading the url
 	 */
-	public void setWaitTimeAfterReloadUrl(int milliseconds) {
-		this.waitTimeAfterReloadUrl = milliseconds;
+	public void setWaitTimeAfterReloadUrl(long time, TimeUnit unit) {
+		this.waitTimeAfterReloadUrl = unit.toMillis(time);
 	}
 
 	/**
 	 * @return the number the number of milliseconds to wait after an event is fired
 	 */
-	protected int getWaitTimeAfterEvent() {
+	protected long getWaitTimeAfterEvent() {
 		return waitTimeAfterEvent;
 	}
 
@@ -265,8 +277,8 @@
 	 * @param milliseconds
 	 *            the number of milliseconds to wait after an event is fired
 	 */
-	public void setWaitTimeAfterEvent(int milliseconds) {
-		this.waitTimeAfterEvent = milliseconds;
+	public void setWaitTimeAfterEvent(long time, TimeUnit unit) {
+		this.waitTimeAfterEvent = unit.toMillis(time);
 	}
 
 	/**
"
d4fe5d1942b71f951beed4cc2dde154fa0b1c175,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 6b50bed..8bc1089 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -42,7 +42,7 @@
 
 	private List<Plugin> plugins = new ArrayList<Plugin>();
 
-	private CrawlSpecification crawlSpecification = new CrawlSpecification("""");
+	private CrawlSpecification crawlSpecification = new CrawlSpecification(""http://localhost"");
 	private ProxyConfiguration proxyConfiguration = null;
 	private ThreadConfiguration threadConfiguration = new ThreadConfiguration();
 
"
d4fe5d1942b71f951beed4cc2dde154fa0b1c175,Alex Nederlof,ExportableSession.java,MODIFY,setUrl -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/plugins/savecrawlsession/ExportableSession.java b/core/src/main/java/com/crawljax/plugins/savecrawlsession/ExportableSession.java
index b41f241..2110280 100644
--- a/core/src/main/java/com/crawljax/plugins/savecrawlsession/ExportableSession.java
+++ b/core/src/main/java/com/crawljax/plugins/savecrawlsession/ExportableSession.java
@@ -1,5 +1,6 @@
 package com.crawljax.plugins.savecrawlsession;
 
+import java.net.URL;
 import java.util.List;
 import java.util.Map;
 
@@ -19,7 +20,7 @@
 	private Map<Long, Eventable> mapEventables;
 	private List<Transition> transitions;
 	private List<List<Transition>> crawlPaths;
-	private String url;
+	private URL url;
 
 	/**
 	 * @param mapStates
@@ -35,7 +36,7 @@
 	 */
 	public ExportableSession(Map<String, StateVertex> mapStates,
 	        Map<Long, Eventable> mapEventables, List<Transition> transitions,
-	        List<List<Transition>> crawlPaths, String url) {
+	        List<List<Transition>> crawlPaths, URL url) {
 		super();
 		this.mapStates = mapStates;
 		this.mapEventables = mapEventables;
@@ -114,7 +115,7 @@
 	/**
 	 * @return the crawled url
 	 */
-	public String getUrl() {
+	public URL getUrl() {
 		return url;
 	}
 
@@ -122,7 +123,7 @@
 	 * @param url
 	 *            the crawled url
 	 */
-	public void setUrl(String url) {
+	public void setUrl(URL url) {
 		this.url = url;
 	}
 
"
d4fe5d1942b71f951beed4cc2dde154fa0b1c175,Alex Nederlof,LargeTestSuper.java,MODIFY,"getCrawlSpecification -> [String url, int waintAfterEvent, int waitAfterReload] | [String url, long waintAfterEvent, long waitAfterReload]","diff --git a/core/src/test/java/com/crawljax/core/largetests/LargeTestSuper.java b/core/src/test/java/com/crawljax/core/largetests/LargeTestSuper.java
index c04148e..9095a7e 100644
--- a/core/src/test/java/com/crawljax/core/largetests/LargeTestSuper.java
+++ b/core/src/test/java/com/crawljax/core/largetests/LargeTestSuper.java
@@ -6,6 +6,7 @@
 
 import java.util.ArrayList;
 import java.util.List;
+import java.util.concurrent.TimeUnit;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
@@ -284,12 +285,12 @@
 	 *            the amount of time in ms to wait after a reload.
 	 * @return the new CrawlSpecification.
 	 */
-	protected static CrawlSpecification getCrawlSpecification(String url, int waintAfterEvent,
-	        int waitAfterReload) {
+	protected static CrawlSpecification getCrawlSpecification(String url, long waintAfterEvent,
+	        long waitAfterReload) {
 
 		CrawlSpecification crawler = new CrawlSpecification(url);
-		crawler.setWaitTimeAfterEvent(waintAfterEvent);
-		crawler.setWaitTimeAfterReloadUrl(waitAfterReload);
+		crawler.setWaitTimeAfterEvent(waintAfterEvent, TimeUnit.MILLISECONDS);
+		crawler.setWaitTimeAfterReloadUrl(waitAfterReload, TimeUnit.MILLISECONDS);
 		crawler.setDepth(3);
 		crawler.setClickOnce(true);
 
"
5ffba8f9dec2853307bd8de2e3db4b2cbde86ee6,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index 77394ed..83567f5 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -10,8 +10,9 @@
 
 import com.crawljax.browser.BrowserPool;
 import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.condition.ConditionTypeChecker;
 import com.crawljax.condition.browserwaiter.WaitConditionChecker;
-import com.crawljax.condition.crawlcondition.CrawlConditionChecker;
+import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.eventablecondition.EventableConditionChecker;
 import com.crawljax.condition.invariant.Invariant;
 import com.crawljax.core.configuration.CrawlSpecificationReader;
@@ -39,7 +40,7 @@
 	private long startCrawl;
 
 	private final StateComparator stateComparator;
-	private final CrawlConditionChecker crawlConditionChecker;
+	private final ConditionTypeChecker<CrawlCondition> crawlConditionChecker;
 	private final EventableConditionChecker eventableConditionChecker;
 
 	private final WaitConditionChecker waitConditionChecker = new WaitConditionChecker();
@@ -73,11 +74,12 @@
 
 		stateComparator = new StateComparator(crawlerReader.getOracleComparators());
 		invariantList = crawlerReader.getInvariants();
-		crawlConditionChecker = new CrawlConditionChecker(crawlerReader.getCrawlConditions());
+
 		waitConditionChecker.setWaitConditions(crawlerReader.getWaitConditions());
 		eventableConditionChecker =
 		        new EventableConditionChecker(configurationReader.getEventableConditions());
 
+		crawlConditionChecker = new ConditionTypeChecker<>(crawlerReader.getCrawlConditions());
 		elementChecker =
 		        new CandidateElementManager(eventableConditionChecker, crawlConditionChecker);
 
"
5ffba8f9dec2853307bd8de2e3db4b2cbde86ee6,Alex Nederlof,StateFlowGraph.java,MODIFY,"addState -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index aaca56f..da12f27 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -357,10 +357,8 @@
 
 		final KShortestPaths<StateVertex, Eventable> kPaths =
 		        new KShortestPaths<StateVertex, Eventable>(this.sfg, index, Integer.MAX_VALUE);
-		// System.out.println(sfg.toString());
 
 		for (StateVertex state : getDeepStates(index)) {
-			// System.out.println(""Deep State: "" + state.getName());
 
 			try {
 				List<GraphPath<StateVertex, Eventable>> paths = kPaths.getPaths(state);
"
5ffba8f9dec2853307bd8de2e3db4b2cbde86ee6,Alex Nederlof,LargeTestSuper.java,MODIFY,"getCrawlSpecification -> [String url, long waintAfterEvent, long waitAfterReload] | [String url, int waintAfterEvent, int waitAfterReload]","diff --git a/core/src/test/java/com/crawljax/core/largetests/LargeTestSuper.java b/core/src/test/java/com/crawljax/core/largetests/LargeTestSuper.java
index c04148e..c18db7c 100644
--- a/core/src/test/java/com/crawljax/core/largetests/LargeTestSuper.java
+++ b/core/src/test/java/com/crawljax/core/largetests/LargeTestSuper.java
@@ -1,6 +1,10 @@
 package com.crawljax.core.largetests;
 
+import static com.crawljax.browser.matchers.StateFlowGraphMatchers.stateWithDomSubstring;
+import static org.hamcrest.Matchers.everyItem;
+import static org.hamcrest.core.IsNot.not;
 import static org.junit.Assert.assertEquals;
+import static org.junit.Assert.assertThat;
 import static org.junit.Assert.assertTrue;
 import static org.junit.Assert.fail;
 
@@ -61,11 +65,6 @@
 	private static final String INVARIANT_TEXT = ""TEST_INVARIANTS"";
 	private static boolean violatedInvariantStateIsCorrect = false;
 
-	private static final RegexCondition REGEX_CONDITION_TRUE = new RegexCondition(
-	        ""REGEX_CONDITION_TRUE"");
-	private static final NotRegexCondition ALLOW_BUTTON_CLICK = new NotRegexCondition(
-	        ""DONT_CLICK_BUTTONS_ON_THIS_PAGE"");
-
 	private static final String TITLE_RESULT_RANDOM_INPUT = ""RESULT_RANDOM_INPUT"";
 	private static final String REGEX_RESULT_RANDOM_INPUT = ""[a-zA-Z]{8};"" + ""[a-zA-Z]{8};""
 	        + ""(true|false);"" + ""(true|false);"" + ""OPTION[1234];"" + ""[a-zA-Z]{8}"";
@@ -92,6 +91,153 @@
 	private static final String[] MULTIPLE_INPUT_RESULTS = { ""first;foo;true;false;OPTION1;same"",
 	        ""second;bar;false;true;OPTION2;same"", "";foo;true;false;OPTION1;same"" };
 
+	/* setting up */
+
+	/**
+	 * retrieve / build the crawlspecification for the given arguments.
+	 * 
+	 * @param url
+	 *            the url where the large test run is located.
+	 * @param waintAfterEvent
+	 *            the amount of time in ms to wait after an event is fired.
+	 * @param waitAfterReload
+	 *            the amount of time in ms to wait after a reload.
+	 * @return the new CrawlSpecification.
+	 */
+	protected static CrawlSpecification getCrawlSpecification(String url, int waintAfterEvent,
+	        int waitAfterReload) {
+
+		CrawlSpecification crawler = new CrawlSpecification(url);
+		crawler.setWaitTimeAfterEvent(waintAfterEvent);
+		crawler.setWaitTimeAfterReloadUrl(waitAfterReload);
+		crawler.setDepth(3);
+		crawler.setClickOnce(true);
+
+		addCrawlElements(crawler);
+
+		crawler.setInputSpecification(getInputSpecification());
+
+		addCrawlConditions(crawler);
+		addOracleComparators(crawler);
+		addInvariants(crawler);
+		addWaitConditions(crawler);
+
+		return crawler;
+	}
+
+	private static InputSpecification getInputSpecification() {
+		InputSpecification input = new InputSpecification();
+		input.field(""textManual"").setValue(MANUAL_INPUT_TEXT);
+		input.field(""text2Manual"").setValue(MANUAL_INPUT_TEXT2);
+		input.field(""checkboxManual"").setValue(MANUAL_INPUT_CHECKBOX);
+		input.field(""radioManual"").setValue(MANUAL_INPUT_RADIO);
+		input.field(""selectManual"").setValue(MANUAL_INPUT_SELECT);
+		input.field(""textareaManual"").setValue(MANUAL_INPUT_TEXTAREA);
+
+		Form form = new Form();
+		form.field(""textMultiple"").setValues(MULTIPLE_INPUT_TEXT);
+		form.field(""text2Multiple"").setValues(MULTIPLE_INPUT_TEXT2);
+		form.field(""checkboxMultiple"").setValues(MULTIPLE_INPUT_CHECKBOX);
+		form.field(""radioMultiple"").setValues(MULTIPLE_INPUT_RADIO);
+		form.field(""selectMultiple"").setValues(MULTIPLE_INPUT_SELECT);
+		form.field(""textareaMultiple"").setValues(MULTIPLE_INPUT_TEXTAREA);
+		input.setValuesInForm(form).beforeClickElement(""a"").withText(""Submit Multiple"");
+		return input;
+	}
+
+	private static void addWaitConditions(CrawlSpecification crawler) {
+		crawler.waitFor(""testWaitCondition.html"", 2000, new ExpectedVisibleCondition(
+		        new Identification(How.id, ""SLOW_WIDGET"")));
+	}
+
+	private static void addInvariants(CrawlSpecification crawler) {
+		// should always fail on test invariant page
+		NotXPathCondition neverDivWithInvariantViolationId =
+		        new NotXPathCondition(""//DIV[@id='INVARIANT_VIOLATION']"");
+		crawler.addInvariant(VIOLATED_INVARIANT_DESCRIPTION, neverDivWithInvariantViolationId);
+
+		// should never fail
+		RegexCondition onInvariantsPagePreCondition = new RegexCondition(INVARIANT_TEXT);
+		XPathCondition expectElement =
+		        new XPathCondition(""//DIV[@id='SHOULD_ALWAYS_BE_ON_THIS_PAGE']"");
+		crawler.addInvariant(""testInvariantWithPrecondiions"", expectElement,
+		        onInvariantsPagePreCondition);
+	}
+
+	private static void addCrawlElements(CrawlSpecification crawler) {
+		crawler.click(""a"");
+		crawler.click(""div"").withText(CLICK_TEXT);
+		crawler.click(""div"").underXPath(""//SPAN[@id='"" + CLICK_UNDER_XPATH_ID + ""']"");
+		crawler.click(""button"").when(new NotRegexCondition(""DONT_CLICK_BUTTONS_ON_THIS_PAGE""));
+		crawler.click(""div"").withAttribute(ATTRIBUTE, ""condition"").when(new RegexCondition(
+		        ""REGEX_CONDITION_TRUE""));
+
+		crawler.dontClick(""a"").withText(DONT_CLICK_TEXT);
+		crawler.dontClick(""a"").withAttribute(ATTRIBUTE, DONT_CLICK_TEXT);
+		crawler.dontClick(""a"").underXPath(""//DIV[@id='"" + DONT_CLICK_UNDER_XPATH_ID + ""']"");
+	}
+
+	private static void addOracleComparators(CrawlSpecification crawler) {
+		crawler.addOracleComparator(""style"", new StyleComparator());
+		crawler.addOracleComparator(""date"", new DateComparator());
+	}
+
+	private static void addCrawlConditions(CrawlSpecification crawler) {
+		crawler.addCrawlCondition(""DONT_CRAWL_ME"", new NotRegexCondition(""DONT_CRAWL_ME""));
+	}
+
+	/**
+	 * Add the plugins to the given crawljaxConfiguration.
+	 * 
+	 * @param crawljaxConfiguration
+	 *            the configuration to add the plugins to.
+	 */
+	protected static void addPlugins(CrawljaxConfiguration crawljaxConfiguration) {
+		// plugin to retrieve session data
+		crawljaxConfiguration.addPlugin(new PostCrawlingPlugin() {
+
+			@Override
+			public void postCrawling(CrawlSession session) {
+				LargeTestSuper.session = session;
+
+			}
+
+		});
+
+		crawljaxConfiguration.addPlugin(new OnInvariantViolationPlugin() {
+
+			@Override
+			public void onInvariantViolation(Invariant invariant, CrawlSession session) {
+				LargeTestSuper.violatedInvariants.add(invariant);
+				if (session.getCurrentState().getDom().contains(INVARIANT_TEXT)) {
+					violatedInvariantStateIsCorrect = true;
+					LOG.warn(""Invariant violated: "" + invariant.getDescription());
+				}
+			}
+		});
+
+		crawljaxConfiguration.addPlugin(new OnNewStatePlugin() {
+			@Override
+			public void onNewState(CrawlSession session) {
+				try {
+					if (!session.getCurrentState().equals(session.getInitialState())) {
+						assertEquals(
+						        ""Target State from ExactEventPath equals current state"",
+						        session.getCurrentCrawlPath()
+						                .get(session.getCurrentCrawlPath().size() - 1)
+						                .getTargetStateVertex(), session.getCurrentState());
+					}
+				} catch (CrawljaxException e) {
+					Assert.fail(e.getMessage());
+				}
+			}
+		});
+	}
+
+	private StateFlowGraph getStateFlowGraph() {
+		return session.getStateFlowGraph();
+	}
+
 	/**
 	 * Tests random input.
 	 */
@@ -165,10 +311,8 @@
 	 */
 	@Test
 	public void testForIllegalStates() {
-		for (StateVertex state : getStateFlowGraph().getAllStates()) {
-			assertTrue(""Only legal states: "" + state.getName(),
-			        !state.getDom().contains(ILLEGAL_STATE));
-		}
+		assertThat(getStateFlowGraph().getAllStates(),
+		        everyItem(not(stateWithDomSubstring(ILLEGAL_STATE))));
 	}
 
 	/**
@@ -270,150 +414,4 @@
 		assertTrue(""Too less nodes found at level 2 number of nodes: "" + level2 + "" Required: ""
 		        + 5, level2 >= 5);
 	}
-
-	/* setting up */
-
-	/**
-	 * retrieve / build the crawlspecification for the given arguments.
-	 * 
-	 * @param url
-	 *            the url where the large test run is located.
-	 * @param waintAfterEvent
-	 *            the amount of time in ms to wait after an event is fired.
-	 * @param waitAfterReload
-	 *            the amount of time in ms to wait after a reload.
-	 * @return the new CrawlSpecification.
-	 */
-	protected static CrawlSpecification getCrawlSpecification(String url, int waintAfterEvent,
-	        int waitAfterReload) {
-
-		CrawlSpecification crawler = new CrawlSpecification(url);
-		crawler.setWaitTimeAfterEvent(waintAfterEvent);
-		crawler.setWaitTimeAfterReloadUrl(waitAfterReload);
-		crawler.setDepth(3);
-		crawler.setClickOnce(true);
-
-		addCrawlElements(crawler);
-
-		crawler.setInputSpecification(getInputSpecification());
-
-		addCrawlConditions(crawler);
-		addOracleComparators(crawler);
-		addInvariants(crawler);
-		addWaitConditions(crawler);
-
-		return crawler;
-	}
-
-	private static InputSpecification getInputSpecification() {
-		InputSpecification input = new InputSpecification();
-		input.field(""textManual"").setValue(MANUAL_INPUT_TEXT);
-		input.field(""text2Manual"").setValue(MANUAL_INPUT_TEXT2);
-		input.field(""checkboxManual"").setValue(MANUAL_INPUT_CHECKBOX);
-		input.field(""radioManual"").setValue(MANUAL_INPUT_RADIO);
-		input.field(""selectManual"").setValue(MANUAL_INPUT_SELECT);
-		input.field(""textareaManual"").setValue(MANUAL_INPUT_TEXTAREA);
-
-		Form form = new Form();
-		form.field(""textMultiple"").setValues(MULTIPLE_INPUT_TEXT);
-		form.field(""text2Multiple"").setValues(MULTIPLE_INPUT_TEXT2);
-		form.field(""checkboxMultiple"").setValues(MULTIPLE_INPUT_CHECKBOX);
-		form.field(""radioMultiple"").setValues(MULTIPLE_INPUT_RADIO);
-		form.field(""selectMultiple"").setValues(MULTIPLE_INPUT_SELECT);
-		form.field(""textareaMultiple"").setValues(MULTIPLE_INPUT_TEXTAREA);
-		input.setValuesInForm(form).beforeClickElement(""a"").withText(""Submit Multiple"");
-		return input;
-	}
-
-	private static void addWaitConditions(CrawlSpecification crawler) {
-		crawler.waitFor(""testWaitCondition.html"", 2000, new ExpectedVisibleCondition(
-		        new Identification(How.id, ""SLOW_WIDGET"")));
-	}
-
-	private static void addInvariants(CrawlSpecification crawler) {
-		// should always fail on test invariant page
-		NotXPathCondition neverDivWithInvariantViolationId =
-		        new NotXPathCondition(""//DIV[@id='INVARIANT_VIOLATION']"");
-		crawler.addInvariant(VIOLATED_INVARIANT_DESCRIPTION, neverDivWithInvariantViolationId);
-
-		// should never fail
-		RegexCondition onInvariantsPagePreCondition = new RegexCondition(INVARIANT_TEXT);
-		XPathCondition expectElement =
-		        new XPathCondition(""//DIV[@id='SHOULD_ALWAYS_BE_ON_THIS_PAGE']"");
-		crawler.addInvariant(""testInvariantWithPrecondiions"", expectElement,
-		        onInvariantsPagePreCondition);
-	}
-
-	private static void addCrawlElements(CrawlSpecification crawler) {
-		crawler.click(""a"");
-		crawler.click(""div"").withText(CLICK_TEXT);
-		crawler.click(""div"").underXPath(""//SPAN[@id='"" + CLICK_UNDER_XPATH_ID + ""']"");
-		crawler.click(""button"").when(ALLOW_BUTTON_CLICK);
-		crawler.click(""div"").withAttribute(ATTRIBUTE, ""condition"").when(REGEX_CONDITION_TRUE);
-
-		crawler.dontClick(""a"").withText(DONT_CLICK_TEXT);
-		crawler.dontClick(""a"").withAttribute(ATTRIBUTE, DONT_CLICK_TEXT);
-		crawler.dontClick(""a"").underXPath(""//DIV[@id='"" + DONT_CLICK_UNDER_XPATH_ID + ""']"");
-	}
-
-	private static void addOracleComparators(CrawlSpecification crawler) {
-		crawler.addOracleComparator(""style"", new StyleComparator());
-		crawler.addOracleComparator(""date"", new DateComparator());
-	}
-
-	private static void addCrawlConditions(CrawlSpecification crawler) {
-		crawler.addCrawlCondition(""DONT_CRAWL_ME"", new NotRegexCondition(""DONT_CRAWL_ME""));
-	}
-
-	/**
-	 * Add the plugins to the given crawljaxConfiguration.
-	 * 
-	 * @param crawljaxConfiguration
-	 *            the configuration to add the plugins to.
-	 */
-	protected static void addPlugins(CrawljaxConfiguration crawljaxConfiguration) {
-		// plugin to retrieve session data
-		crawljaxConfiguration.addPlugin(new PostCrawlingPlugin() {
-
-			@Override
-			public void postCrawling(CrawlSession session) {
-				LargeTestSuper.session = session;
-
-			}
-
-		});
-
-		crawljaxConfiguration.addPlugin(new OnInvariantViolationPlugin() {
-
-			@Override
-			public void onInvariantViolation(Invariant invariant, CrawlSession session) {
-				LargeTestSuper.violatedInvariants.add(invariant);
-				if (session.getCurrentState().getDom().contains(INVARIANT_TEXT)) {
-					violatedInvariantStateIsCorrect = true;
-					LOG.warn(""Invariant violated: "" + invariant.getDescription());
-				}
-			}
-		});
-
-		crawljaxConfiguration.addPlugin(new OnNewStatePlugin() {
-			@Override
-			public void onNewState(CrawlSession session) {
-				try {
-					if (!session.getCurrentState().equals(session.getInitialState())) {
-						assertEquals(
-						        ""Target State from ExactEventPath equals current state"",
-						        session.getCurrentCrawlPath()
-						                .get(session.getCurrentCrawlPath().size() - 1)
-						                .getTargetStateVertex(), session.getCurrentState());
-					}
-				} catch (CrawljaxException e) {
-					Assert.fail(e.getMessage());
-				}
-			}
-		});
-	}
-
-	private StateFlowGraph getStateFlowGraph() {
-		return session.getStateFlowGraph();
-	}
 }
"
ddf6957605eac54dd04f20e47ad025ee85c68351,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index 77394ed..83567f5 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -10,8 +10,9 @@
 
 import com.crawljax.browser.BrowserPool;
 import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.condition.ConditionTypeChecker;
 import com.crawljax.condition.browserwaiter.WaitConditionChecker;
-import com.crawljax.condition.crawlcondition.CrawlConditionChecker;
+import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.eventablecondition.EventableConditionChecker;
 import com.crawljax.condition.invariant.Invariant;
 import com.crawljax.core.configuration.CrawlSpecificationReader;
@@ -39,7 +40,7 @@
 	private long startCrawl;
 
 	private final StateComparator stateComparator;
-	private final CrawlConditionChecker crawlConditionChecker;
+	private final ConditionTypeChecker<CrawlCondition> crawlConditionChecker;
 	private final EventableConditionChecker eventableConditionChecker;
 
 	private final WaitConditionChecker waitConditionChecker = new WaitConditionChecker();
@@ -73,11 +74,12 @@
 
 		stateComparator = new StateComparator(crawlerReader.getOracleComparators());
 		invariantList = crawlerReader.getInvariants();
-		crawlConditionChecker = new CrawlConditionChecker(crawlerReader.getCrawlConditions());
+
 		waitConditionChecker.setWaitConditions(crawlerReader.getWaitConditions());
 		eventableConditionChecker =
 		        new EventableConditionChecker(configurationReader.getEventableConditions());
 
+		crawlConditionChecker = new ConditionTypeChecker<>(crawlerReader.getCrawlConditions());
 		elementChecker =
 		        new CandidateElementManager(eventableConditionChecker, crawlConditionChecker);
 
"
ddf6957605eac54dd04f20e47ad025ee85c68351,Alex Nederlof,StateFlowGraph.java,MODIFY,"addState -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index aaca56f..da12f27 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -357,10 +357,8 @@
 
 		final KShortestPaths<StateVertex, Eventable> kPaths =
 		        new KShortestPaths<StateVertex, Eventable>(this.sfg, index, Integer.MAX_VALUE);
-		// System.out.println(sfg.toString());
 
 		for (StateVertex state : getDeepStates(index)) {
-			// System.out.println(""Deep State: "" + state.getName());
 
 			try {
 				List<GraphPath<StateVertex, Eventable>> paths = kPaths.getPaths(state);
"
28ee341e9b2f57eb87bb9695075f95aebfe7a97f,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index f14cb5e..3d23ff0 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -34,7 +34,6 @@
 import org.w3c.dom.Document;
 import org.w3c.dom.Element;
 import org.w3c.dom.NodeList;
-import org.xml.sax.SAXException;
 
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.AcceptAllFramesChecker;
"
28ee341e9b2f57eb87bb9695075f95aebfe7a97f,Alex Nederlof,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index a0b29d5..7a6121b 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -9,7 +9,6 @@
 import org.w3c.dom.Document;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
-import org.xml.sax.SAXException;
 
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.core.state.Element;
"
e9953c541e1c128062b4e3796b73751f63635960,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 22df7a8..f14cb5e 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -47,7 +47,7 @@
 import com.crawljax.forms.FormInput;
 import com.crawljax.forms.InputValue;
 import com.crawljax.forms.RandomInputValueGenerator;
-import com.crawljax.util.Helper;
+import com.crawljax.util.DomUtils;
 
 /**
  * @author mesbah
@@ -341,15 +341,11 @@
 	public String getDom() {
 
 		try {
-			String dom = toUniformDOM(Helper.getDocumentToString(getDomTreeWithFrames()));
-			LOGGER.debug(dom);
+			String dom = toUniformDOM(DomUtils.getDocumentToString(getDomTreeWithFrames()));
+			LOGGER.trace(dom);
 			return dom;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			LOGGER.warn(e.getMessage(), e);
-			return """";
-		} catch (CrawljaxException e) {
-			LOGGER.warn(e.getMessage(), e);
+		} catch (WebDriverException | CrawljaxException e) {
+			LOGGER.warn(""Could not get the dom"", e);
 			return """";
 		}
 	}
@@ -565,11 +561,9 @@
 	private Document getDomTreeWithFrames() throws CrawljaxException {
 
 		try {
-			Document document = Helper.getDocument(browser.getPageSource());
+			Document document = DomUtils.asDocument(browser.getPageSource());
 			appendFrameContent(document.getDocumentElement(), document, """");
 			return document;
-		} catch (SAXException e) {
-			throw new CrawljaxException(e.getMessage(), e);
 		} catch (IOException e) {
 			throw new CrawljaxException(e.getMessage(), e);
 		}
@@ -603,7 +597,7 @@
 
 			Element frameElement = nodeList.get(i);
 
-			String nameId = Helper.getFrameIdentification(frameElement);
+			String nameId = DomUtils.getFrameIdentification(frameElement);
 
 			if (nameId != null
 			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
@@ -622,19 +616,13 @@
 				browser.switchTo().defaultContent();
 
 				try {
-					Element toAppendElement = Helper.getDocument(toAppend).getDocumentElement();
+					Element toAppendElement = DomUtils.asDocument(toAppend).getDocumentElement();
 					Element importedElement =
 					        (Element) document.importNode(toAppendElement, true);
 					frameElement.appendChild(importedElement);
 
 					appendFrameContent(importedElement, document, frameIdentification);
-				} catch (DOMException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				} catch (SAXException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				} catch (IOException e) {
+				} catch (DOMException | IOException e) {
 					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
 					        + "" continuing..."", e);
 				}
"
e9953c541e1c128062b4e3796b73751f63635960,Ali Mesbah,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index bfe18b8..83567f5 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -1,6 +1,5 @@
 package com.crawljax.core;
 
-import java.util.List;
 import java.util.concurrent.TimeUnit;
 
 import net.jcip.annotations.GuardedBy;
@@ -11,8 +10,9 @@
 
 import com.crawljax.browser.BrowserPool;
 import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.condition.ConditionTypeChecker;
 import com.crawljax.condition.browserwaiter.WaitConditionChecker;
-import com.crawljax.condition.crawlcondition.CrawlConditionChecker;
+import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.eventablecondition.EventableConditionChecker;
 import com.crawljax.condition.invariant.Invariant;
 import com.crawljax.core.configuration.CrawlSpecificationReader;
@@ -40,7 +40,7 @@
 	private long startCrawl;
 
 	private final StateComparator stateComparator;
-	private final CrawlConditionChecker crawlConditionChecker;
+	private final ConditionTypeChecker<CrawlCondition> crawlConditionChecker;
 	private final EventableConditionChecker eventableConditionChecker;
 
 	private final WaitConditionChecker waitConditionChecker = new WaitConditionChecker();
@@ -74,11 +74,12 @@
 
 		stateComparator = new StateComparator(crawlerReader.getOracleComparators());
 		invariantList = crawlerReader.getInvariants();
-		crawlConditionChecker = new CrawlConditionChecker(crawlerReader.getCrawlConditions());
+
 		waitConditionChecker.setWaitConditions(crawlerReader.getWaitConditions());
 		eventableConditionChecker =
 		        new EventableConditionChecker(configurationReader.getEventableConditions());
 
+		crawlConditionChecker = new ConditionTypeChecker<>(crawlerReader.getCrawlConditions());
 		elementChecker =
 		        new CandidateElementManager(eventableConditionChecker, crawlConditionChecker);
 
"
e9953c541e1c128062b4e3796b73751f63635960,Ali Mesbah,CrawlSpecification.java,MODIFY,"setMaximumRuntime -> [long time, TimeUnit timeUnit] | [int seconds]","diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index bd571d4..56127d5 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -7,6 +7,7 @@
 import com.crawljax.condition.browserwaiter.WaitCondition;
 import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.invariant.Invariant;
+import com.crawljax.core.configuration.CrawlActions.ExcludeByParentBuilder;
 import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.oraclecomparator.Comparator;
 import com.crawljax.oraclecomparator.OracleComparator;
@@ -46,6 +47,9 @@
  * @author DannyRoest@gmail.com (Danny Roest)
  * @version $Id$
  */
+/**
+ * @author alex
+ */
 public class CrawlSpecification {
 
 	private static final int DEFAULT_MAXIMUMRUNTIME = 3600;
@@ -154,6 +158,13 @@
 	}
 
 	/**
+	 * {@link CrawlActions#dontClickChildrenOf(String)}
+	 */
+	public ExcludeByParentBuilder dontClickChildrenOf(String tagname) {
+		return crawlActions.dontClickChildrenOf(tagname);
+	}
+
+	/**
 	 * @return the initial url of the site to crawl
 	 */
 	protected String getUrl() {
"
e9953c541e1c128062b4e3796b73751f63635960,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 0d95586..6b50bed 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -8,7 +8,7 @@
 import com.crawljax.browser.WebDriverBrowserBuilder;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.plugin.Plugin;
-import com.crawljax.util.Helper;
+import com.crawljax.util.DomUtils;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableList.Builder;
@@ -144,7 +144,6 @@
 				eventableConditions.add(eventableCondition);
 			}
 		}
-
 		return eventableConditions.build();
 	}
 
@@ -199,7 +198,7 @@
 	 * @return The path of the outputFolder with a trailing slash.
 	 */
 	protected String getOutputFolder() {
-		return Helper.addFolderSlashIfNeeded(outputFolder);
+		return DomUtils.addFolderSlashIfNeeded(outputFolder);
 	}
 
 	/**
@@ -207,7 +206,7 @@
 	 *            The (absolute) path of the output folder.
 	 */
 	public void setOutputFolder(String path) {
-		this.outputFolder = Helper.addFolderSlashIfNeeded(path);
+		this.outputFolder = DomUtils.addFolderSlashIfNeeded(path);
 	}
 
 	/**
"
e9953c541e1c128062b4e3796b73751f63635960,Ali Mesbah,StateFlowGraph.java,MODIFY,"addState -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index aaca56f..da12f27 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -357,10 +357,8 @@
 
 		final KShortestPaths<StateVertex, Eventable> kPaths =
 		        new KShortestPaths<StateVertex, Eventable>(this.sfg, index, Integer.MAX_VALUE);
-		// System.out.println(sfg.toString());
 
 		for (StateVertex state : getDeepStates(index)) {
-			// System.out.println(""Deep State: "" + state.getName());
 
 			try {
 				List<GraphPath<StateVertex, Eventable>> paths = kPaths.getPaths(state);
"
e9953c541e1c128062b4e3796b73751f63635960,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index 46ae2c7..ac9c003 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -16,14 +16,13 @@
 import org.w3c.dom.Element;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
-import org.xml.sax.SAXException;
 
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.CandidateElement;
 import com.crawljax.core.configuration.InputSpecification;
 import com.crawljax.core.exception.BrowserConnectionException;
-import com.crawljax.util.Helper;
+import com.crawljax.util.DomUtils;
 import com.crawljax.util.XPathHelper;
 
 /**
@@ -62,7 +61,7 @@
 	}
 
 	private static final String[] ALLOWED_INPUT_TYPES =
-	        { ""text"", ""radio"", ""checkbox"", ""password"" };
+	{ ""text"", ""radio"", ""checkbox"", ""password"" };
 
 	/**
 	 * Fills in the element with the InputValues for input TODO: improve this by using WebDriver
@@ -88,7 +87,7 @@
 					if (text.equals("""")) {
 						return;
 					}
-					String js = Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
+					String js = DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
 					js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
 					browser.executeJavaScript(js);
 				}
@@ -97,7 +96,7 @@
 				if (input.getType().equals(""checkbox"")) {
 					for (InputValue inputValue : input.getInputValues()) {
 						String js =
-						        Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
+						        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
 						boolean check;
 						if (!randomFieldValue) {
 							check = inputValue.isChecked();
@@ -122,7 +121,7 @@
 					for (InputValue inputValue : input.getInputValues()) {
 						if (inputValue.isChecked()) {
 							String js =
-							        Helper.getJSGetElement(XPathHelper
+							        DomUtils.getJSGetElement(XPathHelper
 							                .getXPathExpression(element));
 							js += ""try{ATUSA_element.checked=true;}catch(e){}"";
 							browser.executeJavaScript(js);
@@ -135,7 +134,7 @@
 					for (InputValue inputValue : input.getInputValues()) {
 						// if(browser.getDriver()==null){
 						String js =
-						        Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
+						        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
 						js +=
 						        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
 						                + ""if(ATUSA_element.options[i].value=='""
@@ -200,7 +199,7 @@
 		List<FormInput> formInputs = new ArrayList<FormInput>();
 		Document dom;
 		try {
-			dom = Helper.getDocument(browser.getDom());
+			dom = DomUtils.asDocument(browser.getDom());
 			List<Node> nodes = getInputElements(dom);
 			for (Node node : nodes) {
 				FormInput formInput =
@@ -209,11 +208,7 @@
 					formInputs.add(formInput);
 				}
 			}
-		} catch (Exception e) {
-			// TODO Stefan; refactor this Exception
-			if (e instanceof BrowserConnectionException) {
-				throw (BrowserConnectionException) e;
-			}
+		} catch (IOException e) {
 			LOGGER.error(e.getMessage(), e);
 		}
 		return formInputs;
@@ -236,19 +231,13 @@
 	 *            form input list.
 	 */
 	public void handleFormElements(List<FormInput> formInputs) {
-		Document dom;
-
 		try {
-			dom = Helper.getDocument(browser.getDomWithoutIframeContent());
+			Document dom = DomUtils.asDocument(browser.getDomWithoutIframeContent());
 			for (FormInput input : formInputs) {
 				LOGGER.debug(""Filling in: "" + input);
 				setInputElementValue(formInputValueHelper.getBelongingNode(input, dom), input);
 			}
-		} catch (SAXException e) {
-			LOGGER.error(e.getMessage(), e);
-		} catch (IOException e) {
-			LOGGER.error(e.getMessage(), e);
-		} catch (XPathExpressionException e) {
+		} catch (IOException | XPathExpressionException e) {
 			LOGGER.error(e.getMessage(), e);
 		}
 
"
e9953c541e1c128062b4e3796b73751f63635960,Ali Mesbah,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index 605a685..a0b29d5 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -53,15 +53,13 @@
 	/**
 	 * @param logging
 	 *            Whether to do logging.
-	 * @return equivalent xpath of element equivalent to Eventable
+	 * @return equivalent xpath of element equivalent to Eventable or an empty string if the DOM
+	 *         cannot be read.
 	 */
 	public String resolve(boolean logging) {
 		Document dom = null;
 		try {
-			dom = Helper.getDocument(browser.getDom());
-		} catch (SAXException e) {
-			LOGGER.error(e.getMessage(), e);
-			return """";
+			dom = DomUtils.asDocument(browser.getDom());
 		} catch (IOException e) {
 			LOGGER.error(e.getMessage(), e);
 			return """";
@@ -69,7 +67,7 @@
 
 		try {
 			String xpathEventable = eventable.getIdentification().getValue();
-			Node nodeSameXpath = Helper.getElementByXpath(dom, xpathEventable);
+			Node nodeSameXpath = DomUtils.getElementByXpath(dom, xpathEventable);
 			if (nodeSameXpath != null) {
 				Element elementSameXpath = new Element(nodeSameXpath);
 				if (logging) {
"
e9953c541e1c128062b4e3796b73751f63635960,Ali Mesbah,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 3693671..5529735 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -1,8 +1,6 @@
-/**
- * Created Dec 13, 2007
- */
 package com.crawljax.util;
 
+import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
@@ -19,23 +17,24 @@
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
 
+import com.google.common.base.Strings;
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableList.Builder;
+
 /**
  * Utility class that contains methods used by Crawljax and some plugin to deal with XPath
  * resolving, constructing etc.
- * 
- * @author mesbah
- * @version $Id$
  */
 public final class XPathHelper {
-	/**
-     * 
-     */
+
+	private static final Pattern TAG_PATTERN = Pattern
+	        .compile(""(?<=[/|::])[a-zA-z]+(?=([/|\\[]|$))"");
+
+	private static final Pattern ID_PATTERN = Pattern.compile(""(@[a-zA-Z]+)"");
+
 	private static final String FULL_XPATH_CACHE = ""FULL_XPATH_CACHE"";
 	private static final int MAX_SEARCH_LOOPS = 10000;
 
-	private XPathHelper() {
-	}
-
 	/**
 	 * Reverse Engineers an XPath Expression of a given Node in the DOM.
 	 * 
@@ -110,19 +109,13 @@
 	/**
 	 * Returns the list of nodes which match the expression xpathExpr in the String domStr.
 	 * 
-	 * @param domStr
-	 *            the string of the document to search in
-	 * @param xpathExpr
-	 *            the xpath query
-	 * @author cor-paul
 	 * @return the list of nodes which match the query
-	 * @throws Exception
-	 *             On erorr.
+	 * @throws XPathExpressionException
+	 * @throws IOException
 	 */
 	public static NodeList evaluateXpathExpression(String domStr, String xpathExpr)
-	        throws Exception {
-		Document dom = Helper.getDocument(domStr);
-
+	        throws XPathExpressionException, IOException {
+		Document dom = DomUtils.asDocument(domStr);
 		return evaluateXpathExpression(dom, xpathExpr);
 	}
 
@@ -145,7 +138,6 @@
 		XPathExpression expr = xpath.compile(xpathExpr);
 		Object result = expr.evaluate(dom, XPathConstants.NODESET);
 		NodeList nodes = (NodeList) result;
-
 		return nodes;
 	}
 
@@ -158,22 +150,19 @@
 	 * @param xpathExpression
 	 *            The expression to find the element.
 	 * @return list of XPaths retrieved by xpathExpression.
+	 * @throws XPathExpressionException
 	 */
-	public static List<String> getXpathForXPathExpressions(Document dom, String xpathExpression) {
-		NodeList nodeList;
-		try {
-			nodeList = XPathHelper.evaluateXpathExpression(dom, xpathExpression);
-		} catch (XPathExpressionException e) {
-			return null;
-		}
-		List<String> result = new ArrayList<String>();
+	public static ImmutableList<String> getXpathForXPathExpressions(Document dom,
+	        String xpathExpression) throws XPathExpressionException {
+		NodeList nodeList = XPathHelper.evaluateXpathExpression(dom, xpathExpression);
+		Builder<String> result = ImmutableList.builder();
 		if (nodeList.getLength() > 0) {
 			for (int i = 0; i < nodeList.getLength(); i++) {
 				Node n = nodeList.item(i);
 				result.add(getXPathExpression(n));
 			}
 		}
-		return result;
+		return result.build();
 	}
 
 	/**
@@ -182,26 +171,33 @@
 	 * @return formatted xpath with tag names in uppercase and attributes in lowercase
 	 */
 	public static String formatXPath(String xpath) {
-		String formatted = xpath;
-		Pattern p = Pattern.compile(""(/(?:[-a-zA-Z]+::)?+)([a-zA-Z]+)"");
-		Matcher m = p.matcher(formatted);
-
-		for (int i = 0; m.find(i); i++) {
-			i = m.start();
-			formatted = m.replaceFirst(m.group(1) + m.group(2).toUpperCase());
-			m = p.matcher(formatted);
-		}
-		p = Pattern.compile(""(@[a-zA-Z]+)"");
-		m = p.matcher(formatted);
-
-		for (int i = 0; m.find(i); i++) {
-			i = m.start();
-			formatted = m.replaceFirst(m.group().toLowerCase());
-			m = p.matcher(formatted);
-		}
+		String formatted = capitalizeTagNames(xpath);
+		formatted = lowerCaseAttributes(formatted);
 		return formatted;
 	}
 
+	private static String lowerCaseAttributes(String formatted) {
+		Matcher m = ID_PATTERN.matcher(formatted);
+		StringBuffer sb = new StringBuffer();
+		while (m.find()) {
+			String text = m.group();
+			m.appendReplacement(sb, Matcher.quoteReplacement(text.toLowerCase()));
+		}
+		m.appendTail(sb);
+		return sb.toString();
+	}
+
+	private static String capitalizeTagNames(String xpath) {
+		Matcher m = TAG_PATTERN.matcher(xpath);
+		StringBuffer sb = new StringBuffer();
+		while (m.find()) {
+			String text = m.group();
+			m.appendReplacement(sb, Matcher.quoteReplacement(text.toUpperCase()));
+		}
+		m.appendTail(sb);
+		return sb.toString();
+	}
+
 	/**
 	 * @param xpath
 	 *            The xpath expression to find the last element of.
@@ -223,10 +219,10 @@
 	 * @return string without the before [
 	 */
 	private static String stripEndSquareBrackets(String string) {
-		if (string.indexOf(""["") == -1) {
-			return string;
+		if (string.contains(""["")) {
+			return string.substring(0, string.indexOf('['));
 		} else {
-			return string.substring(0, string.indexOf(""[""));
+			return string;
 		}
 	}
 
@@ -249,19 +245,18 @@
 		int number;
 		// System.out.println(xpath);
 		for (String element : elements) {
-			if (!element.equals("""") && !element.startsWith(""@"") && element.indexOf(""()"") == -1) {
+			if (!element.isEmpty() && !element.startsWith(""@"") && !element.contains(""()"")) {
 				if (element.indexOf(""["") != -1) {
 					try {
 						number =
 						        Integer.parseInt(element.substring(element.indexOf(""["") + 1,
 						                element.indexOf(""]"")));
-					} catch (Exception e) {
+					} catch (NumberFormatException e) {
 						return -1;
 					}
 				} else {
 					number = 1;
 				}
-				// System.out.println(""number: "" + number);
 				for (int i = 0; i < number; i++) {
 					// find new open element
 					temp = dom.indexOf(""<"" + stripEndSquareBrackets(element), pos);
@@ -311,25 +306,20 @@
 			if (dom.indexOf(openElement, pos) == -1 && dom.indexOf(closeElement, pos) == -1) {
 				return -1;
 			}
-			// System.out.println(""hierzo: "" + dom.substring(pos));
 			if (dom.indexOf(openElement, pos) < dom.indexOf(closeElement, pos)
 			        && dom.indexOf(openElement, pos) != -1) {
 				openElements++;
 				pos = dom.indexOf(openElement, pos) + 1;
-				// System.out.println(""open: "" + dom.substring(pos-1));
 			} else {
 
 				openElements--;
 				pos = dom.indexOf(closeElement, pos) + 1;
-				// System.out.println(""close: "" + dom.substring(pos-1));
 			}
-			// System.out.println(openElements);
 			if (openElements == 0) {
 				break;
 			}
 			i++;
 		}
-		// System.out.println(""Finished: "" + dom.substring(pos-1));
 		return pos - 1;
 
 	}
@@ -353,14 +343,14 @@
 	 *         text()
 	 */
 	public static String stripXPathToElement(String xpath) {
-		if (xpath != null && !xpath.equals("""")) {
-			if (xpath.toLowerCase().indexOf(""/text()"") != -1) {
+		if (!Strings.isNullOrEmpty(xpath)) {
+			if (xpath.toLowerCase().contains(""/text()"")) {
 				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/text()""));
 			}
-			if (xpath.toLowerCase().indexOf(""/comment()"") != -1) {
+			if (xpath.toLowerCase().contains(""/comment()"")) {
 				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/comment()""));
 			}
-			if (xpath.indexOf(""@"") != -1) {
+			if (xpath.contains(""@"")) {
 				xpath = xpath.substring(0, xpath.indexOf(""@"") - 1);
 			}
 		}
@@ -368,4 +358,7 @@
 		return xpath;
 	}
 
+	private XPathHelper() {
+	}
+
 }
"
64b64acf128c16b077a345cd2ea03b9f6abbe367,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index f14cb5e..2c59e55 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -257,7 +257,7 @@
 	 *            The URL.
 	 */
 	@Override
-	public void goToUrl(String url) {
+	public void goToUrl(URL url) {
 		try {
 			browser.navigate().to(url);
 			Thread.sleep(this.crawlWaitReload);
"
64b64acf128c16b077a345cd2ea03b9f6abbe367,Ali Mesbah,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 56127d5..7485d52 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -1,12 +1,16 @@
 package com.crawljax.core.configuration;
 
+import java.net.MalformedURLException;
+import java.net.URL;
 import java.util.List;
+import java.util.concurrent.TimeUnit;
 
 import com.crawljax.condition.Condition;
 import com.crawljax.condition.browserwaiter.ExpectedCondition;
 import com.crawljax.condition.browserwaiter.WaitCondition;
 import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.invariant.Invariant;
+import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlActions.ExcludeByParentBuilder;
 import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.oraclecomparator.Comparator;
@@ -43,20 +47,14 @@
  * //restrict the scope of the crawling<br />
  * crawler.setCrawlMaximumStates(15);<br />
  * crawler.setCrawlDepth(2);
- * 
- * @author DannyRoest@gmail.com (Danny Roest)
- * @version $Id$
- */
-/**
- * @author alex
  */
 public class CrawlSpecification {
 
-	private static final int DEFAULT_MAXIMUMRUNTIME = 3600;
-	private static final int DEFAULT_WAITTIMEAFTERRELOADURL = 500;
-	private static final int DEFAULT_WAITTIMEAFTEREVENT = 500;
+	private static final long DEFAULT_MAXIMUMRUNTIME = TimeUnit.HOURS.toMillis(1);
+	private static final long DEFAULT_WAITTIMEAFTERRELOADURL = 500;
+	private static final long DEFAULT_WAITTIMEAFTEREVENT = 500;
 
-	private final String url;
+	private final URL url;
 
 	private final List<EventType> crawlEvents = Lists.newLinkedList();
 	private final List<String> ignoredFrameIdentifiers = Lists.newLinkedList();
@@ -67,9 +65,10 @@
 
 	private int depth = 2;
 	private int maximumStates = 0;
-	private int maximumRuntime = DEFAULT_MAXIMUMRUNTIME; // in seconds
-	private int waitTimeAfterReloadUrl = DEFAULT_WAITTIMEAFTERRELOADURL; // in milliseconds
-	private int waitTimeAfterEvent = DEFAULT_WAITTIMEAFTEREVENT; // in milliseconds
+	private long maximumRuntime = DEFAULT_MAXIMUMRUNTIME;
+	private long waitTimeAfterReloadUrl = DEFAULT_WAITTIMEAFTERRELOADURL;
+	private long waitTimeAfterEvent = DEFAULT_WAITTIMEAFTEREVENT;
+
 	private final CrawlActions crawlActions = new CrawlActions();
 
 	private boolean randomInputInForms = true;
@@ -84,11 +83,20 @@
 	 * @param url
 	 *            the site to crawl
 	 */
-	public CrawlSpecification(String url) {
+	public CrawlSpecification(URL url) {
 		this.crawlEvents.add(EventType.click);
 		this.url = url;
 	}
 
+	public CrawlSpecification(String url) {
+		this.crawlEvents.add(EventType.click);
+		try {
+			this.url = new URL(url);
+		} catch (MalformedURLException e) {
+			throw new CrawljaxException(""Invalid URL: "" + url);
+		}
+	}
+
 	/**
 	 * Specifies that Crawljax should click all the default clickable elements. These include: All
 	 * anchor tags All buttons
@@ -101,34 +109,38 @@
 	}
 
 	/**
-	 * Guifre Ruiz: This method can be used to crawl more tags and, therefore, more pages in the
-	 * target. However, it slow down a bit the process.
+	 * Click {@link #clickDefaultElements()}, {@link #clickTableElements()} and click
+	 * <code>""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"",
+		        ""refresh"", ""xhr"", ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"",
+		        ""p""</code>
 	 */
 	public void clickMoreElements() {
-		crawlActions.click(""a"");
-		crawlActions.click(""button"");
-		crawlActions.click(""td"");
-		crawlActions.click(""span"");
-		crawlActions.click(""div"");
-		crawlActions.click(""tr"");
-		crawlActions.click(""table"");
-		crawlActions.click(""tbody"");
-		crawlActions.click(""ol"");
-		crawlActions.click(""center"");
-		crawlActions.click(""li"");
-		crawlActions.click(""radio"");
-		crawlActions.click(""non"");
-		crawlActions.click(""meta"");
-		crawlActions.click(""refresh"");
-		crawlActions.click(""xhr"");
-		crawlActions.click(""relative"");
-		crawlActions.click(""link"");
-		crawlActions.click(""self"");
-		crawlActions.click(""form"");
-		crawlActions.click(""input"");
-		crawlActions.click(""option"");
-		crawlActions.click(""img"");
-		crawlActions.click(""p"");
+		clickDefaultElements();
+		clickTableElements();
+		click(""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"",
+		        ""refresh"", ""xhr"", ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"",
+		        ""p"");
+	}
+
+	/**
+	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
+	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}.
+	 * 
+	 * @param tagName
+	 *            the tag name of the elements to be included
+	 * @return this CrawlElement
+	 */
+	public void click(String... tagNames) {
+		for (String tagName : tagNames) {
+			crawlActions.click(tagName);
+		}
+	}
+
+	/**
+	 * Clicks <code>""td"", ""tr"", ""table"", ""tbody""</code>
+	 */
+	public void clickTableElements() {
+		click(""td"", ""tr"", ""table"", ""tbody"");
 	}
 
 	/**
@@ -167,7 +179,7 @@
 	/**
 	 * @return the initial url of the site to crawl
 	 */
-	protected String getUrl() {
+	protected URL getUrl() {
 		return url;
 	}
 
@@ -207,9 +219,9 @@
 	}
 
 	/**
-	 * @return the crawlMaximumRuntime
+	 * @return the crawlMaximumRuntime in millis
 	 */
-	protected int getMaximumRuntime() {
+	protected long getMaximumRuntime() {
 		return maximumRuntime;
 	}
 
@@ -220,8 +232,8 @@
 	 * @param seconds
 	 *            the crawlMaximumRuntime to set
 	 */
-	public void setMaximumRuntime(int seconds) {
-		this.maximumRuntime = seconds;
+	public void setMaximumRuntime(long time, TimeUnit timeUnit) {
+		this.maximumRuntime = timeUnit.toSeconds(time);
 	}
 
 	/**
@@ -242,7 +254,7 @@
 	/**
 	 * @return the number of milliseconds to wait after reloading the url
 	 */
-	protected int getWaitTimeAfterReloadUrl() {
+	protected long getWaitTimeAfterReloadUrl() {
 		return waitTimeAfterReloadUrl;
 	}
 
@@ -250,14 +262,14 @@
 	 * @param milliseconds
 	 *            the number of milliseconds to wait after reloading the url
 	 */
-	public void setWaitTimeAfterReloadUrl(int milliseconds) {
-		this.waitTimeAfterReloadUrl = milliseconds;
+	public void setWaitTimeAfterReloadUrl(long time, TimeUnit unit) {
+		this.waitTimeAfterReloadUrl = unit.toMillis(time);
 	}
 
 	/**
 	 * @return the number the number of milliseconds to wait after an event is fired
 	 */
-	protected int getWaitTimeAfterEvent() {
+	protected long getWaitTimeAfterEvent() {
 		return waitTimeAfterEvent;
 	}
 
@@ -265,8 +277,8 @@
 	 * @param milliseconds
 	 *            the number of milliseconds to wait after an event is fired
 	 */
-	public void setWaitTimeAfterEvent(int milliseconds) {
-		this.waitTimeAfterEvent = milliseconds;
+	public void setWaitTimeAfterEvent(long time, TimeUnit unit) {
+		this.waitTimeAfterEvent = unit.toMillis(time);
 	}
 
 	/**
"
64b64acf128c16b077a345cd2ea03b9f6abbe367,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 6b50bed..8bc1089 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -42,7 +42,7 @@
 
 	private List<Plugin> plugins = new ArrayList<Plugin>();
 
-	private CrawlSpecification crawlSpecification = new CrawlSpecification("""");
+	private CrawlSpecification crawlSpecification = new CrawlSpecification(""http://localhost"");
 	private ProxyConfiguration proxyConfiguration = null;
 	private ThreadConfiguration threadConfiguration = new ThreadConfiguration();
 
"
b1cda1ac9a25b886dd9c96e2ccaf96a379022d59,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 2c59e55..208aa3a 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -34,7 +34,6 @@
 import org.w3c.dom.Document;
 import org.w3c.dom.Element;
 import org.w3c.dom.NodeList;
-import org.xml.sax.SAXException;
 
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.AcceptAllFramesChecker;
"
b1cda1ac9a25b886dd9c96e2ccaf96a379022d59,Ali Mesbah,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index a0b29d5..7a6121b 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -9,7 +9,6 @@
 import org.w3c.dom.Document;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
-import org.xml.sax.SAXException;
 
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.core.state.Element;
"
eba7b563333e5b04c3265951764f1e9de354ab4c,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 3d23ff0..208aa3a 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -256,7 +256,7 @@
 	 *            The URL.
 	 */
 	@Override
-	public void goToUrl(String url) {
+	public void goToUrl(URL url) {
 		try {
 			browser.navigate().to(url);
 			Thread.sleep(this.crawlWaitReload);
"
eba7b563333e5b04c3265951764f1e9de354ab4c,Alex Nederlof,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 56127d5..7485d52 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -1,12 +1,16 @@
 package com.crawljax.core.configuration;
 
+import java.net.MalformedURLException;
+import java.net.URL;
 import java.util.List;
+import java.util.concurrent.TimeUnit;
 
 import com.crawljax.condition.Condition;
 import com.crawljax.condition.browserwaiter.ExpectedCondition;
 import com.crawljax.condition.browserwaiter.WaitCondition;
 import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.invariant.Invariant;
+import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlActions.ExcludeByParentBuilder;
 import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.oraclecomparator.Comparator;
@@ -43,20 +47,14 @@
  * //restrict the scope of the crawling<br />
  * crawler.setCrawlMaximumStates(15);<br />
  * crawler.setCrawlDepth(2);
- * 
- * @author DannyRoest@gmail.com (Danny Roest)
- * @version $Id$
- */
-/**
- * @author alex
  */
 public class CrawlSpecification {
 
-	private static final int DEFAULT_MAXIMUMRUNTIME = 3600;
-	private static final int DEFAULT_WAITTIMEAFTERRELOADURL = 500;
-	private static final int DEFAULT_WAITTIMEAFTEREVENT = 500;
+	private static final long DEFAULT_MAXIMUMRUNTIME = TimeUnit.HOURS.toMillis(1);
+	private static final long DEFAULT_WAITTIMEAFTERRELOADURL = 500;
+	private static final long DEFAULT_WAITTIMEAFTEREVENT = 500;
 
-	private final String url;
+	private final URL url;
 
 	private final List<EventType> crawlEvents = Lists.newLinkedList();
 	private final List<String> ignoredFrameIdentifiers = Lists.newLinkedList();
@@ -67,9 +65,10 @@
 
 	private int depth = 2;
 	private int maximumStates = 0;
-	private int maximumRuntime = DEFAULT_MAXIMUMRUNTIME; // in seconds
-	private int waitTimeAfterReloadUrl = DEFAULT_WAITTIMEAFTERRELOADURL; // in milliseconds
-	private int waitTimeAfterEvent = DEFAULT_WAITTIMEAFTEREVENT; // in milliseconds
+	private long maximumRuntime = DEFAULT_MAXIMUMRUNTIME;
+	private long waitTimeAfterReloadUrl = DEFAULT_WAITTIMEAFTERRELOADURL;
+	private long waitTimeAfterEvent = DEFAULT_WAITTIMEAFTEREVENT;
+
 	private final CrawlActions crawlActions = new CrawlActions();
 
 	private boolean randomInputInForms = true;
@@ -84,11 +83,20 @@
 	 * @param url
 	 *            the site to crawl
 	 */
-	public CrawlSpecification(String url) {
+	public CrawlSpecification(URL url) {
 		this.crawlEvents.add(EventType.click);
 		this.url = url;
 	}
 
+	public CrawlSpecification(String url) {
+		this.crawlEvents.add(EventType.click);
+		try {
+			this.url = new URL(url);
+		} catch (MalformedURLException e) {
+			throw new CrawljaxException(""Invalid URL: "" + url);
+		}
+	}
+
 	/**
 	 * Specifies that Crawljax should click all the default clickable elements. These include: All
 	 * anchor tags All buttons
@@ -101,34 +109,38 @@
 	}
 
 	/**
-	 * Guifre Ruiz: This method can be used to crawl more tags and, therefore, more pages in the
-	 * target. However, it slow down a bit the process.
+	 * Click {@link #clickDefaultElements()}, {@link #clickTableElements()} and click
+	 * <code>""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"",
+		        ""refresh"", ""xhr"", ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"",
+		        ""p""</code>
 	 */
 	public void clickMoreElements() {
-		crawlActions.click(""a"");
-		crawlActions.click(""button"");
-		crawlActions.click(""td"");
-		crawlActions.click(""span"");
-		crawlActions.click(""div"");
-		crawlActions.click(""tr"");
-		crawlActions.click(""table"");
-		crawlActions.click(""tbody"");
-		crawlActions.click(""ol"");
-		crawlActions.click(""center"");
-		crawlActions.click(""li"");
-		crawlActions.click(""radio"");
-		crawlActions.click(""non"");
-		crawlActions.click(""meta"");
-		crawlActions.click(""refresh"");
-		crawlActions.click(""xhr"");
-		crawlActions.click(""relative"");
-		crawlActions.click(""link"");
-		crawlActions.click(""self"");
-		crawlActions.click(""form"");
-		crawlActions.click(""input"");
-		crawlActions.click(""option"");
-		crawlActions.click(""img"");
-		crawlActions.click(""p"");
+		clickDefaultElements();
+		clickTableElements();
+		click(""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"",
+		        ""refresh"", ""xhr"", ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"",
+		        ""p"");
+	}
+
+	/**
+	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
+	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}.
+	 * 
+	 * @param tagName
+	 *            the tag name of the elements to be included
+	 * @return this CrawlElement
+	 */
+	public void click(String... tagNames) {
+		for (String tagName : tagNames) {
+			crawlActions.click(tagName);
+		}
+	}
+
+	/**
+	 * Clicks <code>""td"", ""tr"", ""table"", ""tbody""</code>
+	 */
+	public void clickTableElements() {
+		click(""td"", ""tr"", ""table"", ""tbody"");
 	}
 
 	/**
@@ -167,7 +179,7 @@
 	/**
 	 * @return the initial url of the site to crawl
 	 */
-	protected String getUrl() {
+	protected URL getUrl() {
 		return url;
 	}
 
@@ -207,9 +219,9 @@
 	}
 
 	/**
-	 * @return the crawlMaximumRuntime
+	 * @return the crawlMaximumRuntime in millis
 	 */
-	protected int getMaximumRuntime() {
+	protected long getMaximumRuntime() {
 		return maximumRuntime;
 	}
 
@@ -220,8 +232,8 @@
 	 * @param seconds
 	 *            the crawlMaximumRuntime to set
 	 */
-	public void setMaximumRuntime(int seconds) {
-		this.maximumRuntime = seconds;
+	public void setMaximumRuntime(long time, TimeUnit timeUnit) {
+		this.maximumRuntime = timeUnit.toSeconds(time);
 	}
 
 	/**
@@ -242,7 +254,7 @@
 	/**
 	 * @return the number of milliseconds to wait after reloading the url
 	 */
-	protected int getWaitTimeAfterReloadUrl() {
+	protected long getWaitTimeAfterReloadUrl() {
 		return waitTimeAfterReloadUrl;
 	}
 
@@ -250,14 +262,14 @@
 	 * @param milliseconds
 	 *            the number of milliseconds to wait after reloading the url
 	 */
-	public void setWaitTimeAfterReloadUrl(int milliseconds) {
-		this.waitTimeAfterReloadUrl = milliseconds;
+	public void setWaitTimeAfterReloadUrl(long time, TimeUnit unit) {
+		this.waitTimeAfterReloadUrl = unit.toMillis(time);
 	}
 
 	/**
 	 * @return the number the number of milliseconds to wait after an event is fired
 	 */
-	protected int getWaitTimeAfterEvent() {
+	protected long getWaitTimeAfterEvent() {
 		return waitTimeAfterEvent;
 	}
 
@@ -265,8 +277,8 @@
 	 * @param milliseconds
 	 *            the number of milliseconds to wait after an event is fired
 	 */
-	public void setWaitTimeAfterEvent(int milliseconds) {
-		this.waitTimeAfterEvent = milliseconds;
+	public void setWaitTimeAfterEvent(long time, TimeUnit unit) {
+		this.waitTimeAfterEvent = unit.toMillis(time);
 	}
 
 	/**
"
eba7b563333e5b04c3265951764f1e9de354ab4c,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 6b50bed..8bc1089 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -42,7 +42,7 @@
 
 	private List<Plugin> plugins = new ArrayList<Plugin>();
 
-	private CrawlSpecification crawlSpecification = new CrawlSpecification("""");
+	private CrawlSpecification crawlSpecification = new CrawlSpecification(""http://localhost"");
 	private ProxyConfiguration proxyConfiguration = null;
 	private ThreadConfiguration threadConfiguration = new ThreadConfiguration();
 
"
678237d7c6eb1eace604bbc28092ad3d14c5b7bf,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 208aa3a..e9fd0da 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -366,8 +366,6 @@
 		m = p.matcher(html);
 		htmlFormatted = m.replaceAll("""");
 
-		// html = html.replace(""<?xml:namespace prefix = gwt >"", """");
-
 		// TODO (Stefan), Following lines are a serious performance bottle neck...
 		// Document doc = Helper.getDocument(htmlFormatted);
 		// htmlFormatted = Helper.getDocumentToString(doc);
@@ -543,7 +541,6 @@
 					browser.switchTo().window(handle);
 					LOGGER.info(""Closing other window with title \"""" + browser.getTitle() + ""\"""");
 					browser.close();
-					// browser.switchTo().defaultContent();
 					browser.switchTo().window(current);
 				}
 			}
@@ -654,9 +651,7 @@
 	public String getDomWithoutIframeContent() {
 		try {
 			String dom = browser.getPageSource();
-			// logger.debug(""driver.source: "" + dom);
 			String result = toUniformDOM(dom);
-			// logger.debug(""driver.source toUniformDom: "" + result);
 			return result;
 		} catch (WebDriverException e) {
 			throwIfConnectionException(e);
"
678237d7c6eb1eace604bbc28092ad3d14c5b7bf,Alex Nederlof,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/core/src/main/java/com/crawljax/core/CrawlQueue.java b/core/src/main/java/com/crawljax/core/CrawlQueue.java
index 45dbed6..0d76156 100644
--- a/core/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/core/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -16,7 +16,6 @@
  * separate threads in a Queue like fashion (FILO).
  * 
  * @author Stefan Lenselink <S.R.Lenselink@student.tudelft.nl>
- * @version $Id$
  */
 public class CrawlQueue extends Stack<Runnable> implements BlockingQueue<Runnable> {
 
"
678237d7c6eb1eace604bbc28092ad3d14c5b7bf,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index 83567f5..aca2a42 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -28,7 +28,6 @@
  * The Crawljax Controller class is the core of Crawljax.
  * 
  * @author mesbah
- * @version $Id$
  */
 public class CrawljaxController implements CrawlQueueManager {
 
"
678237d7c6eb1eace604bbc28092ad3d14c5b7bf,Alex Nederlof,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 7485d52..8b8c566 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -117,9 +117,8 @@
 	public void clickMoreElements() {
 		clickDefaultElements();
 		clickTableElements();
-		click(""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"",
-		        ""refresh"", ""xhr"", ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"",
-		        ""p"");
+		click(""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"", ""refresh"", ""xhr"",
+		        ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"", ""p"");
 	}
 
 	/**
"
678237d7c6eb1eace604bbc28092ad3d14c5b7bf,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 8bc1089..c6c2008 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -117,8 +117,7 @@
 		// clicked and not by another random crawlTag
 		return ImmutableList.<CrawlElement> builder()
 		        .addAll(getInputSpecification().getCrawlElements())
-		        .addAll(crawlSpecification.crawlActions().getCrawlElements())
-		        .build();
+		        .addAll(crawlSpecification.crawlActions().getCrawlElements()).build();
 	}
 
 	/**
@@ -128,8 +127,7 @@
 		return ImmutableList.<CrawlElement> builder()
 		        .addAll(getInputSpecification().getCrawlElements())
 		        .addAll(crawlSpecification.crawlActions().getCrawlElements())
-		        .addAll(getCrawlSpecification().crawlActions()
-		                .getCrawlElementsExcluded())
+		        .addAll(getCrawlSpecification().crawlActions().getCrawlElementsExcluded())
 		        .build();
 	}
 
"
678237d7c6eb1eace604bbc28092ad3d14c5b7bf,Alex Nederlof,FormInputField.java,MODIFY,setValues -> [boolean values] | [String values],"diff --git a/core/src/main/java/com/crawljax/core/configuration/FormInputField.java b/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
index c2fd585..dc6e88c 100644
--- a/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
@@ -14,7 +14,6 @@
  * @see Form
  * @see Form#field(String)
  * @author DannyRoest@gmail.com (Danny Roest)
- * @version $Id$
  */
 public class FormInputField extends InputField {
 
"
678237d7c6eb1eace604bbc28092ad3d14c5b7bf,Alex Nederlof,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/core/src/main/java/com/crawljax/core/configuration/InputField.java b/core/src/main/java/com/crawljax/core/configuration/InputField.java
index 474d562..7108d39 100644
--- a/core/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -13,7 +13,6 @@
  * @see InputSpecification#field(String)
  * @see InputSpecification#fields(String...)
  * @author DannyRoest@gmail.com (Danny Roest)
- * @version $Id$
  */
 public class InputField {
 
"
678237d7c6eb1eace604bbc28092ad3d14c5b7bf,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index ac9c003..6854b96 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -28,9 +28,6 @@
 /**
  * Handles form values and fills in the form input elements with random values of the defined
  * values.
- * 
- * @author dannyroest@gmail.com (Danny Roest)
- * @version $Id$
  */
 public class FormHandler {
 	private static final Logger LOGGER = LoggerFactory.getLogger(FormHandler.class.getName());
@@ -61,18 +58,15 @@
 	}
 
 	private static final String[] ALLOWED_INPUT_TYPES =
-	{ ""text"", ""radio"", ""checkbox"", ""password"" };
+	        { ""text"", ""radio"", ""checkbox"", ""password"" };
 
 	/**
 	 * Fills in the element with the InputValues for input TODO: improve this by using WebDriver
 	 * options?
-	 * 
-	 * @param element
-	 * @param input
 	 */
 	private void setInputElementValue(Node element, FormInput input) {
 
-		LOGGER.debug(""INPUTFIELD: "" + input.getIdentification() + "" ("" + input.getType() + "")"");
+		LOGGER.debug(""INPUTFIELD: {} ({})"", input.getIdentification(), input.getType());
 		if (element == null) {
 			return;
 		}
@@ -84,7 +78,7 @@
 				        || input.getType().equalsIgnoreCase(""password"")
 				        || input.getType().equalsIgnoreCase(""hidden"")) {
 					String text = input.getInputValues().iterator().next().getValue();
-					if (text.equals("""")) {
+					if ("""".equals(text)) {
 						return;
 					}
 					String js = DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
@@ -93,7 +87,7 @@
 				}
 
 				// check/uncheck checkboxes
-				if (input.getType().equals(""checkbox"")) {
+				if (""checkbox"".equals(input.getType())) {
 					for (InputValue inputValue : input.getInputValues()) {
 						String js =
 						        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
@@ -158,7 +152,6 @@
 	}
 
 	/**
-	 * @param dom
 	 * @return all input element in dom
 	 */
 	private List<Node> getInputElements(Document dom) {
@@ -171,8 +164,7 @@
 				Node candidate = nodeList.item(i);
 				Node typeAttribute = candidate.getAttributes().getNamedItem(""type"");
 				if (typeAttribute == null
-				        || (typeAttribute != null && allowedTypes.contains(typeAttribute
-				                .getNodeValue()))) {
+				        || (allowedTypes.contains(typeAttribute.getNodeValue()))) {
 					nodes.add(nodeList.item(i));
 				}
 			}
"
678237d7c6eb1eace604bbc28092ad3d14c5b7bf,Alex Nederlof,AttributeInjector.java,MODIFY,"removeInjectedAttributes -> [HTMLElement element, String attrName] | [Vector injectedElements, String attrName]","diff --git a/core/src/main/java/com/crawljax/util/AttributeInjector.java b/core/src/main/java/com/crawljax/util/AttributeInjector.java
index 8bc9fc6..ad942d9 100644
--- a/core/src/main/java/com/crawljax/util/AttributeInjector.java
+++ b/core/src/main/java/com/crawljax/util/AttributeInjector.java
@@ -12,8 +12,6 @@
 
 /**
  * Attribute injector class.
- * 
- * @version $Id$
  */
 public final class AttributeInjector {
 
@@ -39,7 +37,6 @@
 			return null;
 		}
 		srcAttrValue += ""?"" + attrName + ""="" + value;
-		// System.out.println(""Setting value for src to: "" + srcAttrValue);
 		element.setAttribute(""src"", srcAttrValue);
 		return element;
 	}
@@ -60,7 +57,6 @@
 	public static boolean isInjected(Node node, String attrName, String value, boolean checkValue) {
 
 		NamedNodeMap attributes = node.getAttributes();
-		// String tmp = """";
 		// if there are no attributes we know the node does not contain the
 		// injected attribute
 		if (attributes == null) {
"
678237d7c6eb1eace604bbc28092ad3d14c5b7bf,Alex Nederlof,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index 5f23e7a..e9c9b51 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -145,7 +145,6 @@
 		String info = """";
 		if (!text.equals("""")) {
 			info += ""\"""" + text + ""\"" "";
-			// Helper.removeNewLines(this.text.trim()) + "" - "";
 		}
 		if (element != null) {
 			if (element.hasAttribute(""id"")) {
@@ -194,8 +193,6 @@
 	 * @return the changed dom.
 	 */
 	public static Document removeTags(Document dom, String tagName) {
-		// NodeList list = dom.getElementsByTagName(""SCRIPT"");
-
 		NodeList list;
 		try {
 			list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
@@ -208,7 +205,6 @@
 				}
 
 				list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
-				// list = dom.getElementsByTagName(""SCRIPT"");
 			}
 		} catch (XPathExpressionException e) {
 			LOGGER.error(""Error while removing tag "" + tagName, e);
@@ -257,22 +253,16 @@
 			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
 			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
 			// TODO should be fixed to read doctype declaration
-			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			// ""-//W3C//DTD XHTML 1.0 Transitional//EN\""
-			// \""http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"");
 			transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
 			        ""-//W3C//DTD XHTML 1.0 Strict//EN\"" ""
 			                + ""\""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"");
 
-			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			// ""-//W3C//DTD HTML 4.01//EN\"" \""http://www.w3.org/TR/html4/strict.dtd"");
 			DOMSource source = new DOMSource(dom);
 
 			ByteArrayOutputStream out = new ByteArrayOutputStream();
 			Result result = new StreamResult(out);
 			transformer.transform(source, result);
 
-			// System.out.println(""Injected Javascript!"");
 			return out.toByteArray();
 		} catch (TransformerException e) {
 			LOGGER.error(""Error while converting the document to a byte array"", e);
"
678237d7c6eb1eace604bbc28092ad3d14c5b7bf,Alex Nederlof,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index 7a6121b..8d44723 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -18,7 +18,6 @@
  * class for finding and checking elements.
  * 
  * @author danny
- * @version $Id$
  */
 public class ElementResolver {
 	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class.getName());
"
678237d7c6eb1eace604bbc28092ad3d14c5b7bf,Alex Nederlof,PrettyHTML.java,MODIFY,"prettyHTML -> [String html] | [String html, String strIndent]","diff --git a/core/src/main/java/com/crawljax/util/PrettyHTML.java b/core/src/main/java/com/crawljax/util/PrettyHTML.java
index b13adc9..d67a0eb 100644
--- a/core/src/main/java/com/crawljax/util/PrettyHTML.java
+++ b/core/src/main/java/com/crawljax/util/PrettyHTML.java
@@ -6,7 +6,6 @@
  * Class for making presenting HTML without changing it's structure.
  * 
  * @author Danny
- * @version $Id$
  */
 public final class PrettyHTML {
 
"
678237d7c6eb1eace604bbc28092ad3d14c5b7bf,Alex Nederlof,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 5529735..05cdb79 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -243,7 +243,6 @@
 		int pos = 0;
 		int temp;
 		int number;
-		// System.out.println(xpath);
 		for (String element : elements) {
 			if (!element.isEmpty() && !element.startsWith(""@"") && !element.contains(""()"")) {
 				if (element.indexOf(""["") != -1) {
@@ -269,8 +268,6 @@
 							pos =
 							        getCloseElementLocation(dom, pos,
 							                stripEndSquareBrackets(element));
-							// pos = dom.indexOf(""<"" +
-							// stripEndSquareBrackets(element), pos) + 1;
 						}
 
 					}
"
429dec2d2ff25fd0d2d48527a33feae207b22ea3,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 208aa3a..e9fd0da 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -366,8 +366,6 @@
 		m = p.matcher(html);
 		htmlFormatted = m.replaceAll("""");
 
-		// html = html.replace(""<?xml:namespace prefix = gwt >"", """");
-
 		// TODO (Stefan), Following lines are a serious performance bottle neck...
 		// Document doc = Helper.getDocument(htmlFormatted);
 		// htmlFormatted = Helper.getDocumentToString(doc);
@@ -543,7 +541,6 @@
 					browser.switchTo().window(handle);
 					LOGGER.info(""Closing other window with title \"""" + browser.getTitle() + ""\"""");
 					browser.close();
-					// browser.switchTo().defaultContent();
 					browser.switchTo().window(current);
 				}
 			}
@@ -654,9 +651,7 @@
 	public String getDomWithoutIframeContent() {
 		try {
 			String dom = browser.getPageSource();
-			// logger.debug(""driver.source: "" + dom);
 			String result = toUniformDOM(dom);
-			// logger.debug(""driver.source toUniformDom: "" + result);
 			return result;
 		} catch (WebDriverException e) {
 			throwIfConnectionException(e);
"
429dec2d2ff25fd0d2d48527a33feae207b22ea3,Ali Mesbah,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/core/src/main/java/com/crawljax/core/CrawlQueue.java b/core/src/main/java/com/crawljax/core/CrawlQueue.java
index 45dbed6..0d76156 100644
--- a/core/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/core/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -16,7 +16,6 @@
  * separate threads in a Queue like fashion (FILO).
  * 
  * @author Stefan Lenselink <S.R.Lenselink@student.tudelft.nl>
- * @version $Id$
  */
 public class CrawlQueue extends Stack<Runnable> implements BlockingQueue<Runnable> {
 
"
429dec2d2ff25fd0d2d48527a33feae207b22ea3,Ali Mesbah,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index 83567f5..aca2a42 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -28,7 +28,6 @@
  * The Crawljax Controller class is the core of Crawljax.
  * 
  * @author mesbah
- * @version $Id$
  */
 public class CrawljaxController implements CrawlQueueManager {
 
"
429dec2d2ff25fd0d2d48527a33feae207b22ea3,Ali Mesbah,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 7485d52..8b8c566 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -117,9 +117,8 @@
 	public void clickMoreElements() {
 		clickDefaultElements();
 		clickTableElements();
-		click(""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"",
-		        ""refresh"", ""xhr"", ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"",
-		        ""p"");
+		click(""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"", ""refresh"", ""xhr"",
+		        ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"", ""p"");
 	}
 
 	/**
"
429dec2d2ff25fd0d2d48527a33feae207b22ea3,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 8bc1089..c6c2008 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -117,8 +117,7 @@
 		// clicked and not by another random crawlTag
 		return ImmutableList.<CrawlElement> builder()
 		        .addAll(getInputSpecification().getCrawlElements())
-		        .addAll(crawlSpecification.crawlActions().getCrawlElements())
-		        .build();
+		        .addAll(crawlSpecification.crawlActions().getCrawlElements()).build();
 	}
 
 	/**
@@ -128,8 +127,7 @@
 		return ImmutableList.<CrawlElement> builder()
 		        .addAll(getInputSpecification().getCrawlElements())
 		        .addAll(crawlSpecification.crawlActions().getCrawlElements())
-		        .addAll(getCrawlSpecification().crawlActions()
-		                .getCrawlElementsExcluded())
+		        .addAll(getCrawlSpecification().crawlActions().getCrawlElementsExcluded())
 		        .build();
 	}
 
"
429dec2d2ff25fd0d2d48527a33feae207b22ea3,Ali Mesbah,FormInputField.java,MODIFY,setValues -> [boolean values] | [String values],"diff --git a/core/src/main/java/com/crawljax/core/configuration/FormInputField.java b/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
index c2fd585..dc6e88c 100644
--- a/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
@@ -14,7 +14,6 @@
  * @see Form
  * @see Form#field(String)
  * @author DannyRoest@gmail.com (Danny Roest)
- * @version $Id$
  */
 public class FormInputField extends InputField {
 
"
429dec2d2ff25fd0d2d48527a33feae207b22ea3,Ali Mesbah,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/core/src/main/java/com/crawljax/core/configuration/InputField.java b/core/src/main/java/com/crawljax/core/configuration/InputField.java
index 474d562..7108d39 100644
--- a/core/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -13,7 +13,6 @@
  * @see InputSpecification#field(String)
  * @see InputSpecification#fields(String...)
  * @author DannyRoest@gmail.com (Danny Roest)
- * @version $Id$
  */
 public class InputField {
 
"
429dec2d2ff25fd0d2d48527a33feae207b22ea3,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index ac9c003..6854b96 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -28,9 +28,6 @@
 /**
  * Handles form values and fills in the form input elements with random values of the defined
  * values.
- * 
- * @author dannyroest@gmail.com (Danny Roest)
- * @version $Id$
  */
 public class FormHandler {
 	private static final Logger LOGGER = LoggerFactory.getLogger(FormHandler.class.getName());
@@ -61,18 +58,15 @@
 	}
 
 	private static final String[] ALLOWED_INPUT_TYPES =
-	{ ""text"", ""radio"", ""checkbox"", ""password"" };
+	        { ""text"", ""radio"", ""checkbox"", ""password"" };
 
 	/**
 	 * Fills in the element with the InputValues for input TODO: improve this by using WebDriver
 	 * options?
-	 * 
-	 * @param element
-	 * @param input
 	 */
 	private void setInputElementValue(Node element, FormInput input) {
 
-		LOGGER.debug(""INPUTFIELD: "" + input.getIdentification() + "" ("" + input.getType() + "")"");
+		LOGGER.debug(""INPUTFIELD: {} ({})"", input.getIdentification(), input.getType());
 		if (element == null) {
 			return;
 		}
@@ -84,7 +78,7 @@
 				        || input.getType().equalsIgnoreCase(""password"")
 				        || input.getType().equalsIgnoreCase(""hidden"")) {
 					String text = input.getInputValues().iterator().next().getValue();
-					if (text.equals("""")) {
+					if ("""".equals(text)) {
 						return;
 					}
 					String js = DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
@@ -93,7 +87,7 @@
 				}
 
 				// check/uncheck checkboxes
-				if (input.getType().equals(""checkbox"")) {
+				if (""checkbox"".equals(input.getType())) {
 					for (InputValue inputValue : input.getInputValues()) {
 						String js =
 						        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
@@ -158,7 +152,6 @@
 	}
 
 	/**
-	 * @param dom
 	 * @return all input element in dom
 	 */
 	private List<Node> getInputElements(Document dom) {
@@ -171,8 +164,7 @@
 				Node candidate = nodeList.item(i);
 				Node typeAttribute = candidate.getAttributes().getNamedItem(""type"");
 				if (typeAttribute == null
-				        || (typeAttribute != null && allowedTypes.contains(typeAttribute
-				                .getNodeValue()))) {
+				        || (allowedTypes.contains(typeAttribute.getNodeValue()))) {
 					nodes.add(nodeList.item(i));
 				}
 			}
"
429dec2d2ff25fd0d2d48527a33feae207b22ea3,Ali Mesbah,AttributeInjector.java,MODIFY,"removeInjectedAttributes -> [HTMLElement element, String attrName] | [Vector injectedElements, String attrName]","diff --git a/core/src/main/java/com/crawljax/util/AttributeInjector.java b/core/src/main/java/com/crawljax/util/AttributeInjector.java
index 8bc9fc6..ad942d9 100644
--- a/core/src/main/java/com/crawljax/util/AttributeInjector.java
+++ b/core/src/main/java/com/crawljax/util/AttributeInjector.java
@@ -12,8 +12,6 @@
 
 /**
  * Attribute injector class.
- * 
- * @version $Id$
  */
 public final class AttributeInjector {
 
@@ -39,7 +37,6 @@
 			return null;
 		}
 		srcAttrValue += ""?"" + attrName + ""="" + value;
-		// System.out.println(""Setting value for src to: "" + srcAttrValue);
 		element.setAttribute(""src"", srcAttrValue);
 		return element;
 	}
@@ -60,7 +57,6 @@
 	public static boolean isInjected(Node node, String attrName, String value, boolean checkValue) {
 
 		NamedNodeMap attributes = node.getAttributes();
-		// String tmp = """";
 		// if there are no attributes we know the node does not contain the
 		// injected attribute
 		if (attributes == null) {
"
429dec2d2ff25fd0d2d48527a33feae207b22ea3,Ali Mesbah,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index 5f23e7a..e9c9b51 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -145,7 +145,6 @@
 		String info = """";
 		if (!text.equals("""")) {
 			info += ""\"""" + text + ""\"" "";
-			// Helper.removeNewLines(this.text.trim()) + "" - "";
 		}
 		if (element != null) {
 			if (element.hasAttribute(""id"")) {
@@ -194,8 +193,6 @@
 	 * @return the changed dom.
 	 */
 	public static Document removeTags(Document dom, String tagName) {
-		// NodeList list = dom.getElementsByTagName(""SCRIPT"");
-
 		NodeList list;
 		try {
 			list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
@@ -208,7 +205,6 @@
 				}
 
 				list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
-				// list = dom.getElementsByTagName(""SCRIPT"");
 			}
 		} catch (XPathExpressionException e) {
 			LOGGER.error(""Error while removing tag "" + tagName, e);
@@ -257,22 +253,16 @@
 			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
 			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
 			// TODO should be fixed to read doctype declaration
-			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			// ""-//W3C//DTD XHTML 1.0 Transitional//EN\""
-			// \""http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"");
 			transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
 			        ""-//W3C//DTD XHTML 1.0 Strict//EN\"" ""
 			                + ""\""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"");
 
-			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			// ""-//W3C//DTD HTML 4.01//EN\"" \""http://www.w3.org/TR/html4/strict.dtd"");
 			DOMSource source = new DOMSource(dom);
 
 			ByteArrayOutputStream out = new ByteArrayOutputStream();
 			Result result = new StreamResult(out);
 			transformer.transform(source, result);
 
-			// System.out.println(""Injected Javascript!"");
 			return out.toByteArray();
 		} catch (TransformerException e) {
 			LOGGER.error(""Error while converting the document to a byte array"", e);
"
429dec2d2ff25fd0d2d48527a33feae207b22ea3,Ali Mesbah,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index 7a6121b..8d44723 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -18,7 +18,6 @@
  * class for finding and checking elements.
  * 
  * @author danny
- * @version $Id$
  */
 public class ElementResolver {
 	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class.getName());
"
429dec2d2ff25fd0d2d48527a33feae207b22ea3,Ali Mesbah,PrettyHTML.java,MODIFY,"prettyHTML -> [String html] | [String html, String strIndent]","diff --git a/core/src/main/java/com/crawljax/util/PrettyHTML.java b/core/src/main/java/com/crawljax/util/PrettyHTML.java
index b13adc9..d67a0eb 100644
--- a/core/src/main/java/com/crawljax/util/PrettyHTML.java
+++ b/core/src/main/java/com/crawljax/util/PrettyHTML.java
@@ -6,7 +6,6 @@
  * Class for making presenting HTML without changing it's structure.
  * 
  * @author Danny
- * @version $Id$
  */
 public final class PrettyHTML {
 
"
429dec2d2ff25fd0d2d48527a33feae207b22ea3,Ali Mesbah,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 5529735..05cdb79 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -243,7 +243,6 @@
 		int pos = 0;
 		int temp;
 		int number;
-		// System.out.println(xpath);
 		for (String element : elements) {
 			if (!element.isEmpty() && !element.startsWith(""@"") && !element.contains(""()"")) {
 				if (element.indexOf(""["") != -1) {
@@ -269,8 +268,6 @@
 							pos =
 							        getCloseElementLocation(dom, pos,
 							                stripEndSquareBrackets(element));
-							// pos = dom.indexOf(""<"" +
-							// stripEndSquareBrackets(element), pos) + 1;
 						}
 
 					}
"
caf5bb0adfe3a68c2ef211443c1a418cb96879be,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 208aa3a..e9fd0da 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -366,8 +366,6 @@
 		m = p.matcher(html);
 		htmlFormatted = m.replaceAll("""");
 
-		// html = html.replace(""<?xml:namespace prefix = gwt >"", """");
-
 		// TODO (Stefan), Following lines are a serious performance bottle neck...
 		// Document doc = Helper.getDocument(htmlFormatted);
 		// htmlFormatted = Helper.getDocumentToString(doc);
@@ -543,7 +541,6 @@
 					browser.switchTo().window(handle);
 					LOGGER.info(""Closing other window with title \"""" + browser.getTitle() + ""\"""");
 					browser.close();
-					// browser.switchTo().defaultContent();
 					browser.switchTo().window(current);
 				}
 			}
@@ -654,9 +651,7 @@
 	public String getDomWithoutIframeContent() {
 		try {
 			String dom = browser.getPageSource();
-			// logger.debug(""driver.source: "" + dom);
 			String result = toUniformDOM(dom);
-			// logger.debug(""driver.source toUniformDom: "" + result);
 			return result;
 		} catch (WebDriverException e) {
 			throwIfConnectionException(e);
"
caf5bb0adfe3a68c2ef211443c1a418cb96879be,Alex Nederlof,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/core/src/main/java/com/crawljax/core/CrawlQueue.java b/core/src/main/java/com/crawljax/core/CrawlQueue.java
index 45dbed6..0d76156 100644
--- a/core/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/core/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -16,7 +16,6 @@
  * separate threads in a Queue like fashion (FILO).
  * 
  * @author Stefan Lenselink <S.R.Lenselink@student.tudelft.nl>
- * @version $Id$
  */
 public class CrawlQueue extends Stack<Runnable> implements BlockingQueue<Runnable> {
 
"
caf5bb0adfe3a68c2ef211443c1a418cb96879be,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index 83567f5..aca2a42 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -28,7 +28,6 @@
  * The Crawljax Controller class is the core of Crawljax.
  * 
  * @author mesbah
- * @version $Id$
  */
 public class CrawljaxController implements CrawlQueueManager {
 
"
caf5bb0adfe3a68c2ef211443c1a418cb96879be,Alex Nederlof,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 7485d52..8b8c566 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -117,9 +117,8 @@
 	public void clickMoreElements() {
 		clickDefaultElements();
 		clickTableElements();
-		click(""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"",
-		        ""refresh"", ""xhr"", ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"",
-		        ""p"");
+		click(""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"", ""refresh"", ""xhr"",
+		        ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"", ""p"");
 	}
 
 	/**
"
caf5bb0adfe3a68c2ef211443c1a418cb96879be,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,setFilterAttributeNames -> [String filterAttributeNames] | [List filterAttributeNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 8bc1089..c6c2008 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -117,8 +117,7 @@
 		// clicked and not by another random crawlTag
 		return ImmutableList.<CrawlElement> builder()
 		        .addAll(getInputSpecification().getCrawlElements())
-		        .addAll(crawlSpecification.crawlActions().getCrawlElements())
-		        .build();
+		        .addAll(crawlSpecification.crawlActions().getCrawlElements()).build();
 	}
 
 	/**
@@ -128,8 +127,7 @@
 		return ImmutableList.<CrawlElement> builder()
 		        .addAll(getInputSpecification().getCrawlElements())
 		        .addAll(crawlSpecification.crawlActions().getCrawlElements())
-		        .addAll(getCrawlSpecification().crawlActions()
-		                .getCrawlElementsExcluded())
+		        .addAll(getCrawlSpecification().crawlActions().getCrawlElementsExcluded())
 		        .build();
 	}
 
"
caf5bb0adfe3a68c2ef211443c1a418cb96879be,Alex Nederlof,FormInputField.java,MODIFY,setValues -> [boolean values] | [String values],"diff --git a/core/src/main/java/com/crawljax/core/configuration/FormInputField.java b/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
index c2fd585..dc6e88c 100644
--- a/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
@@ -14,7 +14,6 @@
  * @see Form
  * @see Form#field(String)
  * @author DannyRoest@gmail.com (Danny Roest)
- * @version $Id$
  */
 public class FormInputField extends InputField {
 
"
caf5bb0adfe3a68c2ef211443c1a418cb96879be,Alex Nederlof,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/core/src/main/java/com/crawljax/core/configuration/InputField.java b/core/src/main/java/com/crawljax/core/configuration/InputField.java
index 474d562..7108d39 100644
--- a/core/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -13,7 +13,6 @@
  * @see InputSpecification#field(String)
  * @see InputSpecification#fields(String...)
  * @author DannyRoest@gmail.com (Danny Roest)
- * @version $Id$
  */
 public class InputField {
 
"
caf5bb0adfe3a68c2ef211443c1a418cb96879be,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index ac9c003..6854b96 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -28,9 +28,6 @@
 /**
  * Handles form values and fills in the form input elements with random values of the defined
  * values.
- * 
- * @author dannyroest@gmail.com (Danny Roest)
- * @version $Id$
  */
 public class FormHandler {
 	private static final Logger LOGGER = LoggerFactory.getLogger(FormHandler.class.getName());
@@ -61,18 +58,15 @@
 	}
 
 	private static final String[] ALLOWED_INPUT_TYPES =
-	{ ""text"", ""radio"", ""checkbox"", ""password"" };
+	        { ""text"", ""radio"", ""checkbox"", ""password"" };
 
 	/**
 	 * Fills in the element with the InputValues for input TODO: improve this by using WebDriver
 	 * options?
-	 * 
-	 * @param element
-	 * @param input
 	 */
 	private void setInputElementValue(Node element, FormInput input) {
 
-		LOGGER.debug(""INPUTFIELD: "" + input.getIdentification() + "" ("" + input.getType() + "")"");
+		LOGGER.debug(""INPUTFIELD: {} ({})"", input.getIdentification(), input.getType());
 		if (element == null) {
 			return;
 		}
@@ -84,7 +78,7 @@
 				        || input.getType().equalsIgnoreCase(""password"")
 				        || input.getType().equalsIgnoreCase(""hidden"")) {
 					String text = input.getInputValues().iterator().next().getValue();
-					if (text.equals("""")) {
+					if ("""".equals(text)) {
 						return;
 					}
 					String js = DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
@@ -93,7 +87,7 @@
 				}
 
 				// check/uncheck checkboxes
-				if (input.getType().equals(""checkbox"")) {
+				if (""checkbox"".equals(input.getType())) {
 					for (InputValue inputValue : input.getInputValues()) {
 						String js =
 						        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
@@ -158,7 +152,6 @@
 	}
 
 	/**
-	 * @param dom
 	 * @return all input element in dom
 	 */
 	private List<Node> getInputElements(Document dom) {
@@ -171,8 +164,7 @@
 				Node candidate = nodeList.item(i);
 				Node typeAttribute = candidate.getAttributes().getNamedItem(""type"");
 				if (typeAttribute == null
-				        || (typeAttribute != null && allowedTypes.contains(typeAttribute
-				                .getNodeValue()))) {
+				        || (allowedTypes.contains(typeAttribute.getNodeValue()))) {
 					nodes.add(nodeList.item(i));
 				}
 			}
"
caf5bb0adfe3a68c2ef211443c1a418cb96879be,Alex Nederlof,AttributeInjector.java,MODIFY,"removeInjectedAttributes -> [HTMLElement element, String attrName] | [Vector injectedElements, String attrName]","diff --git a/core/src/main/java/com/crawljax/util/AttributeInjector.java b/core/src/main/java/com/crawljax/util/AttributeInjector.java
index 8bc9fc6..ad942d9 100644
--- a/core/src/main/java/com/crawljax/util/AttributeInjector.java
+++ b/core/src/main/java/com/crawljax/util/AttributeInjector.java
@@ -12,8 +12,6 @@
 
 /**
  * Attribute injector class.
- * 
- * @version $Id$
  */
 public final class AttributeInjector {
 
@@ -39,7 +37,6 @@
 			return null;
 		}
 		srcAttrValue += ""?"" + attrName + ""="" + value;
-		// System.out.println(""Setting value for src to: "" + srcAttrValue);
 		element.setAttribute(""src"", srcAttrValue);
 		return element;
 	}
@@ -60,7 +57,6 @@
 	public static boolean isInjected(Node node, String attrName, String value, boolean checkValue) {
 
 		NamedNodeMap attributes = node.getAttributes();
-		// String tmp = """";
 		// if there are no attributes we know the node does not contain the
 		// injected attribute
 		if (attributes == null) {
"
caf5bb0adfe3a68c2ef211443c1a418cb96879be,Alex Nederlof,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index 5f23e7a..e9c9b51 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -145,7 +145,6 @@
 		String info = """";
 		if (!text.equals("""")) {
 			info += ""\"""" + text + ""\"" "";
-			// Helper.removeNewLines(this.text.trim()) + "" - "";
 		}
 		if (element != null) {
 			if (element.hasAttribute(""id"")) {
@@ -194,8 +193,6 @@
 	 * @return the changed dom.
 	 */
 	public static Document removeTags(Document dom, String tagName) {
-		// NodeList list = dom.getElementsByTagName(""SCRIPT"");
-
 		NodeList list;
 		try {
 			list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
@@ -208,7 +205,6 @@
 				}
 
 				list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
-				// list = dom.getElementsByTagName(""SCRIPT"");
 			}
 		} catch (XPathExpressionException e) {
 			LOGGER.error(""Error while removing tag "" + tagName, e);
@@ -257,22 +253,16 @@
 			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
 			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
 			// TODO should be fixed to read doctype declaration
-			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			// ""-//W3C//DTD XHTML 1.0 Transitional//EN\""
-			// \""http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd"");
 			transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
 			        ""-//W3C//DTD XHTML 1.0 Strict//EN\"" ""
 			                + ""\""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"");
 
-			// transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			// ""-//W3C//DTD HTML 4.01//EN\"" \""http://www.w3.org/TR/html4/strict.dtd"");
 			DOMSource source = new DOMSource(dom);
 
 			ByteArrayOutputStream out = new ByteArrayOutputStream();
 			Result result = new StreamResult(out);
 			transformer.transform(source, result);
 
-			// System.out.println(""Injected Javascript!"");
 			return out.toByteArray();
 		} catch (TransformerException e) {
 			LOGGER.error(""Error while converting the document to a byte array"", e);
"
caf5bb0adfe3a68c2ef211443c1a418cb96879be,Alex Nederlof,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index 7a6121b..8d44723 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -18,7 +18,6 @@
  * class for finding and checking elements.
  * 
  * @author danny
- * @version $Id$
  */
 public class ElementResolver {
 	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class.getName());
"
caf5bb0adfe3a68c2ef211443c1a418cb96879be,Alex Nederlof,PrettyHTML.java,MODIFY,"prettyHTML -> [String html] | [String html, String strIndent]","diff --git a/core/src/main/java/com/crawljax/util/PrettyHTML.java b/core/src/main/java/com/crawljax/util/PrettyHTML.java
index b13adc9..d67a0eb 100644
--- a/core/src/main/java/com/crawljax/util/PrettyHTML.java
+++ b/core/src/main/java/com/crawljax/util/PrettyHTML.java
@@ -6,7 +6,6 @@
  * Class for making presenting HTML without changing it's structure.
  * 
  * @author Danny
- * @version $Id$
  */
 public final class PrettyHTML {
 
"
caf5bb0adfe3a68c2ef211443c1a418cb96879be,Alex Nederlof,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 5529735..05cdb79 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -243,7 +243,6 @@
 		int pos = 0;
 		int temp;
 		int number;
-		// System.out.println(xpath);
 		for (String element : elements) {
 			if (!element.isEmpty() && !element.startsWith(""@"") && !element.contains(""()"")) {
 				if (element.indexOf(""["") != -1) {
@@ -269,8 +268,6 @@
 							pos =
 							        getCloseElementLocation(dom, pos,
 							                stripEndSquareBrackets(element));
-							// pos = dom.indexOf(""<"" +
-							// stripEndSquareBrackets(element), pos) + 1;
 						}
 
 					}
"
25342239467f9c0719bf66e1b188ca0adfcd3284,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index e9fd0da..10112fd 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -292,27 +292,24 @@
 	 *            The HTML event type (onclick, onmouseover, ...).
 	 * @return true if firing event is successful.
 	 */
-	protected boolean fireEventWait(WebElement webElement, Eventable eventable) {
+	protected boolean fireEventWait(WebElement webElement, Eventable eventable)
+	        throws ElementNotVisibleException {
 		switch (eventable.getEventType()) {
 			case click:
 				try {
 					webElement.click();
-				} catch (ElementNotVisibleException e1) {
-					LOGGER.info(""Element not visible, so cannot be clicked: ""
-					        + webElement.getTagName().toUpperCase() + "" "" + webElement.getText());
-					return false;
+				} catch (ElementNotVisibleException e) {
+					throw e;
 				} catch (WebDriverException e) {
 					throwIfConnectionException(e);
 					return false;
 				}
 				break;
 			case hover:
-				// todo
+				LOGGER.info(""Eventype hover called but this isnt implemented yet"");
 				break;
-
 			default:
-				LOGGER.info(""EventType "" + eventable.getEventType()
-				        + "" not supported in WebDriver."");
+				LOGGER.info(""EventType {} not supported in WebDriver."", eventable.getEventType());
 				return false;
 		}
 
@@ -437,7 +434,7 @@
 	 * @return true if it is able to fire the event successfully on the element.
 	 */
 	@Override
-	public synchronized boolean fireEvent(Eventable eventable) {
+	public synchronized boolean fireEvent(Eventable eventable) throws ElementNotVisibleException {
 		try {
 
 			boolean handleChanged = false;
@@ -468,6 +465,8 @@
 				browser.switchTo().defaultContent();
 			}
 			return result;
+		} catch (ElementNotVisibleException e) {
+			throw e;
 		} catch (NoSuchElementException e) {
 			LOGGER.warn(""Could not fire eventable: "" + eventable.toString());
 			return false;
"
dc966cdbe2109732271659a9a8712aef779d3370,Alex Nederlof,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 8b8c566..4501ec6 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -79,6 +79,8 @@
 	private boolean clicklOnce = true;
 	private boolean disableCrawlFrames = false;
 
+	private boolean clickHiddenAnchors = true;
+
 	/**
 	 * @param url
 	 *            the site to crawl
@@ -501,4 +503,25 @@
 	protected boolean isCrawlFrames() {
 		return !disableCrawlFrames;
 	}
+
+	boolean isClickHiddenAnchors() {
+		return clickHiddenAnchors;
+	}
+
+	/**
+	 * Set Crawljax to click hidden anchors or not. <code>true</code> by default. @ *
+	 * <dl>
+	 * <dd>Pro:</dd>
+	 * <dt>The benefit of clicking hidden anchors is that Crawljax isn't capable of clicking
+	 * elements that are hidden for example because you have to hover another element first. This
+	 * happens in most fold-out menus for example. Enabling this function allows Crawljax to find
+	 * more states that are hidden this way.</dt>
+	 * <dd>Con:</dd>
+	 * <dt>If a anchor tag is never visible in the browser in any way, Crawljax will crawl it
+	 * anyway. This makes the Crawl inconsistent with what the user experiences.</dt>
+	 * </dl>
+	 */
+	public void clickHiddenAnchors(boolean clickHiddenAnchors) {
+		this.clickHiddenAnchors = clickHiddenAnchors;
+	}
 }
"
4de8c1f44772512a5b66c03ed450e7ed66c0bb2f,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 10112fd..05347af 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -18,6 +18,7 @@
 import org.openqa.selenium.OutputType;
 import org.openqa.selenium.Platform;
 import org.openqa.selenium.TakesScreenshot;
+import org.openqa.selenium.UnhandledAlertException;
 import org.openqa.selenium.WebDriver;
 import org.openqa.selenium.WebDriverException;
 import org.openqa.selenium.WebElement;
@@ -51,13 +52,13 @@
 /**
  * @author mesbah
  * @author Frank Groeneveld
- * @version $Id: WebDriverBackedEmbeddedBrowser.java 387 2010-07-13 13:55:49Z slenselink@google.com
- *          $
+ * @version $Id: WebDriverBackedEmbeddedBrowser.java 387 2010-07-13 13:55:49Z
+ *          slenselink@google.com $
  */
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
 	private long crawlWaitEvent;
 	private static final Logger LOGGER = LoggerFactory
-	        .getLogger(WebDriverBackedEmbeddedBrowser.class);
+			.getLogger(WebDriverBackedEmbeddedBrowser.class);
 	private final WebDriver browser;
 
 	private List<String> filterAttributes;
@@ -68,8 +69,7 @@
 	 * Constructor without configuration values, these must be updated using the
 	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
 	 * 
-	 * @param driver
-	 *            The WebDriver to use.
+	 * @param driver The WebDriver to use.
 	 */
 	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
 		this.browser = driver;
@@ -78,17 +78,13 @@
 	/**
 	 * Constructor.
 	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
+	 * @param driver The WebDriver to use.
+	 * @param filterAttributes the attributes to be filtered from DOM.
+	 * @param crawlWaitReload the period to wait after a reload.
+	 * @param crawlWaitEvent the period to wait after an event is fired.
 	 */
 	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent) {
+			long crawlWaitReload, long crawlWaitEvent) {
 		this(driver);
 		this.filterAttributes = filterAttributes;
 		this.crawlWaitEvent = crawlWaitEvent;
@@ -98,19 +94,15 @@
 	/**
 	 * Constructor.
 	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
+	 * @param driver The WebDriver to use.
+	 * @param filterAttributes the attributes to be filtered from DOM.
+	 * @param crawlWaitReload the period to wait after a reload.
+	 * @param crawlWaitEvent the period to wait after an event is fired.
+	 * @param ignoreFrameChecker the checker used to determine if a certain frame
+	 *           must be ignored.
 	 */
 	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
+			long crawlWaitReload, long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
 		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
 		this.ignoreFrameChecker = ignoreFrameChecker;
 	}
@@ -118,90 +110,73 @@
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
 	 * 
-	 * @param hubUrl
-	 *            Url of the server.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
+	 * @param hubUrl Url of the server.
+	 * @param filterAttributes the attributes to be filtered from DOM.
+	 * @param crawlWaitReload the period to wait after a reload.
+	 * @param crawlWaitEvent the period to wait after an event is fired.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+			List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
 		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
-		        filterAttributes, crawlWaitEvent, crawlWaitReload);
+				filterAttributes, crawlWaitEvent, crawlWaitReload);
 	}
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
 	 * 
-	 * @param hubUrl
-	 *            Url of the server.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
+	 * @param hubUrl Url of the server.
+	 * @param filterAttributes the attributes to be filtered from DOM.
+	 * @param crawlWaitReload the period to wait after a reload.
+	 * @param crawlWaitEvent the period to wait after an event is fired.
+	 * @param ignoreFrameChecker the checker used to determine if a certain frame
+	 *           must be ignored.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-	        IgnoreFrameChecker ignoreFrameChecker) {
+			List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
+			IgnoreFrameChecker ignoreFrameChecker) {
 		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
-		        filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
+				filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
 	}
 
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
 	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
+	 * @param driver The WebDriver to use.
+	 * @param filterAttributes the attributes to be filtered from DOM.
+	 * @param crawlWaitReload the period to wait after a reload.
+	 * @param crawlWaitEvent the period to wait after an event is fired.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+			List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
 		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
-		        crawlWaitReload);
+				crawlWaitReload);
 	}
 
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
 	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
+	 * @param driver The WebDriver to use.
+	 * @param filterAttributes the attributes to be filtered from DOM.
+	 * @param crawlWaitReload the period to wait after a reload.
+	 * @param crawlWaitEvent the period to wait after an event is fired.
+	 * @param ignoreFrameChecker the checker used to determine if a certain frame
+	 *           must be ignored.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-	        IgnoreFrameChecker ignoreFrameChecker) {
+			List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
+			IgnoreFrameChecker ignoreFrameChecker) {
 		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
-		        crawlWaitReload, ignoreFrameChecker);
+				crawlWaitReload, ignoreFrameChecker);
 	}
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
 	 * 
-	 * @param hubUrl
-	 *            Url of the server.
+	 * @param hubUrl Url of the server.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl) {
@@ -209,11 +184,10 @@
 	}
 
 	/**
-	 * Private used static method for creation of a RemoteWebDriver. Taking care of the default
-	 * Capabilities and using the HttpCommandExecutor.
+	 * Private used static method for creation of a RemoteWebDriver. Taking care
+	 * of the default Capabilities and using the HttpCommandExecutor.
 	 * 
-	 * @param hubUrl
-	 *            the url of the hub to use.
+	 * @param hubUrl the url of the hub to use.
 	 * @return the RemoteWebDriver instance.
 	 */
 	private static RemoteWebDriver buildRemoteWebDriver(String hubUrl) {
@@ -224,17 +198,18 @@
 			url = new URL(hubUrl);
 		} catch (MalformedURLException e) {
 			LOGGER.error(""The given hub url of the remote server is malformed can not continue!"",
-			        e);
+					e);
 			return null;
 		}
 		HttpCommandExecutor executor = null;
 		try {
 			executor = new HttpCommandExecutor(url);
 		} catch (Exception e) {
-			// TODO Stefan; refactor this catch, this will definitely result in NullPointers, why
+			// TODO Stefan; refactor this catch, this will definitely result in
+			// NullPointers, why
 			// not throw RuntimeExcption direct?
 			LOGGER.error(""Received unknown exception while creating the ""
-			        + ""HttpCommandExecutor, can not continue!"", e);
+					+ ""HttpCommandExecutor, can not continue!"", e);
 			return null;
 		}
 		return new RemoteWebDriver(executor, capabilities);
@@ -243,8 +218,7 @@
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
 	 * 
-	 * @param driver
-	 *            The WebDriver to use.
+	 * @param driver The WebDriver to use.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver) {
@@ -252,8 +226,7 @@
 	}
 
 	/**
-	 * @param url
-	 *            The URL.
+	 * @param url The URL.
 	 */
 	@Override
 	public void goToUrl(URL url) {
@@ -276,8 +249,8 @@
 	private void handlePopups() {
 		try {
 			executeJavaScript(""window.alert = function(msg){return true;};""
-			        + ""window.confirm = function(msg){return true;};""
-			        + ""window.prompt = function(msg){return true;};"");
+					+ ""window.confirm = function(msg){return true;};""
+					+ ""window.prompt = function(msg){return true;};"");
 		} catch (CrawljaxException e) {
 			LOGGER.error(""Handling of PopUp windows failed"", e);
 		}
@@ -286,14 +259,12 @@
 	/**
 	 * Fires the event and waits for a specified time.
 	 * 
-	 * @param webElement
-	 *            the element to fire event on.
-	 * @param eventable
-	 *            The HTML event type (onclick, onmouseover, ...).
+	 * @param webElement the element to fire event on.
+	 * @param eventable The HTML event type (onclick, onmouseover, ...).
 	 * @return true if firing event is successful.
 	 */
 	protected boolean fireEventWait(WebElement webElement, Eventable eventable)
-	        throws ElementNotVisibleException {
+			throws ElementNotVisibleException {
 		switch (eventable.getEventType()) {
 			case click:
 				try {
@@ -347,15 +318,14 @@
 	}
 
 	/**
-	 * @param html
-	 *            The html string.
+	 * @param html The html string.
 	 * @return uniform version of dom with predefined attributes stripped
 	 */
 	private String toUniformDOM(String html) {
 
 		Pattern p =
-		        Pattern.compile(""<SCRIPT(.*?)</SCRIPT>"", Pattern.DOTALL
-		                | Pattern.CASE_INSENSITIVE);
+				Pattern.compile(""<SCRIPT(.*?)</SCRIPT>"", Pattern.DOTALL
+						| Pattern.CASE_INSENSITIVE);
 		Matcher m = p.matcher(html);
 		String htmlFormatted = m.replaceAll("""");
 
@@ -374,8 +344,7 @@
 	/**
 	 * Filters attributes from the HTML string.
 	 * 
-	 * @param html
-	 *            The HTML to filter.
+	 * @param html The HTML to filter.
 	 * @return The filtered HTML string.
 	 */
 	private String filterAttributes(String html) {
@@ -400,10 +369,8 @@
 	}
 
 	/**
-	 * @param identification
-	 *            The identification object.
-	 * @param text
-	 *            The input.
+	 * @param identification The identification object.
+	 * @param text The input.
 	 * @return true if succeeds.
 	 */
 	@Override
@@ -429,12 +396,11 @@
 	/**
 	 * Fires an event on an element using its identification.
 	 * 
-	 * @param eventable
-	 *            The eventable.
+	 * @param eventable The eventable.
 	 * @return true if it is able to fire the event successfully on the element.
 	 */
 	@Override
-	public synchronized boolean fireEvent(Eventable eventable) throws ElementNotVisibleException {
+	public synchronized boolean fireEvent(Eventable eventable) throws ElementNotVisibleException, NoSuchElementException {
 		try {
 
 			boolean handleChanged = false;
@@ -447,15 +413,17 @@
 					switchToFrame(eventable.getRelatedFrame());
 				} catch (NoSuchFrameException e) {
 					LOGGER.debug(""Frame not found, possibily while back-tracking.."", e);
-					// TODO Stefan, This exception is catched to prevent stopping from working
-					// This was the case on the Gmail case; find out if not switching (catching)
+					// TODO Stefan, This exception is catched to prevent stopping
+					// from working
+					// This was the case on the Gmail case; find out if not switching
+					// (catching)
 					// Results in good performance...
 				}
 				handleChanged = true;
 			}
 
 			WebElement webElement =
-			        browser.findElement(eventable.getIdentification().getWebDriverBy());
+					browser.findElement(eventable.getIdentification().getWebDriverBy());
 
 			if (webElement != null) {
 				result = fireEventWait(webElement, eventable);
@@ -465,11 +433,8 @@
 				browser.switchTo().defaultContent();
 			}
 			return result;
-		} catch (ElementNotVisibleException e) {
+		} catch (ElementNotVisibleException | NoSuchElementException e) {
 			throw e;
-		} catch (NoSuchElementException e) {
-			LOGGER.warn(""Could not fire eventable: "" + eventable.toString());
-			return false;
 		} catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return false;
@@ -479,11 +444,9 @@
 	/**
 	 * Execute JavaScript in the browser.
 	 * 
-	 * @param code
-	 *            The code to execute.
+	 * @param code The code to execute.
 	 * @return The return value of the JavaScript.
-	 * @throws CrawljaxException
-	 *             when javascript execution failed.
+	 * @throws CrawljaxException when javascript execution failed.
 	 */
 	@Override
 	public Object executeJavaScript(String code) throws CrawljaxException {
@@ -499,8 +462,7 @@
 	/**
 	 * Determines whether the corresponding element is visible.
 	 * 
-	 * @param identification
-	 *            The element to search for.
+	 * @param identification The element to search for.
 	 * @return true if the element is visible
 	 */
 	@Override
@@ -543,6 +505,8 @@
 					browser.switchTo().window(current);
 				}
 			}
+		} catch (UnhandledAlertException e) {
+			LOGGER.warn(""While closing the window, an alert got ignored: {}"", e.getMessage());
 		} catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
@@ -550,8 +514,7 @@
 
 	/**
 	 * @return a Document object containing the contents of iframes as well.
-	 * @throws CrawljaxException
-	 *             if an exception is thrown.
+	 * @throws CrawljaxException if an exception is thrown.
 	 */
 	private Document getDomTreeWithFrames() throws CrawljaxException {
 
@@ -595,7 +558,7 @@
 			String nameId = DomUtils.getFrameIdentification(frameElement);
 
 			if (nameId != null
-			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
+					&& !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
 				frameIdentification += nameId;
 
 				String handle = browser.getWindowHandle();
@@ -613,13 +576,13 @@
 				try {
 					Element toAppendElement = DomUtils.asDocument(toAppend).getDocumentElement();
 					Element importedElement =
-					        (Element) document.importNode(toAppendElement, true);
+							(Element) document.importNode(toAppendElement, true);
 					frameElement.appendChild(importedElement);
 
 					appendFrameContent(importedElement, document, frameIdentification);
 				} catch (DOMException | IOException e) {
 					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
+							+ "" continuing..."", e);
 				}
 			}
 		}
@@ -659,8 +622,7 @@
 	}
 
 	/**
-	 * @param input
-	 *            the input to be filled.
+	 * @param input the input to be filled.
 	 * @return FormInput with random value assigned if possible
 	 */
 	@Override
@@ -684,9 +646,9 @@
 
 		if (input.getType().toLowerCase().startsWith(""text"")) {
 			values.add(new InputValue(new RandomInputValueGenerator()
-			        .getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
+					.getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
 		} else if (input.getType().equalsIgnoreCase(""checkbox"")
-		        || input.getType().equalsIgnoreCase(""radio"") && !webElement.isSelected()) {
+				|| input.getType().equalsIgnoreCase(""radio"") && !webElement.isSelected()) {
 			if (new RandomInputValueGenerator().getCheck()) {
 				values.add(new InputValue(""1"", true));
 			} else {
@@ -697,8 +659,8 @@
 			try {
 				Select select = new Select(webElement);
 				WebElement option =
-				        (WebElement) new RandomInputValueGenerator().getRandomOption(select
-				                .getOptions());
+						(WebElement) new RandomInputValueGenerator().getRandomOption(select
+								.getOptions());
 				values.add(new InputValue(option.getText(), true));
 			} catch (WebDriverException e) {
 				throwIfConnectionException(e);
@@ -733,15 +695,15 @@
 	}
 
 	/**
-	 * @param identification
-	 *            the identification of the element.
+	 * @param identification the identification of the element.
 	 * @return true if the element can be found in the DOM tree.
 	 */
 	@Override
 	public boolean elementExists(Identification identification) {
 		try {
 			WebElement el = browser.findElement(identification.getWebDriverBy());
-			// TODO Stefan; I think el will never be null as a NoSuchElementExcpetion will be
+			// TODO Stefan; I think el will never be null as a
+			// NoSuchElementExcpetion will be
 			// thrown, catched below.
 			return el != null;
 		} catch (WebDriverException e) {
@@ -751,8 +713,7 @@
 	}
 
 	/**
-	 * @param identification
-	 *            the identification of the element.
+	 * @param identification the identification of the element.
 	 * @return the found element.
 	 */
 	@Override
@@ -825,7 +786,7 @@
 			executeJavaScript(js);
 		} catch (CrawljaxException e) {
 			LOGGER.error(""Removing of Canvas Generated By FirefoxDriver failed,""
-			        + "" most likely leaving it in the browser"", e);
+					+ "" most likely leaving it in the browser"", e);
 		}
 	}
 
@@ -841,18 +802,18 @@
 		// Retrieve the config values used
 		this.filterAttributes = configuration.getFilterAttributeNames();
 		this.crawlWaitReload =
-		        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
+				configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
 		this.crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
 		this.ignoreFrameChecker = configuration.getCrawlSpecificationReader();
 	}
 
 	private boolean exceptionIsConnectionException(WebDriverException exception) {
 		return exception != null && exception.getCause() != null
-		        && exception.getCause() instanceof IOException;
+				&& exception.getCause() instanceof IOException;
 	}
 
 	private RuntimeException wrapWebDriverExceptionIfConnectionException(
-	        WebDriverException exception) {
+			WebDriverException exception) {
 		if (exceptionIsConnectionException(exception)) {
 			return new BrowserConnectionException(exception);
 		}
"
f5df8cd2614dc43bfb8355c17a119f3b9b9b7cd8,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index e9fd0da..7629f3c 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -662,7 +662,8 @@
 	/**
 	 * @param input
 	 *            the input to be filled.
-	 * @return FormInput with random value assigned if possible
+	 * @return FormInput with random value assigned if possible. If no values were set it returns
+	 *         <code>null</code>
 	 */
 	@Override
 	public FormInput getInputWithRandomValue(FormInput input) {
@@ -670,8 +671,7 @@
 		WebElement webElement;
 		try {
 			webElement = browser.findElement(input.getIdentification().getWebDriverBy());
-			if (!(webElement.isDisplayed())) {
-
+			if (!webElement.isDisplayed()) {
 				return null;
 			}
 		} catch (WebDriverException e) {
@@ -679,35 +679,14 @@
 			return null;
 		}
 
-		Set<InputValue> values = new HashSet<InputValue>();
-
-		// create some random value
-
-		if (input.getType().toLowerCase().startsWith(""text"")) {
-			values.add(new InputValue(new RandomInputValueGenerator()
-			        .getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
-		} else if (input.getType().equalsIgnoreCase(""checkbox"")
-		        || input.getType().equalsIgnoreCase(""radio"") && !webElement.isSelected()) {
-			if (new RandomInputValueGenerator().getCheck()) {
-				values.add(new InputValue(""1"", true));
-			} else {
-				values.add(new InputValue(""0"", false));
-
-			}
-		} else if (input.getType().equalsIgnoreCase(""select"")) {
-			try {
-				Select select = new Select(webElement);
-				WebElement option =
-				        (WebElement) new RandomInputValueGenerator().getRandomOption(select
-				                .getOptions());
-				values.add(new InputValue(option.getText(), true));
-			} catch (WebDriverException e) {
-				throwIfConnectionException(e);
-				return null;
-			}
+		Set<InputValue> values = new HashSet<>();
+		try {
+			setRandomValues(input, webElement, values);
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return null;
 		}
-
-		if (values.size() == 0) {
+		if (values.isEmpty()) {
 			return null;
 		}
 		input.setInputValues(values);
@@ -715,6 +694,29 @@
 
 	}
 
+	private void setRandomValues(FormInput input, WebElement webElement, Set<InputValue> values) {
+		String inputString = input.getType().toLowerCase();
+		if (inputString.startsWith(""text"")) {
+			values.add(new InputValue(new RandomInputValueGenerator()
+			        .getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
+		} else if (inputString.equals(""checkbox"") || inputString.equals(""radio"")
+		        && !webElement.isSelected()) {
+			if (new RandomInputValueGenerator().getCheck()) {
+				values.add(new InputValue(""1"", true));
+			} else {
+				values.add(new InputValue(""0"", false));
+			}
+		} else if (input.getType().equalsIgnoreCase(""select"")) {
+			Select select = new Select(webElement);
+			if (!select.getOptions().isEmpty()) {
+				WebElement option =
+				        new RandomInputValueGenerator().getRandomItem(select.getOptions());
+				values.add(new InputValue(option.getText(), true));
+			}
+
+		}
+	}
+
 	@Override
 	public String getFrameDom(String iframeIdentification) {
 		try {
"
f5df8cd2614dc43bfb8355c17a119f3b9b9b7cd8,Alex Nederlof,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/core/src/main/java/com/crawljax/core/configuration/InputField.java b/core/src/main/java/com/crawljax/core/configuration/InputField.java
index 7108d39..b25765c 100644
--- a/core/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -99,7 +99,7 @@
 	 * @return The value.
 	 */
 	protected String getValue() {
-		if (fieldValues.size() == 0) {
+		if (fieldValues.isEmpty()) {
 			return null;
 		} else {
 			return fieldValues.get(0);
"
93cb270907f4ec028a2659034cdaa8054bfccdda,Alex Nederlof,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 8b8c566..696f586 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -225,17 +225,30 @@
 	}
 
 	/**
-	 * Sets the maximum time for Crawljax to run. Crawljax will stop crawling when this timelimit is
-	 * reached.
+	 * Sets the maximum time for Crawljax to run. Crawljax will stop crawling when this time limit
+	 * is reached.
 	 * 
-	 * @param seconds
-	 *            the crawlMaximumRuntime to set
+	 * @param the
+	 *            crawlMaximumRuntime to set
 	 */
 	public void setMaximumRuntime(long time, TimeUnit timeUnit) {
 		this.maximumRuntime = timeUnit.toSeconds(time);
 	}
 
 	/**
+	 * Sets the maximum time for Crawljax to run. Crawljax will stop crawling when this time limit
+	 * is reached.
+	 * 
+	 * @deprecated use {@link #setMaximumRuntime(long, TimeUnit)}.
+	 * @param seconds
+	 *            the crawlMaximumRuntime to set
+	 */
+	@Deprecated
+	public void setMaximumRuntime(long time) {
+		this.maximumRuntime = time;
+	}
+
+	/**
 	 * @return whether to Crawljax should enter random values in form input fields
 	 */
 	protected boolean getRandomInputInForms() {
@@ -258,14 +271,24 @@
 	}
 
 	/**
-	 * @param milliseconds
-	 *            the number of milliseconds to wait after reloading the url
+	 * @param time
+	 *            to wait after reloading the url
 	 */
 	public void setWaitTimeAfterReloadUrl(long time, TimeUnit unit) {
 		this.waitTimeAfterReloadUrl = unit.toMillis(time);
 	}
 
 	/**
+	 * @deprecated use {@link #setWaitTimeAfterReloadUrl(long, TimeUnit)}
+	 * @param time
+	 *            to wait after reloading the url
+	 */
+	@Deprecated
+	public void setWaitTimeAfterReloadUrl(long timeInMillis) {
+		this.waitTimeAfterReloadUrl = timeInMillis;
+	}
+
+	/**
 	 * @return the number the number of milliseconds to wait after an event is fired
 	 */
 	protected long getWaitTimeAfterEvent() {
@@ -273,14 +296,24 @@
 	}
 
 	/**
-	 * @param milliseconds
-	 *            the number of milliseconds to wait after an event is fired
+	 * @param the
+	 *            time to wait after an event is fired
 	 */
 	public void setWaitTimeAfterEvent(long time, TimeUnit unit) {
 		this.waitTimeAfterEvent = unit.toMillis(time);
 	}
 
 	/**
+	 * @deprecated use {@link #setWaitTimeAfterEvent(long, TimeUnit)}
+	 * @param milliseconds
+	 *            the number of milliseconds to wait after an event is fired
+	 */
+	@Deprecated
+	public void setWaitTimeAfterEvent(long time) {
+		this.waitTimeAfterEvent = time;
+	}
+
+	/**
 	 * @return the events that should be fired (e.g. onclick)
 	 */
 	protected ImmutableList<EventType> getCrawlEvents() {
"
d110fa1170bf123982d4f99167bdb6f09e4be175,Ali Mesbah,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 8b8c566..696f586 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -225,17 +225,30 @@
 	}
 
 	/**
-	 * Sets the maximum time for Crawljax to run. Crawljax will stop crawling when this timelimit is
-	 * reached.
+	 * Sets the maximum time for Crawljax to run. Crawljax will stop crawling when this time limit
+	 * is reached.
 	 * 
-	 * @param seconds
-	 *            the crawlMaximumRuntime to set
+	 * @param the
+	 *            crawlMaximumRuntime to set
 	 */
 	public void setMaximumRuntime(long time, TimeUnit timeUnit) {
 		this.maximumRuntime = timeUnit.toSeconds(time);
 	}
 
 	/**
+	 * Sets the maximum time for Crawljax to run. Crawljax will stop crawling when this time limit
+	 * is reached.
+	 * 
+	 * @deprecated use {@link #setMaximumRuntime(long, TimeUnit)}.
+	 * @param seconds
+	 *            the crawlMaximumRuntime to set
+	 */
+	@Deprecated
+	public void setMaximumRuntime(long time) {
+		this.maximumRuntime = time;
+	}
+
+	/**
 	 * @return whether to Crawljax should enter random values in form input fields
 	 */
 	protected boolean getRandomInputInForms() {
@@ -258,14 +271,24 @@
 	}
 
 	/**
-	 * @param milliseconds
-	 *            the number of milliseconds to wait after reloading the url
+	 * @param time
+	 *            to wait after reloading the url
 	 */
 	public void setWaitTimeAfterReloadUrl(long time, TimeUnit unit) {
 		this.waitTimeAfterReloadUrl = unit.toMillis(time);
 	}
 
 	/**
+	 * @deprecated use {@link #setWaitTimeAfterReloadUrl(long, TimeUnit)}
+	 * @param time
+	 *            to wait after reloading the url
+	 */
+	@Deprecated
+	public void setWaitTimeAfterReloadUrl(long timeInMillis) {
+		this.waitTimeAfterReloadUrl = timeInMillis;
+	}
+
+	/**
 	 * @return the number the number of milliseconds to wait after an event is fired
 	 */
 	protected long getWaitTimeAfterEvent() {
@@ -273,14 +296,24 @@
 	}
 
 	/**
-	 * @param milliseconds
-	 *            the number of milliseconds to wait after an event is fired
+	 * @param the
+	 *            time to wait after an event is fired
 	 */
 	public void setWaitTimeAfterEvent(long time, TimeUnit unit) {
 		this.waitTimeAfterEvent = unit.toMillis(time);
 	}
 
 	/**
+	 * @deprecated use {@link #setWaitTimeAfterEvent(long, TimeUnit)}
+	 * @param milliseconds
+	 *            the number of milliseconds to wait after an event is fired
+	 */
+	@Deprecated
+	public void setWaitTimeAfterEvent(long time) {
+		this.waitTimeAfterEvent = time;
+	}
+
+	/**
 	 * @return the events that should be fired (e.g. onclick)
 	 */
 	protected ImmutableList<EventType> getCrawlEvents() {
"
012a26699973065ecb038ea023df5486871cfd43,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index e9fd0da..7629f3c 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -662,7 +662,8 @@
 	/**
 	 * @param input
 	 *            the input to be filled.
-	 * @return FormInput with random value assigned if possible
+	 * @return FormInput with random value assigned if possible. If no values were set it returns
+	 *         <code>null</code>
 	 */
 	@Override
 	public FormInput getInputWithRandomValue(FormInput input) {
@@ -670,8 +671,7 @@
 		WebElement webElement;
 		try {
 			webElement = browser.findElement(input.getIdentification().getWebDriverBy());
-			if (!(webElement.isDisplayed())) {
-
+			if (!webElement.isDisplayed()) {
 				return null;
 			}
 		} catch (WebDriverException e) {
@@ -679,35 +679,14 @@
 			return null;
 		}
 
-		Set<InputValue> values = new HashSet<InputValue>();
-
-		// create some random value
-
-		if (input.getType().toLowerCase().startsWith(""text"")) {
-			values.add(new InputValue(new RandomInputValueGenerator()
-			        .getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
-		} else if (input.getType().equalsIgnoreCase(""checkbox"")
-		        || input.getType().equalsIgnoreCase(""radio"") && !webElement.isSelected()) {
-			if (new RandomInputValueGenerator().getCheck()) {
-				values.add(new InputValue(""1"", true));
-			} else {
-				values.add(new InputValue(""0"", false));
-
-			}
-		} else if (input.getType().equalsIgnoreCase(""select"")) {
-			try {
-				Select select = new Select(webElement);
-				WebElement option =
-				        (WebElement) new RandomInputValueGenerator().getRandomOption(select
-				                .getOptions());
-				values.add(new InputValue(option.getText(), true));
-			} catch (WebDriverException e) {
-				throwIfConnectionException(e);
-				return null;
-			}
+		Set<InputValue> values = new HashSet<>();
+		try {
+			setRandomValues(input, webElement, values);
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return null;
 		}
-
-		if (values.size() == 0) {
+		if (values.isEmpty()) {
 			return null;
 		}
 		input.setInputValues(values);
@@ -715,6 +694,29 @@
 
 	}
 
+	private void setRandomValues(FormInput input, WebElement webElement, Set<InputValue> values) {
+		String inputString = input.getType().toLowerCase();
+		if (inputString.startsWith(""text"")) {
+			values.add(new InputValue(new RandomInputValueGenerator()
+			        .getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
+		} else if (inputString.equals(""checkbox"") || inputString.equals(""radio"")
+		        && !webElement.isSelected()) {
+			if (new RandomInputValueGenerator().getCheck()) {
+				values.add(new InputValue(""1"", true));
+			} else {
+				values.add(new InputValue(""0"", false));
+			}
+		} else if (input.getType().equalsIgnoreCase(""select"")) {
+			Select select = new Select(webElement);
+			if (!select.getOptions().isEmpty()) {
+				WebElement option =
+				        new RandomInputValueGenerator().getRandomItem(select.getOptions());
+				values.add(new InputValue(option.getText(), true));
+			}
+
+		}
+	}
+
 	@Override
 	public String getFrameDom(String iframeIdentification) {
 		try {
"
012a26699973065ecb038ea023df5486871cfd43,Ali Mesbah,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/core/src/main/java/com/crawljax/core/configuration/InputField.java b/core/src/main/java/com/crawljax/core/configuration/InputField.java
index 7108d39..b25765c 100644
--- a/core/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -99,7 +99,7 @@
 	 * @return The value.
 	 */
 	protected String getValue() {
-		if (fieldValues.size() == 0) {
+		if (fieldValues.isEmpty()) {
 			return null;
 		} else {
 			return fieldValues.get(0);
"
c21386eaec3ab902db4b0fe28062dd957d03cb0a,Ali Mesbah,OutputBuilder.java,MODIFY,write -> [CrawlSpecificationReader crawlSpecificationReader] | [OutPutModel outModel],"diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
index 770b2eb..2cba28f 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
@@ -12,6 +12,7 @@
 import java.io.IOException;
 import java.net.URISyntaxException;
 import java.net.URL;
+import java.util.Arrays;
 import java.util.zip.ZipEntry;
 import java.util.zip.ZipInputStream;
 
@@ -35,6 +36,7 @@
 import com.fasterxml.jackson.annotation.PropertyAccessor;
 import com.fasterxml.jackson.core.JsonProcessingException;
 import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.ObjectWriter;
 import com.google.common.base.Charsets;
 import com.google.common.base.Strings;
 import com.google.common.io.ByteStreams;
@@ -74,11 +76,14 @@
 
 		indexFile = new File(outputDir, ""index.html"");
 		ve = new VelocityEngine();
+		configureVelocity();
+	}
+
+	private void configureVelocity() {
 		ve.setProperty(RuntimeConstants.RUNTIME_LOG_LOGSYSTEM_CLASS,
 		        ""org.apache.velocity.runtime.log.NullLogChute"");
 		ve.setProperty(RuntimeConstants.RESOURCE_LOADER, ""classpath"");
 		ve.setProperty(""classpath.resource.loader.class"", ClasspathResourceLoader.class.getName());
-
 	}
 
 	private void checkPermissions() {
@@ -201,6 +206,17 @@
 		writeFile(context, file, ""urls.html"");
 	}
 
+	public void write(CrawlSpecificationReader crawlSpecificationReader) {
+		ObjectMapper objectMapper = new ObjectMapper();
+		try {
+			ObjectWriter prettyPrinter = objectMapper.writer().withDefaultPrettyPrinter();
+			prettyPrinter
+			        .writeValue(new File(outputDir, ""config.json""), crawlSpecificationReader);
+		} catch (Exception e) {
+			throw new RuntimeException(""Cannot save config"", e);
+		}
+	}
+
 	private void writeFile(VelocityContext context, File outFile, String template) {
 		try {
 			Template templatee = ve.getTemplate(template);
"
f50841ce3507f16b336a3390926b386fa29f52c5,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 05347af..3f21f86 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -52,13 +52,13 @@
 /**
  * @author mesbah
  * @author Frank Groeneveld
- * @version $Id: WebDriverBackedEmbeddedBrowser.java 387 2010-07-13 13:55:49Z
- *          slenselink@google.com $
+ * @version $Id: WebDriverBackedEmbeddedBrowser.java 387 2010-07-13 13:55:49Z slenselink@google.com
+ *          $
  */
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
 	private long crawlWaitEvent;
 	private static final Logger LOGGER = LoggerFactory
-			.getLogger(WebDriverBackedEmbeddedBrowser.class);
+	        .getLogger(WebDriverBackedEmbeddedBrowser.class);
 	private final WebDriver browser;
 
 	private List<String> filterAttributes;
@@ -69,7 +69,8 @@
 	 * Constructor without configuration values, these must be updated using the
 	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
 	 * 
-	 * @param driver The WebDriver to use.
+	 * @param driver
+	 *            The WebDriver to use.
 	 */
 	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
 		this.browser = driver;
@@ -78,13 +79,17 @@
 	/**
 	 * Constructor.
 	 * 
-	 * @param driver The WebDriver to use.
-	 * @param filterAttributes the attributes to be filtered from DOM.
-	 * @param crawlWaitReload the period to wait after a reload.
-	 * @param crawlWaitEvent the period to wait after an event is fired.
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
 	 */
 	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-			long crawlWaitReload, long crawlWaitEvent) {
+	        long crawlWaitReload, long crawlWaitEvent) {
 		this(driver);
 		this.filterAttributes = filterAttributes;
 		this.crawlWaitEvent = crawlWaitEvent;
@@ -94,15 +99,19 @@
 	/**
 	 * Constructor.
 	 * 
-	 * @param driver The WebDriver to use.
-	 * @param filterAttributes the attributes to be filtered from DOM.
-	 * @param crawlWaitReload the period to wait after a reload.
-	 * @param crawlWaitEvent the period to wait after an event is fired.
-	 * @param ignoreFrameChecker the checker used to determine if a certain frame
-	 *           must be ignored.
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
 	 */
 	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-			long crawlWaitReload, long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
+	        long crawlWaitReload, long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
 		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
 		this.ignoreFrameChecker = ignoreFrameChecker;
 	}
@@ -110,73 +119,90 @@
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
 	 * 
-	 * @param hubUrl Url of the server.
-	 * @param filterAttributes the attributes to be filtered from DOM.
-	 * @param crawlWaitReload the period to wait after a reload.
-	 * @param crawlWaitEvent the period to wait after an event is fired.
+	 * @param hubUrl
+	 *            Url of the server.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-			List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
 		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
-				filterAttributes, crawlWaitEvent, crawlWaitReload);
+		        filterAttributes, crawlWaitEvent, crawlWaitReload);
 	}
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
 	 * 
-	 * @param hubUrl Url of the server.
-	 * @param filterAttributes the attributes to be filtered from DOM.
-	 * @param crawlWaitReload the period to wait after a reload.
-	 * @param crawlWaitEvent the period to wait after an event is fired.
-	 * @param ignoreFrameChecker the checker used to determine if a certain frame
-	 *           must be ignored.
+	 * @param hubUrl
+	 *            Url of the server.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-			List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-			IgnoreFrameChecker ignoreFrameChecker) {
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
+	        IgnoreFrameChecker ignoreFrameChecker) {
 		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
-				filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
+		        filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
 	}
 
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
 	 * 
-	 * @param driver The WebDriver to use.
-	 * @param filterAttributes the attributes to be filtered from DOM.
-	 * @param crawlWaitReload the period to wait after a reload.
-	 * @param crawlWaitEvent the period to wait after an event is fired.
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-			List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
 		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
-				crawlWaitReload);
+		        crawlWaitReload);
 	}
 
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
 	 * 
-	 * @param driver The WebDriver to use.
-	 * @param filterAttributes the attributes to be filtered from DOM.
-	 * @param crawlWaitReload the period to wait after a reload.
-	 * @param crawlWaitEvent the period to wait after an event is fired.
-	 * @param ignoreFrameChecker the checker used to determine if a certain frame
-	 *           must be ignored.
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-			List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-			IgnoreFrameChecker ignoreFrameChecker) {
+	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
+	        IgnoreFrameChecker ignoreFrameChecker) {
 		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
-				crawlWaitReload, ignoreFrameChecker);
+		        crawlWaitReload, ignoreFrameChecker);
 	}
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
 	 * 
-	 * @param hubUrl Url of the server.
+	 * @param hubUrl
+	 *            Url of the server.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl) {
@@ -184,10 +210,11 @@
 	}
 
 	/**
-	 * Private used static method for creation of a RemoteWebDriver. Taking care
-	 * of the default Capabilities and using the HttpCommandExecutor.
+	 * Private used static method for creation of a RemoteWebDriver. Taking care of the default
+	 * Capabilities and using the HttpCommandExecutor.
 	 * 
-	 * @param hubUrl the url of the hub to use.
+	 * @param hubUrl
+	 *            the url of the hub to use.
 	 * @return the RemoteWebDriver instance.
 	 */
 	private static RemoteWebDriver buildRemoteWebDriver(String hubUrl) {
@@ -198,7 +225,7 @@
 			url = new URL(hubUrl);
 		} catch (MalformedURLException e) {
 			LOGGER.error(""The given hub url of the remote server is malformed can not continue!"",
-					e);
+			        e);
 			return null;
 		}
 		HttpCommandExecutor executor = null;
@@ -209,7 +236,7 @@
 			// NullPointers, why
 			// not throw RuntimeExcption direct?
 			LOGGER.error(""Received unknown exception while creating the ""
-					+ ""HttpCommandExecutor, can not continue!"", e);
+			        + ""HttpCommandExecutor, can not continue!"", e);
 			return null;
 		}
 		return new RemoteWebDriver(executor, capabilities);
@@ -218,7 +245,8 @@
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
 	 * 
-	 * @param driver The WebDriver to use.
+	 * @param driver
+	 *            The WebDriver to use.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver) {
@@ -226,7 +254,8 @@
 	}
 
 	/**
-	 * @param url The URL.
+	 * @param url
+	 *            The URL.
 	 */
 	@Override
 	public void goToUrl(URL url) {
@@ -249,8 +278,8 @@
 	private void handlePopups() {
 		try {
 			executeJavaScript(""window.alert = function(msg){return true;};""
-					+ ""window.confirm = function(msg){return true;};""
-					+ ""window.prompt = function(msg){return true;};"");
+			        + ""window.confirm = function(msg){return true;};""
+			        + ""window.prompt = function(msg){return true;};"");
 		} catch (CrawljaxException e) {
 			LOGGER.error(""Handling of PopUp windows failed"", e);
 		}
@@ -259,12 +288,14 @@
 	/**
 	 * Fires the event and waits for a specified time.
 	 * 
-	 * @param webElement the element to fire event on.
-	 * @param eventable The HTML event type (onclick, onmouseover, ...).
+	 * @param webElement
+	 *            the element to fire event on.
+	 * @param eventable
+	 *            The HTML event type (onclick, onmouseover, ...).
 	 * @return true if firing event is successful.
 	 */
 	protected boolean fireEventWait(WebElement webElement, Eventable eventable)
-			throws ElementNotVisibleException {
+	        throws ElementNotVisibleException {
 		switch (eventable.getEventType()) {
 			case click:
 				try {
@@ -318,14 +349,15 @@
 	}
 
 	/**
-	 * @param html The html string.
+	 * @param html
+	 *            The html string.
 	 * @return uniform version of dom with predefined attributes stripped
 	 */
 	private String toUniformDOM(String html) {
 
 		Pattern p =
-				Pattern.compile(""<SCRIPT(.*?)</SCRIPT>"", Pattern.DOTALL
-						| Pattern.CASE_INSENSITIVE);
+		        Pattern.compile(""<SCRIPT(.*?)</SCRIPT>"", Pattern.DOTALL
+		                | Pattern.CASE_INSENSITIVE);
 		Matcher m = p.matcher(html);
 		String htmlFormatted = m.replaceAll("""");
 
@@ -344,7 +376,8 @@
 	/**
 	 * Filters attributes from the HTML string.
 	 * 
-	 * @param html The HTML to filter.
+	 * @param html
+	 *            The HTML to filter.
 	 * @return The filtered HTML string.
 	 */
 	private String filterAttributes(String html) {
@@ -369,8 +402,10 @@
 	}
 
 	/**
-	 * @param identification The identification object.
-	 * @param text The input.
+	 * @param identification
+	 *            The identification object.
+	 * @param text
+	 *            The input.
 	 * @return true if succeeds.
 	 */
 	@Override
@@ -396,11 +431,13 @@
 	/**
 	 * Fires an event on an element using its identification.
 	 * 
-	 * @param eventable The eventable.
+	 * @param eventable
+	 *            The eventable.
 	 * @return true if it is able to fire the event successfully on the element.
 	 */
 	@Override
-	public synchronized boolean fireEvent(Eventable eventable) throws ElementNotVisibleException, NoSuchElementException {
+	public synchronized boolean fireEvent(Eventable eventable) throws ElementNotVisibleException,
+	        NoSuchElementException {
 		try {
 
 			boolean handleChanged = false;
@@ -423,7 +460,7 @@
 			}
 
 			WebElement webElement =
-					browser.findElement(eventable.getIdentification().getWebDriverBy());
+			        browser.findElement(eventable.getIdentification().getWebDriverBy());
 
 			if (webElement != null) {
 				result = fireEventWait(webElement, eventable);
@@ -444,9 +481,11 @@
 	/**
 	 * Execute JavaScript in the browser.
 	 * 
-	 * @param code The code to execute.
+	 * @param code
+	 *            The code to execute.
 	 * @return The return value of the JavaScript.
-	 * @throws CrawljaxException when javascript execution failed.
+	 * @throws CrawljaxException
+	 *             when javascript execution failed.
 	 */
 	@Override
 	public Object executeJavaScript(String code) throws CrawljaxException {
@@ -462,7 +501,8 @@
 	/**
 	 * Determines whether the corresponding element is visible.
 	 * 
-	 * @param identification The element to search for.
+	 * @param identification
+	 *            The element to search for.
 	 * @return true if the element is visible
 	 */
 	@Override
@@ -514,7 +554,8 @@
 
 	/**
 	 * @return a Document object containing the contents of iframes as well.
-	 * @throws CrawljaxException if an exception is thrown.
+	 * @throws CrawljaxException
+	 *             if an exception is thrown.
 	 */
 	private Document getDomTreeWithFrames() throws CrawljaxException {
 
@@ -558,7 +599,7 @@
 			String nameId = DomUtils.getFrameIdentification(frameElement);
 
 			if (nameId != null
-					&& !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
+			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
 				frameIdentification += nameId;
 
 				String handle = browser.getWindowHandle();
@@ -576,13 +617,13 @@
 				try {
 					Element toAppendElement = DomUtils.asDocument(toAppend).getDocumentElement();
 					Element importedElement =
-							(Element) document.importNode(toAppendElement, true);
+					        (Element) document.importNode(toAppendElement, true);
 					frameElement.appendChild(importedElement);
 
 					appendFrameContent(importedElement, document, frameIdentification);
 				} catch (DOMException | IOException e) {
 					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-							+ "" continuing..."", e);
+					        + "" continuing..."", e);
 				}
 			}
 		}
@@ -622,8 +663,10 @@
 	}
 
 	/**
-	 * @param input the input to be filled.
-	 * @return FormInput with random value assigned if possible
+	 * @param input
+	 *            the input to be filled.
+	 * @return FormInput with random value assigned if possible. If no values were set it returns
+	 *         <code>null</code>
 	 */
 	@Override
 	public FormInput getInputWithRandomValue(FormInput input) {
@@ -631,8 +674,7 @@
 		WebElement webElement;
 		try {
 			webElement = browser.findElement(input.getIdentification().getWebDriverBy());
-			if (!(webElement.isDisplayed())) {
-
+			if (!webElement.isDisplayed()) {
 				return null;
 			}
 		} catch (WebDriverException e) {
@@ -640,35 +682,14 @@
 			return null;
 		}
 
-		Set<InputValue> values = new HashSet<InputValue>();
-
-		// create some random value
-
-		if (input.getType().toLowerCase().startsWith(""text"")) {
-			values.add(new InputValue(new RandomInputValueGenerator()
-					.getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
-		} else if (input.getType().equalsIgnoreCase(""checkbox"")
-				|| input.getType().equalsIgnoreCase(""radio"") && !webElement.isSelected()) {
-			if (new RandomInputValueGenerator().getCheck()) {
-				values.add(new InputValue(""1"", true));
-			} else {
-				values.add(new InputValue(""0"", false));
-
-			}
-		} else if (input.getType().equalsIgnoreCase(""select"")) {
-			try {
-				Select select = new Select(webElement);
-				WebElement option =
-						(WebElement) new RandomInputValueGenerator().getRandomOption(select
-								.getOptions());
-				values.add(new InputValue(option.getText(), true));
-			} catch (WebDriverException e) {
-				throwIfConnectionException(e);
-				return null;
-			}
+		Set<InputValue> values = new HashSet<>();
+		try {
+			setRandomValues(input, webElement, values);
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return null;
 		}
-
-		if (values.size() == 0) {
+		if (values.isEmpty()) {
 			return null;
 		}
 		input.setInputValues(values);
@@ -676,6 +697,29 @@
 
 	}
 
+	private void setRandomValues(FormInput input, WebElement webElement, Set<InputValue> values) {
+		String inputString = input.getType().toLowerCase();
+		if (inputString.startsWith(""text"")) {
+			values.add(new InputValue(new RandomInputValueGenerator()
+			        .getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
+		} else if (inputString.equals(""checkbox"") || inputString.equals(""radio"")
+		        && !webElement.isSelected()) {
+			if (new RandomInputValueGenerator().getCheck()) {
+				values.add(new InputValue(""1"", true));
+			} else {
+				values.add(new InputValue(""0"", false));
+			}
+		} else if (inputString.equals(""select"")) {
+			Select select = new Select(webElement);
+			if (!select.getOptions().isEmpty()) {
+				WebElement option =
+				        new RandomInputValueGenerator().getRandomItem(select.getOptions());
+				values.add(new InputValue(option.getText(), true));
+			}
+
+		}
+	}
+
 	@Override
 	public String getFrameDom(String iframeIdentification) {
 		try {
@@ -695,7 +739,8 @@
 	}
 
 	/**
-	 * @param identification the identification of the element.
+	 * @param identification
+	 *            the identification of the element.
 	 * @return true if the element can be found in the DOM tree.
 	 */
 	@Override
@@ -713,7 +758,8 @@
 	}
 
 	/**
-	 * @param identification the identification of the element.
+	 * @param identification
+	 *            the identification of the element.
 	 * @return the found element.
 	 */
 	@Override
@@ -786,7 +832,7 @@
 			executeJavaScript(js);
 		} catch (CrawljaxException e) {
 			LOGGER.error(""Removing of Canvas Generated By FirefoxDriver failed,""
-					+ "" most likely leaving it in the browser"", e);
+			        + "" most likely leaving it in the browser"", e);
 		}
 	}
 
@@ -802,18 +848,18 @@
 		// Retrieve the config values used
 		this.filterAttributes = configuration.getFilterAttributeNames();
 		this.crawlWaitReload =
-				configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
+		        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
 		this.crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
 		this.ignoreFrameChecker = configuration.getCrawlSpecificationReader();
 	}
 
 	private boolean exceptionIsConnectionException(WebDriverException exception) {
 		return exception != null && exception.getCause() != null
-				&& exception.getCause() instanceof IOException;
+		        && exception.getCause() instanceof IOException;
 	}
 
 	private RuntimeException wrapWebDriverExceptionIfConnectionException(
-			WebDriverException exception) {
+	        WebDriverException exception) {
 		if (exceptionIsConnectionException(exception)) {
 			return new BrowserConnectionException(exception);
 		}
"
f50841ce3507f16b336a3390926b386fa29f52c5,Alex Nederlof,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 4501ec6..9c8c274 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -227,17 +227,30 @@
 	}
 
 	/**
-	 * Sets the maximum time for Crawljax to run. Crawljax will stop crawling when this timelimit is
-	 * reached.
+	 * Sets the maximum time for Crawljax to run. Crawljax will stop crawling when this time limit
+	 * is reached.
 	 * 
-	 * @param seconds
-	 *            the crawlMaximumRuntime to set
+	 * @param the
+	 *            crawlMaximumRuntime to set
 	 */
 	public void setMaximumRuntime(long time, TimeUnit timeUnit) {
 		this.maximumRuntime = timeUnit.toSeconds(time);
 	}
 
 	/**
+	 * Sets the maximum time for Crawljax to run. Crawljax will stop crawling when this time limit
+	 * is reached.
+	 * 
+	 * @deprecated use {@link #setMaximumRuntime(long, TimeUnit)}.
+	 * @param seconds
+	 *            the crawlMaximumRuntime to set
+	 */
+	@Deprecated
+	public void setMaximumRuntime(long time) {
+		this.maximumRuntime = time;
+	}
+
+	/**
 	 * @return whether to Crawljax should enter random values in form input fields
 	 */
 	protected boolean getRandomInputInForms() {
@@ -260,14 +273,24 @@
 	}
 
 	/**
-	 * @param milliseconds
-	 *            the number of milliseconds to wait after reloading the url
+	 * @param time
+	 *            to wait after reloading the url
 	 */
 	public void setWaitTimeAfterReloadUrl(long time, TimeUnit unit) {
 		this.waitTimeAfterReloadUrl = unit.toMillis(time);
 	}
 
 	/**
+	 * @deprecated use {@link #setWaitTimeAfterReloadUrl(long, TimeUnit)}
+	 * @param time
+	 *            to wait after reloading the url
+	 */
+	@Deprecated
+	public void setWaitTimeAfterReloadUrl(long timeInMillis) {
+		this.waitTimeAfterReloadUrl = timeInMillis;
+	}
+
+	/**
 	 * @return the number the number of milliseconds to wait after an event is fired
 	 */
 	protected long getWaitTimeAfterEvent() {
@@ -275,14 +298,24 @@
 	}
 
 	/**
-	 * @param milliseconds
-	 *            the number of milliseconds to wait after an event is fired
+	 * @param the
+	 *            time to wait after an event is fired
 	 */
 	public void setWaitTimeAfterEvent(long time, TimeUnit unit) {
 		this.waitTimeAfterEvent = unit.toMillis(time);
 	}
 
 	/**
+	 * @deprecated use {@link #setWaitTimeAfterEvent(long, TimeUnit)}
+	 * @param milliseconds
+	 *            the number of milliseconds to wait after an event is fired
+	 */
+	@Deprecated
+	public void setWaitTimeAfterEvent(long time) {
+		this.waitTimeAfterEvent = time;
+	}
+
+	/**
 	 * @return the events that should be fired (e.g. onclick)
 	 */
 	protected ImmutableList<EventType> getCrawlEvents() {
"
f50841ce3507f16b336a3390926b386fa29f52c5,Alex Nederlof,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/core/src/main/java/com/crawljax/core/configuration/InputField.java b/core/src/main/java/com/crawljax/core/configuration/InputField.java
index 7108d39..b25765c 100644
--- a/core/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -99,7 +99,7 @@
 	 * @return The value.
 	 */
 	protected String getValue() {
-		if (fieldValues.size() == 0) {
+		if (fieldValues.isEmpty()) {
 			return null;
 		} else {
 			return fieldValues.get(0);
"
f50841ce3507f16b336a3390926b386fa29f52c5,Alex Nederlof,OutputBuilder.java,MODIFY,write -> [CrawlSpecificationReader crawlSpecificationReader] | [OutPutModel outModel],"diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
index 770b2eb..2cba28f 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
@@ -12,6 +12,7 @@
 import java.io.IOException;
 import java.net.URISyntaxException;
 import java.net.URL;
+import java.util.Arrays;
 import java.util.zip.ZipEntry;
 import java.util.zip.ZipInputStream;
 
@@ -35,6 +36,7 @@
 import com.fasterxml.jackson.annotation.PropertyAccessor;
 import com.fasterxml.jackson.core.JsonProcessingException;
 import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.ObjectWriter;
 import com.google.common.base.Charsets;
 import com.google.common.base.Strings;
 import com.google.common.io.ByteStreams;
@@ -74,11 +76,14 @@
 
 		indexFile = new File(outputDir, ""index.html"");
 		ve = new VelocityEngine();
+		configureVelocity();
+	}
+
+	private void configureVelocity() {
 		ve.setProperty(RuntimeConstants.RUNTIME_LOG_LOGSYSTEM_CLASS,
 		        ""org.apache.velocity.runtime.log.NullLogChute"");
 		ve.setProperty(RuntimeConstants.RESOURCE_LOADER, ""classpath"");
 		ve.setProperty(""classpath.resource.loader.class"", ClasspathResourceLoader.class.getName());
-
 	}
 
 	private void checkPermissions() {
@@ -201,6 +206,17 @@
 		writeFile(context, file, ""urls.html"");
 	}
 
+	public void write(CrawlSpecificationReader crawlSpecificationReader) {
+		ObjectMapper objectMapper = new ObjectMapper();
+		try {
+			ObjectWriter prettyPrinter = objectMapper.writer().withDefaultPrettyPrinter();
+			prettyPrinter
+			        .writeValue(new File(outputDir, ""config.json""), crawlSpecificationReader);
+		} catch (Exception e) {
+			throw new RuntimeException(""Cannot save config"", e);
+		}
+	}
+
 	private void writeFile(VelocityContext context, File outFile, String template) {
 		try {
 			Template templatee = ve.getTemplate(template);
"
935c2b6620b57f7c77a6dcf224d43d6a2adaaeb9,Alex Nederlof,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 9c8c274..77d2d9a 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -79,7 +79,7 @@
 	private boolean clicklOnce = true;
 	private boolean disableCrawlFrames = false;
 
-	private boolean clickHiddenAnchors = true;
+	private boolean clickHiddenAnchors = false;
 
 	/**
 	 * @param url
"
fbdd6b98e6316c88a712da5af64a52879ab69385,Alex Nederlof,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 696f586..9699997 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -232,7 +232,7 @@
 	 *            crawlMaximumRuntime to set
 	 */
 	public void setMaximumRuntime(long time, TimeUnit timeUnit) {
-		this.maximumRuntime = timeUnit.toSeconds(time);
+		this.maximumRuntime = timeUnit.toMillis(time);
 	}
 
 	/**
@@ -245,7 +245,7 @@
 	 */
 	@Deprecated
 	public void setMaximumRuntime(long time) {
-		this.maximumRuntime = time;
+		this.maximumRuntime = TimeUnit.SECONDS.toMillis(time);
 	}
 
 	/**
"
31e842e716384679429c4f15a7dafdd267745dc3,Alex Nederlof,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 696f586..022ff1d 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -109,19 +109,6 @@
 	}
 
 	/**
-	 * Click {@link #clickDefaultElements()}, {@link #clickTableElements()} and click
-	 * <code>""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"",
-		        ""refresh"", ""xhr"", ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"",
-		        ""p""</code>
-	 */
-	public void clickMoreElements() {
-		clickDefaultElements();
-		clickTableElements();
-		click(""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"", ""refresh"", ""xhr"",
-		        ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"", ""p"");
-	}
-
-	/**
 	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
 	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}.
 	 * 
@@ -136,13 +123,6 @@
 	}
 
 	/**
-	 * Clicks <code>""td"", ""tr"", ""table"", ""tbody""</code>
-	 */
-	public void clickTableElements() {
-		click(""td"", ""tr"", ""table"", ""tbody"");
-	}
-
-	/**
 	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
 	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}.
 	 * 
"
a22d5cdff6bd20c860da7fd93772a2cc356c5072,Alex Nederlof,StateFlowGraph.java,MODIFY,"addState -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index da12f27..32844d0 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -22,11 +22,10 @@
  * The State-Flow Graph is a multi-edge directed graph with states (StateVetex) on the vertices and
  * clickables (Eventable) on the edges.
  */
+@SuppressWarnings(""serial"")
 public class StateFlowGraph implements Serializable {
 
-	private static final long serialVersionUID = 923403417983488L;
-
-	private static final Logger LOGGER = LoggerFactory.getLogger(StateFlowGraph.class.getName());
+	private static final Logger LOG = LoggerFactory.getLogger(StateFlowGraph.class.getName());
 
 	private final DirectedGraph<StateVertex, Eventable> sfg;
 
@@ -34,13 +33,13 @@
 	 * Intermediate counter for the number of states, not relaying on getAllStates.size() because of
 	 * Thread-safety.
 	 */
-	private final AtomicInteger stateCounter = new AtomicInteger(1);
+	private final AtomicInteger stateCounter = new AtomicInteger();
 
 	/**
 	 * Empty constructor.
 	 */
 	public StateFlowGraph() {
-		sfg = new DirectedMultigraph<StateVertex, Eventable>(Eventable.class);
+		sfg = new DirectedMultigraph<>(Eventable.class);
 	}
 
 	/**
@@ -93,29 +92,27 @@
 		synchronized (sfg) {
 			if (!sfg.addVertex(stateVertix)) {
 				// Graph already contained the vertix
+				LOG.debug(""Graph already contained vertex {}"", stateVertix);
 				return this.getStateInGraph(stateVertix);
 			} else {
-				/**
-				 * A new State has been added so check to see if the name is correct, remember this
-				 * is the only place states can be added and we are now locked so getAllStates.size
-				 * works correctly.
-				 */
+				LOG.debug(""Number of states is now {}"", stateCounter.incrementAndGet());
 				if (correctName) {
-					// the -1 is for the ""index"" state.
-					int totalNumberOfStates = this.getAllStates().size() - 1;
-					String correctedName =
-					        makeStateName(totalNumberOfStates, stateVertix.isGuidedCrawling());
-					if (!stateVertix.getName().equals(""index"")
-					        && !stateVertix.getName().equals(correctedName)) {
-						LOGGER.info(""Correcting state name from  "" + stateVertix.getName()
-						        + "" to "" + correctedName);
-						stateVertix.setName(correctedName);
-					}
+					correctStateName(stateVertix);
 				}
+				return null;
 			}
-			stateCounter.set(this.getAllStates().size() - 1);
 		}
-		return null;
+	}
+
+	private void correctStateName(StateVertex stateVertix) {
+		// the -1 is for the ""index"" state.
+		int totalNumberOfStates = this.getAllStates().size() - 1;
+		String correctedName = makeStateName(totalNumberOfStates, stateVertix.isGuidedCrawling());
+		if (!""index"".equals(stateVertix.getName())
+		        && !stateVertix.getName().equals(correctedName)) {
+			LOG.info(""Correcting state name from {}  to {}"", stateVertix.getName(), correctedName);
+			stateVertix.setName(correctedName);
+		}
 	}
 
 	/**
@@ -140,14 +137,12 @@
 	@GuardedBy(""sfg"")
 	public boolean addEdge(StateVertex sourceVert, StateVertex targetVert, Eventable clickable) {
 		synchronized (sfg) {
-			// TODO Ali; Why is this code (if-stmt) here? Its the same as what happens in sfg.addEge
-			// imo (21-01-10 Stefan).
 			if (sfg.containsEdge(sourceVert, targetVert)
 			        && sfg.getAllEdges(sourceVert, targetVert).contains(clickable)) {
 				return false;
+			} else {
+				return sfg.addEdge(sourceVert, targetVert, clickable);
 			}
-
-			return sfg.addEdge(sourceVert, targetVert, clickable);
 		}
 	}
 
@@ -157,7 +152,9 @@
 	 */
 	@Override
 	public String toString() {
-		return sfg.toString();
+		synchronized (sfg) {
+			return sfg.toString();
+		}
 	}
 
 	/**
@@ -291,13 +288,6 @@
 	}
 
 	/**
-	 * @return the state-flow graph.
-	 */
-	public DirectedGraph<StateVertex, Eventable> getSfg() {
-		return sfg;
-	}
-
-	/**
 	 * @param state
 	 *            The starting state.
 	 * @return A list of the deepest states (states with no outgoing edges).
@@ -365,7 +355,7 @@
 				results.add(paths);
 			} catch (Exception e) {
 				// TODO Stefan; which Exception is catched here???Can this be removed?
-				LOGGER.error(""Error with "" + state.toString(), e);
+				LOG.error(""Error with "" + state.toString(), e);
 			}
 
 		}
"
69e43b9acc547eea4ae7070eeababbdb123a4ff8,Alex Nederlof,StateFlowGraph.java,MODIFY,"addState -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index 32844d0..806f3d3 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -18,6 +18,8 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import com.google.common.base.Preconditions;
+
 /**
  * The State-Flow Graph is a multi-edge directed graph with states (StateVetex) on the vertices and
  * clickables (Eventable) on the edges.
@@ -35,12 +37,7 @@
 	 */
 	private final AtomicInteger stateCounter = new AtomicInteger();
 
-	/**
-	 * Empty constructor.
-	 */
-	public StateFlowGraph() {
-		sfg = new DirectedMultigraph<>(Eventable.class);
-	}
+	private final StateVertex initialState;
 
 	/**
 	 * The constructor.
@@ -49,8 +46,10 @@
 	 *            the state to start from.
 	 */
 	public StateFlowGraph(StateVertex initialState) {
-		this();
+		Preconditions.checkNotNull(initialState);
+		sfg = new DirectedMultigraph<>(Eventable.class);
 		sfg.addVertex(initialState);
+		this.initialState = initialState;
 	}
 
 	/**
@@ -390,4 +389,8 @@
 
 		return ""state"" + id;
 	}
+
+	public boolean isInitialState(StateVertex state) {
+		return initialState.equals(state);
+	}
 }
"
cc9666ecaf31219ac95fab6ca1b4350963c119a2,Ali Mesbah,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 696f586..022ff1d 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -109,19 +109,6 @@
 	}
 
 	/**
-	 * Click {@link #clickDefaultElements()}, {@link #clickTableElements()} and click
-	 * <code>""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"",
-		        ""refresh"", ""xhr"", ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"",
-		        ""p""</code>
-	 */
-	public void clickMoreElements() {
-		clickDefaultElements();
-		clickTableElements();
-		click(""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"", ""refresh"", ""xhr"",
-		        ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"", ""p"");
-	}
-
-	/**
 	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
 	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}.
 	 * 
@@ -136,13 +123,6 @@
 	}
 
 	/**
-	 * Clicks <code>""td"", ""tr"", ""table"", ""tbody""</code>
-	 */
-	public void clickTableElements() {
-		click(""td"", ""tr"", ""table"", ""tbody"");
-	}
-
-	/**
 	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
 	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}.
 	 * 
"
2502f89bfc7b29a37ecaabaaa76bbb38fc93a431,Ali Mesbah,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 022ff1d..552a95d 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -212,7 +212,7 @@
 	 *            crawlMaximumRuntime to set
 	 */
 	public void setMaximumRuntime(long time, TimeUnit timeUnit) {
-		this.maximumRuntime = timeUnit.toSeconds(time);
+		this.maximumRuntime = timeUnit.toMillis(time);
 	}
 
 	/**
@@ -225,7 +225,7 @@
 	 */
 	@Deprecated
 	public void setMaximumRuntime(long time) {
-		this.maximumRuntime = time;
+		this.maximumRuntime = TimeUnit.SECONDS.toMillis(time);
 	}
 
 	/**
"
f313837d9f4cb35a8b30c3538d479fb6c7942617,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 7629f3c..3f21f86 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -18,6 +18,7 @@
 import org.openqa.selenium.OutputType;
 import org.openqa.selenium.Platform;
 import org.openqa.selenium.TakesScreenshot;
+import org.openqa.selenium.UnhandledAlertException;
 import org.openqa.selenium.WebDriver;
 import org.openqa.selenium.WebDriverException;
 import org.openqa.selenium.WebElement;
@@ -231,7 +232,8 @@
 		try {
 			executor = new HttpCommandExecutor(url);
 		} catch (Exception e) {
-			// TODO Stefan; refactor this catch, this will definitely result in NullPointers, why
+			// TODO Stefan; refactor this catch, this will definitely result in
+			// NullPointers, why
 			// not throw RuntimeExcption direct?
 			LOGGER.error(""Received unknown exception while creating the ""
 			        + ""HttpCommandExecutor, can not continue!"", e);
@@ -292,27 +294,24 @@
 	 *            The HTML event type (onclick, onmouseover, ...).
 	 * @return true if firing event is successful.
 	 */
-	protected boolean fireEventWait(WebElement webElement, Eventable eventable) {
+	protected boolean fireEventWait(WebElement webElement, Eventable eventable)
+	        throws ElementNotVisibleException {
 		switch (eventable.getEventType()) {
 			case click:
 				try {
 					webElement.click();
-				} catch (ElementNotVisibleException e1) {
-					LOGGER.info(""Element not visible, so cannot be clicked: ""
-					        + webElement.getTagName().toUpperCase() + "" "" + webElement.getText());
-					return false;
+				} catch (ElementNotVisibleException e) {
+					throw e;
 				} catch (WebDriverException e) {
 					throwIfConnectionException(e);
 					return false;
 				}
 				break;
 			case hover:
-				// todo
+				LOGGER.info(""Eventype hover called but this isnt implemented yet"");
 				break;
-
 			default:
-				LOGGER.info(""EventType "" + eventable.getEventType()
-				        + "" not supported in WebDriver."");
+				LOGGER.info(""EventType {} not supported in WebDriver."", eventable.getEventType());
 				return false;
 		}
 
@@ -437,7 +436,8 @@
 	 * @return true if it is able to fire the event successfully on the element.
 	 */
 	@Override
-	public synchronized boolean fireEvent(Eventable eventable) {
+	public synchronized boolean fireEvent(Eventable eventable) throws ElementNotVisibleException,
+	        NoSuchElementException {
 		try {
 
 			boolean handleChanged = false;
@@ -450,8 +450,10 @@
 					switchToFrame(eventable.getRelatedFrame());
 				} catch (NoSuchFrameException e) {
 					LOGGER.debug(""Frame not found, possibily while back-tracking.."", e);
-					// TODO Stefan, This exception is catched to prevent stopping from working
-					// This was the case on the Gmail case; find out if not switching (catching)
+					// TODO Stefan, This exception is catched to prevent stopping
+					// from working
+					// This was the case on the Gmail case; find out if not switching
+					// (catching)
 					// Results in good performance...
 				}
 				handleChanged = true;
@@ -468,9 +470,8 @@
 				browser.switchTo().defaultContent();
 			}
 			return result;
-		} catch (NoSuchElementException e) {
-			LOGGER.warn(""Could not fire eventable: "" + eventable.toString());
-			return false;
+		} catch (ElementNotVisibleException | NoSuchElementException e) {
+			throw e;
 		} catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return false;
@@ -544,6 +545,8 @@
 					browser.switchTo().window(current);
 				}
 			}
+		} catch (UnhandledAlertException e) {
+			LOGGER.warn(""While closing the window, an alert got ignored: {}"", e.getMessage());
 		} catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
@@ -706,7 +709,7 @@
 			} else {
 				values.add(new InputValue(""0"", false));
 			}
-		} else if (input.getType().equalsIgnoreCase(""select"")) {
+		} else if (inputString.equals(""select"")) {
 			Select select = new Select(webElement);
 			if (!select.getOptions().isEmpty()) {
 				WebElement option =
@@ -744,7 +747,8 @@
 	public boolean elementExists(Identification identification) {
 		try {
 			WebElement el = browser.findElement(identification.getWebDriverBy());
-			// TODO Stefan; I think el will never be null as a NoSuchElementExcpetion will be
+			// TODO Stefan; I think el will never be null as a
+			// NoSuchElementExcpetion will be
 			// thrown, catched below.
 			return el != null;
 		} catch (WebDriverException e) {
"
f313837d9f4cb35a8b30c3538d479fb6c7942617,Alex Nederlof,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 552a95d..4a31314 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -79,6 +79,8 @@
 	private boolean clicklOnce = true;
 	private boolean disableCrawlFrames = false;
 
+	private boolean clickHiddenAnchors = false;
+
 	/**
 	 * @param url
 	 *            the site to crawl
@@ -514,4 +516,25 @@
 	protected boolean isCrawlFrames() {
 		return !disableCrawlFrames;
 	}
+
+	boolean isClickHiddenAnchors() {
+		return clickHiddenAnchors;
+	}
+
+	/**
+	 * Set Crawljax to click hidden anchors or not. <code>true</code> by default. @ *
+	 * <dl>
+	 * <dd>Pro:</dd>
+	 * <dt>The benefit of clicking hidden anchors is that Crawljax isn't capable of clicking
+	 * elements that are hidden for example because you have to hover another element first. This
+	 * happens in most fold-out menus for example. Enabling this function allows Crawljax to find
+	 * more states that are hidden this way.</dt>
+	 * <dd>Con:</dd>
+	 * <dt>If a anchor tag is never visible in the browser in any way, Crawljax will crawl it
+	 * anyway. This makes the Crawl inconsistent with what the user experiences.</dt>
+	 * </dl>
+	 */
+	public void clickHiddenAnchors(boolean clickHiddenAnchors) {
+		this.clickHiddenAnchors = clickHiddenAnchors;
+	}
 }
"
c4f9cdaf0ed94f27d700847c07d0eb29f8853879,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 7629f3c..3f21f86 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -18,6 +18,7 @@
 import org.openqa.selenium.OutputType;
 import org.openqa.selenium.Platform;
 import org.openqa.selenium.TakesScreenshot;
+import org.openqa.selenium.UnhandledAlertException;
 import org.openqa.selenium.WebDriver;
 import org.openqa.selenium.WebDriverException;
 import org.openqa.selenium.WebElement;
@@ -231,7 +232,8 @@
 		try {
 			executor = new HttpCommandExecutor(url);
 		} catch (Exception e) {
-			// TODO Stefan; refactor this catch, this will definitely result in NullPointers, why
+			// TODO Stefan; refactor this catch, this will definitely result in
+			// NullPointers, why
 			// not throw RuntimeExcption direct?
 			LOGGER.error(""Received unknown exception while creating the ""
 			        + ""HttpCommandExecutor, can not continue!"", e);
@@ -292,27 +294,24 @@
 	 *            The HTML event type (onclick, onmouseover, ...).
 	 * @return true if firing event is successful.
 	 */
-	protected boolean fireEventWait(WebElement webElement, Eventable eventable) {
+	protected boolean fireEventWait(WebElement webElement, Eventable eventable)
+	        throws ElementNotVisibleException {
 		switch (eventable.getEventType()) {
 			case click:
 				try {
 					webElement.click();
-				} catch (ElementNotVisibleException e1) {
-					LOGGER.info(""Element not visible, so cannot be clicked: ""
-					        + webElement.getTagName().toUpperCase() + "" "" + webElement.getText());
-					return false;
+				} catch (ElementNotVisibleException e) {
+					throw e;
 				} catch (WebDriverException e) {
 					throwIfConnectionException(e);
 					return false;
 				}
 				break;
 			case hover:
-				// todo
+				LOGGER.info(""Eventype hover called but this isnt implemented yet"");
 				break;
-
 			default:
-				LOGGER.info(""EventType "" + eventable.getEventType()
-				        + "" not supported in WebDriver."");
+				LOGGER.info(""EventType {} not supported in WebDriver."", eventable.getEventType());
 				return false;
 		}
 
@@ -437,7 +436,8 @@
 	 * @return true if it is able to fire the event successfully on the element.
 	 */
 	@Override
-	public synchronized boolean fireEvent(Eventable eventable) {
+	public synchronized boolean fireEvent(Eventable eventable) throws ElementNotVisibleException,
+	        NoSuchElementException {
 		try {
 
 			boolean handleChanged = false;
@@ -450,8 +450,10 @@
 					switchToFrame(eventable.getRelatedFrame());
 				} catch (NoSuchFrameException e) {
 					LOGGER.debug(""Frame not found, possibily while back-tracking.."", e);
-					// TODO Stefan, This exception is catched to prevent stopping from working
-					// This was the case on the Gmail case; find out if not switching (catching)
+					// TODO Stefan, This exception is catched to prevent stopping
+					// from working
+					// This was the case on the Gmail case; find out if not switching
+					// (catching)
 					// Results in good performance...
 				}
 				handleChanged = true;
@@ -468,9 +470,8 @@
 				browser.switchTo().defaultContent();
 			}
 			return result;
-		} catch (NoSuchElementException e) {
-			LOGGER.warn(""Could not fire eventable: "" + eventable.toString());
-			return false;
+		} catch (ElementNotVisibleException | NoSuchElementException e) {
+			throw e;
 		} catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return false;
@@ -544,6 +545,8 @@
 					browser.switchTo().window(current);
 				}
 			}
+		} catch (UnhandledAlertException e) {
+			LOGGER.warn(""While closing the window, an alert got ignored: {}"", e.getMessage());
 		} catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
@@ -706,7 +709,7 @@
 			} else {
 				values.add(new InputValue(""0"", false));
 			}
-		} else if (input.getType().equalsIgnoreCase(""select"")) {
+		} else if (inputString.equals(""select"")) {
 			Select select = new Select(webElement);
 			if (!select.getOptions().isEmpty()) {
 				WebElement option =
@@ -744,7 +747,8 @@
 	public boolean elementExists(Identification identification) {
 		try {
 			WebElement el = browser.findElement(identification.getWebDriverBy());
-			// TODO Stefan; I think el will never be null as a NoSuchElementExcpetion will be
+			// TODO Stefan; I think el will never be null as a
+			// NoSuchElementExcpetion will be
 			// thrown, catched below.
 			return el != null;
 		} catch (WebDriverException e) {
"
c4f9cdaf0ed94f27d700847c07d0eb29f8853879,Alex Nederlof,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 696f586..4a31314 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -79,6 +79,8 @@
 	private boolean clicklOnce = true;
 	private boolean disableCrawlFrames = false;
 
+	private boolean clickHiddenAnchors = false;
+
 	/**
 	 * @param url
 	 *            the site to crawl
@@ -109,19 +111,6 @@
 	}
 
 	/**
-	 * Click {@link #clickDefaultElements()}, {@link #clickTableElements()} and click
-	 * <code>""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"",
-		        ""refresh"", ""xhr"", ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"",
-		        ""p""</code>
-	 */
-	public void clickMoreElements() {
-		clickDefaultElements();
-		clickTableElements();
-		click(""span"", ""div"", ""ol"", ""center"", ""li"", ""radio"", ""non"", ""meta"", ""refresh"", ""xhr"",
-		        ""relative"", ""link"", ""self"", ""form"", ""input"", ""option"", ""img"", ""p"");
-	}
-
-	/**
 	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
 	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}.
 	 * 
@@ -136,13 +125,6 @@
 	}
 
 	/**
-	 * Clicks <code>""td"", ""tr"", ""table"", ""tbody""</code>
-	 */
-	public void clickTableElements() {
-		click(""td"", ""tr"", ""table"", ""tbody"");
-	}
-
-	/**
 	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
 	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}.
 	 * 
@@ -232,7 +214,7 @@
 	 *            crawlMaximumRuntime to set
 	 */
 	public void setMaximumRuntime(long time, TimeUnit timeUnit) {
-		this.maximumRuntime = timeUnit.toSeconds(time);
+		this.maximumRuntime = timeUnit.toMillis(time);
 	}
 
 	/**
@@ -245,7 +227,7 @@
 	 */
 	@Deprecated
 	public void setMaximumRuntime(long time) {
-		this.maximumRuntime = time;
+		this.maximumRuntime = TimeUnit.SECONDS.toMillis(time);
 	}
 
 	/**
@@ -534,4 +516,25 @@
 	protected boolean isCrawlFrames() {
 		return !disableCrawlFrames;
 	}
+
+	boolean isClickHiddenAnchors() {
+		return clickHiddenAnchors;
+	}
+
+	/**
+	 * Set Crawljax to click hidden anchors or not. <code>true</code> by default. @ *
+	 * <dl>
+	 * <dd>Pro:</dd>
+	 * <dt>The benefit of clicking hidden anchors is that Crawljax isn't capable of clicking
+	 * elements that are hidden for example because you have to hover another element first. This
+	 * happens in most fold-out menus for example. Enabling this function allows Crawljax to find
+	 * more states that are hidden this way.</dt>
+	 * <dd>Con:</dd>
+	 * <dt>If a anchor tag is never visible in the browser in any way, Crawljax will crawl it
+	 * anyway. This makes the Crawl inconsistent with what the user experiences.</dt>
+	 * </dl>
+	 */
+	public void clickHiddenAnchors(boolean clickHiddenAnchors) {
+		this.clickHiddenAnchors = clickHiddenAnchors;
+	}
 }
"
794f0ff5bac71e6034fccb15d649dc0a3b0e9525,Alex Nederlof,EmbeddedBrowser.java,MODIFY,updateConfiguration -> [CrawljaxConfigurationReader configuration] | [CrawljaxConfiguration configuration],"diff --git a/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
index 40a4a43..41c944b 100644
--- a/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
@@ -7,7 +7,7 @@
 import org.openqa.selenium.WebElement;
 
 import com.crawljax.core.CrawljaxException;
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.Identification;
 import com.crawljax.forms.FormInput;
@@ -145,5 +145,5 @@
 	 * @param configuration
 	 *            the new configuration values that needs to be updated.
 	 */
-	void updateConfiguration(CrawljaxConfigurationReader configuration);
+	void updateConfiguration(CrawljaxConfiguration configuration);
 }
"
794f0ff5bac71e6034fccb15d649dc0a3b0e9525,Alex Nederlof,EmbeddedBrowserBuilder.java,MODIFY,buildEmbeddedBrowser -> [CrawljaxConfigurationReader configuration] | [CrawljaxConfiguration configuration],"diff --git a/core/src/main/java/com/crawljax/browser/EmbeddedBrowserBuilder.java b/core/src/main/java/com/crawljax/browser/EmbeddedBrowserBuilder.java
index 57b831f..ef1fd98 100644
--- a/core/src/main/java/com/crawljax/browser/EmbeddedBrowserBuilder.java
+++ b/core/src/main/java/com/crawljax/browser/EmbeddedBrowserBuilder.java
@@ -1,6 +1,6 @@
 package com.crawljax.browser;
 
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
 
 /**
  * This is the main interface for building a concrete EmbeddedBrowser implementation. By default
@@ -38,5 +38,5 @@
 	 *            The configuration reader object to read the specific configuration options form.
 	 * @return the new created instance of a EmbeddedBrowser to be used.
 	 */
-	EmbeddedBrowser buildEmbeddedBrowser(CrawljaxConfigurationReader configuration);
+	EmbeddedBrowser buildEmbeddedBrowser(CrawljaxConfiguration configuration);
 }
"
794f0ff5bac71e6034fccb15d649dc0a3b0e9525,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 3f21f86..724a7e3 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -38,7 +38,7 @@
 
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.AcceptAllFramesChecker;
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.crawljax.core.configuration.IgnoreFrameChecker;
 import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.core.state.Eventable;
@@ -48,6 +48,7 @@
 import com.crawljax.forms.InputValue;
 import com.crawljax.forms.RandomInputValueGenerator;
 import com.crawljax.util.DomUtils;
+import com.google.common.collect.ImmutableSortedSet;
 
 /**
  * @author mesbah
@@ -61,7 +62,7 @@
 	        .getLogger(WebDriverBackedEmbeddedBrowser.class);
 	private final WebDriver browser;
 
-	private List<String> filterAttributes;
+	private ImmutableSortedSet<String> filterAttributes;
 	private long crawlWaitReload;
 	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
 
@@ -88,8 +89,8 @@
 	 * @param crawlWaitEvent
 	 *            the period to wait after an event is fired.
 	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent) {
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload, long crawlWaitEvent) {
 		this(driver);
 		this.filterAttributes = filterAttributes;
 		this.crawlWaitEvent = crawlWaitEvent;
@@ -110,8 +111,9 @@
 	 * @param ignoreFrameChecker
 	 *            the checker used to determine if a certain frame must be ignored.
 	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload,
+	        long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
 		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
 		this.ignoreFrameChecker = ignoreFrameChecker;
 	}
@@ -130,7 +132,7 @@
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
 		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
 		        filterAttributes, crawlWaitEvent, crawlWaitReload);
 	}
@@ -151,8 +153,8 @@
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-	        IgnoreFrameChecker ignoreFrameChecker) {
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent,
+	        long crawlWaitReload, IgnoreFrameChecker ignoreFrameChecker) {
 		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
 		        filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
 	}
@@ -171,7 +173,7 @@
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
 		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
 		        crawlWaitReload);
 	}
@@ -192,8 +194,8 @@
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-	        IgnoreFrameChecker ignoreFrameChecker) {
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent,
+	        long crawlWaitReload, IgnoreFrameChecker ignoreFrameChecker) {
 		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
 		        crawlWaitReload, ignoreFrameChecker);
 	}
@@ -781,7 +783,7 @@
 	/**
 	 * @return the list of attributes to be filtered from DOM.
 	 */
-	protected List<String> getFilterAttributes() {
+	protected ImmutableSortedSet<String> getFilterAttributes() {
 		return filterAttributes;
 	}
 
@@ -844,12 +846,12 @@
 	}
 
 	@Override
-	public void updateConfiguration(CrawljaxConfigurationReader configuration) {
+	public void updateConfiguration(CrawljaxConfiguration configuration) {
 		// Retrieve the config values used
-		this.filterAttributes = configuration.getFilterAttributeNames();
-		this.crawlWaitReload =
-		        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
-		this.crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
+		this.filterAttributes =
+		        configuration.getCrawlRules().getPreCrawlConfig().getFilterAttributeNames();
+		this.crawlWaitReload = configuration.getCrawlRules().getWaitAfterReloadUrl();
+		this.crawlWaitEvent = configuration.getCrawlRules().getWaitAfterEvent();
 		this.ignoreFrameChecker = configuration.getCrawlSpecificationReader();
 	}
 
"
794f0ff5bac71e6034fccb15d649dc0a3b0e9525,Alex Nederlof,WebDriverBrowserBuilder.java,MODIFY,buildEmbeddedBrowser -> [CrawljaxConfigurationReader configuration] | [CrawljaxConfiguration configuration],"diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java b/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java
index 2edbd5c..622f432 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java
@@ -1,7 +1,5 @@
 package com.crawljax.browser;
 
-import java.util.List;
-
 import org.openqa.selenium.android.AndroidDriver;
 import org.openqa.selenium.chrome.ChromeDriver;
 import org.openqa.selenium.chrome.ChromeOptions;
@@ -13,8 +11,9 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.gargoylesoftware.htmlunit.BrowserVersion;
+import com.google.common.collect.ImmutableSortedSet;
 
 /**
  * Default implementation of the EmbeddedBrowserBuilder based on Selenium WebDriver API.
@@ -32,15 +31,15 @@
 	 * @return the new build WebDriver based embeddedBrowser
 	 */
 	@Override
-	public EmbeddedBrowser buildEmbeddedBrowser(CrawljaxConfigurationReader configuration) {
+	public EmbeddedBrowser buildEmbeddedBrowser(CrawljaxConfiguration configuration) {
 		// Retrieve the config values used
-		List<String> filterAttributes = configuration.getFilterAttributeNames();
-		long crawlWaitReload =
-		        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
-		long crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
+		ImmutableSortedSet<String> filterAttributes =
+		        configuration.getCrawlRules().getPreCrawlConfig().getFilterAttributeNames();
+		long crawlWaitReload = configuration.getCrawlRules().getWaitAfterReloadUrl();
+		long crawlWaitEvent = configuration.getCrawlRules().getWaitAfterEvent();
 
 		// Determine the requested browser type
-		switch (configuration.getBrowser()) {
+		switch (configuration.getBrowserConfig().getBrowsertype()) {
 			case firefox:
 				if (configuration.getProxyConfiguration() != null) {
 					FirefoxProfile profile = new FirefoxProfile();
@@ -59,15 +58,11 @@
 				}
 
 				return WebDriverBackedEmbeddedBrowser.withDriver(new FirefoxDriver(),
-				        configuration.getFilterAttributeNames(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterEvent(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterReloadUrl());
+				        filterAttributes, crawlWaitEvent, crawlWaitReload);
 
 			case ie:
 				return WebDriverBackedEmbeddedBrowser.withDriver(new InternetExplorerDriver(),
-				        configuration.getFilterAttributeNames(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterEvent(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterReloadUrl());
+				        filterAttributes, crawlWaitEvent, crawlWaitReload);
 
 			case chrome:
 				ChromeDriver driverChrome;
@@ -81,16 +76,13 @@
 					driverChrome = new ChromeDriver();
 				}
 
-				return WebDriverBackedEmbeddedBrowser.withDriver(driverChrome, configuration
-				        .getFilterAttributeNames(), configuration.getCrawlSpecificationReader()
-				        .getWaitAfterEvent(), configuration.getCrawlSpecificationReader()
-				        .getWaitAfterReloadUrl());
+				return WebDriverBackedEmbeddedBrowser.withDriver(driverChrome, filterAttributes,
+				        crawlWaitEvent, crawlWaitReload);
 
 			case remote:
-				return WebDriverBackedEmbeddedBrowser.withRemoteDriver(
-				        configuration.getRemoteHubUrl(), configuration.getFilterAttributeNames(),
-				        configuration.getCrawlSpecificationReader().getWaitAfterEvent(),
-				        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl());
+				return WebDriverBackedEmbeddedBrowser.withRemoteDriver(configuration
+				        .getBrowserConfig().getRemoteHubUrl(), filterAttributes, crawlWaitEvent,
+				        crawlWaitReload);
 
 			case htmlunit:
 				HtmlUnitDriver driverHtmlUnit = new HtmlUnitDriver(BrowserVersion.FIREFOX_10);
@@ -100,32 +92,24 @@
 					        configuration.getProxyConfiguration().getPort());
 				}
 
-				return WebDriverBackedEmbeddedBrowser.withDriver(driverHtmlUnit, configuration
-				        .getFilterAttributeNames(), configuration.getCrawlSpecificationReader()
-				        .getWaitAfterEvent(), configuration.getCrawlSpecificationReader()
-				        .getWaitAfterReloadUrl());
+				return WebDriverBackedEmbeddedBrowser.withDriver(driverHtmlUnit,
+				        filterAttributes, crawlWaitEvent, crawlWaitReload);
 
 			case android:
 				return WebDriverBackedEmbeddedBrowser.withDriver(new AndroidDriver(),
-				        configuration.getFilterAttributeNames(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterEvent(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterReloadUrl());
+				        filterAttributes, crawlWaitEvent, crawlWaitReload);
 
 			case iphone:
 				try {
 					return WebDriverBackedEmbeddedBrowser.withDriver(new IPhoneDriver(),
-					        configuration.getFilterAttributeNames(), configuration
-					                .getCrawlSpecificationReader().getWaitAfterEvent(),
-					        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl());
+					        filterAttributes, crawlWaitEvent, crawlWaitReload);
 				} catch (Exception e) {
 					LOGGER.error(""Could not load driver: "" + e.getMessage(), e);
 				}
 
 			default:
 				return WebDriverBackedEmbeddedBrowser.withDriver(new FirefoxDriver(),
-				        configuration.getFilterAttributeNames(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterEvent(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterReloadUrl());
+				        filterAttributes, crawlWaitEvent, crawlWaitReload);
 		}
 	}
 }
"
794f0ff5bac71e6034fccb15d649dc0a3b0e9525,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index aca2a42..f470b15 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -15,9 +15,7 @@
 import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.eventablecondition.EventableConditionChecker;
 import com.crawljax.condition.invariant.Invariant;
-import com.crawljax.core.configuration.CrawlSpecificationReader;
 import com.crawljax.core.configuration.CrawljaxConfiguration;
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
 import com.crawljax.core.plugin.CrawljaxPluginsUtil;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateFlowGraph;
@@ -47,7 +45,7 @@
 	// TODO Stefan, Can not be final because, must be created after the loading of the plugins
 	private Crawler initialCrawler;
 
-	private final CrawljaxConfigurationReader configurationReader;
+	private final CrawljaxConfiguration configurationReader;
 
 	private final ImmutableList<Invariant> invariantList;
 
@@ -67,22 +65,23 @@
 	 *             if the configuration fails.
 	 */
 	public CrawljaxController(final CrawljaxConfiguration config) throws CrawljaxException {
-		configurationReader = new CrawljaxConfigurationReader(config);
-		CrawlSpecificationReader crawlerReader =
-		        configurationReader.getCrawlSpecificationReader();
+		configurationReader = config;
 
-		stateComparator = new StateComparator(crawlerReader.getOracleComparators());
-		invariantList = crawlerReader.getInvariants();
+		stateComparator = new StateComparator(config.getCrawlRules().getOracleComparators());
+		invariantList = config.getCrawlRules().getInvariants();
 
-		waitConditionChecker.setWaitConditions(crawlerReader.getWaitConditions());
+		waitConditionChecker.setWaitConditions(config.getCrawlRules().getPreCrawlConfig()
+		        .getWaitConditions());
 		eventableConditionChecker =
-		        new EventableConditionChecker(configurationReader.getEventableConditions());
+		        new EventableConditionChecker(config.getCrawlRules().getPreCrawlConfig());
 
-		crawlConditionChecker = new ConditionTypeChecker<>(crawlerReader.getCrawlConditions());
+		crawlConditionChecker =
+		        new ConditionTypeChecker<>(config.getCrawlRules().getPreCrawlConfig()
+		                .getCrawlConditions());
 		elementChecker =
 		        new CandidateElementManager(eventableConditionChecker, crawlConditionChecker);
 
-		browserPool = new BrowserPool(configurationReader);
+		browserPool = new BrowserPool(config);
 
 		workQueue = init();
 	}
@@ -103,17 +102,13 @@
 			        .runProxyServerPlugins(configurationReader.getProxyConfiguration());
 		}
 
-		LOGGER.info(""Embedded browser implementation: {}"", configurationReader.getBrowser());
+		LOGGER.info(""Embedded browser implementation: {}"", configurationReader.getBrowserConfig()
+		        .getBrowsertype());
 
-		LOGGER.info(""Number of threads: {}"", configurationReader.getThreadConfigurationReader()
-		        .getNumberThreads());
-
-		LOGGER.info(""Crawl depth: {}"", configurationReader.getCrawlSpecificationReader()
-		        .getDepth());
+		LOGGER.info(""Crawl depth: {}"", configurationReader.getMaximumDepth());
 		LOGGER.info(""Crawljax initialized!"");
 
-		return new CrawlerExecutor(configurationReader.getThreadConfigurationReader()
-		        .getNumberThreads());
+		return new CrawlerExecutor(configurationReader);
 	}
 
 	/**
@@ -129,8 +124,8 @@
 
 		startCrawl = System.currentTimeMillis();
 
-		LOGGER.info(""Start crawling with {} crawl elements"", configurationReader
-		        .getAllIncludedCrawlElements().size());
+		LOGGER.info(""Start crawling with {} crawl elements"", configurationReader.getCrawlRules()
+		        .getPreCrawlConfig().getIncludedElements());
 
 		// Create the initailCrawler
 		initialCrawler = new InitialCrawler(this);
@@ -330,7 +325,7 @@
 	/**
 	 * @return the configurationReader
 	 */
-	public CrawljaxConfigurationReader getConfigurationReader() {
+	public CrawljaxConfiguration getConfigurationReader() {
 		return configurationReader;
 	}
 
"
794f0ff5bac71e6034fccb15d649dc0a3b0e9525,Alex Nederlof,StateVertex.java,MODIFY,"searchForCandidateElements -> [CandidateElementExtractor candidateExtractor, List crawlTagElements, List crawlExcludeTagElements, boolean clickOnce] | [CandidateElementExtractor candidateExtractor]","diff --git a/core/src/main/java/com/crawljax/core/state/StateVertex.java b/core/src/main/java/com/crawljax/core/state/StateVertex.java
index af29b70..325e93e 100644
--- a/core/src/main/java/com/crawljax/core/state/StateVertex.java
+++ b/core/src/main/java/com/crawljax/core/state/StateVertex.java
@@ -22,17 +22,15 @@
 import com.crawljax.core.CrawlQueueManager;
 import com.crawljax.core.Crawler;
 import com.crawljax.core.CrawljaxException;
-import com.crawljax.core.TagElement;
 import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.util.DomUtils;
 import com.google.common.base.Strings;
 
 /**
- * The state vertex class which represents a state in the browser. This class
- * implements the Iterable interface because on a StateVertex it is possible to
- * iterate over the possible CandidateElements found in this state. When
- * iterating over the possible candidate elements every time a candidate is
- * returned its removed from the list so it is a one time only access to the
+ * The state vertex class which represents a state in the browser. This class implements the
+ * Iterable interface because on a StateVertex it is possible to iterate over the possible
+ * CandidateElements found in this state. When iterating over the possible candidate elements every
+ * time a candidate is returned its removed from the list so it is a one time only access to the
  * candidates.
  */
 public class StateVertex implements Serializable {
@@ -48,16 +46,16 @@
 	private boolean guidedCrawling = false;
 
 	/**
-	 * This list is used to store the possible candidates. If it is null its not
-	 * initialised if it's a empty list its empty.
+	 * This list is used to store the possible candidates. If it is null its not initialised if it's
+	 * a empty list its empty.
 	 */
 	private LinkedBlockingDeque<CandidateCrawlAction> candidateActions =
-			new LinkedBlockingDeque<>();;
+	        new LinkedBlockingDeque<>();;
 
 	private final ConcurrentHashMap<Crawler, CandidateCrawlAction> registerdCandidateActions =
-			new ConcurrentHashMap<>();
+	        new ConcurrentHashMap<>();
 	private final ConcurrentHashMap<Crawler, CandidateCrawlAction> workInProgressCandidateActions =
-			new ConcurrentHashMap<>();
+	        new ConcurrentHashMap<>();
 
 	private final LinkedBlockingDeque<Crawler> registeredCrawlers = new LinkedBlockingDeque<>();
 
@@ -70,11 +68,12 @@
 	}
 
 	/**
-	 * Creates a current state without an url and the stripped dom equals the
-	 * dom.
+	 * Creates a current state without an url and the stripped dom equals the dom.
 	 * 
-	 * @param name the name of the state
-	 * @param dom the current DOM tree of the browser
+	 * @param name
+	 *            the name of the state
+	 * @param dom
+	 *            the current DOM tree of the browser
 	 */
 	public StateVertex(String name, String dom) {
 		this(null, name, dom, dom);
@@ -83,10 +82,14 @@
 	/**
 	 * Defines a State.
 	 * 
-	 * @param url the current url of the state
-	 * @param name the name of the state
-	 * @param dom the current DOM tree of the browser
-	 * @param strippedDom the stripped dom by the OracleComparators
+	 * @param url
+	 *            the current url of the state
+	 * @param name
+	 *            the name of the state
+	 * @param dom
+	 *            the current DOM tree of the browser
+	 * @param strippedDom
+	 *            the stripped dom by the OracleComparators
 	 */
 	public StateVertex(String url, String name, String dom, String strippedDom) {
 		this.url = url;
@@ -147,7 +150,8 @@
 	/**
 	 * Compare this vertex to a other StateVertex.
 	 * 
-	 * @param obj the Object to compare this vertex
+	 * @param obj
+	 *            the Object to compare this vertex
 	 * @return Return true if equal. Uses reflection.
 	 * @see java.lang.Object#equals(java.lang.Object)
 	 */
@@ -163,7 +167,7 @@
 		final StateVertex rhs = (StateVertex) obj;
 
 		return new EqualsBuilder().append(this.strippedDom, rhs.getStrippedDom())
-				.append(this.guidedCrawling, rhs.guidedCrawling).isEquals();
+		        .append(this.guidedCrawling, rhs.guidedCrawling).isEquals();
 	}
 
 	/**
@@ -193,21 +197,24 @@
 	}
 
 	/**
-	 * @param id the id to set
+	 * @param id
+	 *            the id to set
 	 */
 	public void setId(long id) {
 		this.id = id;
 	}
 
 	/**
-	 * @param name the name to set
+	 * @param name
+	 *            the name to set
 	 */
 	public void setName(String name) {
 		this.name = name;
 	}
 
 	/**
-	 * @param dom the dom to set
+	 * @param dom
+	 *            the dom to set
 	 */
 	public void setDom(String dom) {
 		this.dom = dom;
@@ -221,27 +228,29 @@
 	}
 
 	/**
-	 * @param guidedCrawling true if set through guided crawling.
+	 * @param guidedCrawling
+	 *            true if set through guided crawling.
 	 */
 	public void setGuidedCrawling(boolean guidedCrawling) {
 		this.guidedCrawling = guidedCrawling;
 	}
 
 	/**
-	 * search for new Candidates from this state. The search for candidates is
-	 * only done when no list is available yet (candidateActions == null).
+	 * search for new Candidates from this state. The search for candidates is only done when no
+	 * list is available yet (candidateActions == null).
 	 * 
-	 * @param candidateExtractor the CandidateElementExtractor to use.
-	 * @param crawlTagElements the tag elements to examine.
-	 * @param crawlExcludeTagElements the elements to exclude.
-	 * @param clickOnce if true examine each element once.
+	 * @param candidateExtractor
+	 *            the CandidateElementExtractor to use.
+	 * @param crawlTagElements
+	 *            the tag elements to examine.
+	 * @param crawlExcludeTagElements
+	 *            the elements to exclude.
+	 * @param clickOnce
+	 *            if true examine each element once.
 	 * @return true if the searchForCandidateElemens has run false otherwise
 	 */
 	@GuardedBy(""candidateActionsSearchLock"")
-	public boolean searchForCandidateElements(CandidateElementExtractor candidateExtractor,
-			List<TagElement> crawlTagElements, List<TagElement> crawlExcludeTagElements,
-			boolean clickOnce) {
-
+	public boolean searchForCandidateElements(CandidateElementExtractor candidateExtractor) {
 		try {
 			List<CandidateElement> candidateList = candidateExtractor.extract(this);
 			for (CandidateElement candidateElement : candidateList) {
@@ -250,10 +259,10 @@
 			}
 		} catch (CrawljaxException e) {
 			LOGGER.error(
-					""Catched exception while searching for candidates in state "" + getName(), e);
+			        ""Catched exception while searching for candidates in state "" + getName(), e);
 		}
 		return !candidateActions.isEmpty(); // Only notify of found candidates
-														// when there are...
+		                                    // when there are...
 
 	}
 
@@ -278,8 +287,8 @@
 	}
 
 	/**
-	 * Removes Candidate Actions on candidateElements that have been removed by
-	 * the pre-state crawl plugin.
+	 * Removes Candidate Actions on candidateElements that have been removed by the pre-state crawl
+	 * plugin.
 	 * 
 	 * @param candidateElements
 	 */
@@ -294,7 +303,7 @@
 			if (!candidateElements.contains(currentAction.getCandidateElement())) {
 				iter.remove();
 				LOGGER.info(""filtered candidate action: "" + currentAction.getEventType().name()
-						+ "" on "" + currentAction.getCandidateElement().getGeneralString());
+				        + "" on "" + currentAction.getCandidateElement().getGeneralString());
 
 			}
 		}
@@ -302,28 +311,29 @@
 
 	/**
 	 * @return a Document instance of the dom string.
-	 * @throws IOException if an exception is thrown.
+	 * @throws IOException
+	 *             if an exception is thrown.
 	 */
 	public Document getDocument() throws IOException {
 		return DomUtils.asDocument(this.dom);
 	}
 
 	/**
-	 * This is the main work divider function, calling this function will first
-	 * look at the registeedCandidateActions to see if the current Crawler has
-	 * already registered itself at one of the jobs. Second it tries to see if
-	 * the current crawler is not already processing one of the actions and
-	 * return that action and last it tries to find an unregistered candidate. If
-	 * all else fails it tries to return a action that is registered by an other
-	 * crawler and disables that crawler.
+	 * This is the main work divider function, calling this function will first look at the
+	 * registeedCandidateActions to see if the current Crawler has already registered itself at one
+	 * of the jobs. Second it tries to see if the current crawler is not already processing one of
+	 * the actions and return that action and last it tries to find an unregistered candidate. If
+	 * all else fails it tries to return a action that is registered by an other crawler and
+	 * disables that crawler.
 	 * 
-	 * @param requestingCrawler the Crawler placing the request for the Action
-	 * @param manager the manager that can be used to remove a crawler from the
-	 *           queue.
+	 * @param requestingCrawler
+	 *            the Crawler placing the request for the Action
+	 * @param manager
+	 *            the manager that can be used to remove a crawler from the queue.
 	 * @return the action that needs to be performed by the Crawler.
 	 */
 	public CandidateCrawlAction pollCandidateCrawlAction(Crawler requestingCrawler,
-			CrawlQueueManager manager) {
+	        CrawlQueueManager manager) {
 		CandidateCrawlAction action = registerdCandidateActions.remove(requestingCrawler);
 		if (action != null) {
 			workInProgressCandidateActions.put(requestingCrawler, action);
@@ -348,10 +358,10 @@
 					action = registerdCandidateActions.remove(c);
 					if (action != null) {
 						/*
-						 * We got a action and removed the registeredCandidateActions
-						 * for the crawler, remove the crawler from queue as the first
-						 * thing. As the crawler might just have started the run
-						 * method of the crawler must also be added with a check hook.
+						 * We got a action and removed the registeredCandidateActions for the
+						 * crawler, remove the crawler from queue as the first thing. As the crawler
+						 * might just have started the run method of the crawler must also be added
+						 * with a check hook.
 						 */
 						LOGGER.info(""Stolen work from other Crawler"");
 						return action;
@@ -370,7 +380,8 @@
 	/**
 	 * Register an assignment to the crawler.
 	 * 
-	 * @param newCrawler the crawler that wants an assignment
+	 * @param newCrawler
+	 *            the crawler that wants an assignment
 	 * @return true if the crawler has an assignment false otherwise.
 	 */
 	public boolean registerCrawler(Crawler newCrawler) {
@@ -386,7 +397,8 @@
 	/**
 	 * Register a Crawler that is going to work, tell if his must go on or abort.
 	 * 
-	 * @param crawler the crawler to register
+	 * @param crawler
+	 *            the crawler to register
 	 * @return true if the crawler is successfully registered
 	 */
 	public boolean startWorking(Crawler crawler) {
@@ -401,11 +413,13 @@
 	}
 
 	/**
-	 * Notify the current StateVertex that the given crawler has finished working
-	 * on the given action.
+	 * Notify the current StateVertex that the given crawler has finished working on the given
+	 * action.
 	 * 
-	 * @param crawler the crawler that is finished
-	 * @param action the action that have been examined
+	 * @param crawler
+	 *            the crawler that is finished
+	 * @param action
+	 *            the action that have been examined
 	 */
 	public void finishedWorking(Crawler crawler, CandidateCrawlAction action) {
 		candidateActions.remove(action);
@@ -413,4 +427,5 @@
 		workInProgressCandidateActions.remove(crawler);
 		registeredCrawlers.remove(crawler);
 	}
+
 }
"
ec5d3cece0858a758ff24792237e85641edae6a2,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 724a7e3..0cc6efe 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -852,7 +852,6 @@
 		        configuration.getCrawlRules().getPreCrawlConfig().getFilterAttributeNames();
 		this.crawlWaitReload = configuration.getCrawlRules().getWaitAfterReloadUrl();
 		this.crawlWaitEvent = configuration.getCrawlRules().getWaitAfterEvent();
-		this.ignoreFrameChecker = configuration.getCrawlSpecificationReader();
 	}
 
 	private boolean exceptionIsConnectionException(WebDriverException exception) {
"
ec5d3cece0858a758ff24792237e85641edae6a2,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index f470b15..4643d2c 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -24,8 +24,6 @@
 
 /**
  * The Crawljax Controller class is the core of Crawljax.
- * 
- * @author mesbah
  */
 public class CrawljaxController implements CrawlQueueManager {
 
@@ -45,7 +43,7 @@
 	// TODO Stefan, Can not be final because, must be created after the loading of the plugins
 	private Crawler initialCrawler;
 
-	private final CrawljaxConfiguration configurationReader;
+	private final CrawljaxConfiguration configuration;
 
 	private final ImmutableList<Invariant> invariantList;
 
@@ -65,7 +63,7 @@
 	 *             if the configuration fails.
 	 */
 	public CrawljaxController(final CrawljaxConfiguration config) throws CrawljaxException {
-		configurationReader = config;
+		configuration = config;
 
 		stateComparator = new StateComparator(config.getCrawlRules().getOracleComparators());
 		invariantList = config.getCrawlRules().getInvariants();
@@ -95,20 +93,19 @@
 		LOGGER.info(""Starting Crawljax..."");
 
 		LOGGER.info(""Used plugins:"");
-		CrawljaxPluginsUtil.loadPlugins(configurationReader.getPlugins());
+		CrawljaxPluginsUtil.loadPlugins(configuration.getPlugins());
 
-		if (configurationReader.getProxyConfiguration() != null) {
-			CrawljaxPluginsUtil
-			        .runProxyServerPlugins(configurationReader.getProxyConfiguration());
+		if (configuration.getProxyConfiguration() != null) {
+			CrawljaxPluginsUtil.runProxyServerPlugins(configuration.getProxyConfiguration());
 		}
 
-		LOGGER.info(""Embedded browser implementation: {}"", configurationReader.getBrowserConfig()
+		LOGGER.info(""Embedded browser implementation: {}"", configuration.getBrowserConfig()
 		        .getBrowsertype());
 
-		LOGGER.info(""Crawl depth: {}"", configurationReader.getMaximumDepth());
+		LOGGER.info(""Crawl depth: {}"", configuration.getMaximumDepth());
 		LOGGER.info(""Crawljax initialized!"");
 
-		return new CrawlerExecutor(configurationReader);
+		return new CrawlerExecutor(configuration.getBrowserConfig());
 	}
 
 	/**
@@ -124,7 +121,7 @@
 
 		startCrawl = System.currentTimeMillis();
 
-		LOGGER.info(""Start crawling with {} crawl elements"", configurationReader.getCrawlRules()
+		LOGGER.info(""Start crawling with {} crawl elements"", configuration.getCrawlRules()
 		        .getPreCrawlConfig().getIncludedElements());
 
 		// Create the initailCrawler
@@ -325,8 +322,8 @@
 	/**
 	 * @return the configurationReader
 	 */
-	public CrawljaxConfiguration getConfigurationReader() {
-		return configurationReader;
+	public CrawljaxConfiguration getConfiguration() {
+		return configuration;
 	}
 
 	/**
"
ec5d3cece0858a758ff24792237e85641edae6a2,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index f3672c9..3249ae8 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -7,6 +7,7 @@
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.core.Crawler;
 import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
@@ -19,7 +20,8 @@
 	public static class CrawljaxConfigurationBuilder {
 
 		private final ImmutableList.Builder<Plugin> pluginBuilder = ImmutableList.builder();
-		private CrawljaxConfiguration config;
+		private final CrawljaxConfiguration config;
+		private final CrawlRulesBuilder crawlRules = CrawlRules.builder();
 
 		private CrawljaxConfigurationBuilder(URL url) {
 			config = new CrawljaxConfiguration();
@@ -38,6 +40,14 @@
 		}
 
 		/**
+		 * Crawl without a maximum state limit.
+		 */
+		public CrawljaxConfigurationBuilder setUnlimitedStates() {
+			config.maximumStates = 0;
+			return this;
+		}
+
+		/**
 		 * @param time
 		 *            The maximum time the crawler should run. Default is one hour.
 		 */
@@ -48,6 +58,14 @@
 		}
 
 		/**
+		 * Set the maximum runtime to unlimited.
+		 */
+		public CrawljaxConfigurationBuilder setUnlimitedRuntime() {
+			config.maximumRuntime = 0;
+			return this;
+		}
+
+		/**
 		 * @param time
 		 *            The maximum depth the crawler can reach. The default is <code>2</code>.
 		 */
@@ -58,6 +76,14 @@
 		}
 
 		/**
+		 * Set the crawl depth to unlimited.
+		 */
+		public CrawljaxConfigurationBuilder setUnlimitedCrawlDepth() {
+			config.maximumDepth = 0;
+			return this;
+		}
+
+		/**
 		 * Add plugins to Crawljax. Note that without plugins, Crawljax won't give any ouput. For
 		 * basic output at least enable the CrawlOverviewPlugin.
 		 * <p>
@@ -82,6 +108,14 @@
 		}
 
 		/**
+		 * @return The {@link CrawlRulesBuilder} to define crawling rules. If no specified, Crawljax
+		 *         will do {@link CrawlRulesBuilder#}
+		 */
+		public CrawlRulesBuilder crawlRules() {
+			return crawlRules;
+		}
+
+		/**
 		 * @param configuration
 		 *            a custom {@link BrowserConfiguration}. The default is a single
 		 *            {@link BrowserType#firefox} browser.
@@ -93,6 +127,7 @@
 
 		public CrawljaxConfiguration build() {
 			config.plugins = pluginBuilder.build();
+			config.crawlRules = crawlRules.build();
 			return config;
 		}
 
@@ -168,4 +203,87 @@
 		return maximumDepth;
 	}
 
+	@Override
+	public int hashCode() {
+		final int prime = 31;
+		int result = 1;
+		result = prime * result + ((browserConfig == null) ? 0 : browserConfig.hashCode());
+		result = prime * result + ((crawlRules == null) ? 0 : crawlRules.hashCode());
+		result = prime * result + maximumDepth;
+		result = prime * result + (int) (maximumRuntime ^ (maximumRuntime >>> 32));
+		result = prime * result + maximumStates;
+		result = prime * result + ((plugins == null) ? 0 : plugins.hashCode());
+		result =
+		        prime * result
+		                + ((proxyConfiguration == null) ? 0 : proxyConfiguration.hashCode());
+		result = prime * result + ((url == null) ? 0 : url.hashCode());
+		return result;
+	}
+
+	@Override
+	public boolean equals(Object obj) {
+		if (this == obj)
+			return true;
+		if (obj == null)
+			return false;
+		if (getClass() != obj.getClass())
+			return false;
+		CrawljaxConfiguration other = (CrawljaxConfiguration) obj;
+		if (browserConfig == null) {
+			if (other.browserConfig != null)
+				return false;
+		} else if (!browserConfig.equals(other.browserConfig))
+			return false;
+		if (crawlRules == null) {
+			if (other.crawlRules != null)
+				return false;
+		} else if (!crawlRules.equals(other.crawlRules))
+			return false;
+		if (maximumDepth != other.maximumDepth)
+			return false;
+		if (maximumRuntime != other.maximumRuntime)
+			return false;
+		if (maximumStates != other.maximumStates)
+			return false;
+		if (plugins == null) {
+			if (other.plugins != null)
+				return false;
+		} else if (!plugins.equals(other.plugins))
+			return false;
+		if (proxyConfiguration == null) {
+			if (other.proxyConfiguration != null)
+				return false;
+		} else if (!proxyConfiguration.equals(other.proxyConfiguration))
+			return false;
+		if (url == null) {
+			if (other.url != null)
+				return false;
+		} else if (!url.equals(other.url))
+			return false;
+		return true;
+	}
+
+	@Override
+	public String toString() {
+		StringBuilder builder = new StringBuilder();
+		builder.append(""CrawljaxConfiguration [url="");
+		builder.append(url);
+		builder.append("", browserConfig="");
+		builder.append(browserConfig);
+		builder.append("", plugins="");
+		builder.append(plugins);
+		builder.append("", proxyConfiguration="");
+		builder.append(proxyConfiguration);
+		builder.append("", crawlRules="");
+		builder.append(crawlRules);
+		builder.append("", maximumStates="");
+		builder.append(maximumStates);
+		builder.append("", maximumRuntime="");
+		builder.append(maximumRuntime);
+		builder.append("", maximumDepth="");
+		builder.append(maximumDepth);
+		builder.append(""]"");
+		return builder.toString();
+	}
+
 }
\ No newline at end of file
"
ec5d3cece0858a758ff24792237e85641edae6a2,Alex Nederlof,OutputBuilder.java,MODIFY,write -> [CrawlSpecificationReader crawlSpecificationReader] | [OutPutModel outModel],"diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
index 2cba28f..0b7cce9 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
@@ -12,7 +12,6 @@
 import java.io.IOException;
 import java.net.URISyntaxException;
 import java.net.URL;
-import java.util.Arrays;
 import java.util.zip.ZipEntry;
 import java.util.zip.ZipInputStream;
 
@@ -28,7 +27,6 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.crawljax.core.configuration.CrawlSpecificationReader;
 import com.crawljax.plugins.crawloverview.model.CrawlConfiguration;
 import com.crawljax.plugins.crawloverview.model.OutPutModel;
 import com.crawljax.plugins.crawloverview.model.Statistics;
@@ -159,7 +157,7 @@
 		try {
 			writeIndexFile(outModel);
 			writeStatistics(outModel.getStatistics());
-			writeConfig(outModel.getConfiguration(), outModel.getCrawlSpecification());
+			writeConfig(outModel.getConfiguration());
 		} catch (Exception e) {
 			LOG.error(e.getMessage(), e);
 		}
@@ -167,11 +165,10 @@
 		LOG.info(""Overview report generated"");
 	}
 
-	private void writeConfig(CrawlConfiguration configuration, CrawlSpecificationReader crawlSpec) {
+	private void writeConfig(CrawlConfiguration configuration) {
 		File file = new File(outputDir, ""config.html"");
 		VelocityContext context = new VelocityContext();
 		context.put(""config"", BeanToReadableMap.toMap(configuration));
-		context.put(""spec"", BeanToReadableMap.toMap(crawlSpec));
 		writeFile(context, file, ""config.html"");
 	}
 
@@ -206,7 +203,7 @@
 		writeFile(context, file, ""urls.html"");
 	}
 
-	public void write(CrawlSpecificationReader crawlSpecificationReader) {
+	public void write(CrawlConfiguration crawlSpecificationReader) {
 		ObjectMapper objectMapper = new ObjectMapper();
 		try {
 			ObjectWriter prettyPrinter = objectMapper.writer().withDefaultPrettyPrinter();
"
92dad094c3940a3f9677d136bdf087866b2b0b4f,Alex Nederlof,CandidateElementExtractor.java,MODIFY,"asTagElements -> [List crawlElements] | [List crawlElements, InputSpecification inputSpecification]","diff --git a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
index 323cea8..4e32145 100644
--- a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
+++ b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
@@ -21,6 +21,7 @@
 import com.crawljax.condition.eventablecondition.EventableConditionChecker;
 import com.crawljax.core.configuration.CrawlElement;
 import com.crawljax.core.configuration.CrawljaxConfiguration;
+import com.crawljax.core.configuration.InputSpecification;
 import com.crawljax.core.configuration.PreCrawlConfiguration;
 import com.crawljax.core.state.Identification;
 import com.crawljax.core.state.StateVertex;
@@ -75,7 +76,9 @@
 		this.formHandler = formHandler;
 		PreCrawlConfiguration preCrawlConfig = config.getCrawlRules().getPreCrawlConfig();
 		this.excludeTagElements = asMultiMap(preCrawlConfig.getExcludedElements());
-		this.includedTagElements = asTagElements(preCrawlConfig.getIncludedElements());
+		this.includedTagElements =
+		        asTagElements(preCrawlConfig.getIncludedElements(), config.getCrawlRules()
+		                .getInputSpecification());
 		crawlFrames = config.getCrawlRules().shouldCrawlFrames();
 		clickOnce = config.getCrawlRules().isClickOnce();
 		ignoredFrameIdentifiers = config.getCrawlRules().getIgnoredFrameIdentifiers();
@@ -90,11 +93,15 @@
 		return builder.build();
 	}
 
-	private ImmutableList<TagElement> asTagElements(List<CrawlElement> crawlElements) {
+	private ImmutableList<TagElement> asTagElements(List<CrawlElement> crawlElements,
+	        InputSpecification inputSpecification) {
 		ImmutableList.Builder<TagElement> builder = ImmutableList.builder();
 		for (CrawlElement crawlElement : crawlElements) {
 			builder.add(new TagElement(crawlElement));
 		}
+		for (CrawlElement crawlElement : inputSpecification.getCrawlElements()) {
+			builder.add(new TagElement(crawlElement));
+		}
 		return builder.build();
 	}
 
"
92dad094c3940a3f9677d136bdf087866b2b0b4f,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index 4643d2c..1ce4556 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -71,7 +71,7 @@
 		waitConditionChecker.setWaitConditions(config.getCrawlRules().getPreCrawlConfig()
 		        .getWaitConditions());
 		eventableConditionChecker =
-		        new EventableConditionChecker(config.getCrawlRules().getPreCrawlConfig());
+		        new EventableConditionChecker(config.getCrawlRules());
 
 		crawlConditionChecker =
 		        new ConditionTypeChecker<>(config.getCrawlRules().getPreCrawlConfig()
"
08f28182043d03fd1992ae1babfec4fcd4973f6f,Alex Nederlof,OutputBuilder.java,MODIFY,write -> [CrawlConfiguration crawlSpecificationReader] | [OutPutModel outModel],"diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
index 2cba28f..37e568d 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
@@ -12,7 +12,6 @@
 import java.io.IOException;
 import java.net.URISyntaxException;
 import java.net.URL;
-import java.util.Arrays;
 import java.util.zip.ZipEntry;
 import java.util.zip.ZipInputStream;
 
@@ -36,7 +35,6 @@
 import com.fasterxml.jackson.annotation.PropertyAccessor;
 import com.fasterxml.jackson.core.JsonProcessingException;
 import com.fasterxml.jackson.databind.ObjectMapper;
-import com.fasterxml.jackson.databind.ObjectWriter;
 import com.google.common.base.Charsets;
 import com.google.common.base.Strings;
 import com.google.common.io.ByteStreams;
@@ -206,17 +204,6 @@
 		writeFile(context, file, ""urls.html"");
 	}
 
-	public void write(CrawlSpecificationReader crawlSpecificationReader) {
-		ObjectMapper objectMapper = new ObjectMapper();
-		try {
-			ObjectWriter prettyPrinter = objectMapper.writer().withDefaultPrettyPrinter();
-			prettyPrinter
-			        .writeValue(new File(outputDir, ""config.json""), crawlSpecificationReader);
-		} catch (Exception e) {
-			throw new RuntimeException(""Cannot save config"", e);
-		}
-	}
-
 	private void writeFile(VelocityContext context, File outFile, String template) {
 		try {
 			Template templatee = ve.getTemplate(template);
"
9c36a0e43c6966a50a539288e5bacd2d5ac8fc08,Alex Nederlof,OutputBuilder.java,MODIFY,"writeConfig -> [CrawlConfiguration configuration, CrawlSpecificationReader crawlSpec] | [CrawlConfiguration configuration]","diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
index 0b7cce9..c5c09b6 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
@@ -34,7 +34,6 @@
 import com.fasterxml.jackson.annotation.PropertyAccessor;
 import com.fasterxml.jackson.core.JsonProcessingException;
 import com.fasterxml.jackson.databind.ObjectMapper;
-import com.fasterxml.jackson.databind.ObjectWriter;
 import com.google.common.base.Charsets;
 import com.google.common.base.Strings;
 import com.google.common.io.ByteStreams;
@@ -203,17 +202,6 @@
 		writeFile(context, file, ""urls.html"");
 	}
 
-	public void write(CrawlConfiguration crawlSpecificationReader) {
-		ObjectMapper objectMapper = new ObjectMapper();
-		try {
-			ObjectWriter prettyPrinter = objectMapper.writer().withDefaultPrettyPrinter();
-			prettyPrinter
-			        .writeValue(new File(outputDir, ""config.json""), crawlSpecificationReader);
-		} catch (Exception e) {
-			throw new RuntimeException(""Cannot save config"", e);
-		}
-	}
-
 	private void writeFile(VelocityContext context, File outFile, String template) {
 		try {
 			Template templatee = ve.getTemplate(template);
"
0bf12a9971be4ae1dc96e93bbc98557736550f15,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 3249ae8..d451ae0 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -222,44 +222,60 @@
 
 	@Override
 	public boolean equals(Object obj) {
-		if (this == obj)
+		if (this == obj) {
 			return true;
-		if (obj == null)
+		}
+		if (obj == null) {
 			return false;
-		if (getClass() != obj.getClass())
+		}
+		if (getClass() != obj.getClass()) {
 			return false;
+		}
 		CrawljaxConfiguration other = (CrawljaxConfiguration) obj;
 		if (browserConfig == null) {
-			if (other.browserConfig != null)
+			if (other.browserConfig != null) {
 				return false;
-		} else if (!browserConfig.equals(other.browserConfig))
+			}
+		} else if (!browserConfig.equals(other.browserConfig)) {
 			return false;
+		}
 		if (crawlRules == null) {
-			if (other.crawlRules != null)
+			if (other.crawlRules != null) {
 				return false;
-		} else if (!crawlRules.equals(other.crawlRules))
+			}
+		} else if (!crawlRules.equals(other.crawlRules)) {
 			return false;
-		if (maximumDepth != other.maximumDepth)
+		}
+		if (maximumDepth != other.maximumDepth) {
 			return false;
-		if (maximumRuntime != other.maximumRuntime)
+		}
+		if (maximumRuntime != other.maximumRuntime) {
 			return false;
-		if (maximumStates != other.maximumStates)
+		}
+		if (maximumStates != other.maximumStates) {
 			return false;
+		}
 		if (plugins == null) {
-			if (other.plugins != null)
+			if (other.plugins != null) {
 				return false;
-		} else if (!plugins.equals(other.plugins))
+			}
+		} else if (!plugins.equals(other.plugins)) {
 			return false;
+		}
 		if (proxyConfiguration == null) {
-			if (other.proxyConfiguration != null)
+			if (other.proxyConfiguration != null) {
 				return false;
-		} else if (!proxyConfiguration.equals(other.proxyConfiguration))
+			}
+		} else if (!proxyConfiguration.equals(other.proxyConfiguration)) {
 			return false;
+		}
 		if (url == null) {
-			if (other.url != null)
+			if (other.url != null) {
 				return false;
-		} else if (!url.equals(other.url))
+			}
+		} else if (!url.equals(other.url)) {
 			return false;
+		}
 		return true;
 	}
 
"
0bf12a9971be4ae1dc96e93bbc98557736550f15,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index 6854b96..287b05d 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -58,7 +58,7 @@
 	}
 
 	private static final String[] ALLOWED_INPUT_TYPES =
-	        { ""text"", ""radio"", ""checkbox"", ""password"" };
+	{ ""text"", ""radio"", ""checkbox"", ""password"" };
 
 	/**
 	 * Fills in the element with the InputValues for input TODO: improve this by using WebDriver
"
0bf12a9971be4ae1dc96e93bbc98557736550f15,Alex Nederlof,OutputBuilder.java,MODIFY,writeConfig -> [CrawlConfiguration configuration] | [CrawljaxConfiguration configuration],"diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
index c5c09b6..94e91e5 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
@@ -27,13 +27,19 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.crawljax.plugins.crawloverview.model.CrawlConfiguration;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
+import com.crawljax.core.plugin.Plugin;
 import com.crawljax.plugins.crawloverview.model.OutPutModel;
 import com.crawljax.plugins.crawloverview.model.Statistics;
 import com.fasterxml.jackson.annotation.JsonAutoDetect.Visibility;
 import com.fasterxml.jackson.annotation.PropertyAccessor;
+import com.fasterxml.jackson.core.JsonGenerator;
 import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.JsonSerializer;
 import com.fasterxml.jackson.databind.ObjectMapper;
+import com.fasterxml.jackson.databind.SerializationFeature;
+import com.fasterxml.jackson.databind.SerializerProvider;
+import com.fasterxml.jackson.databind.module.SimpleModule;
 import com.google.common.base.Charsets;
 import com.google.common.base.Strings;
 import com.google.common.io.ByteStreams;
@@ -164,7 +170,7 @@
 		LOG.info(""Overview report generated"");
 	}
 
-	private void writeConfig(CrawlConfiguration configuration) {
+	private void writeConfig(CrawljaxConfiguration configuration) {
 		File file = new File(outputDir, ""config.html"");
 		VelocityContext context = new VelocityContext();
 		context.put(""config"", BeanToReadableMap.toMap(configuration));
@@ -245,13 +251,33 @@
 		}
 	}
 
-	private String toJson(Object o) {
+	static String toJson(Object o) {
 		ObjectMapper mapper = new ObjectMapper();
 		try {
 			mapper.setVisibility(PropertyAccessor.FIELD, Visibility.ANY);
+			mapper.setVisibility(PropertyAccessor.GETTER, Visibility.NONE);
+			mapper.disable(SerializationFeature.FAIL_ON_EMPTY_BEANS);
+			SimpleModule testModule = new SimpleModule(""Plugin serialiezr"");
+			testModule.addSerializer(new JsonSerializer<Plugin>() {
+
+				@Override
+				public void serialize(Plugin plugin, JsonGenerator jgen,
+				        SerializerProvider provider) throws IOException, JsonProcessingException {
+					jgen.writeString(plugin.getClass().getSimpleName());
+				}
+
+				@Override
+				public Class<Plugin> handledType() {
+					return Plugin.class;
+				}
+			});
+			mapper.registerModule(testModule);
 			return mapper.writerWithDefaultPrettyPrinter().writeValueAsString(o);
 		} catch (JsonProcessingException e) {
-			throw new RuntimeException(e);
+			LOG.error(
+			        ""Could not serialize the object. This will be ignored and the error will be written instead. Object was {}"",
+			        o, e);
+			return ""\"""" + e.getMessage() + ""\"""";
 		}
 	}
 
"
a9633a65ef67f6e9c4f0b06ad5cde767e6bb2d91,Alex Nederlof,OutputBuilder.java,MODIFY,"writeConfig -> [CrawljaxConfiguration configuration] | [CrawlConfiguration configuration, CrawlSpecificationReader crawlSpec]","diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
index 2cba28f..37e568d 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
@@ -12,7 +12,6 @@
 import java.io.IOException;
 import java.net.URISyntaxException;
 import java.net.URL;
-import java.util.Arrays;
 import java.util.zip.ZipEntry;
 import java.util.zip.ZipInputStream;
 
@@ -36,7 +35,6 @@
 import com.fasterxml.jackson.annotation.PropertyAccessor;
 import com.fasterxml.jackson.core.JsonProcessingException;
 import com.fasterxml.jackson.databind.ObjectMapper;
-import com.fasterxml.jackson.databind.ObjectWriter;
 import com.google.common.base.Charsets;
 import com.google.common.base.Strings;
 import com.google.common.io.ByteStreams;
@@ -206,17 +204,6 @@
 		writeFile(context, file, ""urls.html"");
 	}
 
-	public void write(CrawlSpecificationReader crawlSpecificationReader) {
-		ObjectMapper objectMapper = new ObjectMapper();
-		try {
-			ObjectWriter prettyPrinter = objectMapper.writer().withDefaultPrettyPrinter();
-			prettyPrinter
-			        .writeValue(new File(outputDir, ""config.json""), crawlSpecificationReader);
-		} catch (Exception e) {
-			throw new RuntimeException(""Cannot save config"", e);
-		}
-	}
-
 	private void writeFile(VelocityContext context, File outFile, String template) {
 		try {
 			Template templatee = ve.getTemplate(template);
"
7bd6b64af09b9c5e4247544767cbe35fd75fa61c,Ryan Carniato,EmbeddedBrowser.java,MODIFY,updateConfiguration -> [CrawljaxConfiguration configuration] | [CrawljaxConfigurationReader configuration],"diff --git a/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
index e8685dc..40a4a43 100644
--- a/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
@@ -1,7 +1,9 @@
 package com.crawljax.browser;
 
 import java.io.File;
+import java.net.URL;
 
+import org.openqa.selenium.ElementNotVisibleException;
 import org.openqa.selenium.WebElement;
 
 import com.crawljax.core.CrawljaxException;
@@ -28,7 +30,7 @@
 	 * @param url
 	 *            the URL.
 	 */
-	void goToUrl(String url);
+	void goToUrl(URL url);
 
 	/**
 	 * fires the event.
@@ -37,7 +39,7 @@
 	 *            the event.
 	 * @return if fails.
 	 */
-	boolean fireEvent(Eventable event);
+	boolean fireEvent(Eventable event) throws ElementNotVisibleException;
 
 	/**
 	 * @return the DOM string with all the iframe content.
"
7bd6b64af09b9c5e4247544767cbe35fd75fa61c,Ryan Carniato,EmbeddedBrowserBuilder.java,MODIFY,buildEmbeddedBrowser -> [CrawljaxConfiguration configuration] | [CrawljaxConfigurationReader configuration],"diff --git a/core/src/main/java/com/crawljax/browser/EmbeddedBrowserBuilder.java b/core/src/main/java/com/crawljax/browser/EmbeddedBrowserBuilder.java
index 8ed6444..57b831f 100644
--- a/core/src/main/java/com/crawljax/browser/EmbeddedBrowserBuilder.java
+++ b/core/src/main/java/com/crawljax/browser/EmbeddedBrowserBuilder.java
@@ -26,7 +26,6 @@
  * classes to so more browser specific manipulation in plugins.
  * 
  * @author Stefan Lenselink <S.R.Lenselink@student.tudelft.nl>
- * @version $Id$
  */
 public interface EmbeddedBrowserBuilder {
 
"
7bd6b64af09b9c5e4247544767cbe35fd75fa61c,Ryan Carniato,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, List filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 22df7a8..3f21f86 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -18,6 +18,7 @@
 import org.openqa.selenium.OutputType;
 import org.openqa.selenium.Platform;
 import org.openqa.selenium.TakesScreenshot;
+import org.openqa.selenium.UnhandledAlertException;
 import org.openqa.selenium.WebDriver;
 import org.openqa.selenium.WebDriverException;
 import org.openqa.selenium.WebElement;
@@ -34,7 +35,6 @@
 import org.w3c.dom.Document;
 import org.w3c.dom.Element;
 import org.w3c.dom.NodeList;
-import org.xml.sax.SAXException;
 
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.AcceptAllFramesChecker;
@@ -47,7 +47,7 @@
 import com.crawljax.forms.FormInput;
 import com.crawljax.forms.InputValue;
 import com.crawljax.forms.RandomInputValueGenerator;
-import com.crawljax.util.Helper;
+import com.crawljax.util.DomUtils;
 
 /**
  * @author mesbah
@@ -232,7 +232,8 @@
 		try {
 			executor = new HttpCommandExecutor(url);
 		} catch (Exception e) {
-			// TODO Stefan; refactor this catch, this will definitely result in NullPointers, why
+			// TODO Stefan; refactor this catch, this will definitely result in
+			// NullPointers, why
 			// not throw RuntimeExcption direct?
 			LOGGER.error(""Received unknown exception while creating the ""
 			        + ""HttpCommandExecutor, can not continue!"", e);
@@ -257,7 +258,7 @@
 	 *            The URL.
 	 */
 	@Override
-	public void goToUrl(String url) {
+	public void goToUrl(URL url) {
 		try {
 			browser.navigate().to(url);
 			Thread.sleep(this.crawlWaitReload);
@@ -293,27 +294,24 @@
 	 *            The HTML event type (onclick, onmouseover, ...).
 	 * @return true if firing event is successful.
 	 */
-	protected boolean fireEventWait(WebElement webElement, Eventable eventable) {
+	protected boolean fireEventWait(WebElement webElement, Eventable eventable)
+	        throws ElementNotVisibleException {
 		switch (eventable.getEventType()) {
 			case click:
 				try {
 					webElement.click();
-				} catch (ElementNotVisibleException e1) {
-					LOGGER.info(""Element not visible, so cannot be clicked: ""
-					        + webElement.getTagName().toUpperCase() + "" "" + webElement.getText());
-					return false;
+				} catch (ElementNotVisibleException e) {
+					throw e;
 				} catch (WebDriverException e) {
 					throwIfConnectionException(e);
 					return false;
 				}
 				break;
 			case hover:
-				// todo
+				LOGGER.info(""Eventype hover called but this isnt implemented yet"");
 				break;
-
 			default:
-				LOGGER.info(""EventType "" + eventable.getEventType()
-				        + "" not supported in WebDriver."");
+				LOGGER.info(""EventType {} not supported in WebDriver."", eventable.getEventType());
 				return false;
 		}
 
@@ -341,15 +339,11 @@
 	public String getDom() {
 
 		try {
-			String dom = toUniformDOM(Helper.getDocumentToString(getDomTreeWithFrames()));
-			LOGGER.debug(dom);
+			String dom = toUniformDOM(DomUtils.getDocumentToString(getDomTreeWithFrames()));
+			LOGGER.trace(dom);
 			return dom;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			LOGGER.warn(e.getMessage(), e);
-			return """";
-		} catch (CrawljaxException e) {
-			LOGGER.warn(e.getMessage(), e);
+		} catch (WebDriverException | CrawljaxException e) {
+			LOGGER.warn(""Could not get the dom"", e);
 			return """";
 		}
 	}
@@ -371,8 +365,6 @@
 		m = p.matcher(html);
 		htmlFormatted = m.replaceAll("""");
 
-		// html = html.replace(""<?xml:namespace prefix = gwt >"", """");
-
 		// TODO (Stefan), Following lines are a serious performance bottle neck...
 		// Document doc = Helper.getDocument(htmlFormatted);
 		// htmlFormatted = Helper.getDocumentToString(doc);
@@ -444,7 +436,8 @@
 	 * @return true if it is able to fire the event successfully on the element.
 	 */
 	@Override
-	public synchronized boolean fireEvent(Eventable eventable) {
+	public synchronized boolean fireEvent(Eventable eventable) throws ElementNotVisibleException,
+	        NoSuchElementException {
 		try {
 
 			boolean handleChanged = false;
@@ -457,8 +450,10 @@
 					switchToFrame(eventable.getRelatedFrame());
 				} catch (NoSuchFrameException e) {
 					LOGGER.debug(""Frame not found, possibily while back-tracking.."", e);
-					// TODO Stefan, This exception is catched to prevent stopping from working
-					// This was the case on the Gmail case; find out if not switching (catching)
+					// TODO Stefan, This exception is catched to prevent stopping
+					// from working
+					// This was the case on the Gmail case; find out if not switching
+					// (catching)
 					// Results in good performance...
 				}
 				handleChanged = true;
@@ -475,9 +470,8 @@
 				browser.switchTo().defaultContent();
 			}
 			return result;
-		} catch (NoSuchElementException e) {
-			LOGGER.warn(""Could not fire eventable: "" + eventable.toString());
-			return false;
+		} catch (ElementNotVisibleException | NoSuchElementException e) {
+			throw e;
 		} catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return false;
@@ -548,10 +542,11 @@
 					browser.switchTo().window(handle);
 					LOGGER.info(""Closing other window with title \"""" + browser.getTitle() + ""\"""");
 					browser.close();
-					// browser.switchTo().defaultContent();
 					browser.switchTo().window(current);
 				}
 			}
+		} catch (UnhandledAlertException e) {
+			LOGGER.warn(""While closing the window, an alert got ignored: {}"", e.getMessage());
 		} catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
@@ -565,11 +560,9 @@
 	private Document getDomTreeWithFrames() throws CrawljaxException {
 
 		try {
-			Document document = Helper.getDocument(browser.getPageSource());
+			Document document = DomUtils.asDocument(browser.getPageSource());
 			appendFrameContent(document.getDocumentElement(), document, """");
 			return document;
-		} catch (SAXException e) {
-			throw new CrawljaxException(e.getMessage(), e);
 		} catch (IOException e) {
 			throw new CrawljaxException(e.getMessage(), e);
 		}
@@ -603,7 +596,7 @@
 
 			Element frameElement = nodeList.get(i);
 
-			String nameId = Helper.getFrameIdentification(frameElement);
+			String nameId = DomUtils.getFrameIdentification(frameElement);
 
 			if (nameId != null
 			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
@@ -622,19 +615,13 @@
 				browser.switchTo().defaultContent();
 
 				try {
-					Element toAppendElement = Helper.getDocument(toAppend).getDocumentElement();
+					Element toAppendElement = DomUtils.asDocument(toAppend).getDocumentElement();
 					Element importedElement =
 					        (Element) document.importNode(toAppendElement, true);
 					frameElement.appendChild(importedElement);
 
 					appendFrameContent(importedElement, document, frameIdentification);
-				} catch (DOMException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				} catch (SAXException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				} catch (IOException e) {
+				} catch (DOMException | IOException e) {
 					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
 					        + "" continuing..."", e);
 				}
@@ -667,9 +654,7 @@
 	public String getDomWithoutIframeContent() {
 		try {
 			String dom = browser.getPageSource();
-			// logger.debug(""driver.source: "" + dom);
 			String result = toUniformDOM(dom);
-			// logger.debug(""driver.source toUniformDom: "" + result);
 			return result;
 		} catch (WebDriverException e) {
 			throwIfConnectionException(e);
@@ -680,7 +665,8 @@
 	/**
 	 * @param input
 	 *            the input to be filled.
-	 * @return FormInput with random value assigned if possible
+	 * @return FormInput with random value assigned if possible. If no values were set it returns
+	 *         <code>null</code>
 	 */
 	@Override
 	public FormInput getInputWithRandomValue(FormInput input) {
@@ -688,8 +674,7 @@
 		WebElement webElement;
 		try {
 			webElement = browser.findElement(input.getIdentification().getWebDriverBy());
-			if (!(webElement.isDisplayed())) {
-
+			if (!webElement.isDisplayed()) {
 				return null;
 			}
 		} catch (WebDriverException e) {
@@ -697,35 +682,14 @@
 			return null;
 		}
 
-		Set<InputValue> values = new HashSet<InputValue>();
-
-		// create some random value
-
-		if (input.getType().toLowerCase().startsWith(""text"")) {
-			values.add(new InputValue(new RandomInputValueGenerator()
-			        .getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
-		} else if (input.getType().equalsIgnoreCase(""checkbox"")
-		        || input.getType().equalsIgnoreCase(""radio"") && !webElement.isSelected()) {
-			if (new RandomInputValueGenerator().getCheck()) {
-				values.add(new InputValue(""1"", true));
-			} else {
-				values.add(new InputValue(""0"", false));
-
-			}
-		} else if (input.getType().equalsIgnoreCase(""select"")) {
-			try {
-				Select select = new Select(webElement);
-				WebElement option =
-				        (WebElement) new RandomInputValueGenerator().getRandomOption(select
-				                .getOptions());
-				values.add(new InputValue(option.getText(), true));
-			} catch (WebDriverException e) {
-				throwIfConnectionException(e);
-				return null;
-			}
+		Set<InputValue> values = new HashSet<>();
+		try {
+			setRandomValues(input, webElement, values);
+		} catch (WebDriverException e) {
+			throwIfConnectionException(e);
+			return null;
 		}
-
-		if (values.size() == 0) {
+		if (values.isEmpty()) {
 			return null;
 		}
 		input.setInputValues(values);
@@ -733,6 +697,29 @@
 
 	}
 
+	private void setRandomValues(FormInput input, WebElement webElement, Set<InputValue> values) {
+		String inputString = input.getType().toLowerCase();
+		if (inputString.startsWith(""text"")) {
+			values.add(new InputValue(new RandomInputValueGenerator()
+			        .getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
+		} else if (inputString.equals(""checkbox"") || inputString.equals(""radio"")
+		        && !webElement.isSelected()) {
+			if (new RandomInputValueGenerator().getCheck()) {
+				values.add(new InputValue(""1"", true));
+			} else {
+				values.add(new InputValue(""0"", false));
+			}
+		} else if (inputString.equals(""select"")) {
+			Select select = new Select(webElement);
+			if (!select.getOptions().isEmpty()) {
+				WebElement option =
+				        new RandomInputValueGenerator().getRandomItem(select.getOptions());
+				values.add(new InputValue(option.getText(), true));
+			}
+
+		}
+	}
+
 	@Override
 	public String getFrameDom(String iframeIdentification) {
 		try {
@@ -760,7 +747,8 @@
 	public boolean elementExists(Identification identification) {
 		try {
 			WebElement el = browser.findElement(identification.getWebDriverBy());
-			// TODO Stefan; I think el will never be null as a NoSuchElementExcpetion will be
+			// TODO Stefan; I think el will never be null as a
+			// NoSuchElementExcpetion will be
 			// thrown, catched below.
 			return el != null;
 		} catch (WebDriverException e) {
"
7bd6b64af09b9c5e4247544767cbe35fd75fa61c,Ryan Carniato,WebDriverBrowserBuilder.java,MODIFY,buildEmbeddedBrowser -> [CrawljaxConfiguration configuration] | [CrawljaxConfigurationReader configuration],"diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java b/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java
index 2f756b3..2edbd5c 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java
@@ -35,8 +35,9 @@
 	public EmbeddedBrowser buildEmbeddedBrowser(CrawljaxConfigurationReader configuration) {
 		// Retrieve the config values used
 		List<String> filterAttributes = configuration.getFilterAttributeNames();
-		int crawlWaitReload = configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
-		int crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
+		long crawlWaitReload =
+		        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
+		long crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
 
 		// Determine the requested browser type
 		switch (configuration.getBrowser()) {
@@ -104,6 +105,12 @@
 				        .getWaitAfterEvent(), configuration.getCrawlSpecificationReader()
 				        .getWaitAfterReloadUrl());
 
+			case android:
+				return WebDriverBackedEmbeddedBrowser.withDriver(new AndroidDriver(),
+				        configuration.getFilterAttributeNames(), configuration
+				                .getCrawlSpecificationReader().getWaitAfterEvent(), configuration
+				                .getCrawlSpecificationReader().getWaitAfterReloadUrl());
+
 			case iphone:
 				try {
 					return WebDriverBackedEmbeddedBrowser.withDriver(new IPhoneDriver(),
@@ -111,15 +118,9 @@
 					                .getCrawlSpecificationReader().getWaitAfterEvent(),
 					        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl());
 				} catch (Exception e) {
-					LOGGER.error(e.getMessage(), e);
+					LOGGER.error(""Could not load driver: "" + e.getMessage(), e);
 				}
 
-			case android:
-				return WebDriverBackedEmbeddedBrowser.withDriver(new AndroidDriver(),
-				        configuration.getFilterAttributeNames(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterEvent(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterReloadUrl());
-
 			default:
 				return WebDriverBackedEmbeddedBrowser.withDriver(new FirefoxDriver(),
 				        configuration.getFilterAttributeNames(), configuration
"
7bd6b64af09b9c5e4247544767cbe35fd75fa61c,Ryan Carniato,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/core/src/main/java/com/crawljax/core/CrawlQueue.java b/core/src/main/java/com/crawljax/core/CrawlQueue.java
index 45dbed6..0d76156 100644
--- a/core/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/core/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -16,7 +16,6 @@
  * separate threads in a Queue like fashion (FILO).
  * 
  * @author Stefan Lenselink <S.R.Lenselink@student.tudelft.nl>
- * @version $Id$
  */
 public class CrawlQueue extends Stack<Runnable> implements BlockingQueue<Runnable> {
 
"
7bd6b64af09b9c5e4247544767cbe35fd75fa61c,Ryan Carniato,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index bfe18b8..aca2a42 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -1,6 +1,5 @@
 package com.crawljax.core;
 
-import java.util.List;
 import java.util.concurrent.TimeUnit;
 
 import net.jcip.annotations.GuardedBy;
@@ -11,8 +10,9 @@
 
 import com.crawljax.browser.BrowserPool;
 import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.condition.ConditionTypeChecker;
 import com.crawljax.condition.browserwaiter.WaitConditionChecker;
-import com.crawljax.condition.crawlcondition.CrawlConditionChecker;
+import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.eventablecondition.EventableConditionChecker;
 import com.crawljax.condition.invariant.Invariant;
 import com.crawljax.core.configuration.CrawlSpecificationReader;
@@ -28,7 +28,6 @@
  * The Crawljax Controller class is the core of Crawljax.
  * 
  * @author mesbah
- * @version $Id$
  */
 public class CrawljaxController implements CrawlQueueManager {
 
@@ -40,7 +39,7 @@
 	private long startCrawl;
 
 	private final StateComparator stateComparator;
-	private final CrawlConditionChecker crawlConditionChecker;
+	private final ConditionTypeChecker<CrawlCondition> crawlConditionChecker;
 	private final EventableConditionChecker eventableConditionChecker;
 
 	private final WaitConditionChecker waitConditionChecker = new WaitConditionChecker();
@@ -74,11 +73,12 @@
 
 		stateComparator = new StateComparator(crawlerReader.getOracleComparators());
 		invariantList = crawlerReader.getInvariants();
-		crawlConditionChecker = new CrawlConditionChecker(crawlerReader.getCrawlConditions());
+
 		waitConditionChecker.setWaitConditions(crawlerReader.getWaitConditions());
 		eventableConditionChecker =
 		        new EventableConditionChecker(configurationReader.getEventableConditions());
 
+		crawlConditionChecker = new ConditionTypeChecker<>(crawlerReader.getCrawlConditions());
 		elementChecker =
 		        new CandidateElementManager(eventableConditionChecker, crawlConditionChecker);
 
"
7bd6b64af09b9c5e4247544767cbe35fd75fa61c,Ryan Carniato,CrawlSpecification.java,MODIFY,click -> [String tagName] | [String tagNames],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
index 1a759f0..4a31314 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlSpecification.java
@@ -1,16 +1,22 @@
 package com.crawljax.core.configuration;
 
-import java.util.ArrayList;
+import java.net.MalformedURLException;
+import java.net.URL;
 import java.util.List;
+import java.util.concurrent.TimeUnit;
 
 import com.crawljax.condition.Condition;
 import com.crawljax.condition.browserwaiter.ExpectedCondition;
 import com.crawljax.condition.browserwaiter.WaitCondition;
 import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.invariant.Invariant;
+import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.configuration.CrawlActions.ExcludeByParentBuilder;
 import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.oraclecomparator.Comparator;
 import com.crawljax.oraclecomparator.OracleComparator;
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.Lists;
 
 /**
  * Specifies the crawl options for a single crawl session. The user must specify which HTML elements
@@ -41,49 +47,58 @@
  * //restrict the scope of the crawling<br />
  * crawler.setCrawlMaximumStates(15);<br />
  * crawler.setCrawlDepth(2);
- * 
- * @author DannyRoest@gmail.com (Danny Roest)
- * @version $Id$
  */
 public class CrawlSpecification {
 
-	private static final int DEFAULT_MAXIMUMRUNTIME = 3600;
-	private static final int DEFAULT_WAITTIMEAFTERRELOADURL = 500;
-	private static final int DEFAULT_WAITTIMEAFTEREVENT = 500;
+	private static final long DEFAULT_MAXIMUMRUNTIME = TimeUnit.HOURS.toMillis(1);
+	private static final long DEFAULT_WAITTIMEAFTERRELOADURL = 500;
+	private static final long DEFAULT_WAITTIMEAFTEREVENT = 500;
 
-	private final String url;
+	private final URL url;
 
-	private List<EventType> crawlEvents = new ArrayList<EventType>();
+	private final List<EventType> crawlEvents = Lists.newLinkedList();
+	private final List<String> ignoredFrameIdentifiers = Lists.newLinkedList();
+	private final List<Invariant> invariants = Lists.newLinkedList();
+	private final List<OracleComparator> oracleComparators = Lists.newLinkedList();
+	private final List<WaitCondition> waitConditions = Lists.newLinkedList();
+	private final List<CrawlCondition> crawlConditions = Lists.newLinkedList();
 
 	private int depth = 2;
 	private int maximumStates = 0;
-	private int maximumRuntime = DEFAULT_MAXIMUMRUNTIME; // in seconds
-	private int waitTimeAfterReloadUrl = DEFAULT_WAITTIMEAFTERRELOADURL; // in milliseconds
-	private int waitTimeAfterEvent = DEFAULT_WAITTIMEAFTEREVENT; // in milliseconds
+	private long maximumRuntime = DEFAULT_MAXIMUMRUNTIME;
+	private long waitTimeAfterReloadUrl = DEFAULT_WAITTIMEAFTERRELOADURL;
+	private long waitTimeAfterEvent = DEFAULT_WAITTIMEAFTEREVENT;
+
 	private final CrawlActions crawlActions = new CrawlActions();
 
 	private boolean randomInputInForms = true;
 	private InputSpecification inputSpecification = new InputSpecification();
 
 	private boolean testInvariantsWhileCrawling = true;
-	private final List<Invariant> invariants = new ArrayList<Invariant>();
 
-	private final List<OracleComparator> oracleComparators = new ArrayList<OracleComparator>();
-	private final List<WaitCondition> waitConditions = new ArrayList<WaitCondition>();
-	private final List<CrawlCondition> crawlConditions = new ArrayList<CrawlCondition>();
 	private boolean clicklOnce = true;
-	private final List<String> ignoredFrameIdentifiers = new ArrayList<String>();
 	private boolean disableCrawlFrames = false;
 
+	private boolean clickHiddenAnchors = false;
+
 	/**
 	 * @param url
 	 *            the site to crawl
 	 */
-	public CrawlSpecification(String url) {
+	public CrawlSpecification(URL url) {
 		this.crawlEvents.add(EventType.click);
 		this.url = url;
 	}
 
+	public CrawlSpecification(String url) {
+		this.crawlEvents.add(EventType.click);
+		try {
+			this.url = new URL(url);
+		} catch (MalformedURLException e) {
+			throw new CrawljaxException(""Invalid URL: "" + url);
+		}
+	}
+
 	/**
 	 * Specifies that Crawljax should click all the default clickable elements. These include: All
 	 * anchor tags All buttons
@@ -96,34 +111,17 @@
 	}
 
 	/**
-	 * Guifre Ruiz: This method can be used to crawl more tags and, therefore, more pages in the
-	 * target. However, it slow down a bit the process.
+	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
+	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}.
+	 * 
+	 * @param tagName
+	 *            the tag name of the elements to be included
+	 * @return this CrawlElement
 	 */
-	public void clickMoreElements() {
-		crawlActions.click(""a"");
-		crawlActions.click(""button"");
-		crawlActions.click(""td"");
-		crawlActions.click(""span"");
-		crawlActions.click(""div"");
-		crawlActions.click(""tr"");
-		crawlActions.click(""table"");
-		crawlActions.click(""tbody"");
-		crawlActions.click(""ol"");
-		crawlActions.click(""center"");
-		crawlActions.click(""li"");
-		crawlActions.click(""radio"");
-		crawlActions.click(""non"");
-		crawlActions.click(""meta"");
-		crawlActions.click(""refresh"");
-		crawlActions.click(""xhr"");
-		crawlActions.click(""relative"");
-		crawlActions.click(""link"");
-		crawlActions.click(""self"");
-		crawlActions.click(""form"");
-		crawlActions.click(""input"");
-		crawlActions.click(""option"");
-		crawlActions.click(""img"");
-		crawlActions.click(""p"");
+	public void click(String... tagNames) {
+		for (String tagName : tagNames) {
+			crawlActions.click(tagName);
+		}
 	}
 
 	/**
@@ -153,22 +151,16 @@
 	}
 
 	/**
-	 * Crawljax will the HTML elements while crawling if and only if all the specified conditions
-	 * are satisfied. IMPORTANT: only works with click()!!! For example:
-	 * when(onContactPageCondition) will only click the HTML element if it is on the contact page
-	 * 
-	 * @param conditions
-	 *            the condition to be met.
-	 * @return this CrawlActions
+	 * {@link CrawlActions#dontClickChildrenOf(String)}
 	 */
-	public CrawlActions when(Condition... conditions) {
-		return crawlActions.when(conditions);
+	public ExcludeByParentBuilder dontClickChildrenOf(String tagname) {
+		return crawlActions.dontClickChildrenOf(tagname);
 	}
 
 	/**
 	 * @return the initial url of the site to crawl
 	 */
-	protected String getUrl() {
+	protected URL getUrl() {
 		return url;
 	}
 
@@ -208,21 +200,34 @@
 	}
 
 	/**
-	 * @return the crawlMaximumRuntime
+	 * @return the crawlMaximumRuntime in millis
 	 */
-	protected int getMaximumRuntime() {
+	protected long getMaximumRuntime() {
 		return maximumRuntime;
 	}
 
 	/**
-	 * Sets the maximum time for Crawljax to run. Crawljax will stop crawling when this timelimit is
-	 * reached.
+	 * Sets the maximum time for Crawljax to run. Crawljax will stop crawling when this time limit
+	 * is reached.
 	 * 
+	 * @param the
+	 *            crawlMaximumRuntime to set
+	 */
+	public void setMaximumRuntime(long time, TimeUnit timeUnit) {
+		this.maximumRuntime = timeUnit.toMillis(time);
+	}
+
+	/**
+	 * Sets the maximum time for Crawljax to run. Crawljax will stop crawling when this time limit
+	 * is reached.
+	 * 
+	 * @deprecated use {@link #setMaximumRuntime(long, TimeUnit)}.
 	 * @param seconds
 	 *            the crawlMaximumRuntime to set
 	 */
-	public void setMaximumRuntime(int seconds) {
-		this.maximumRuntime = seconds;
+	@Deprecated
+	public void setMaximumRuntime(long time) {
+		this.maximumRuntime = TimeUnit.SECONDS.toMillis(time);
 	}
 
 	/**
@@ -243,38 +248,58 @@
 	/**
 	 * @return the number of milliseconds to wait after reloading the url
 	 */
-	protected int getWaitTimeAfterReloadUrl() {
+	protected long getWaitTimeAfterReloadUrl() {
 		return waitTimeAfterReloadUrl;
 	}
 
 	/**
-	 * @param milliseconds
-	 *            the number of milliseconds to wait after reloading the url
+	 * @param time
+	 *            to wait after reloading the url
 	 */
-	public void setWaitTimeAfterReloadUrl(int milliseconds) {
-		this.waitTimeAfterReloadUrl = milliseconds;
+	public void setWaitTimeAfterReloadUrl(long time, TimeUnit unit) {
+		this.waitTimeAfterReloadUrl = unit.toMillis(time);
+	}
+
+	/**
+	 * @deprecated use {@link #setWaitTimeAfterReloadUrl(long, TimeUnit)}
+	 * @param time
+	 *            to wait after reloading the url
+	 */
+	@Deprecated
+	public void setWaitTimeAfterReloadUrl(long timeInMillis) {
+		this.waitTimeAfterReloadUrl = timeInMillis;
 	}
 
 	/**
 	 * @return the number the number of milliseconds to wait after an event is fired
 	 */
-	protected int getWaitTimeAfterEvent() {
+	protected long getWaitTimeAfterEvent() {
 		return waitTimeAfterEvent;
 	}
 
 	/**
+	 * @param the
+	 *            time to wait after an event is fired
+	 */
+	public void setWaitTimeAfterEvent(long time, TimeUnit unit) {
+		this.waitTimeAfterEvent = unit.toMillis(time);
+	}
+
+	/**
+	 * @deprecated use {@link #setWaitTimeAfterEvent(long, TimeUnit)}
 	 * @param milliseconds
 	 *            the number of milliseconds to wait after an event is fired
 	 */
-	public void setWaitTimeAfterEvent(int milliseconds) {
-		this.waitTimeAfterEvent = milliseconds;
+	@Deprecated
+	public void setWaitTimeAfterEvent(long time) {
+		this.waitTimeAfterEvent = time;
 	}
 
 	/**
 	 * @return the events that should be fired (e.g. onclick)
 	 */
-	protected List<EventType> getCrawlEvents() {
-		return crawlEvents;
+	protected ImmutableList<EventType> getCrawlEvents() {
+		return ImmutableList.copyOf(crawlEvents);
 	}
 
 	/**
@@ -302,8 +327,8 @@
 	/**
 	 * @return the oracleComparators
 	 */
-	protected List<OracleComparator> getOracleComparators() {
-		return oracleComparators;
+	protected ImmutableList<OracleComparator> getOracleComparators() {
+		return ImmutableList.copyOf(oracleComparators);
 	}
 
 	/**
@@ -336,8 +361,8 @@
 	/**
 	 * @return the invariants
 	 */
-	protected List<Invariant> getInvariants() {
-		return invariants;
+	protected ImmutableList<Invariant> getInvariants() {
+		return ImmutableList.copyOf(invariants);
 	}
 
 	/**
@@ -380,8 +405,8 @@
 	/**
 	 * @return the waitConditions
 	 */
-	protected List<WaitCondition> getWaitConditions() {
-		return waitConditions;
+	protected ImmutableList<WaitCondition> getWaitConditions() {
+		return ImmutableList.copyOf(waitConditions);
 	}
 
 	/**
@@ -411,8 +436,8 @@
 	/**
 	 * @return the crawlConditions
 	 */
-	protected List<CrawlCondition> getCrawlConditions() {
-		return crawlConditions;
+	protected ImmutableList<CrawlCondition> getCrawlConditions() {
+		return ImmutableList.copyOf(crawlConditions);
 	}
 
 	/**
@@ -457,8 +482,8 @@
 	 * @param crawlEvents
 	 *            the crawlEvents to set
 	 */
-	public void setCrawlEvents(List<EventType> crawlEvents) {
-		this.crawlEvents = crawlEvents;
+	public void addCrawlEvents(List<EventType> crawlEvents) {
+		this.crawlEvents.addAll(crawlEvents);
 	}
 
 	/**
@@ -472,8 +497,8 @@
 	/**
 	 * @return the list of ignored frames
 	 */
-	protected List<String> ignoredFrameIdentifiers() {
-		return ignoredFrameIdentifiers;
+	protected ImmutableList<String> ignoredFrameIdentifiers() {
+		return ImmutableList.copyOf(ignoredFrameIdentifiers);
 	}
 
 	/**
@@ -491,4 +516,25 @@
 	protected boolean isCrawlFrames() {
 		return !disableCrawlFrames;
 	}
+
+	boolean isClickHiddenAnchors() {
+		return clickHiddenAnchors;
+	}
+
+	/**
+	 * Set Crawljax to click hidden anchors or not. <code>true</code> by default. @ *
+	 * <dl>
+	 * <dd>Pro:</dd>
+	 * <dt>The benefit of clicking hidden anchors is that Crawljax isn't capable of clicking
+	 * elements that are hidden for example because you have to hover another element first. This
+	 * happens in most fold-out menus for example. Enabling this function allows Crawljax to find
+	 * more states that are hidden this way.</dt>
+	 * <dd>Con:</dd>
+	 * <dt>If a anchor tag is never visible in the browser in any way, Crawljax will crawl it
+	 * anyway. This makes the Crawl inconsistent with what the user experiences.</dt>
+	 * </dl>
+	 */
+	public void clickHiddenAnchors(boolean clickHiddenAnchors) {
+		this.clickHiddenAnchors = clickHiddenAnchors;
+	}
 }
"
7bd6b64af09b9c5e4247544767cbe35fd75fa61c,Ryan Carniato,FormInputField.java,MODIFY,setValues -> [boolean values] | [String values],"diff --git a/core/src/main/java/com/crawljax/core/configuration/FormInputField.java b/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
index c2fd585..dc6e88c 100644
--- a/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
@@ -14,7 +14,6 @@
  * @see Form
  * @see Form#field(String)
  * @author DannyRoest@gmail.com (Danny Roest)
- * @version $Id$
  */
 public class FormInputField extends InputField {
 
"
7bd6b64af09b9c5e4247544767cbe35fd75fa61c,Ryan Carniato,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/core/src/main/java/com/crawljax/core/configuration/InputField.java b/core/src/main/java/com/crawljax/core/configuration/InputField.java
index 474d562..b25765c 100644
--- a/core/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -13,7 +13,6 @@
  * @see InputSpecification#field(String)
  * @see InputSpecification#fields(String...)
  * @author DannyRoest@gmail.com (Danny Roest)
- * @version $Id$
  */
 public class InputField {
 
@@ -100,7 +99,7 @@
 	 * @return The value.
 	 */
 	protected String getValue() {
-		if (fieldValues.size() == 0) {
+		if (fieldValues.isEmpty()) {
 			return null;
 		} else {
 			return fieldValues.get(0);
"
7bd6b64af09b9c5e4247544767cbe35fd75fa61c,Ryan Carniato,StateFlowGraph.java,MODIFY,"addState -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index aaca56f..da12f27 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -357,10 +357,8 @@
 
 		final KShortestPaths<StateVertex, Eventable> kPaths =
 		        new KShortestPaths<StateVertex, Eventable>(this.sfg, index, Integer.MAX_VALUE);
-		// System.out.println(sfg.toString());
 
 		for (StateVertex state : getDeepStates(index)) {
-			// System.out.println(""Deep State: "" + state.getName());
 
 			try {
 				List<GraphPath<StateVertex, Eventable>> paths = kPaths.getPaths(state);
"
7bd6b64af09b9c5e4247544767cbe35fd75fa61c,Ryan Carniato,StateVertex.java,MODIFY,"searchForCandidateElements -> [CandidateElementExtractor candidateExtractor] | [CandidateElementExtractor candidateExtractor, List crawlTagElements, List crawlExcludeTagElements, boolean clickOnce]","diff --git a/core/src/main/java/com/crawljax/core/state/StateVertex.java b/core/src/main/java/com/crawljax/core/state/StateVertex.java
index c7a2092..af29b70 100644
--- a/core/src/main/java/com/crawljax/core/state/StateVertex.java
+++ b/core/src/main/java/com/crawljax/core/state/StateVertex.java
@@ -15,7 +15,6 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.w3c.dom.Document;
-import org.xml.sax.SAXException;
 
 import com.crawljax.core.CandidateCrawlAction;
 import com.crawljax.core.CandidateElement;
@@ -25,17 +24,16 @@
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.TagElement;
 import com.crawljax.core.state.Eventable.EventType;
-import com.crawljax.util.Helper;
+import com.crawljax.util.DomUtils;
+import com.google.common.base.Strings;
 
 /**
- * The state vertex class which represents a state in the browser. This class implements the
- * Iterable interface because on a StateVertex it is possible to iterate over the possible
- * CandidateElements found in this state. When iterating over the possible candidate elements every
- * time a candidate is returned its removed from the list so it is a one time only access to the
+ * The state vertex class which represents a state in the browser. This class
+ * implements the Iterable interface because on a StateVertex it is possible to
+ * iterate over the possible CandidateElements found in this state. When
+ * iterating over the possible candidate elements every time a candidate is
+ * returned its removed from the list so it is a one time only access to the
  * candidates.
- * 
- * @author mesbah
- * @version $Id$
  */
 public class StateVertex implements Serializable {
 
@@ -50,20 +48,18 @@
 	private boolean guidedCrawling = false;
 
 	/**
-	 * This list is used to store the possible candidates. If it is null its not initialised if it's
-	 * a empty list its empty.
+	 * This list is used to store the possible candidates. If it is null its not
+	 * initialised if it's a empty list its empty.
 	 */
-	private LinkedBlockingDeque<CandidateCrawlAction> candidateActions;
+	private LinkedBlockingDeque<CandidateCrawlAction> candidateActions =
+			new LinkedBlockingDeque<>();;
 
 	private final ConcurrentHashMap<Crawler, CandidateCrawlAction> registerdCandidateActions =
-	        new ConcurrentHashMap<Crawler, CandidateCrawlAction>();
+			new ConcurrentHashMap<>();
 	private final ConcurrentHashMap<Crawler, CandidateCrawlAction> workInProgressCandidateActions =
-	        new ConcurrentHashMap<Crawler, CandidateCrawlAction>();
+			new ConcurrentHashMap<>();
 
-	private final Object candidateActionsSearchLock = new String("""");
-
-	private final LinkedBlockingDeque<Crawler> registeredCrawlers =
-	        new LinkedBlockingDeque<Crawler>();
+	private final LinkedBlockingDeque<Crawler> registeredCrawlers = new LinkedBlockingDeque<>();
 
 	/**
 	 * Default constructor to support saving instances of this class as an XML.
@@ -74,12 +70,11 @@
 	}
 
 	/**
-	 * Creates a current state without an url and the stripped dom equals the dom.
+	 * Creates a current state without an url and the stripped dom equals the
+	 * dom.
 	 * 
-	 * @param name
-	 *            the name of the state
-	 * @param dom
-	 *            the current DOM tree of the browser
+	 * @param name the name of the state
+	 * @param dom the current DOM tree of the browser
 	 */
 	public StateVertex(String name, String dom) {
 		this(null, name, dom, dom);
@@ -88,14 +83,10 @@
 	/**
 	 * Defines a State.
 	 * 
-	 * @param url
-	 *            the current url of the state
-	 * @param name
-	 *            the name of the state
-	 * @param dom
-	 *            the current DOM tree of the browser
-	 * @param strippedDom
-	 *            the stripped dom by the OracleComparators
+	 * @param url the current url of the state
+	 * @param name the name of the state
+	 * @param dom the current DOM tree of the browser
+	 * @param strippedDom the stripped dom by the OracleComparators
 	 */
 	public StateVertex(String url, String name, String dom, String strippedDom) {
 		this.url = url;
@@ -144,7 +135,7 @@
 	@Override
 	public int hashCode() {
 		HashCodeBuilder builder = new HashCodeBuilder();
-		if (strippedDom == null || """".equals(strippedDom)) {
+		if (Strings.isNullOrEmpty(strippedDom)) {
 			builder.append(dom);
 		} else {
 			builder.append(strippedDom);
@@ -156,8 +147,7 @@
 	/**
 	 * Compare this vertex to a other StateVertex.
 	 * 
-	 * @param obj
-	 *            the Object to compare this vertex
+	 * @param obj the Object to compare this vertex
 	 * @return Return true if equal. Uses reflection.
 	 * @see java.lang.Object#equals(java.lang.Object)
 	 */
@@ -173,7 +163,7 @@
 		final StateVertex rhs = (StateVertex) obj;
 
 		return new EqualsBuilder().append(this.strippedDom, rhs.getStrippedDom())
-		        .append(this.guidedCrawling, rhs.guidedCrawling).isEquals();
+				.append(this.guidedCrawling, rhs.guidedCrawling).isEquals();
 	}
 
 	/**
@@ -203,24 +193,21 @@
 	}
 
 	/**
-	 * @param id
-	 *            the id to set
+	 * @param id the id to set
 	 */
 	public void setId(long id) {
 		this.id = id;
 	}
 
 	/**
-	 * @param name
-	 *            the name to set
+	 * @param name the name to set
 	 */
 	public void setName(String name) {
 		this.name = name;
 	}
 
 	/**
-	 * @param dom
-	 *            the dom to set
+	 * @param dom the dom to set
 	 */
 	public void setDom(String dom) {
 		this.dom = dom;
@@ -234,67 +221,39 @@
 	}
 
 	/**
-	 * @param guidedCrawling
-	 *            true if set through guided crawling.
+	 * @param guidedCrawling true if set through guided crawling.
 	 */
 	public void setGuidedCrawling(boolean guidedCrawling) {
 		this.guidedCrawling = guidedCrawling;
 	}
 
 	/**
-	 * search for new Candidates from this state. The search for candidates is only done when no
-	 * list is available yet (candidateActions == null).
+	 * search for new Candidates from this state. The search for candidates is
+	 * only done when no list is available yet (candidateActions == null).
 	 * 
-	 * @param candidateExtractor
-	 *            the CandidateElementExtractor to use.
-	 * @param crawlTagElements
-	 *            the tag elements to examine.
-	 * @param crawlExcludeTagElements
-	 *            the elements to exclude.
-	 * @param clickOnce
-	 *            if true examine each element once.
+	 * @param candidateExtractor the CandidateElementExtractor to use.
+	 * @param crawlTagElements the tag elements to examine.
+	 * @param crawlExcludeTagElements the elements to exclude.
+	 * @param clickOnce if true examine each element once.
 	 * @return true if the searchForCandidateElemens has run false otherwise
 	 */
 	@GuardedBy(""candidateActionsSearchLock"")
 	public boolean searchForCandidateElements(CandidateElementExtractor candidateExtractor,
-	        List<TagElement> crawlTagElements, List<TagElement> crawlExcludeTagElements,
-	        boolean clickOnce) {
-		synchronized (candidateActionsSearchLock) {
-			if (candidateActions == null) {
-				candidateActions = new LinkedBlockingDeque<CandidateCrawlAction>();
-			} else {
-				return false;
-			}
-		}
-		// TODO read the eventtypes from the crawl elements instead
-		List<String> eventTypes = new ArrayList<String>();
-		eventTypes.add(EventType.click.toString());
+			List<TagElement> crawlTagElements, List<TagElement> crawlExcludeTagElements,
+			boolean clickOnce) {
 
 		try {
-			List<CandidateElement> candidateList =
-			        candidateExtractor.extract(crawlTagElements, crawlExcludeTagElements,
-			                clickOnce, this);
-
+			List<CandidateElement> candidateList = candidateExtractor.extract(this);
 			for (CandidateElement candidateElement : candidateList) {
-				for (String eventType : eventTypes) {
-					if (eventType.equals(EventType.click.toString())) {
-						candidateActions.add(new CandidateCrawlAction(candidateElement,
-						        EventType.click));
-					} else {
-						if (eventType.equals(EventType.hover.toString())) {
-							candidateActions.add(new CandidateCrawlAction(candidateElement,
-							        EventType.hover));
-						} else {
-							LOGGER.warn(""The Event Type: "" + eventType + "" is not supported."");
-						}
-					}
-				}
+				// TODO add support for Hovers.
+				candidateActions.add(new CandidateCrawlAction(candidateElement, EventType.click));
 			}
 		} catch (CrawljaxException e) {
 			LOGGER.error(
-			        ""Catched exception while searching for candidates in state "" + getName(), e);
+					""Catched exception while searching for candidates in state "" + getName(), e);
 		}
-		return candidateActions.size() > 0; // Only notify of found candidates when there are...
+		return !candidateActions.isEmpty(); // Only notify of found candidates
+														// when there are...
 
 	}
 
@@ -319,8 +278,8 @@
 	}
 
 	/**
-	 * Removes Candidate Actions on candidateElements that have been removed by the pre-state crawl
-	 * plugin.
+	 * Removes Candidate Actions on candidateElements that have been removed by
+	 * the pre-state crawl plugin.
 	 * 
 	 * @param candidateElements
 	 */
@@ -335,7 +294,7 @@
 			if (!candidateElements.contains(currentAction.getCandidateElement())) {
 				iter.remove();
 				LOGGER.info(""filtered candidate action: "" + currentAction.getEventType().name()
-				        + "" on "" + currentAction.getCandidateElement().getGeneralString());
+						+ "" on "" + currentAction.getCandidateElement().getGeneralString());
 
 			}
 		}
@@ -343,31 +302,28 @@
 
 	/**
 	 * @return a Document instance of the dom string.
-	 * @throws SAXException
-	 *             if an exception is thrown.
-	 * @throws IOException
-	 *             if an exception is thrown.
+	 * @throws IOException if an exception is thrown.
 	 */
-	public Document getDocument() throws SAXException, IOException {
-		return Helper.getDocument(this.dom);
+	public Document getDocument() throws IOException {
+		return DomUtils.asDocument(this.dom);
 	}
 
 	/**
-	 * This is the main work divider function, calling this function will first look at the
-	 * registeedCandidateActions to see if the current Crawler has already registered itself at one
-	 * of the jobs. Second it tries to see if the current crawler is not already processing one of
-	 * the actions and return that action and last it tries to find an unregistered candidate. If
-	 * all else fails it tries to return a action that is registered by an other crawler and
-	 * disables that crawler.
+	 * This is the main work divider function, calling this function will first
+	 * look at the registeedCandidateActions to see if the current Crawler has
+	 * already registered itself at one of the jobs. Second it tries to see if
+	 * the current crawler is not already processing one of the actions and
+	 * return that action and last it tries to find an unregistered candidate. If
+	 * all else fails it tries to return a action that is registered by an other
+	 * crawler and disables that crawler.
 	 * 
-	 * @param requestingCrawler
-	 *            the Crawler placing the request for the Action
-	 * @param manager
-	 *            the manager that can be used to remove a crawler from the queue.
+	 * @param requestingCrawler the Crawler placing the request for the Action
+	 * @param manager the manager that can be used to remove a crawler from the
+	 *           queue.
 	 * @return the action that needs to be performed by the Crawler.
 	 */
 	public CandidateCrawlAction pollCandidateCrawlAction(Crawler requestingCrawler,
-	        CrawlQueueManager manager) {
+			CrawlQueueManager manager) {
 		CandidateCrawlAction action = registerdCandidateActions.remove(requestingCrawler);
 		if (action != null) {
 			workInProgressCandidateActions.put(requestingCrawler, action);
@@ -388,23 +344,22 @@
 			}
 			do {
 				if (manager.removeWorkFromQueue(c)) {
-					LOGGER.info(""Crawler "" + c + "" REMOVED from Queue!"");
+					LOGGER.info(""Crawler {} REMOVED from Queue!"", c);
 					action = registerdCandidateActions.remove(c);
 					if (action != null) {
 						/*
-						 * We got a action and removed the registeredCandidateActions for the
-						 * crawler, remove the crawler from queue as the first thinng. As the
-						 * crawler might just have started the run method of the crawler must also
-						 * be added with a check hook.
+						 * We got a action and removed the registeredCandidateActions
+						 * for the crawler, remove the crawler from queue as the first
+						 * thing. As the crawler might just have started the run
+						 * method of the crawler must also be added with a check hook.
 						 */
 						LOGGER.info(""Stolen work from other Crawler"");
 						return action;
 					} else {
-						LOGGER.warn(""Oh my! I just removed "" + c
-						        + "" from the queue with no action!"");
+						LOGGER.warn(""Oh my! I just removed {} from the queue with no action!"", c);
 					}
 				} else {
-					LOGGER.warn(""FAILED TO REMOVE "" + c + "" from Queue!"");
+					LOGGER.warn(""FAILED TO REMOVE {} from Queue!"", c);
 				}
 				c = registeredCrawlers.pollFirst();
 			} while (c != null);
@@ -415,8 +370,7 @@
 	/**
 	 * Register an assignment to the crawler.
 	 * 
-	 * @param newCrawler
-	 *            the crawler that wants an assignment
+	 * @param newCrawler the crawler that wants an assignment
 	 * @return true if the crawler has an assignment false otherwise.
 	 */
 	public boolean registerCrawler(Crawler newCrawler) {
@@ -432,8 +386,7 @@
 	/**
 	 * Register a Crawler that is going to work, tell if his must go on or abort.
 	 * 
-	 * @param crawler
-	 *            the crawler to register
+	 * @param crawler the crawler to register
 	 * @return true if the crawler is successfully registered
 	 */
 	public boolean startWorking(Crawler crawler) {
@@ -448,13 +401,11 @@
 	}
 
 	/**
-	 * Notify the current StateVertex that the given crawler has finished working on the given
-	 * action.
+	 * Notify the current StateVertex that the given crawler has finished working
+	 * on the given action.
 	 * 
-	 * @param crawler
-	 *            the crawler that is finished
-	 * @param action
-	 *            the action that have been examined
+	 * @param crawler the crawler that is finished
+	 * @param action the action that have been examined
 	 */
 	public void finishedWorking(Crawler crawler, CandidateCrawlAction action) {
 		candidateActions.remove(action);
"
7bd6b64af09b9c5e4247544767cbe35fd75fa61c,Ryan Carniato,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index 46ae2c7..6854b96 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -16,22 +16,18 @@
 import org.w3c.dom.Element;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
-import org.xml.sax.SAXException;
 
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.CandidateElement;
 import com.crawljax.core.configuration.InputSpecification;
 import com.crawljax.core.exception.BrowserConnectionException;
-import com.crawljax.util.Helper;
+import com.crawljax.util.DomUtils;
 import com.crawljax.util.XPathHelper;
 
 /**
  * Handles form values and fills in the form input elements with random values of the defined
  * values.
- * 
- * @author dannyroest@gmail.com (Danny Roest)
- * @version $Id$
  */
 public class FormHandler {
 	private static final Logger LOGGER = LoggerFactory.getLogger(FormHandler.class.getName());
@@ -67,13 +63,10 @@
 	/**
 	 * Fills in the element with the InputValues for input TODO: improve this by using WebDriver
 	 * options?
-	 * 
-	 * @param element
-	 * @param input
 	 */
 	private void setInputElementValue(Node element, FormInput input) {
 
-		LOGGER.debug(""INPUTFIELD: "" + input.getIdentification() + "" ("" + input.getType() + "")"");
+		LOGGER.debug(""INPUTFIELD: {} ({})"", input.getIdentification(), input.getType());
 		if (element == null) {
 			return;
 		}
@@ -85,19 +78,19 @@
 				        || input.getType().equalsIgnoreCase(""password"")
 				        || input.getType().equalsIgnoreCase(""hidden"")) {
 					String text = input.getInputValues().iterator().next().getValue();
-					if (text.equals("""")) {
+					if ("""".equals(text)) {
 						return;
 					}
-					String js = Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
+					String js = DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
 					js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
 					browser.executeJavaScript(js);
 				}
 
 				// check/uncheck checkboxes
-				if (input.getType().equals(""checkbox"")) {
+				if (""checkbox"".equals(input.getType())) {
 					for (InputValue inputValue : input.getInputValues()) {
 						String js =
-						        Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
+						        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
 						boolean check;
 						if (!randomFieldValue) {
 							check = inputValue.isChecked();
@@ -122,7 +115,7 @@
 					for (InputValue inputValue : input.getInputValues()) {
 						if (inputValue.isChecked()) {
 							String js =
-							        Helper.getJSGetElement(XPathHelper
+							        DomUtils.getJSGetElement(XPathHelper
 							                .getXPathExpression(element));
 							js += ""try{ATUSA_element.checked=true;}catch(e){}"";
 							browser.executeJavaScript(js);
@@ -135,7 +128,7 @@
 					for (InputValue inputValue : input.getInputValues()) {
 						// if(browser.getDriver()==null){
 						String js =
-						        Helper.getJSGetElement(XPathHelper.getXPathExpression(element));
+						        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
 						js +=
 						        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
 						                + ""if(ATUSA_element.options[i].value=='""
@@ -159,7 +152,6 @@
 	}
 
 	/**
-	 * @param dom
 	 * @return all input element in dom
 	 */
 	private List<Node> getInputElements(Document dom) {
@@ -172,8 +164,7 @@
 				Node candidate = nodeList.item(i);
 				Node typeAttribute = candidate.getAttributes().getNamedItem(""type"");
 				if (typeAttribute == null
-				        || (typeAttribute != null && allowedTypes.contains(typeAttribute
-				                .getNodeValue()))) {
+				        || (allowedTypes.contains(typeAttribute.getNodeValue()))) {
 					nodes.add(nodeList.item(i));
 				}
 			}
@@ -200,7 +191,7 @@
 		List<FormInput> formInputs = new ArrayList<FormInput>();
 		Document dom;
 		try {
-			dom = Helper.getDocument(browser.getDom());
+			dom = DomUtils.asDocument(browser.getDom());
 			List<Node> nodes = getInputElements(dom);
 			for (Node node : nodes) {
 				FormInput formInput =
@@ -209,11 +200,7 @@
 					formInputs.add(formInput);
 				}
 			}
-		} catch (Exception e) {
-			// TODO Stefan; refactor this Exception
-			if (e instanceof BrowserConnectionException) {
-				throw (BrowserConnectionException) e;
-			}
+		} catch (IOException e) {
 			LOGGER.error(e.getMessage(), e);
 		}
 		return formInputs;
@@ -236,19 +223,13 @@
 	 *            form input list.
 	 */
 	public void handleFormElements(List<FormInput> formInputs) {
-		Document dom;
-
 		try {
-			dom = Helper.getDocument(browser.getDomWithoutIframeContent());
+			Document dom = DomUtils.asDocument(browser.getDomWithoutIframeContent());
 			for (FormInput input : formInputs) {
 				LOGGER.debug(""Filling in: "" + input);
 				setInputElementValue(formInputValueHelper.getBelongingNode(input, dom), input);
 			}
-		} catch (SAXException e) {
-			LOGGER.error(e.getMessage(), e);
-		} catch (IOException e) {
-			LOGGER.error(e.getMessage(), e);
-		} catch (XPathExpressionException e) {
+		} catch (IOException | XPathExpressionException e) {
 			LOGGER.error(e.getMessage(), e);
 		}
 
"
7bd6b64af09b9c5e4247544767cbe35fd75fa61c,Ryan Carniato,AttributeInjector.java,MODIFY,"removeInjectedAttributes -> [HTMLElement element, String attrName] | [Vector injectedElements, String attrName]","diff --git a/core/src/main/java/com/crawljax/util/AttributeInjector.java b/core/src/main/java/com/crawljax/util/AttributeInjector.java
index 8bc9fc6..ad942d9 100644
--- a/core/src/main/java/com/crawljax/util/AttributeInjector.java
+++ b/core/src/main/java/com/crawljax/util/AttributeInjector.java
@@ -12,8 +12,6 @@
 
 /**
  * Attribute injector class.
- * 
- * @version $Id$
  */
 public final class AttributeInjector {
 
@@ -39,7 +37,6 @@
 			return null;
 		}
 		srcAttrValue += ""?"" + attrName + ""="" + value;
-		// System.out.println(""Setting value for src to: "" + srcAttrValue);
 		element.setAttribute(""src"", srcAttrValue);
 		return element;
 	}
@@ -60,7 +57,6 @@
 	public static boolean isInjected(Node node, String attrName, String value, boolean checkValue) {
 
 		NamedNodeMap attributes = node.getAttributes();
-		// String tmp = """";
 		// if there are no attributes we know the node does not contain the
 		// injected attribute
 		if (attributes == null) {
"
7bd6b64af09b9c5e4247544767cbe35fd75fa61c,Ryan Carniato,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index 605a685..8d44723 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -9,7 +9,6 @@
 import org.w3c.dom.Document;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
-import org.xml.sax.SAXException;
 
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.core.state.Element;
@@ -19,7 +18,6 @@
  * class for finding and checking elements.
  * 
  * @author danny
- * @version $Id$
  */
 public class ElementResolver {
 	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class.getName());
@@ -53,15 +51,13 @@
 	/**
 	 * @param logging
 	 *            Whether to do logging.
-	 * @return equivalent xpath of element equivalent to Eventable
+	 * @return equivalent xpath of element equivalent to Eventable or an empty string if the DOM
+	 *         cannot be read.
 	 */
 	public String resolve(boolean logging) {
 		Document dom = null;
 		try {
-			dom = Helper.getDocument(browser.getDom());
-		} catch (SAXException e) {
-			LOGGER.error(e.getMessage(), e);
-			return """";
+			dom = DomUtils.asDocument(browser.getDom());
 		} catch (IOException e) {
 			LOGGER.error(e.getMessage(), e);
 			return """";
@@ -69,7 +65,7 @@
 
 		try {
 			String xpathEventable = eventable.getIdentification().getValue();
-			Node nodeSameXpath = Helper.getElementByXpath(dom, xpathEventable);
+			Node nodeSameXpath = DomUtils.getElementByXpath(dom, xpathEventable);
 			if (nodeSameXpath != null) {
 				Element elementSameXpath = new Element(nodeSameXpath);
 				if (logging) {
"
7bd6b64af09b9c5e4247544767cbe35fd75fa61c,Ryan Carniato,PrettyHTML.java,MODIFY,"prettyHTML -> [String html] | [String html, String strIndent]","diff --git a/core/src/main/java/com/crawljax/util/PrettyHTML.java b/core/src/main/java/com/crawljax/util/PrettyHTML.java
index b13adc9..d67a0eb 100644
--- a/core/src/main/java/com/crawljax/util/PrettyHTML.java
+++ b/core/src/main/java/com/crawljax/util/PrettyHTML.java
@@ -6,7 +6,6 @@
  * Class for making presenting HTML without changing it's structure.
  * 
  * @author Danny
- * @version $Id$
  */
 public final class PrettyHTML {
 
"
7bd6b64af09b9c5e4247544767cbe35fd75fa61c,Ryan Carniato,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 3693671..05cdb79 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -1,8 +1,6 @@
-/**
- * Created Dec 13, 2007
- */
 package com.crawljax.util;
 
+import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Arrays;
 import java.util.List;
@@ -19,23 +17,24 @@
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
 
+import com.google.common.base.Strings;
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableList.Builder;
+
 /**
  * Utility class that contains methods used by Crawljax and some plugin to deal with XPath
  * resolving, constructing etc.
- * 
- * @author mesbah
- * @version $Id$
  */
 public final class XPathHelper {
-	/**
-     * 
-     */
+
+	private static final Pattern TAG_PATTERN = Pattern
+	        .compile(""(?<=[/|::])[a-zA-z]+(?=([/|\\[]|$))"");
+
+	private static final Pattern ID_PATTERN = Pattern.compile(""(@[a-zA-Z]+)"");
+
 	private static final String FULL_XPATH_CACHE = ""FULL_XPATH_CACHE"";
 	private static final int MAX_SEARCH_LOOPS = 10000;
 
-	private XPathHelper() {
-	}
-
 	/**
 	 * Reverse Engineers an XPath Expression of a given Node in the DOM.
 	 * 
@@ -110,19 +109,13 @@
 	/**
 	 * Returns the list of nodes which match the expression xpathExpr in the String domStr.
 	 * 
-	 * @param domStr
-	 *            the string of the document to search in
-	 * @param xpathExpr
-	 *            the xpath query
-	 * @author cor-paul
 	 * @return the list of nodes which match the query
-	 * @throws Exception
-	 *             On erorr.
+	 * @throws XPathExpressionException
+	 * @throws IOException
 	 */
 	public static NodeList evaluateXpathExpression(String domStr, String xpathExpr)
-	        throws Exception {
-		Document dom = Helper.getDocument(domStr);
-
+	        throws XPathExpressionException, IOException {
+		Document dom = DomUtils.asDocument(domStr);
 		return evaluateXpathExpression(dom, xpathExpr);
 	}
 
@@ -145,7 +138,6 @@
 		XPathExpression expr = xpath.compile(xpathExpr);
 		Object result = expr.evaluate(dom, XPathConstants.NODESET);
 		NodeList nodes = (NodeList) result;
-
 		return nodes;
 	}
 
@@ -158,22 +150,19 @@
 	 * @param xpathExpression
 	 *            The expression to find the element.
 	 * @return list of XPaths retrieved by xpathExpression.
+	 * @throws XPathExpressionException
 	 */
-	public static List<String> getXpathForXPathExpressions(Document dom, String xpathExpression) {
-		NodeList nodeList;
-		try {
-			nodeList = XPathHelper.evaluateXpathExpression(dom, xpathExpression);
-		} catch (XPathExpressionException e) {
-			return null;
-		}
-		List<String> result = new ArrayList<String>();
+	public static ImmutableList<String> getXpathForXPathExpressions(Document dom,
+	        String xpathExpression) throws XPathExpressionException {
+		NodeList nodeList = XPathHelper.evaluateXpathExpression(dom, xpathExpression);
+		Builder<String> result = ImmutableList.builder();
 		if (nodeList.getLength() > 0) {
 			for (int i = 0; i < nodeList.getLength(); i++) {
 				Node n = nodeList.item(i);
 				result.add(getXPathExpression(n));
 			}
 		}
-		return result;
+		return result.build();
 	}
 
 	/**
@@ -182,26 +171,33 @@
 	 * @return formatted xpath with tag names in uppercase and attributes in lowercase
 	 */
 	public static String formatXPath(String xpath) {
-		String formatted = xpath;
-		Pattern p = Pattern.compile(""(/(?:[-a-zA-Z]+::)?+)([a-zA-Z]+)"");
-		Matcher m = p.matcher(formatted);
-
-		for (int i = 0; m.find(i); i++) {
-			i = m.start();
-			formatted = m.replaceFirst(m.group(1) + m.group(2).toUpperCase());
-			m = p.matcher(formatted);
-		}
-		p = Pattern.compile(""(@[a-zA-Z]+)"");
-		m = p.matcher(formatted);
-
-		for (int i = 0; m.find(i); i++) {
-			i = m.start();
-			formatted = m.replaceFirst(m.group().toLowerCase());
-			m = p.matcher(formatted);
-		}
+		String formatted = capitalizeTagNames(xpath);
+		formatted = lowerCaseAttributes(formatted);
 		return formatted;
 	}
 
+	private static String lowerCaseAttributes(String formatted) {
+		Matcher m = ID_PATTERN.matcher(formatted);
+		StringBuffer sb = new StringBuffer();
+		while (m.find()) {
+			String text = m.group();
+			m.appendReplacement(sb, Matcher.quoteReplacement(text.toLowerCase()));
+		}
+		m.appendTail(sb);
+		return sb.toString();
+	}
+
+	private static String capitalizeTagNames(String xpath) {
+		Matcher m = TAG_PATTERN.matcher(xpath);
+		StringBuffer sb = new StringBuffer();
+		while (m.find()) {
+			String text = m.group();
+			m.appendReplacement(sb, Matcher.quoteReplacement(text.toUpperCase()));
+		}
+		m.appendTail(sb);
+		return sb.toString();
+	}
+
 	/**
 	 * @param xpath
 	 *            The xpath expression to find the last element of.
@@ -223,10 +219,10 @@
 	 * @return string without the before [
 	 */
 	private static String stripEndSquareBrackets(String string) {
-		if (string.indexOf(""["") == -1) {
-			return string;
+		if (string.contains(""["")) {
+			return string.substring(0, string.indexOf('['));
 		} else {
-			return string.substring(0, string.indexOf(""[""));
+			return string;
 		}
 	}
 
@@ -247,21 +243,19 @@
 		int pos = 0;
 		int temp;
 		int number;
-		// System.out.println(xpath);
 		for (String element : elements) {
-			if (!element.equals("""") && !element.startsWith(""@"") && element.indexOf(""()"") == -1) {
+			if (!element.isEmpty() && !element.startsWith(""@"") && !element.contains(""()"")) {
 				if (element.indexOf(""["") != -1) {
 					try {
 						number =
 						        Integer.parseInt(element.substring(element.indexOf(""["") + 1,
 						                element.indexOf(""]"")));
-					} catch (Exception e) {
+					} catch (NumberFormatException e) {
 						return -1;
 					}
 				} else {
 					number = 1;
 				}
-				// System.out.println(""number: "" + number);
 				for (int i = 0; i < number; i++) {
 					// find new open element
 					temp = dom.indexOf(""<"" + stripEndSquareBrackets(element), pos);
@@ -274,8 +268,6 @@
 							pos =
 							        getCloseElementLocation(dom, pos,
 							                stripEndSquareBrackets(element));
-							// pos = dom.indexOf(""<"" +
-							// stripEndSquareBrackets(element), pos) + 1;
 						}
 
 					}
@@ -311,25 +303,20 @@
 			if (dom.indexOf(openElement, pos) == -1 && dom.indexOf(closeElement, pos) == -1) {
 				return -1;
 			}
-			// System.out.println(""hierzo: "" + dom.substring(pos));
 			if (dom.indexOf(openElement, pos) < dom.indexOf(closeElement, pos)
 			        && dom.indexOf(openElement, pos) != -1) {
 				openElements++;
 				pos = dom.indexOf(openElement, pos) + 1;
-				// System.out.println(""open: "" + dom.substring(pos-1));
 			} else {
 
 				openElements--;
 				pos = dom.indexOf(closeElement, pos) + 1;
-				// System.out.println(""close: "" + dom.substring(pos-1));
 			}
-			// System.out.println(openElements);
 			if (openElements == 0) {
 				break;
 			}
 			i++;
 		}
-		// System.out.println(""Finished: "" + dom.substring(pos-1));
 		return pos - 1;
 
 	}
@@ -353,14 +340,14 @@
 	 *         text()
 	 */
 	public static String stripXPathToElement(String xpath) {
-		if (xpath != null && !xpath.equals("""")) {
-			if (xpath.toLowerCase().indexOf(""/text()"") != -1) {
+		if (!Strings.isNullOrEmpty(xpath)) {
+			if (xpath.toLowerCase().contains(""/text()"")) {
 				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/text()""));
 			}
-			if (xpath.toLowerCase().indexOf(""/comment()"") != -1) {
+			if (xpath.toLowerCase().contains(""/comment()"")) {
 				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/comment()""));
 			}
-			if (xpath.indexOf(""@"") != -1) {
+			if (xpath.contains(""@"")) {
 				xpath = xpath.substring(0, xpath.indexOf(""@"") - 1);
 			}
 		}
@@ -368,4 +355,7 @@
 		return xpath;
 	}
 
+	private XPathHelper() {
+	}
+
 }
"
7bd6b64af09b9c5e4247544767cbe35fd75fa61c,Ryan Carniato,CandidateElementExtractorTest.java,MODIFY,setupCrawler -> [CrawljaxConfiguration config] | [CrawlSpecification spec],"diff --git a/core/src/test/java/com/crawljax/core/CandidateElementExtractorTest.java b/core/src/test/java/com/crawljax/core/CandidateElementExtractorTest.java
index 39c2396..44a5447 100644
--- a/core/src/test/java/com/crawljax/core/CandidateElementExtractorTest.java
+++ b/core/src/test/java/com/crawljax/core/CandidateElementExtractorTest.java
@@ -1,15 +1,14 @@
 package com.crawljax.core;
 
+import static org.hamcrest.collection.IsCollectionWithSize.hasSize;
 import static org.junit.Assert.assertEquals;
 import static org.junit.Assert.assertNotNull;
+import static org.junit.Assert.assertThat;
 
-import java.io.File;
-import java.util.ArrayList;
-import java.util.HashSet;
 import java.util.List;
-import java.util.Set;
 
 import org.apache.commons.configuration.ConfigurationException;
+import org.junit.After;
 import org.junit.ClassRule;
 import org.junit.Test;
 import org.junit.experimental.categories.Category;
@@ -32,36 +31,37 @@
 	private static final StateVertex DUMMY_STATE = new StateVertex(""DUMMY"", """");
 
 	@ClassRule
-	public static final RunWithWebServer SERVER = new RunWithWebServer(""/demo-site"");
+	public static final RunWithWebServer DEMO_SITE_SERVER = new RunWithWebServer(""/demo-site"");
 
 	private CrawljaxController controller;
 	private Crawler crawler;
 
+	@After
+	public void shutDown() {
+		controller.getBrowserPool().shutdown();
+	}
+
 	@Test
 	public void testExtract() throws InterruptedException, CrawljaxException,
 	        ConfigurationException {
-		setupCrawler(new CrawlSpecification(SERVER.getSiteUrl().toExternalForm()));
+		CrawlSpecification spec =
+		        new CrawlSpecification(DEMO_SITE_SERVER.getSiteUrl().toExternalForm());
+		spec.click(""a"");
+		setupCrawler(spec);
 
 		FormHandler formHandler =
 		        new FormHandler(crawler.getBrowser(), controller.getConfigurationReader()
 		                .getInputSpecification(), true);
+
 		CandidateElementExtractor extractor =
 		        new CandidateElementExtractor(controller.getElementChecker(),
-		                crawler.getBrowser(), formHandler, controller.getConfigurationReader()
-		                        .getCrawlSpecificationReader());
-		assertNotNull(extractor);
+		                crawler.getBrowser(), formHandler, controller.getConfigurationReader());
 
-		TagElement tagElementInc = new TagElement(null, ""a"");
-		List<TagElement> includes = new ArrayList<TagElement>();
-		includes.add(tagElementInc);
-
-		List<CandidateElement> candidates =
-		        extractor.extract(includes, new ArrayList<TagElement>(), true, DUMMY_STATE);
+		List<CandidateElement> candidates = extractor.extract(DUMMY_STATE);
 
 		assertNotNull(candidates);
 		assertEquals(15, candidates.size());
 
-		controller.getBrowserPool().shutdown();
 	}
 
 	private void setupCrawler(CrawlSpecification spec) throws ConfigurationException,
@@ -71,50 +71,19 @@
 		controller = new CrawljaxController(config);
 		crawler = new CEETCrawler(controller);
 
-		assertNotNull(crawler);
-
 		crawler.goToInitialURL();
+		spec.setClickOnce(true);
 
 		Thread.sleep(400);
 	}
 
 	@Test
 	public void testExtractExclude() throws Exception {
-		setupCrawler(new CrawlSpecification(SERVER.getSiteUrl().toExternalForm()));
+		CrawlSpecification spec =
+		        new CrawlSpecification(DEMO_SITE_SERVER.getSiteUrl().toExternalForm());
+		spec.click(""a"");
+		spec.dontClick(""div"").withAttribute(""id"", ""menubar"");
 
-		FormHandler formHandler =
-		        new FormHandler(crawler.getBrowser(), controller.getConfigurationReader()
-		                .getInputSpecification(), true);
-		CandidateElementExtractor extractor =
-		        new CandidateElementExtractor(controller.getElementChecker(),
-		                crawler.getBrowser(), formHandler, controller.getConfigurationReader()
-		                        .getCrawlSpecificationReader());
-		assertNotNull(extractor);
-
-		TagElement tagElementInc = new TagElement(null, ""a"");
-		List<TagElement> includes = new ArrayList<TagElement>();
-		includes.add(tagElementInc);
-
-		List<TagElement> excludes = new ArrayList<TagElement>();
-		TagAttribute attr = new TagAttribute(""id"", ""menubar"");
-		Set<TagAttribute> attributes = new HashSet<TagAttribute>();
-		attributes.add(attr);
-		TagElement tagElementExc = new TagElement(attributes, ""div"");
-		excludes.add(tagElementExc);
-
-		List<CandidateElement> candidates =
-		        extractor.extract(includes, excludes, true, DUMMY_STATE);
-
-		assertNotNull(candidates);
-		assertEquals(11, candidates.size());
-
-		controller.getBrowserPool().shutdown();
-	}
-
-	@Test
-	public void testExtractIframeContents() throws Exception {
-		File index = new File(""src/test/resources/site/iframe/index.html"");
-		CrawlSpecification spec = new CrawlSpecification(""file://"" + index.getAbsolutePath());
 		setupCrawler(spec);
 
 		FormHandler formHandler =
@@ -122,25 +91,41 @@
 		                .getInputSpecification(), true);
 		CandidateElementExtractor extractor =
 		        new CandidateElementExtractor(controller.getElementChecker(),
-		                crawler.getBrowser(), formHandler, controller.getConfigurationReader()
-		                        .getCrawlSpecificationReader());
-		assertNotNull(extractor);
+		                crawler.getBrowser(), formHandler, controller.getConfigurationReader());
 
-		TagElement tagElementInc = new TagElement(null, ""a"");
-		List<TagElement> includes = new ArrayList<TagElement>();
-		includes.add(tagElementInc);
+		List<CandidateElement> candidates = extractor.extract(DUMMY_STATE);
 
-		List<CandidateElement> candidates =
-		        extractor.extract(includes, new ArrayList<TagElement>(), true, DUMMY_STATE);
+		assertNotNull(candidates);
+		assertThat(candidates, hasSize(11));
+
+	}
+
+	@Test
+	public void testExtractIframeContents() throws Exception {
+		RunWithWebServer server = new RunWithWebServer(""/site"");
+		server.before();
+		CrawlSpecification spec = new CrawlSpecification(server.getSiteUrl() + ""iframe/"");
+		spec.click(""a"");
+		setupCrawler(spec);
+
+		FormHandler formHandler =
+		        new FormHandler(crawler.getBrowser(), controller.getConfigurationReader()
+		                .getInputSpecification(), true);
+		CandidateElementExtractor extractor =
+		        new CandidateElementExtractor(controller.getElementChecker(),
+		                crawler.getBrowser(), formHandler, controller.getConfigurationReader());
+
+		List<CandidateElement> candidates = extractor.extract(DUMMY_STATE);
 
 		for (CandidateElement e : candidates) {
 			LOG.debug(""candidate: "" + e.getUniqueString());
 		}
 
-		assertNotNull(candidates);
-		assertEquals(9, candidates.size());
+		server.after();
 
-		controller.getBrowserPool().shutdown();
+		assertNotNull(extractor);
+		assertNotNull(candidates);
+		assertThat(candidates, hasSize(9));
 
 	}
 
"
1d32c94ea0baf9e801c0db1324311c76ce9566c3,Ali Mesbah,EmbeddedBrowser.java,MODIFY,updateConfiguration -> [CrawljaxConfigurationReader configuration] | [CrawljaxConfiguration configuration],"diff --git a/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
index 40a4a43..41c944b 100644
--- a/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
@@ -7,7 +7,7 @@
 import org.openqa.selenium.WebElement;
 
 import com.crawljax.core.CrawljaxException;
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.Identification;
 import com.crawljax.forms.FormInput;
@@ -145,5 +145,5 @@
 	 * @param configuration
 	 *            the new configuration values that needs to be updated.
 	 */
-	void updateConfiguration(CrawljaxConfigurationReader configuration);
+	void updateConfiguration(CrawljaxConfiguration configuration);
 }
"
1d32c94ea0baf9e801c0db1324311c76ce9566c3,Ali Mesbah,EmbeddedBrowserBuilder.java,MODIFY,buildEmbeddedBrowser -> [CrawljaxConfigurationReader configuration] | [CrawljaxConfiguration configuration],"diff --git a/core/src/main/java/com/crawljax/browser/EmbeddedBrowserBuilder.java b/core/src/main/java/com/crawljax/browser/EmbeddedBrowserBuilder.java
index 57b831f..ef1fd98 100644
--- a/core/src/main/java/com/crawljax/browser/EmbeddedBrowserBuilder.java
+++ b/core/src/main/java/com/crawljax/browser/EmbeddedBrowserBuilder.java
@@ -1,6 +1,6 @@
 package com.crawljax.browser;
 
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
 
 /**
  * This is the main interface for building a concrete EmbeddedBrowser implementation. By default
@@ -38,5 +38,5 @@
 	 *            The configuration reader object to read the specific configuration options form.
 	 * @return the new created instance of a EmbeddedBrowser to be used.
 	 */
-	EmbeddedBrowser buildEmbeddedBrowser(CrawljaxConfigurationReader configuration);
+	EmbeddedBrowser buildEmbeddedBrowser(CrawljaxConfiguration configuration);
 }
"
1d32c94ea0baf9e801c0db1324311c76ce9566c3,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 3f21f86..0cc6efe 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -38,7 +38,7 @@
 
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.AcceptAllFramesChecker;
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.crawljax.core.configuration.IgnoreFrameChecker;
 import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.core.state.Eventable;
@@ -48,6 +48,7 @@
 import com.crawljax.forms.InputValue;
 import com.crawljax.forms.RandomInputValueGenerator;
 import com.crawljax.util.DomUtils;
+import com.google.common.collect.ImmutableSortedSet;
 
 /**
  * @author mesbah
@@ -61,7 +62,7 @@
 	        .getLogger(WebDriverBackedEmbeddedBrowser.class);
 	private final WebDriver browser;
 
-	private List<String> filterAttributes;
+	private ImmutableSortedSet<String> filterAttributes;
 	private long crawlWaitReload;
 	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
 
@@ -88,8 +89,8 @@
 	 * @param crawlWaitEvent
 	 *            the period to wait after an event is fired.
 	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent) {
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload, long crawlWaitEvent) {
 		this(driver);
 		this.filterAttributes = filterAttributes;
 		this.crawlWaitEvent = crawlWaitEvent;
@@ -110,8 +111,9 @@
 	 * @param ignoreFrameChecker
 	 *            the checker used to determine if a certain frame must be ignored.
 	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload,
+	        long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
 		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
 		this.ignoreFrameChecker = ignoreFrameChecker;
 	}
@@ -130,7 +132,7 @@
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
 		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
 		        filterAttributes, crawlWaitEvent, crawlWaitReload);
 	}
@@ -151,8 +153,8 @@
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-	        IgnoreFrameChecker ignoreFrameChecker) {
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent,
+	        long crawlWaitReload, IgnoreFrameChecker ignoreFrameChecker) {
 		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
 		        filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
 	}
@@ -171,7 +173,7 @@
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
 		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
 		        crawlWaitReload);
 	}
@@ -192,8 +194,8 @@
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-	        IgnoreFrameChecker ignoreFrameChecker) {
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent,
+	        long crawlWaitReload, IgnoreFrameChecker ignoreFrameChecker) {
 		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
 		        crawlWaitReload, ignoreFrameChecker);
 	}
@@ -781,7 +783,7 @@
 	/**
 	 * @return the list of attributes to be filtered from DOM.
 	 */
-	protected List<String> getFilterAttributes() {
+	protected ImmutableSortedSet<String> getFilterAttributes() {
 		return filterAttributes;
 	}
 
@@ -844,13 +846,12 @@
 	}
 
 	@Override
-	public void updateConfiguration(CrawljaxConfigurationReader configuration) {
+	public void updateConfiguration(CrawljaxConfiguration configuration) {
 		// Retrieve the config values used
-		this.filterAttributes = configuration.getFilterAttributeNames();
-		this.crawlWaitReload =
-		        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
-		this.crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
-		this.ignoreFrameChecker = configuration.getCrawlSpecificationReader();
+		this.filterAttributes =
+		        configuration.getCrawlRules().getPreCrawlConfig().getFilterAttributeNames();
+		this.crawlWaitReload = configuration.getCrawlRules().getWaitAfterReloadUrl();
+		this.crawlWaitEvent = configuration.getCrawlRules().getWaitAfterEvent();
 	}
 
 	private boolean exceptionIsConnectionException(WebDriverException exception) {
"
1d32c94ea0baf9e801c0db1324311c76ce9566c3,Ali Mesbah,WebDriverBrowserBuilder.java,MODIFY,buildEmbeddedBrowser -> [CrawljaxConfigurationReader configuration] | [CrawljaxConfiguration configuration],"diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java b/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java
index 2edbd5c..622f432 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java
@@ -1,7 +1,5 @@
 package com.crawljax.browser;
 
-import java.util.List;
-
 import org.openqa.selenium.android.AndroidDriver;
 import org.openqa.selenium.chrome.ChromeDriver;
 import org.openqa.selenium.chrome.ChromeOptions;
@@ -13,8 +11,9 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.gargoylesoftware.htmlunit.BrowserVersion;
+import com.google.common.collect.ImmutableSortedSet;
 
 /**
  * Default implementation of the EmbeddedBrowserBuilder based on Selenium WebDriver API.
@@ -32,15 +31,15 @@
 	 * @return the new build WebDriver based embeddedBrowser
 	 */
 	@Override
-	public EmbeddedBrowser buildEmbeddedBrowser(CrawljaxConfigurationReader configuration) {
+	public EmbeddedBrowser buildEmbeddedBrowser(CrawljaxConfiguration configuration) {
 		// Retrieve the config values used
-		List<String> filterAttributes = configuration.getFilterAttributeNames();
-		long crawlWaitReload =
-		        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
-		long crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
+		ImmutableSortedSet<String> filterAttributes =
+		        configuration.getCrawlRules().getPreCrawlConfig().getFilterAttributeNames();
+		long crawlWaitReload = configuration.getCrawlRules().getWaitAfterReloadUrl();
+		long crawlWaitEvent = configuration.getCrawlRules().getWaitAfterEvent();
 
 		// Determine the requested browser type
-		switch (configuration.getBrowser()) {
+		switch (configuration.getBrowserConfig().getBrowsertype()) {
 			case firefox:
 				if (configuration.getProxyConfiguration() != null) {
 					FirefoxProfile profile = new FirefoxProfile();
@@ -59,15 +58,11 @@
 				}
 
 				return WebDriverBackedEmbeddedBrowser.withDriver(new FirefoxDriver(),
-				        configuration.getFilterAttributeNames(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterEvent(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterReloadUrl());
+				        filterAttributes, crawlWaitEvent, crawlWaitReload);
 
 			case ie:
 				return WebDriverBackedEmbeddedBrowser.withDriver(new InternetExplorerDriver(),
-				        configuration.getFilterAttributeNames(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterEvent(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterReloadUrl());
+				        filterAttributes, crawlWaitEvent, crawlWaitReload);
 
 			case chrome:
 				ChromeDriver driverChrome;
@@ -81,16 +76,13 @@
 					driverChrome = new ChromeDriver();
 				}
 
-				return WebDriverBackedEmbeddedBrowser.withDriver(driverChrome, configuration
-				        .getFilterAttributeNames(), configuration.getCrawlSpecificationReader()
-				        .getWaitAfterEvent(), configuration.getCrawlSpecificationReader()
-				        .getWaitAfterReloadUrl());
+				return WebDriverBackedEmbeddedBrowser.withDriver(driverChrome, filterAttributes,
+				        crawlWaitEvent, crawlWaitReload);
 
 			case remote:
-				return WebDriverBackedEmbeddedBrowser.withRemoteDriver(
-				        configuration.getRemoteHubUrl(), configuration.getFilterAttributeNames(),
-				        configuration.getCrawlSpecificationReader().getWaitAfterEvent(),
-				        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl());
+				return WebDriverBackedEmbeddedBrowser.withRemoteDriver(configuration
+				        .getBrowserConfig().getRemoteHubUrl(), filterAttributes, crawlWaitEvent,
+				        crawlWaitReload);
 
 			case htmlunit:
 				HtmlUnitDriver driverHtmlUnit = new HtmlUnitDriver(BrowserVersion.FIREFOX_10);
@@ -100,32 +92,24 @@
 					        configuration.getProxyConfiguration().getPort());
 				}
 
-				return WebDriverBackedEmbeddedBrowser.withDriver(driverHtmlUnit, configuration
-				        .getFilterAttributeNames(), configuration.getCrawlSpecificationReader()
-				        .getWaitAfterEvent(), configuration.getCrawlSpecificationReader()
-				        .getWaitAfterReloadUrl());
+				return WebDriverBackedEmbeddedBrowser.withDriver(driverHtmlUnit,
+				        filterAttributes, crawlWaitEvent, crawlWaitReload);
 
 			case android:
 				return WebDriverBackedEmbeddedBrowser.withDriver(new AndroidDriver(),
-				        configuration.getFilterAttributeNames(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterEvent(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterReloadUrl());
+				        filterAttributes, crawlWaitEvent, crawlWaitReload);
 
 			case iphone:
 				try {
 					return WebDriverBackedEmbeddedBrowser.withDriver(new IPhoneDriver(),
-					        configuration.getFilterAttributeNames(), configuration
-					                .getCrawlSpecificationReader().getWaitAfterEvent(),
-					        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl());
+					        filterAttributes, crawlWaitEvent, crawlWaitReload);
 				} catch (Exception e) {
 					LOGGER.error(""Could not load driver: "" + e.getMessage(), e);
 				}
 
 			default:
 				return WebDriverBackedEmbeddedBrowser.withDriver(new FirefoxDriver(),
-				        configuration.getFilterAttributeNames(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterEvent(), configuration
-				                .getCrawlSpecificationReader().getWaitAfterReloadUrl());
+				        filterAttributes, crawlWaitEvent, crawlWaitReload);
 		}
 	}
 }
"
1d32c94ea0baf9e801c0db1324311c76ce9566c3,Ali Mesbah,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index aca2a42..1ce4556 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -15,9 +15,7 @@
 import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.eventablecondition.EventableConditionChecker;
 import com.crawljax.condition.invariant.Invariant;
-import com.crawljax.core.configuration.CrawlSpecificationReader;
 import com.crawljax.core.configuration.CrawljaxConfiguration;
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
 import com.crawljax.core.plugin.CrawljaxPluginsUtil;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateFlowGraph;
@@ -26,8 +24,6 @@
 
 /**
  * The Crawljax Controller class is the core of Crawljax.
- * 
- * @author mesbah
  */
 public class CrawljaxController implements CrawlQueueManager {
 
@@ -47,7 +43,7 @@
 	// TODO Stefan, Can not be final because, must be created after the loading of the plugins
 	private Crawler initialCrawler;
 
-	private final CrawljaxConfigurationReader configurationReader;
+	private final CrawljaxConfiguration configuration;
 
 	private final ImmutableList<Invariant> invariantList;
 
@@ -67,22 +63,23 @@
 	 *             if the configuration fails.
 	 */
 	public CrawljaxController(final CrawljaxConfiguration config) throws CrawljaxException {
-		configurationReader = new CrawljaxConfigurationReader(config);
-		CrawlSpecificationReader crawlerReader =
-		        configurationReader.getCrawlSpecificationReader();
+		configuration = config;
 
-		stateComparator = new StateComparator(crawlerReader.getOracleComparators());
-		invariantList = crawlerReader.getInvariants();
+		stateComparator = new StateComparator(config.getCrawlRules().getOracleComparators());
+		invariantList = config.getCrawlRules().getInvariants();
 
-		waitConditionChecker.setWaitConditions(crawlerReader.getWaitConditions());
+		waitConditionChecker.setWaitConditions(config.getCrawlRules().getPreCrawlConfig()
+		        .getWaitConditions());
 		eventableConditionChecker =
-		        new EventableConditionChecker(configurationReader.getEventableConditions());
+		        new EventableConditionChecker(config.getCrawlRules());
 
-		crawlConditionChecker = new ConditionTypeChecker<>(crawlerReader.getCrawlConditions());
+		crawlConditionChecker =
+		        new ConditionTypeChecker<>(config.getCrawlRules().getPreCrawlConfig()
+		                .getCrawlConditions());
 		elementChecker =
 		        new CandidateElementManager(eventableConditionChecker, crawlConditionChecker);
 
-		browserPool = new BrowserPool(configurationReader);
+		browserPool = new BrowserPool(config);
 
 		workQueue = init();
 	}
@@ -96,24 +93,19 @@
 		LOGGER.info(""Starting Crawljax..."");
 
 		LOGGER.info(""Used plugins:"");
-		CrawljaxPluginsUtil.loadPlugins(configurationReader.getPlugins());
+		CrawljaxPluginsUtil.loadPlugins(configuration.getPlugins());
 
-		if (configurationReader.getProxyConfiguration() != null) {
-			CrawljaxPluginsUtil
-			        .runProxyServerPlugins(configurationReader.getProxyConfiguration());
+		if (configuration.getProxyConfiguration() != null) {
+			CrawljaxPluginsUtil.runProxyServerPlugins(configuration.getProxyConfiguration());
 		}
 
-		LOGGER.info(""Embedded browser implementation: {}"", configurationReader.getBrowser());
+		LOGGER.info(""Embedded browser implementation: {}"", configuration.getBrowserConfig()
+		        .getBrowsertype());
 
-		LOGGER.info(""Number of threads: {}"", configurationReader.getThreadConfigurationReader()
-		        .getNumberThreads());
-
-		LOGGER.info(""Crawl depth: {}"", configurationReader.getCrawlSpecificationReader()
-		        .getDepth());
+		LOGGER.info(""Crawl depth: {}"", configuration.getMaximumDepth());
 		LOGGER.info(""Crawljax initialized!"");
 
-		return new CrawlerExecutor(configurationReader.getThreadConfigurationReader()
-		        .getNumberThreads());
+		return new CrawlerExecutor(configuration.getBrowserConfig());
 	}
 
 	/**
@@ -129,8 +121,8 @@
 
 		startCrawl = System.currentTimeMillis();
 
-		LOGGER.info(""Start crawling with {} crawl elements"", configurationReader
-		        .getAllIncludedCrawlElements().size());
+		LOGGER.info(""Start crawling with {} crawl elements"", configuration.getCrawlRules()
+		        .getPreCrawlConfig().getIncludedElements());
 
 		// Create the initailCrawler
 		initialCrawler = new InitialCrawler(this);
@@ -330,8 +322,8 @@
 	/**
 	 * @return the configurationReader
 	 */
-	public CrawljaxConfigurationReader getConfigurationReader() {
-		return configurationReader;
+	public CrawljaxConfiguration getConfiguration() {
+		return configuration;
 	}
 
 	/**
"
1d32c94ea0baf9e801c0db1324311c76ce9566c3,Ali Mesbah,StateVertex.java,MODIFY,"searchForCandidateElements -> [CandidateElementExtractor candidateExtractor, List crawlTagElements, List crawlExcludeTagElements, boolean clickOnce] | [CandidateElementExtractor candidateExtractor]","diff --git a/core/src/main/java/com/crawljax/core/state/StateVertex.java b/core/src/main/java/com/crawljax/core/state/StateVertex.java
index af29b70..325e93e 100644
--- a/core/src/main/java/com/crawljax/core/state/StateVertex.java
+++ b/core/src/main/java/com/crawljax/core/state/StateVertex.java
@@ -22,17 +22,15 @@
 import com.crawljax.core.CrawlQueueManager;
 import com.crawljax.core.Crawler;
 import com.crawljax.core.CrawljaxException;
-import com.crawljax.core.TagElement;
 import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.util.DomUtils;
 import com.google.common.base.Strings;
 
 /**
- * The state vertex class which represents a state in the browser. This class
- * implements the Iterable interface because on a StateVertex it is possible to
- * iterate over the possible CandidateElements found in this state. When
- * iterating over the possible candidate elements every time a candidate is
- * returned its removed from the list so it is a one time only access to the
+ * The state vertex class which represents a state in the browser. This class implements the
+ * Iterable interface because on a StateVertex it is possible to iterate over the possible
+ * CandidateElements found in this state. When iterating over the possible candidate elements every
+ * time a candidate is returned its removed from the list so it is a one time only access to the
  * candidates.
  */
 public class StateVertex implements Serializable {
@@ -48,16 +46,16 @@
 	private boolean guidedCrawling = false;
 
 	/**
-	 * This list is used to store the possible candidates. If it is null its not
-	 * initialised if it's a empty list its empty.
+	 * This list is used to store the possible candidates. If it is null its not initialised if it's
+	 * a empty list its empty.
 	 */
 	private LinkedBlockingDeque<CandidateCrawlAction> candidateActions =
-			new LinkedBlockingDeque<>();;
+	        new LinkedBlockingDeque<>();;
 
 	private final ConcurrentHashMap<Crawler, CandidateCrawlAction> registerdCandidateActions =
-			new ConcurrentHashMap<>();
+	        new ConcurrentHashMap<>();
 	private final ConcurrentHashMap<Crawler, CandidateCrawlAction> workInProgressCandidateActions =
-			new ConcurrentHashMap<>();
+	        new ConcurrentHashMap<>();
 
 	private final LinkedBlockingDeque<Crawler> registeredCrawlers = new LinkedBlockingDeque<>();
 
@@ -70,11 +68,12 @@
 	}
 
 	/**
-	 * Creates a current state without an url and the stripped dom equals the
-	 * dom.
+	 * Creates a current state without an url and the stripped dom equals the dom.
 	 * 
-	 * @param name the name of the state
-	 * @param dom the current DOM tree of the browser
+	 * @param name
+	 *            the name of the state
+	 * @param dom
+	 *            the current DOM tree of the browser
 	 */
 	public StateVertex(String name, String dom) {
 		this(null, name, dom, dom);
@@ -83,10 +82,14 @@
 	/**
 	 * Defines a State.
 	 * 
-	 * @param url the current url of the state
-	 * @param name the name of the state
-	 * @param dom the current DOM tree of the browser
-	 * @param strippedDom the stripped dom by the OracleComparators
+	 * @param url
+	 *            the current url of the state
+	 * @param name
+	 *            the name of the state
+	 * @param dom
+	 *            the current DOM tree of the browser
+	 * @param strippedDom
+	 *            the stripped dom by the OracleComparators
 	 */
 	public StateVertex(String url, String name, String dom, String strippedDom) {
 		this.url = url;
@@ -147,7 +150,8 @@
 	/**
 	 * Compare this vertex to a other StateVertex.
 	 * 
-	 * @param obj the Object to compare this vertex
+	 * @param obj
+	 *            the Object to compare this vertex
 	 * @return Return true if equal. Uses reflection.
 	 * @see java.lang.Object#equals(java.lang.Object)
 	 */
@@ -163,7 +167,7 @@
 		final StateVertex rhs = (StateVertex) obj;
 
 		return new EqualsBuilder().append(this.strippedDom, rhs.getStrippedDom())
-				.append(this.guidedCrawling, rhs.guidedCrawling).isEquals();
+		        .append(this.guidedCrawling, rhs.guidedCrawling).isEquals();
 	}
 
 	/**
@@ -193,21 +197,24 @@
 	}
 
 	/**
-	 * @param id the id to set
+	 * @param id
+	 *            the id to set
 	 */
 	public void setId(long id) {
 		this.id = id;
 	}
 
 	/**
-	 * @param name the name to set
+	 * @param name
+	 *            the name to set
 	 */
 	public void setName(String name) {
 		this.name = name;
 	}
 
 	/**
-	 * @param dom the dom to set
+	 * @param dom
+	 *            the dom to set
 	 */
 	public void setDom(String dom) {
 		this.dom = dom;
@@ -221,27 +228,29 @@
 	}
 
 	/**
-	 * @param guidedCrawling true if set through guided crawling.
+	 * @param guidedCrawling
+	 *            true if set through guided crawling.
 	 */
 	public void setGuidedCrawling(boolean guidedCrawling) {
 		this.guidedCrawling = guidedCrawling;
 	}
 
 	/**
-	 * search for new Candidates from this state. The search for candidates is
-	 * only done when no list is available yet (candidateActions == null).
+	 * search for new Candidates from this state. The search for candidates is only done when no
+	 * list is available yet (candidateActions == null).
 	 * 
-	 * @param candidateExtractor the CandidateElementExtractor to use.
-	 * @param crawlTagElements the tag elements to examine.
-	 * @param crawlExcludeTagElements the elements to exclude.
-	 * @param clickOnce if true examine each element once.
+	 * @param candidateExtractor
+	 *            the CandidateElementExtractor to use.
+	 * @param crawlTagElements
+	 *            the tag elements to examine.
+	 * @param crawlExcludeTagElements
+	 *            the elements to exclude.
+	 * @param clickOnce
+	 *            if true examine each element once.
 	 * @return true if the searchForCandidateElemens has run false otherwise
 	 */
 	@GuardedBy(""candidateActionsSearchLock"")
-	public boolean searchForCandidateElements(CandidateElementExtractor candidateExtractor,
-			List<TagElement> crawlTagElements, List<TagElement> crawlExcludeTagElements,
-			boolean clickOnce) {
-
+	public boolean searchForCandidateElements(CandidateElementExtractor candidateExtractor) {
 		try {
 			List<CandidateElement> candidateList = candidateExtractor.extract(this);
 			for (CandidateElement candidateElement : candidateList) {
@@ -250,10 +259,10 @@
 			}
 		} catch (CrawljaxException e) {
 			LOGGER.error(
-					""Catched exception while searching for candidates in state "" + getName(), e);
+			        ""Catched exception while searching for candidates in state "" + getName(), e);
 		}
 		return !candidateActions.isEmpty(); // Only notify of found candidates
-														// when there are...
+		                                    // when there are...
 
 	}
 
@@ -278,8 +287,8 @@
 	}
 
 	/**
-	 * Removes Candidate Actions on candidateElements that have been removed by
-	 * the pre-state crawl plugin.
+	 * Removes Candidate Actions on candidateElements that have been removed by the pre-state crawl
+	 * plugin.
 	 * 
 	 * @param candidateElements
 	 */
@@ -294,7 +303,7 @@
 			if (!candidateElements.contains(currentAction.getCandidateElement())) {
 				iter.remove();
 				LOGGER.info(""filtered candidate action: "" + currentAction.getEventType().name()
-						+ "" on "" + currentAction.getCandidateElement().getGeneralString());
+				        + "" on "" + currentAction.getCandidateElement().getGeneralString());
 
 			}
 		}
@@ -302,28 +311,29 @@
 
 	/**
 	 * @return a Document instance of the dom string.
-	 * @throws IOException if an exception is thrown.
+	 * @throws IOException
+	 *             if an exception is thrown.
 	 */
 	public Document getDocument() throws IOException {
 		return DomUtils.asDocument(this.dom);
 	}
 
 	/**
-	 * This is the main work divider function, calling this function will first
-	 * look at the registeedCandidateActions to see if the current Crawler has
-	 * already registered itself at one of the jobs. Second it tries to see if
-	 * the current crawler is not already processing one of the actions and
-	 * return that action and last it tries to find an unregistered candidate. If
-	 * all else fails it tries to return a action that is registered by an other
-	 * crawler and disables that crawler.
+	 * This is the main work divider function, calling this function will first look at the
+	 * registeedCandidateActions to see if the current Crawler has already registered itself at one
+	 * of the jobs. Second it tries to see if the current crawler is not already processing one of
+	 * the actions and return that action and last it tries to find an unregistered candidate. If
+	 * all else fails it tries to return a action that is registered by an other crawler and
+	 * disables that crawler.
 	 * 
-	 * @param requestingCrawler the Crawler placing the request for the Action
-	 * @param manager the manager that can be used to remove a crawler from the
-	 *           queue.
+	 * @param requestingCrawler
+	 *            the Crawler placing the request for the Action
+	 * @param manager
+	 *            the manager that can be used to remove a crawler from the queue.
 	 * @return the action that needs to be performed by the Crawler.
 	 */
 	public CandidateCrawlAction pollCandidateCrawlAction(Crawler requestingCrawler,
-			CrawlQueueManager manager) {
+	        CrawlQueueManager manager) {
 		CandidateCrawlAction action = registerdCandidateActions.remove(requestingCrawler);
 		if (action != null) {
 			workInProgressCandidateActions.put(requestingCrawler, action);
@@ -348,10 +358,10 @@
 					action = registerdCandidateActions.remove(c);
 					if (action != null) {
 						/*
-						 * We got a action and removed the registeredCandidateActions
-						 * for the crawler, remove the crawler from queue as the first
-						 * thing. As the crawler might just have started the run
-						 * method of the crawler must also be added with a check hook.
+						 * We got a action and removed the registeredCandidateActions for the
+						 * crawler, remove the crawler from queue as the first thing. As the crawler
+						 * might just have started the run method of the crawler must also be added
+						 * with a check hook.
 						 */
 						LOGGER.info(""Stolen work from other Crawler"");
 						return action;
@@ -370,7 +380,8 @@
 	/**
 	 * Register an assignment to the crawler.
 	 * 
-	 * @param newCrawler the crawler that wants an assignment
+	 * @param newCrawler
+	 *            the crawler that wants an assignment
 	 * @return true if the crawler has an assignment false otherwise.
 	 */
 	public boolean registerCrawler(Crawler newCrawler) {
@@ -386,7 +397,8 @@
 	/**
 	 * Register a Crawler that is going to work, tell if his must go on or abort.
 	 * 
-	 * @param crawler the crawler to register
+	 * @param crawler
+	 *            the crawler to register
 	 * @return true if the crawler is successfully registered
 	 */
 	public boolean startWorking(Crawler crawler) {
@@ -401,11 +413,13 @@
 	}
 
 	/**
-	 * Notify the current StateVertex that the given crawler has finished working
-	 * on the given action.
+	 * Notify the current StateVertex that the given crawler has finished working on the given
+	 * action.
 	 * 
-	 * @param crawler the crawler that is finished
-	 * @param action the action that have been examined
+	 * @param crawler
+	 *            the crawler that is finished
+	 * @param action
+	 *            the action that have been examined
 	 */
 	public void finishedWorking(Crawler crawler, CandidateCrawlAction action) {
 		candidateActions.remove(action);
@@ -413,4 +427,5 @@
 		workInProgressCandidateActions.remove(crawler);
 		registeredCrawlers.remove(crawler);
 	}
+
 }
"
1d32c94ea0baf9e801c0db1324311c76ce9566c3,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index 6854b96..287b05d 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -58,7 +58,7 @@
 	}
 
 	private static final String[] ALLOWED_INPUT_TYPES =
-	        { ""text"", ""radio"", ""checkbox"", ""password"" };
+	{ ""text"", ""radio"", ""checkbox"", ""password"" };
 
 	/**
 	 * Fills in the element with the InputValues for input TODO: improve this by using WebDriver
"
1d32c94ea0baf9e801c0db1324311c76ce9566c3,Ali Mesbah,OutputBuilder.java,MODIFY,write -> [CrawlSpecificationReader crawlSpecificationReader] | [OutPutModel outModel],"diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
index 2cba28f..94e91e5 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
@@ -12,7 +12,6 @@
 import java.io.IOException;
 import java.net.URISyntaxException;
 import java.net.URL;
-import java.util.Arrays;
 import java.util.zip.ZipEntry;
 import java.util.zip.ZipInputStream;
 
@@ -28,15 +27,19 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.crawljax.core.configuration.CrawlSpecificationReader;
-import com.crawljax.plugins.crawloverview.model.CrawlConfiguration;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
+import com.crawljax.core.plugin.Plugin;
 import com.crawljax.plugins.crawloverview.model.OutPutModel;
 import com.crawljax.plugins.crawloverview.model.Statistics;
 import com.fasterxml.jackson.annotation.JsonAutoDetect.Visibility;
 import com.fasterxml.jackson.annotation.PropertyAccessor;
+import com.fasterxml.jackson.core.JsonGenerator;
 import com.fasterxml.jackson.core.JsonProcessingException;
+import com.fasterxml.jackson.databind.JsonSerializer;
 import com.fasterxml.jackson.databind.ObjectMapper;
-import com.fasterxml.jackson.databind.ObjectWriter;
+import com.fasterxml.jackson.databind.SerializationFeature;
+import com.fasterxml.jackson.databind.SerializerProvider;
+import com.fasterxml.jackson.databind.module.SimpleModule;
 import com.google.common.base.Charsets;
 import com.google.common.base.Strings;
 import com.google.common.io.ByteStreams;
@@ -159,7 +162,7 @@
 		try {
 			writeIndexFile(outModel);
 			writeStatistics(outModel.getStatistics());
-			writeConfig(outModel.getConfiguration(), outModel.getCrawlSpecification());
+			writeConfig(outModel.getConfiguration());
 		} catch (Exception e) {
 			LOG.error(e.getMessage(), e);
 		}
@@ -167,11 +170,10 @@
 		LOG.info(""Overview report generated"");
 	}
 
-	private void writeConfig(CrawlConfiguration configuration, CrawlSpecificationReader crawlSpec) {
+	private void writeConfig(CrawljaxConfiguration configuration) {
 		File file = new File(outputDir, ""config.html"");
 		VelocityContext context = new VelocityContext();
 		context.put(""config"", BeanToReadableMap.toMap(configuration));
-		context.put(""spec"", BeanToReadableMap.toMap(crawlSpec));
 		writeFile(context, file, ""config.html"");
 	}
 
@@ -206,17 +208,6 @@
 		writeFile(context, file, ""urls.html"");
 	}
 
-	public void write(CrawlSpecificationReader crawlSpecificationReader) {
-		ObjectMapper objectMapper = new ObjectMapper();
-		try {
-			ObjectWriter prettyPrinter = objectMapper.writer().withDefaultPrettyPrinter();
-			prettyPrinter
-			        .writeValue(new File(outputDir, ""config.json""), crawlSpecificationReader);
-		} catch (Exception e) {
-			throw new RuntimeException(""Cannot save config"", e);
-		}
-	}
-
 	private void writeFile(VelocityContext context, File outFile, String template) {
 		try {
 			Template templatee = ve.getTemplate(template);
@@ -260,13 +251,33 @@
 		}
 	}
 
-	private String toJson(Object o) {
+	static String toJson(Object o) {
 		ObjectMapper mapper = new ObjectMapper();
 		try {
 			mapper.setVisibility(PropertyAccessor.FIELD, Visibility.ANY);
+			mapper.setVisibility(PropertyAccessor.GETTER, Visibility.NONE);
+			mapper.disable(SerializationFeature.FAIL_ON_EMPTY_BEANS);
+			SimpleModule testModule = new SimpleModule(""Plugin serialiezr"");
+			testModule.addSerializer(new JsonSerializer<Plugin>() {
+
+				@Override
+				public void serialize(Plugin plugin, JsonGenerator jgen,
+				        SerializerProvider provider) throws IOException, JsonProcessingException {
+					jgen.writeString(plugin.getClass().getSimpleName());
+				}
+
+				@Override
+				public Class<Plugin> handledType() {
+					return Plugin.class;
+				}
+			});
+			mapper.registerModule(testModule);
 			return mapper.writerWithDefaultPrettyPrinter().writeValueAsString(o);
 		} catch (JsonProcessingException e) {
-			throw new RuntimeException(e);
+			LOG.error(
+			        ""Could not serialize the object. This will be ignored and the error will be written instead. Object was {}"",
+			        o, e);
+			return ""\"""" + e.getMessage() + ""\"""";
 		}
 	}
 
"
41aae7ca728e60f1e7db8bc62f0eba26dab2d70d,Alex Nederlof,StateFlowGraph.java,MODIFY,"addState -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index 806f3d3..99c24c0 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -94,7 +94,8 @@
 				LOG.debug(""Graph already contained vertex {}"", stateVertix);
 				return this.getStateInGraph(stateVertix);
 			} else {
-				LOG.debug(""Number of states is now {}"", stateCounter.incrementAndGet());
+				int count = stateCounter.incrementAndGet();
+				LOG.debug(""Number of states is now {}"", count);
 				if (correctName) {
 					correctStateName(stateVertix);
 				}
"
3ace7acef7c422d26cb75523c3526d60e60b00ac,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 3f21f86..0cc6efe 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -38,7 +38,7 @@
 
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.AcceptAllFramesChecker;
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.crawljax.core.configuration.IgnoreFrameChecker;
 import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.core.state.Eventable;
@@ -48,6 +48,7 @@
 import com.crawljax.forms.InputValue;
 import com.crawljax.forms.RandomInputValueGenerator;
 import com.crawljax.util.DomUtils;
+import com.google.common.collect.ImmutableSortedSet;
 
 /**
  * @author mesbah
@@ -61,7 +62,7 @@
 	        .getLogger(WebDriverBackedEmbeddedBrowser.class);
 	private final WebDriver browser;
 
-	private List<String> filterAttributes;
+	private ImmutableSortedSet<String> filterAttributes;
 	private long crawlWaitReload;
 	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
 
@@ -88,8 +89,8 @@
 	 * @param crawlWaitEvent
 	 *            the period to wait after an event is fired.
 	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent) {
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload, long crawlWaitEvent) {
 		this(driver);
 		this.filterAttributes = filterAttributes;
 		this.crawlWaitEvent = crawlWaitEvent;
@@ -110,8 +111,9 @@
 	 * @param ignoreFrameChecker
 	 *            the checker used to determine if a certain frame must be ignored.
 	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload,
+	        long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
 		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
 		this.ignoreFrameChecker = ignoreFrameChecker;
 	}
@@ -130,7 +132,7 @@
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
 		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
 		        filterAttributes, crawlWaitEvent, crawlWaitReload);
 	}
@@ -151,8 +153,8 @@
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-	        IgnoreFrameChecker ignoreFrameChecker) {
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent,
+	        long crawlWaitReload, IgnoreFrameChecker ignoreFrameChecker) {
 		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
 		        filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
 	}
@@ -171,7 +173,7 @@
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
 		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
 		        crawlWaitReload);
 	}
@@ -192,8 +194,8 @@
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-	        IgnoreFrameChecker ignoreFrameChecker) {
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent,
+	        long crawlWaitReload, IgnoreFrameChecker ignoreFrameChecker) {
 		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
 		        crawlWaitReload, ignoreFrameChecker);
 	}
@@ -781,7 +783,7 @@
 	/**
 	 * @return the list of attributes to be filtered from DOM.
 	 */
-	protected List<String> getFilterAttributes() {
+	protected ImmutableSortedSet<String> getFilterAttributes() {
 		return filterAttributes;
 	}
 
@@ -844,13 +846,12 @@
 	}
 
 	@Override
-	public void updateConfiguration(CrawljaxConfigurationReader configuration) {
+	public void updateConfiguration(CrawljaxConfiguration configuration) {
 		// Retrieve the config values used
-		this.filterAttributes = configuration.getFilterAttributeNames();
-		this.crawlWaitReload =
-		        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
-		this.crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
-		this.ignoreFrameChecker = configuration.getCrawlSpecificationReader();
+		this.filterAttributes =
+		        configuration.getCrawlRules().getPreCrawlConfig().getFilterAttributeNames();
+		this.crawlWaitReload = configuration.getCrawlRules().getWaitAfterReloadUrl();
+		this.crawlWaitEvent = configuration.getCrawlRules().getWaitAfterEvent();
 	}
 
 	private boolean exceptionIsConnectionException(WebDriverException exception) {
"
3ace7acef7c422d26cb75523c3526d60e60b00ac,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index aca2a42..1ce4556 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -15,9 +15,7 @@
 import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.eventablecondition.EventableConditionChecker;
 import com.crawljax.condition.invariant.Invariant;
-import com.crawljax.core.configuration.CrawlSpecificationReader;
 import com.crawljax.core.configuration.CrawljaxConfiguration;
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
 import com.crawljax.core.plugin.CrawljaxPluginsUtil;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateFlowGraph;
@@ -26,8 +24,6 @@
 
 /**
  * The Crawljax Controller class is the core of Crawljax.
- * 
- * @author mesbah
  */
 public class CrawljaxController implements CrawlQueueManager {
 
@@ -47,7 +43,7 @@
 	// TODO Stefan, Can not be final because, must be created after the loading of the plugins
 	private Crawler initialCrawler;
 
-	private final CrawljaxConfigurationReader configurationReader;
+	private final CrawljaxConfiguration configuration;
 
 	private final ImmutableList<Invariant> invariantList;
 
@@ -67,22 +63,23 @@
 	 *             if the configuration fails.
 	 */
 	public CrawljaxController(final CrawljaxConfiguration config) throws CrawljaxException {
-		configurationReader = new CrawljaxConfigurationReader(config);
-		CrawlSpecificationReader crawlerReader =
-		        configurationReader.getCrawlSpecificationReader();
+		configuration = config;
 
-		stateComparator = new StateComparator(crawlerReader.getOracleComparators());
-		invariantList = crawlerReader.getInvariants();
+		stateComparator = new StateComparator(config.getCrawlRules().getOracleComparators());
+		invariantList = config.getCrawlRules().getInvariants();
 
-		waitConditionChecker.setWaitConditions(crawlerReader.getWaitConditions());
+		waitConditionChecker.setWaitConditions(config.getCrawlRules().getPreCrawlConfig()
+		        .getWaitConditions());
 		eventableConditionChecker =
-		        new EventableConditionChecker(configurationReader.getEventableConditions());
+		        new EventableConditionChecker(config.getCrawlRules());
 
-		crawlConditionChecker = new ConditionTypeChecker<>(crawlerReader.getCrawlConditions());
+		crawlConditionChecker =
+		        new ConditionTypeChecker<>(config.getCrawlRules().getPreCrawlConfig()
+		                .getCrawlConditions());
 		elementChecker =
 		        new CandidateElementManager(eventableConditionChecker, crawlConditionChecker);
 
-		browserPool = new BrowserPool(configurationReader);
+		browserPool = new BrowserPool(config);
 
 		workQueue = init();
 	}
@@ -96,24 +93,19 @@
 		LOGGER.info(""Starting Crawljax..."");
 
 		LOGGER.info(""Used plugins:"");
-		CrawljaxPluginsUtil.loadPlugins(configurationReader.getPlugins());
+		CrawljaxPluginsUtil.loadPlugins(configuration.getPlugins());
 
-		if (configurationReader.getProxyConfiguration() != null) {
-			CrawljaxPluginsUtil
-			        .runProxyServerPlugins(configurationReader.getProxyConfiguration());
+		if (configuration.getProxyConfiguration() != null) {
+			CrawljaxPluginsUtil.runProxyServerPlugins(configuration.getProxyConfiguration());
 		}
 
-		LOGGER.info(""Embedded browser implementation: {}"", configurationReader.getBrowser());
+		LOGGER.info(""Embedded browser implementation: {}"", configuration.getBrowserConfig()
+		        .getBrowsertype());
 
-		LOGGER.info(""Number of threads: {}"", configurationReader.getThreadConfigurationReader()
-		        .getNumberThreads());
-
-		LOGGER.info(""Crawl depth: {}"", configurationReader.getCrawlSpecificationReader()
-		        .getDepth());
+		LOGGER.info(""Crawl depth: {}"", configuration.getMaximumDepth());
 		LOGGER.info(""Crawljax initialized!"");
 
-		return new CrawlerExecutor(configurationReader.getThreadConfigurationReader()
-		        .getNumberThreads());
+		return new CrawlerExecutor(configuration.getBrowserConfig());
 	}
 
 	/**
@@ -129,8 +121,8 @@
 
 		startCrawl = System.currentTimeMillis();
 
-		LOGGER.info(""Start crawling with {} crawl elements"", configurationReader
-		        .getAllIncludedCrawlElements().size());
+		LOGGER.info(""Start crawling with {} crawl elements"", configuration.getCrawlRules()
+		        .getPreCrawlConfig().getIncludedElements());
 
 		// Create the initailCrawler
 		initialCrawler = new InitialCrawler(this);
@@ -330,8 +322,8 @@
 	/**
 	 * @return the configurationReader
 	 */
-	public CrawljaxConfigurationReader getConfigurationReader() {
-		return configurationReader;
+	public CrawljaxConfiguration getConfiguration() {
+		return configuration;
 	}
 
 	/**
"
3ace7acef7c422d26cb75523c3526d60e60b00ac,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index c6c2008..d451ae0 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -1,287 +1,305 @@
 package com.crawljax.core.configuration;
 
-import java.util.ArrayList;
-import java.util.List;
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.util.concurrent.TimeUnit;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
-import com.crawljax.browser.EmbeddedBrowserBuilder;
-import com.crawljax.browser.WebDriverBrowserBuilder;
-import com.crawljax.condition.eventablecondition.EventableCondition;
+import com.crawljax.core.Crawler;
+import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
-import com.crawljax.util.DomUtils;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
-import com.google.common.collect.ImmutableList.Builder;
 
 /**
- * Specifies the settings Crawljax. The methods in this class fall into two categories:Oz
- * <p/>
- * <ul>
- * <li>General properties of Crawljax</li>
- * <li>Properties for the crawling
- * {@link CrawljaxConfiguration#setCrawlSpecification(CrawlSpecification)}</li>
- * </ul>
- * DEFAULT VAlUES: Browser: webdriver firefox Project Full Path: empty Project Relative Path: empty
- * Filter attributes: closure_hashcode_(\\w)*, jquery[0-9]+ Test invariants while crawling: true
- * EXAMPLE: CrawljaxConfiguration crawljaxConfig = new CrawljaxConfiguration(); CrawlSpecification
- * crawler = new CrawlSpecification(""http://www.google.com""); crawler.click(""a"");
- * crawljaxConfig.setCrawlSpecification(crawler);
+ * Configures the {@link Crawler}. Set it up using the {@link #builderFor(String)} function.
  */
 public final class CrawljaxConfiguration {
 
-	private BrowserType browser = BrowserType.firefox;
+	public static class CrawljaxConfigurationBuilder {
 
-	private EmbeddedBrowserBuilder browserBuilder = new WebDriverBrowserBuilder();
+		private final ImmutableList.Builder<Plugin> pluginBuilder = ImmutableList.builder();
+		private final CrawljaxConfiguration config;
+		private final CrawlRulesBuilder crawlRules = CrawlRules.builder();
 
-	private String remoteHubUrl = """";
-
-	private String outputFolder = """";
-	private String projectRelativePath = """";
-
-	private List<String> filterAttributeNames = new ArrayList<String>();
-
-	private List<Plugin> plugins = new ArrayList<Plugin>();
-
-	private CrawlSpecification crawlSpecification = new CrawlSpecification(""http://localhost"");
-	private ProxyConfiguration proxyConfiguration = null;
-	private ThreadConfiguration threadConfiguration = new ThreadConfiguration();
-
-	/**
-	 * Constructor.
-	 */
-	public CrawljaxConfiguration() {
-		addFilterAttribute(""closure_hashcode_(\\w)*"");
-		addFilterAttribute(""jquery[0-9]+"");
-	}
-
-	/**
-	 * @return The crawlSpecification which contains all the crawl settings.
-	 */
-	protected CrawlSpecification getCrawlSpecification() {
-		return crawlSpecification;
-	}
-
-	/**
-	 * @param crawlSpecification
-	 *            Which contains all the crawl settings.
-	 */
-	public void setCrawlSpecification(CrawlSpecification crawlSpecification) {
-		Preconditions.checkNotNull(crawlSpecification);
-		this.crawlSpecification = crawlSpecification;
-	}
-
-	/**
-	 * @return The inputSpecification which contains information the data for setting input fields.
-	 */
-	protected InputSpecification getInputSpecification() {
-		return crawlSpecification.getInputSpecification();
-	}
-
-	/**
-	 * Enable the crawljax proxy extension.
-	 * 
-	 * @param proxyConfiguration
-	 *            The ProxyConfiguration to set.
-	 */
-	public void setProxyConfiguration(ProxyConfiguration proxyConfiguration) {
-		this.proxyConfiguration = proxyConfiguration;
-	}
-
-	/**
-	 * @return The proxyConfiguration to use.
-	 */
-	protected ProxyConfiguration getProxyConfiguration() {
-		return proxyConfiguration;
-	}
-
-	/**
-	 * @param threadConfiguration
-	 *            the threadConfiguration to set
-	 */
-	public void setThreadConfiguration(ThreadConfiguration threadConfiguration) {
-		this.threadConfiguration = threadConfiguration;
-	}
-
-	/**
-	 * @return the threadConfiguration
-	 */
-	protected ThreadConfiguration getThreadConfiguration() {
-		return threadConfiguration;
-	}
-
-	/**
-	 * @return All the included crawlTags.
-	 */
-	protected ImmutableList<CrawlElement> getAllIncludedCrawlElements() {
-		// first add elements for forms so that form action crawlTags are only
-		// clicked and not by another random crawlTag
-		return ImmutableList.<CrawlElement> builder()
-		        .addAll(getInputSpecification().getCrawlElements())
-		        .addAll(crawlSpecification.crawlActions().getCrawlElements()).build();
-	}
-
-	/**
-	 * @return All the added crawlTags.
-	 */
-	protected List<CrawlElement> getAllCrawlElements() {
-		return ImmutableList.<CrawlElement> builder()
-		        .addAll(getInputSpecification().getCrawlElements())
-		        .addAll(crawlSpecification.crawlActions().getCrawlElements())
-		        .addAll(getCrawlSpecification().crawlActions().getCrawlElementsExcluded())
-		        .build();
-	}
-
-	/**
-	 * @return The eventableConditions.
-	 */
-	protected ImmutableList<EventableCondition> getEventableConditions() {
-		Builder<EventableCondition> eventableConditions = ImmutableList.builder();
-		for (CrawlElement crawlTag : getAllCrawlElements()) {
-			EventableCondition eventableCondition = crawlTag.getEventableCondition();
-			if (eventableCondition != null) {
-				eventableConditions.add(eventableCondition);
-			}
+		private CrawljaxConfigurationBuilder(URL url) {
+			config = new CrawljaxConfiguration();
+			config.url = url;
 		}
-		return eventableConditions.build();
+
+		/**
+		 * @param states
+		 *            The maximum number of states the Crawler should crawl. The default is
+		 *            unlimited.
+		 */
+		public CrawljaxConfigurationBuilder setMaximumStates(int states) {
+			Preconditions.checkArgument(states > 1, ""States should be positive"");
+			config.maximumStates = states;
+			return this;
+		}
+
+		/**
+		 * Crawl without a maximum state limit.
+		 */
+		public CrawljaxConfigurationBuilder setUnlimitedStates() {
+			config.maximumStates = 0;
+			return this;
+		}
+
+		/**
+		 * @param time
+		 *            The maximum time the crawler should run. Default is one hour.
+		 */
+		public CrawljaxConfigurationBuilder setMaximumRunTime(long time, TimeUnit unit) {
+			Preconditions.checkArgument(time > 0, ""Time should larger than 0"");
+			config.maximumRuntime = unit.toMillis(time);
+			return this;
+		}
+
+		/**
+		 * Set the maximum runtime to unlimited.
+		 */
+		public CrawljaxConfigurationBuilder setUnlimitedRuntime() {
+			config.maximumRuntime = 0;
+			return this;
+		}
+
+		/**
+		 * @param time
+		 *            The maximum depth the crawler can reach. The default is <code>2</code>.
+		 */
+		public CrawljaxConfigurationBuilder setMaximumDepth(int depth) {
+			Preconditions.checkArgument(depth > 1, ""Time should larger than 1"");
+			config.maximumDepth = depth;
+			return this;
+		}
+
+		/**
+		 * Set the crawl depth to unlimited.
+		 */
+		public CrawljaxConfigurationBuilder setUnlimitedCrawlDepth() {
+			config.maximumDepth = 0;
+			return this;
+		}
+
+		/**
+		 * Add plugins to Crawljax. Note that without plugins, Crawljax won't give any ouput. For
+		 * basic output at least enable the CrawlOverviewPlugin.
+		 * <p>
+		 * You can call this method several times to add multiple plugins
+		 * </p>
+		 * 
+		 * @param plugins
+		 *            the plugins you would like to enable.
+		 */
+		public CrawljaxConfigurationBuilder addPlugin(Plugin... plugins) {
+			pluginBuilder.add(plugins);
+			return this;
+		}
+
+		/**
+		 * @param configuration
+		 *            The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
+		 */
+		public CrawljaxConfigurationBuilder setProxyConfig(ProxyConfiguration configuration) {
+			config.proxyConfiguration = configuration;
+			return this;
+		}
+
+		/**
+		 * @return The {@link CrawlRulesBuilder} to define crawling rules. If no specified, Crawljax
+		 *         will do {@link CrawlRulesBuilder#}
+		 */
+		public CrawlRulesBuilder crawlRules() {
+			return crawlRules;
+		}
+
+		/**
+		 * @param configuration
+		 *            a custom {@link BrowserConfiguration}. The default is a single
+		 *            {@link BrowserType#firefox} browser.
+		 */
+		public CrawljaxConfigurationBuilder setBrowserConfig(BrowserConfiguration configuration) {
+			config.browserConfig = configuration;
+			return this;
+		}
+
+		public CrawljaxConfiguration build() {
+			config.plugins = pluginBuilder.build();
+			config.crawlRules = crawlRules.build();
+			return config;
+		}
+
 	}
 
 	/**
-	 * @return The browser used to crawl. By default firefox is used.
+	 * @param url
+	 *            The url you want to setup a configuration for
+	 * @return The builder to configure the crawler.
 	 */
-	protected BrowserType getBrowser() {
-		return browser;
+	public static CrawljaxConfigurationBuilder builderFor(URL url) {
+		Preconditions.checkNotNull(url, ""URL was null"");
+		return new CrawljaxConfigurationBuilder(url);
 	}
 
 	/**
-	 * @param browser
-	 *            The browser used to crawl.
+	 * @param url
+	 *            The url you want to setup a configuration for
+	 * @return The builder to configure the crawler.
 	 */
-	public void setBrowser(BrowserType browser) {
-		this.browser = browser;
-	}
-
-	/**
-	 * @return the browserBuilder
-	 */
-	protected EmbeddedBrowserBuilder getBrowserBuilder() {
-		return browserBuilder;
-	}
-
-	/**
-	 * Set the remote hub url that needs to be taken when using remote crawling.
-	 * 
-	 * @param remoteHubUrl
-	 *            the url of the remote hub
-	 */
-	public void setRemoteHubUrl(String remoteHubUrl) {
-		this.remoteHubUrl = remoteHubUrl;
-	}
-
-	/**
-	 * @return the remoteHubUrl
-	 */
-	protected String getRemoteHubUrl() {
-		return remoteHubUrl;
-	}
-
-	/**
-	 * @param browserBuilder
-	 *            the browserBuilder to set
-	 */
-	public void setBrowserBuilder(EmbeddedBrowserBuilder browserBuilder) {
-		this.browserBuilder = browserBuilder;
-	}
-
-	/**
-	 * @return The path of the outputFolder with a trailing slash.
-	 */
-	protected String getOutputFolder() {
-		return DomUtils.addFolderSlashIfNeeded(outputFolder);
-	}
-
-	/**
-	 * @param path
-	 *            The (absolute) path of the output folder.
-	 */
-	public void setOutputFolder(String path) {
-		this.outputFolder = DomUtils.addFolderSlashIfNeeded(path);
-	}
-
-	/**
-	 * @return The relative path of the project.
-	 */
-	protected String getProjectRelativePath() {
-		return projectRelativePath;
-	}
-
-	/**
-	 * @param projectRelativePath
-	 *            The relative path of the project.
-	 */
-	public void setProjectRelativePath(String projectRelativePath) {
-		this.projectRelativePath = projectRelativePath;
-	}
-
-	/**
-	 * @return The attributes which are filtered before the DOM is used.
-	 */
-	protected List<String> getFilterAttributeNames() {
-		return filterAttributeNames;
-	}
-
-	/**
-	 * @param filterAttributeNames
-	 *            The attributes which are filtered before the DOM is used.
-	 */
-	public void setFilterAttributeNames(List<String> filterAttributeNames) {
-		this.filterAttributeNames = filterAttributeNames;
-	}
-
-	/**
-	 * Sets filter attribute names.
-	 * 
-	 * @param filterAttributeNames
-	 *            The attribute names to filter.
-	 */
-	public void setFilterAttributeNames(String... filterAttributeNames) {
-		for (String name : filterAttributeNames) {
-			this.filterAttributeNames.add(name);
+	public static CrawljaxConfigurationBuilder builderFor(String url) {
+		try {
+			return new CrawljaxConfigurationBuilder(new URL(url));
+		} catch (MalformedURLException e) {
+			throw new CrawljaxException(""Could not read that URL"", e);
 		}
 	}
 
-	/**
-	 * @param attributeName
-	 *            The name of the attributes which should be filtered before the DOM is used.
-	 */
-	public void addFilterAttribute(String attributeName) {
-		this.filterAttributeNames.add(attributeName);
+	private URL url;
+
+	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.firefox);
+	private ImmutableList<Plugin> plugins;
+	private ProxyConfiguration proxyConfiguration = ProxyConfiguration.noProxy();
+
+	private CrawlRules crawlRules;
+
+	private int maximumStates = 0;
+	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);;
+	private int maximumDepth = 2;
+
+	private CrawljaxConfiguration() {
 	}
 
-	/**
-	 * @return The plugins See {@link Plugin}.
-	 */
-	protected List<Plugin> getPlugins() {
+	public URL getUrl() {
+		return url;
+	}
+
+	public BrowserConfiguration getBrowserConfig() {
+		return browserConfig;
+	}
+
+	public ImmutableList<Plugin> getPlugins() {
 		return plugins;
 	}
 
-	/**
-	 * @param plugins
-	 *            The plugins to set. See {@link Plugin}.
-	 */
-	public void setPlugins(List<Plugin> plugins) {
-		this.plugins = plugins;
+	public ProxyConfiguration getProxyConfiguration() {
+		return proxyConfiguration;
 	}
 
-	/**
-	 * Add a plugin to the execution. Note that the order of adding is the same as running for the
-	 * same type of plugin. This means that if you add a precrawling plugin p1 and next you add a
-	 * precrawling plugin p2, p1 will be executed before p2.
-	 * 
-	 * @param plugin
-	 *            Add a plugin. See {@link Plugin}.
-	 */
-	public void addPlugin(Plugin plugin) {
-		this.plugins.add(plugin);
+	public CrawlRules getCrawlRules() {
+		return crawlRules;
 	}
 
-}
+	public int getMaximumStates() {
+		return maximumStates;
+	}
+
+	public long getMaximumRuntime() {
+		return maximumRuntime;
+	}
+
+	public int getMaximumDepth() {
+		return maximumDepth;
+	}
+
+	@Override
+	public int hashCode() {
+		final int prime = 31;
+		int result = 1;
+		result = prime * result + ((browserConfig == null) ? 0 : browserConfig.hashCode());
+		result = prime * result + ((crawlRules == null) ? 0 : crawlRules.hashCode());
+		result = prime * result + maximumDepth;
+		result = prime * result + (int) (maximumRuntime ^ (maximumRuntime >>> 32));
+		result = prime * result + maximumStates;
+		result = prime * result + ((plugins == null) ? 0 : plugins.hashCode());
+		result =
+		        prime * result
+		                + ((proxyConfiguration == null) ? 0 : proxyConfiguration.hashCode());
+		result = prime * result + ((url == null) ? 0 : url.hashCode());
+		return result;
+	}
+
+	@Override
+	public boolean equals(Object obj) {
+		if (this == obj) {
+			return true;
+		}
+		if (obj == null) {
+			return false;
+		}
+		if (getClass() != obj.getClass()) {
+			return false;
+		}
+		CrawljaxConfiguration other = (CrawljaxConfiguration) obj;
+		if (browserConfig == null) {
+			if (other.browserConfig != null) {
+				return false;
+			}
+		} else if (!browserConfig.equals(other.browserConfig)) {
+			return false;
+		}
+		if (crawlRules == null) {
+			if (other.crawlRules != null) {
+				return false;
+			}
+		} else if (!crawlRules.equals(other.crawlRules)) {
+			return false;
+		}
+		if (maximumDepth != other.maximumDepth) {
+			return false;
+		}
+		if (maximumRuntime != other.maximumRuntime) {
+			return false;
+		}
+		if (maximumStates != other.maximumStates) {
+			return false;
+		}
+		if (plugins == null) {
+			if (other.plugins != null) {
+				return false;
+			}
+		} else if (!plugins.equals(other.plugins)) {
+			return false;
+		}
+		if (proxyConfiguration == null) {
+			if (other.proxyConfiguration != null) {
+				return false;
+			}
+		} else if (!proxyConfiguration.equals(other.proxyConfiguration)) {
+			return false;
+		}
+		if (url == null) {
+			if (other.url != null) {
+				return false;
+			}
+		} else if (!url.equals(other.url)) {
+			return false;
+		}
+		return true;
+	}
+
+	@Override
+	public String toString() {
+		StringBuilder builder = new StringBuilder();
+		builder.append(""CrawljaxConfiguration [url="");
+		builder.append(url);
+		builder.append("", browserConfig="");
+		builder.append(browserConfig);
+		builder.append("", plugins="");
+		builder.append(plugins);
+		builder.append("", proxyConfiguration="");
+		builder.append(proxyConfiguration);
+		builder.append("", crawlRules="");
+		builder.append(crawlRules);
+		builder.append("", maximumStates="");
+		builder.append(maximumStates);
+		builder.append("", maximumRuntime="");
+		builder.append(maximumRuntime);
+		builder.append("", maximumDepth="");
+		builder.append(maximumDepth);
+		builder.append(""]"");
+		return builder.toString();
+	}
+
+}
\ No newline at end of file
"
3ace7acef7c422d26cb75523c3526d60e60b00ac,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index 6854b96..287b05d 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -58,7 +58,7 @@
 	}
 
 	private static final String[] ALLOWED_INPUT_TYPES =
-	        { ""text"", ""radio"", ""checkbox"", ""password"" };
+	{ ""text"", ""radio"", ""checkbox"", ""password"" };
 
 	/**
 	 * Fills in the element with the InputValues for input TODO: improve this by using WebDriver
"
3ace7acef7c422d26cb75523c3526d60e60b00ac,Alex Nederlof,RunWithWebServer.java,MODIFY,newConfigBuilder -> [String context] | [],"diff --git a/core/src/test/java/com/crawljax/test/RunWithWebServer.java b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
index 587d615..f64d1f8 100644
--- a/core/src/test/java/com/crawljax/test/RunWithWebServer.java
+++ b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
@@ -8,6 +8,8 @@
 import org.eclipse.jetty.util.resource.Resource;
 import org.junit.rules.ExternalResource;
 
+import com.crawljax.core.configuration.CrawljaxConfiguration;
+import com.crawljax.core.configuration.CrawljaxConfiguration.CrawljaxConfigurationBuilder;
 import com.google.common.base.Preconditions;
 
 public class RunWithWebServer extends ExternalResource {
@@ -60,6 +62,14 @@
 		return port;
 	}
 
+	public CrawljaxConfigurationBuilder newConfigBuilder() {
+		return CrawljaxConfiguration.builderFor(getSiteUrl());
+	}
+
+	public CrawljaxConfigurationBuilder newConfigBuilder(String context) {
+		return CrawljaxConfiguration.builderFor(getSiteUrl() + context);
+	}
+
 	public void stop() throws Exception {
 		checkServerStarted();
 		server.stop();
"
f7c1ef7a814485ca76f203452f61a35387cd81b2,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index 1ce4556..f38d691 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -16,7 +16,6 @@
 import com.crawljax.condition.eventablecondition.EventableConditionChecker;
 import com.crawljax.condition.invariant.Invariant;
 import com.crawljax.core.configuration.CrawljaxConfiguration;
-import com.crawljax.core.plugin.CrawljaxPluginsUtil;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateFlowGraph;
 import com.crawljax.oraclecomparator.StateComparator;
@@ -93,10 +92,10 @@
 		LOGGER.info(""Starting Crawljax..."");
 
 		LOGGER.info(""Used plugins:"");
-		CrawljaxPluginsUtil.loadPlugins(configuration.getPlugins());
 
 		if (configuration.getProxyConfiguration() != null) {
-			CrawljaxPluginsUtil.runProxyServerPlugins(configuration.getProxyConfiguration());
+			configuration.getPlugins().runProxyServerPlugins(
+			        configuration.getProxyConfiguration());
 		}
 
 		LOGGER.info(""Embedded browser implementation: {}"", configuration.getBrowserConfig()
@@ -125,7 +124,7 @@
 		        .getPreCrawlConfig().getIncludedElements());
 
 		// Create the initailCrawler
-		initialCrawler = new InitialCrawler(this);
+		initialCrawler = new InitialCrawler(this, configuration.getPlugins());
 
 		// Start the Crawling by adding the initialCrawler to the the workQueue.
 		addWorkToQueue(initialCrawler);
@@ -159,7 +158,7 @@
 		} catch (InterruptedException e1) {
 			LOGGER.warn(""Re-Request for a browser was interrupted"", e1);
 		}
-		CrawljaxPluginsUtil.runPostCrawlingPlugins(session);
+		configuration.getPlugins().runPostCrawlingPlugins(session);
 		this.getBrowserPool().freeBrowser(b);
 
 		this.shutdown(timeCrawlCalc);
"
f7c1ef7a814485ca76f203452f61a35387cd81b2,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index d451ae0..36d9a33 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -9,6 +9,7 @@
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
+import com.crawljax.core.plugin.Plugins;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
 
@@ -126,7 +127,7 @@
 		}
 
 		public CrawljaxConfiguration build() {
-			config.plugins = pluginBuilder.build();
+			config.plugins = new Plugins(pluginBuilder.build());
 			config.crawlRules = crawlRules.build();
 			return config;
 		}
@@ -159,7 +160,7 @@
 	private URL url;
 
 	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.firefox);
-	private ImmutableList<Plugin> plugins;
+	private Plugins plugins;
 	private ProxyConfiguration proxyConfiguration = ProxyConfiguration.noProxy();
 
 	private CrawlRules crawlRules;
@@ -179,7 +180,7 @@
 		return browserConfig;
 	}
 
-	public ImmutableList<Plugin> getPlugins() {
+	public Plugins getPlugins() {
 		return plugins;
 	}
 
"
90418c5a124e7820c71076be8ed077d61c09ff3b,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index d451ae0..09e1a6f 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -52,7 +52,8 @@
 		 *            The maximum time the crawler should run. Default is one hour.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumRunTime(long time, TimeUnit unit) {
-			Preconditions.checkArgument(time > 0, ""Time should larger than 0"");
+			Preconditions
+			        .checkArgument(time >= 0, ""Time should larger than 0, or 0 for infinate."");
 			config.maximumRuntime = unit.toMillis(time);
 			return this;
 		}
@@ -70,7 +71,8 @@
 		 *            The maximum depth the crawler can reach. The default is <code>2</code>.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumDepth(int depth) {
-			Preconditions.checkArgument(depth > 1, ""Time should larger than 1"");
+			Preconditions.checkArgument(depth >= 0,
+			        ""Depth should be 0 for infinite, or larger for a certain depth."");
 			config.maximumDepth = depth;
 			return this;
 		}
"
6d2ff1ae972ab85b5dff9438a0b4fd5e2178d526,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 09e1a6f..342ee90 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -1,5 +1,7 @@
 package com.crawljax.core.configuration;
 
+import static com.google.common.base.Preconditions.checkArgument;
+
 import java.net.MalformedURLException;
 import java.net.URL;
 import java.util.concurrent.TimeUnit;
@@ -24,6 +26,7 @@
 		private final CrawlRulesBuilder crawlRules = CrawlRules.builder();
 
 		private CrawljaxConfigurationBuilder(URL url) {
+			Preconditions.checkNotNull(url);
 			config = new CrawljaxConfiguration();
 			config.url = url;
 		}
@@ -34,7 +37,7 @@
 		 *            unlimited.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumStates(int states) {
-			Preconditions.checkArgument(states > 1, ""States should be positive"");
+			checkArgument(states > 1, ""Number of maximum states should be largen than 1"");
 			config.maximumStates = states;
 			return this;
 		}
@@ -52,8 +55,7 @@
 		 *            The maximum time the crawler should run. Default is one hour.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumRunTime(long time, TimeUnit unit) {
-			Preconditions
-			        .checkArgument(time >= 0, ""Time should larger than 0, or 0 for infinate."");
+			checkArgument(time >= 0, ""Time should be larger than 0, or 0 for infinate."");
 			config.maximumRuntime = unit.toMillis(time);
 			return this;
 		}
@@ -105,6 +107,7 @@
 		 *            The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
 		 */
 		public CrawljaxConfigurationBuilder setProxyConfig(ProxyConfiguration configuration) {
+			Preconditions.checkNotNull(configuration);
 			config.proxyConfiguration = configuration;
 			return this;
 		}
@@ -123,6 +126,7 @@
 		 *            {@link BrowserType#firefox} browser.
 		 */
 		public CrawljaxConfigurationBuilder setBrowserConfig(BrowserConfiguration configuration) {
+			Preconditions.checkNotNull(configuration);
 			config.browserConfig = configuration;
 			return this;
 		}
"
9e4440e67544403d08e1add84324d0d4e52bff3d,Alex Nederlof,JarRunnerTest.java,MODIFY,assertHelpWasPrinted -> [] | [boolean missingArguments],"diff --git a/cli/src/test/java/com/crawljax/cli/JarRunnerTest.java b/cli/src/test/java/com/crawljax/cli/JarRunnerTest.java
index 6204078..d4d462b 100644
--- a/cli/src/test/java/com/crawljax/cli/JarRunnerTest.java
+++ b/cli/src/test/java/com/crawljax/cli/JarRunnerTest.java
@@ -2,10 +2,12 @@
 
 import static org.hamcrest.Matchers.isEmptyString;
 import static org.hamcrest.Matchers.startsWith;
+import static org.hamcrest.collection.IsCollectionWithSize.hasSize;
 import static org.hamcrest.core.Is.is;
 import static org.junit.Assert.assertThat;
 
 import java.io.IOException;
+import java.util.concurrent.TimeUnit;
 
 import org.junit.After;
 import org.junit.Rule;
@@ -14,8 +16,11 @@
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.core.configuration.BrowserConfiguration;
+import com.crawljax.core.configuration.CrawlElement;
+import com.crawljax.core.configuration.CrawlRules;
 import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.crawljax.test.util.CaptureSystemStreams;
+import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ObjectArrays;
 
 public class JarRunnerTest {
@@ -29,7 +34,27 @@
 	@Test
 	public void whenNoArgsCommitedItPrintsHelp() {
 		new JarRunner(new String[0]);
-		assertHelpWasPrinted();
+		assertHelpWasPrinted(true);
+	}
+
+	private void assertHelpWasPrinted(boolean missingArguments) {
+		String helpMessage = ""usage: "" + JarRunner.HELP_MESSAGE;
+		if (missingArguments) {
+			helpMessage = JarRunner.MISSING_ARGUMENT_MESSAGE + ""\n"" + helpMessage;
+		}
+		assertThat(streams.getConsoleOutput(), startsWith(helpMessage));
+	}
+
+	@Test
+	public void whenOneArgIsInsertItAlsoPrintsHelp() {
+		new JarRunner(""http://nu.nl -a"".split("" ""));
+		assertHelpWasPrinted(true);
+	}
+
+	@Test
+	public void whenHelpArgumentSpecifiedPrintHelp() {
+		new JarRunner(""-h"".split("" ""));
+		assertHelpWasPrinted(false);
 	}
 
 	@Test
@@ -102,9 +127,32 @@
 		assertThat(configForArgs(""-a"").getCrawlRules().isCrawlHiddenAnchors(), is(true));
 	}
 
-	private void assertHelpWasPrinted() {
-		String helpMessage = ""usage: "" + JarRunner.HELP_MESSAGE;
-		assertThat(streams.getConsoleOutput(), startsWith(helpMessage));
+	@Test
+	public void testCustomClicks() {
+		CrawlRules crawlRules = configForArgs(""--click a,b,c"").getCrawlRules();
+		ImmutableList<CrawlElement> includedElements =
+		        crawlRules.getPreCrawlConfig().getIncludedElements();
+		assertThat(includedElements, hasSize(3));
+	}
+
+	@Test
+	public void testWithMaxCrawlTime() {
+		assertThat(configForArgs(""-t 123"").getMaximumRuntime(),
+		        is(TimeUnit.MINUTES.toMillis(123)));
+	}
+
+	@Test
+	public void testWaitAfterReload() {
+		CrawlRules crawlRules =
+		        configForArgs(""-"" + JarRunner.WAIT_AFTER_RELOAD + "" 123"").getCrawlRules();
+		assertThat(crawlRules.getWaitAfterReloadUrl(), is(123L));
+	}
+
+	@Test
+	public void testWaitAfterEvent() {
+		CrawlRules crawlRules =
+		        configForArgs(""-"" + JarRunner.WAIT_AFTER_EVENT + "" 123"").getCrawlRules();
+		assertThat(crawlRules.getWaitAfterEvent(), is(123L));
 	}
 
 	@After
"
c08884794b003f6aabc8ef62238cfdb1d71bb0e4,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index d451ae0..342ee90 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -1,5 +1,7 @@
 package com.crawljax.core.configuration;
 
+import static com.google.common.base.Preconditions.checkArgument;
+
 import java.net.MalformedURLException;
 import java.net.URL;
 import java.util.concurrent.TimeUnit;
@@ -24,6 +26,7 @@
 		private final CrawlRulesBuilder crawlRules = CrawlRules.builder();
 
 		private CrawljaxConfigurationBuilder(URL url) {
+			Preconditions.checkNotNull(url);
 			config = new CrawljaxConfiguration();
 			config.url = url;
 		}
@@ -34,7 +37,7 @@
 		 *            unlimited.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumStates(int states) {
-			Preconditions.checkArgument(states > 1, ""States should be positive"");
+			checkArgument(states > 1, ""Number of maximum states should be largen than 1"");
 			config.maximumStates = states;
 			return this;
 		}
@@ -52,7 +55,7 @@
 		 *            The maximum time the crawler should run. Default is one hour.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumRunTime(long time, TimeUnit unit) {
-			Preconditions.checkArgument(time > 0, ""Time should larger than 0"");
+			checkArgument(time >= 0, ""Time should be larger than 0, or 0 for infinate."");
 			config.maximumRuntime = unit.toMillis(time);
 			return this;
 		}
@@ -70,7 +73,8 @@
 		 *            The maximum depth the crawler can reach. The default is <code>2</code>.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumDepth(int depth) {
-			Preconditions.checkArgument(depth > 1, ""Time should larger than 1"");
+			Preconditions.checkArgument(depth >= 0,
+			        ""Depth should be 0 for infinite, or larger for a certain depth."");
 			config.maximumDepth = depth;
 			return this;
 		}
@@ -103,6 +107,7 @@
 		 *            The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
 		 */
 		public CrawljaxConfigurationBuilder setProxyConfig(ProxyConfiguration configuration) {
+			Preconditions.checkNotNull(configuration);
 			config.proxyConfiguration = configuration;
 			return this;
 		}
@@ -121,6 +126,7 @@
 		 *            {@link BrowserType#firefox} browser.
 		 */
 		public CrawljaxConfigurationBuilder setBrowserConfig(BrowserConfiguration configuration) {
+			Preconditions.checkNotNull(configuration);
 			config.browserConfig = configuration;
 			return this;
 		}
"
3ea0fe24288ef84fa4cc84ca524bf17668b45d09,Alex Nederlof,CrawlOverview.java,MODIFY,"saveScreenshot -> [String name, StateVertex vertex] | [CrawlSession session, String name, StateVertex vertex]","diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java
index 4e38772..cf9987b 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java
@@ -44,7 +44,6 @@
 	private final OutputBuilder outputBuilder;
 	private final Map<String, StateVertex> visitedStates;
 
-	private CrawlSession session;
 	private OutPutModel result;
 
 	private final OutPutModelCache outModelCache;
@@ -63,10 +62,9 @@
 	@Override
 	public void onNewState(CrawlSession session) {
 		LOG.debug(""onNewState"");
-		this.session = session;
 		StateVertex vertex = session.getCurrentState();
 		StateBuilder state = outModelCache.addStateIfAbsent(vertex);
-		saveScreenshot(state.getName(), vertex);
+		saveScreenshot(session, state.getName(), vertex);
 		outputBuilder.persistDom(state.getName(), session.getBrowser().getDom());
 		Point point = getOffSet(session.getBrowser());
 		state.setScreenShotOffset(point);
@@ -98,7 +96,7 @@
 		return ""relative"".equals(position);
 	}
 
-	private void saveScreenshot(String name, StateVertex vertex) {
+	private void saveScreenshot(CrawlSession session, String name, StateVertex vertex) {
 		LOG.trace(""Saving screenshot"");
 		synchronized (visitedStates) {
 			if (!visitedStates.containsKey(name)) {
@@ -123,7 +121,6 @@
 	@Override
 	public void preStateCrawling(CrawlSession session, List<CandidateElement> candidateElements) {
 		LOG.debug(""preStateCrawling"");
-		this.session = session;
 		List<CandidateElementPosition> newElements = Lists.newLinkedList();
 		StateVertex state = session.getCurrentState();
 		LOG.info(""Prestate found new state {} with {} candidates"", state.getName(),
"
b9800e4a4d1aadbdf08b6f4af17343edc55ab1f8,Alex Nederlof,StateFlowGraph.java,MODIFY,"addState -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index 99c24c0..a9d3c2b 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -19,6 +19,8 @@
 import org.slf4j.LoggerFactory;
 
 import com.google.common.base.Preconditions;
+import com.google.common.collect.ImmutableSet;
+import com.google.common.collect.Lists;
 
 /**
  * The State-Flow Graph is a multi-edge directed graph with states (StateVetex) on the vertices and
@@ -49,6 +51,7 @@
 		Preconditions.checkNotNull(initialState);
 		sfg = new DirectedMultigraph<>(Eventable.class);
 		sfg.addVertex(initialState);
+		stateCounter.incrementAndGet();
 		this.initialState = initialState;
 	}
 
@@ -165,8 +168,8 @@
 	 * @return a set of the outgoing edges (clickables) of the stateVertix.
 	 * @see org.jgrapht.DirectedGraph#outgoingEdgesOf(Object)
 	 */
-	public Set<Eventable> getOutgoingClickables(StateVertex stateVertix) {
-		return sfg.outgoingEdgesOf(stateVertix);
+	public ImmutableSet<Eventable> getOutgoingClickables(StateVertex stateVertix) {
+		return ImmutableSet.copyOf(sfg.outgoingEdgesOf(stateVertix));
 	}
 
 	/**
@@ -177,8 +180,8 @@
 	 * @return a set of the incoming edges (clickables) of the stateVertix.
 	 * @see org.jgrapht.DirectedGraph#incomingEdgesOf(Object)
 	 */
-	public Set<Eventable> getIncomingClickable(StateVertex stateVertix) {
-		return sfg.incomingEdgesOf(stateVertix);
+	public ImmutableSet<Eventable> getIncomingClickable(StateVertex stateVertix) {
+		return ImmutableSet.copyOf(sfg.incomingEdgesOf(stateVertix));
 	}
 
 	/**
@@ -188,14 +191,14 @@
 	 *            the state.
 	 * @return the set of outgoing states from the stateVertix.
 	 */
-	public Set<StateVertex> getOutgoingStates(StateVertex stateVertix) {
-		final Set<StateVertex> result = new HashSet<StateVertex>();
+	public ImmutableSet<StateVertex> getOutgoingStates(StateVertex stateVertix) {
+		final Set<StateVertex> result = new HashSet<>();
 
 		for (Eventable c : getOutgoingClickables(stateVertix)) {
 			result.add(sfg.getEdgeTarget(c));
 		}
 
-		return result;
+		return ImmutableSet.copyOf(result);
 	}
 
 	/**
@@ -241,8 +244,8 @@
 	 * 
 	 * @return all the states on the graph.
 	 */
-	public Set<StateVertex> getAllStates() {
-		return sfg.vertexSet();
+	public ImmutableSet<StateVertex> getAllStates() {
+		return ImmutableSet.copyOf(sfg.vertexSet());
 	}
 
 	/**
@@ -250,8 +253,8 @@
 	 * 
 	 * @return a Set of all edges in the StateFlowGraph
 	 */
-	public Set<Eventable> getAllEdges() {
-		return sfg.edgeSet();
+	public ImmutableSet<Eventable> getAllEdges() {
+		return ImmutableSet.copyOf(sfg.edgeSet());
 	}
 
 	/**
@@ -260,17 +263,15 @@
 	 * 
 	 * @param state
 	 *            the StateVertix to search
-	 * @return the copy of the StateVertix in the StateFlowGraph where v.equals(u)
+	 * @return the copy of the StateVertix in the StateFlowGraph where v.equals(u) or
+	 *         <code>null</code> if not found.
 	 */
 	private StateVertex getStateInGraph(StateVertex state) {
-		Set<StateVertex> states = getAllStates();
-
-		for (StateVertex st : states) {
+		for (StateVertex st : sfg.vertexSet()) {
 			if (state.equals(st)) {
 				return st;
 			}
 		}
-
 		return null;
 	}
 
@@ -280,7 +281,7 @@
 	public int getMeanStateStringSize() {
 		final Mean mean = new Mean();
 
-		for (StateVertex state : getAllStates()) {
+		for (StateVertex state : sfg.vertexSet()) {
 			mean.increment(state.getDomSize());
 		}
 
@@ -342,11 +343,10 @@
 	 * @return a list of GraphPath lists.
 	 */
 	public List<List<GraphPath<StateVertex, Eventable>>> getAllPossiblePaths(StateVertex index) {
-		final List<List<GraphPath<StateVertex, Eventable>>> results =
-		        new ArrayList<List<GraphPath<StateVertex, Eventable>>>();
+		final List<List<GraphPath<StateVertex, Eventable>>> results = Lists.newArrayList();
 
 		final KShortestPaths<StateVertex, Eventable> kPaths =
-		        new KShortestPaths<StateVertex, Eventable>(this.sfg, index, Integer.MAX_VALUE);
+		        new KShortestPaths<>(this.sfg, index, Integer.MAX_VALUE);
 
 		for (StateVertex state : getDeepStates(index)) {
 
@@ -394,4 +394,11 @@
 	public boolean isInitialState(StateVertex state) {
 		return initialState.equals(state);
 	}
+
+	/**
+	 * @return The number of states, currently in the graph.
+	 */
+	public int getNumberOfStates() {
+		return stateCounter.get();
+	}
 }
"
9518b9cd975bbe70bb100eb55ac8bf2c5c1cbdd0,Alex Nederlof,JarRunner.java,MODIFY,printHelp -> [] | [Options options],"diff --git a/cli/src/main/java/com/crawljax/cli/JarRunner.java b/cli/src/main/java/com/crawljax/cli/JarRunner.java
index 4fb5a4f..d8377e7 100644
--- a/cli/src/main/java/com/crawljax/cli/JarRunner.java
+++ b/cli/src/main/java/com/crawljax/cli/JarRunner.java
@@ -44,17 +44,15 @@
 		try {
 			Options options = getOptions();
 			final CommandLine commandLine = new GnuParser().parse(options, args);
-
 			if (commandLine.hasOption(HELP)) {
 				printHelp(options);
 			} else if (commandLine.hasOption(VERSION)) {
 				System.out.println(getCrawljaxVersion());
-			} else if (args.length > 2) {
+			} else if (args.length >= 2) {
 				String url = commandLine.getArgs()[0];
 				String outputDir = commandLine.getArgs()[1];
 				if (urlIsInvalid(url)) {
 					System.err.println(""provide a valid URL like http://example.com"");
-					printHelp(options);
 					System.exit(1);
 				} else {
 					checkOutDir(commandLine, outputDir);
"
6cb21d2096447a43ffa2fe7e7f7876e3d22db41e,Alex Nederlof,Crawler.java,MODIFY,depthLimitReached -> [] | [int depth],"diff --git a/core/src/main/java/com/crawljax/core/Crawler.java b/core/src/main/java/com/crawljax/core/Crawler.java
index a6696fd..903e874 100644
--- a/core/src/main/java/com/crawljax/core/Crawler.java
+++ b/core/src/main/java/com/crawljax/core/Crawler.java
@@ -190,8 +190,7 @@
 		try {
 			fired = getBrowser().fireEvent(eventToFire);
 		} catch (ElementNotVisibleException | NoSuchElementException e) {
-			if (config.getCrawlRules().isCrawlHiddenAnchors()
-			        && eventToFire.getElement() != null
+			if (config.getCrawlRules().isCrawlHiddenAnchors() && eventToFire.getElement() != null
 			        && ""A"".equals(eventToFire.getElement().getTag())) {
 				fired = visitAnchorHrefIfPossible(eventToFire);
 			} else {
@@ -317,8 +316,7 @@
 				/*
 				 * Run the onRevisitStateValidator(s)
 				 */
-				plugins.runOnRevisitStatePlugins(this.controller.getSession(),
-				        curState);
+				plugins.runOnRevisitStatePlugins(this.controller.getSession(), curState);
 			}
 
 			if (!controller.getElementChecker().checkCrawlCondition(getBrowser())) {
@@ -371,11 +369,6 @@
 				if (this.getStateMachine().updateAndCheckIfClone(eventable, newState,
 				        this.getBrowser(), this.controller.getSession())) {
 
-					// Change is no clone
-					plugins.runGuidedCrawlingPlugins(controller, controller
-					        .getSession(), controller.getSession().getCurrentCrawlPath(), this
-					        .getStateMachine());
-
 					return ClickResult.newState;
 				} else {
 					// Dom changed; Clone
@@ -388,8 +381,8 @@
 	}
 
 	private boolean domChanged(final Eventable eventable, StateVertex newState) {
-		return plugins.runDomChangeNotifierPlugins(this.getStateMachine()
-		        .getCurrentState(), eventable, newState, getBrowser());
+		return plugins.runDomChangeNotifierPlugins(this.getStateMachine().getCurrentState(),
+		        eventable, newState, getBrowser());
 	}
 
 	/**
@@ -494,8 +487,7 @@
 			LOGGER.info(""Starting preStateCrawlingPlugins..."");
 			List<CandidateElement> candidateElements =
 			        orrigionalState.getUnprocessedCandidateElements();
-			plugins.runPreStateCrawlingPlugins(controller.getSession(),
-			        candidateElements);
+			plugins.runPreStateCrawlingPlugins(controller.getSession(), candidateElements);
 			// update crawlActions
 			orrigionalState.filterCandidateActions(candidateElements);
 		}
@@ -573,9 +565,8 @@
 		}
 		// TODO Stefan ideally this should be placed in the constructor
 		this.formHandler =
-		        new FormHandler(getBrowser(), config.getCrawlRules()
-		                .getInputSpecification(), config.getCrawlRules()
-		                .isRandomInputInForms());
+		        new FormHandler(getBrowser(), config.getCrawlRules().getInputSpecification(),
+		                config.getCrawlRules().isRandomInputInForms());
 
 		this.candidateExtractor =
 		        new CandidateElementExtractor(controller.getElementChecker(), this.getBrowser(),
"
9d5fee6e4375c98d5ddadb4a68640e2ed9dc463b,Alex Nederlof,Crawler.java,MODIFY,depthLimitReached -> [int depth] | [],"diff --git a/core/src/main/java/com/crawljax/core/Crawler.java b/core/src/main/java/com/crawljax/core/Crawler.java
index b63484a..15f76cc 100644
--- a/core/src/main/java/com/crawljax/core/Crawler.java
+++ b/core/src/main/java/com/crawljax/core/Crawler.java
@@ -690,9 +690,9 @@
 		if (maxCrawlTime != 0 && timePassed > maxCrawlTime) {
 			LOG.info(""Max time {} seconds passed!"",
 			        TimeUnit.MILLISECONDS.toSeconds(maxCrawlTime));
-			return false;
-		} else {
 			return true;
+		} else {
+			return false;
 		}
 	}
 
@@ -701,9 +701,9 @@
 		int maxNumberOfStates = configurationReader.getMaximumStates();
 		if ((maxNumberOfStates != 0) && (graph.getNumberOfStates() >= maxNumberOfStates)) {
 			LOG.info(""Max number of states {} reached!"", maxNumberOfStates);
-			return false;
-		} else {
 			return true;
+		} else {
+			return false;
 		}
 	}
 
"
d7093dfbd738b53a709dbea782903cc59d2acf4a,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index 1ce4556..f38d691 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -16,7 +16,6 @@
 import com.crawljax.condition.eventablecondition.EventableConditionChecker;
 import com.crawljax.condition.invariant.Invariant;
 import com.crawljax.core.configuration.CrawljaxConfiguration;
-import com.crawljax.core.plugin.CrawljaxPluginsUtil;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateFlowGraph;
 import com.crawljax.oraclecomparator.StateComparator;
@@ -93,10 +92,10 @@
 		LOGGER.info(""Starting Crawljax..."");
 
 		LOGGER.info(""Used plugins:"");
-		CrawljaxPluginsUtil.loadPlugins(configuration.getPlugins());
 
 		if (configuration.getProxyConfiguration() != null) {
-			CrawljaxPluginsUtil.runProxyServerPlugins(configuration.getProxyConfiguration());
+			configuration.getPlugins().runProxyServerPlugins(
+			        configuration.getProxyConfiguration());
 		}
 
 		LOGGER.info(""Embedded browser implementation: {}"", configuration.getBrowserConfig()
@@ -125,7 +124,7 @@
 		        .getPreCrawlConfig().getIncludedElements());
 
 		// Create the initailCrawler
-		initialCrawler = new InitialCrawler(this);
+		initialCrawler = new InitialCrawler(this, configuration.getPlugins());
 
 		// Start the Crawling by adding the initialCrawler to the the workQueue.
 		addWorkToQueue(initialCrawler);
@@ -159,7 +158,7 @@
 		} catch (InterruptedException e1) {
 			LOGGER.warn(""Re-Request for a browser was interrupted"", e1);
 		}
-		CrawljaxPluginsUtil.runPostCrawlingPlugins(session);
+		configuration.getPlugins().runPostCrawlingPlugins(session);
 		this.getBrowserPool().freeBrowser(b);
 
 		this.shutdown(timeCrawlCalc);
"
d7093dfbd738b53a709dbea782903cc59d2acf4a,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 342ee90..679244f 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -11,6 +11,7 @@
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
+import com.crawljax.core.plugin.Plugins;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
 
@@ -132,7 +133,7 @@
 		}
 
 		public CrawljaxConfiguration build() {
-			config.plugins = pluginBuilder.build();
+			config.plugins = new Plugins(pluginBuilder.build());
 			config.crawlRules = crawlRules.build();
 			return config;
 		}
@@ -165,7 +166,7 @@
 	private URL url;
 
 	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.firefox);
-	private ImmutableList<Plugin> plugins;
+	private Plugins plugins;
 	private ProxyConfiguration proxyConfiguration = ProxyConfiguration.noProxy();
 
 	private CrawlRules crawlRules;
@@ -185,7 +186,7 @@
 		return browserConfig;
 	}
 
-	public ImmutableList<Plugin> getPlugins() {
+	public Plugins getPlugins() {
 		return plugins;
 	}
 
"
2075835c44324ad704106369a6ef1f34a24a8b63,Alex Nederlof,Eventable.java,MODIFY,setRelatedFormInputs -> [List relatedFormInputs] | [CopyOnWriteArrayList relatedFormInputs],"diff --git a/core/src/main/java/com/crawljax/core/state/Eventable.java b/core/src/main/java/com/crawljax/core/state/Eventable.java
index 96a0535..ab62d68 100644
--- a/core/src/main/java/com/crawljax/core/state/Eventable.java
+++ b/core/src/main/java/com/crawljax/core/state/Eventable.java
@@ -6,8 +6,7 @@
 import java.io.Serializable;
 import java.lang.reflect.AccessibleObject;
 import java.lang.reflect.Field;
-import java.util.ArrayList;
-import java.util.List;
+import java.util.concurrent.CopyOnWriteArrayList;
 
 import org.apache.commons.lang.builder.EqualsBuilder;
 import org.apache.commons.lang.builder.HashCodeBuilder;
@@ -31,7 +30,7 @@
 	private EventType eventType;
 	private Identification identification;
 	private Element element;
-	private List<FormInput> relatedFormInputs = new ArrayList<FormInput>();
+	private CopyOnWriteArrayList<FormInput> relatedFormInputs = new CopyOnWriteArrayList<>();
 	private String relatedFrame = """";
 
 	/**
@@ -103,7 +102,7 @@
 		if (candidateElement.getElement() != null) {
 			this.element = new Element(candidateElement.getElement());
 		}
-		this.relatedFormInputs = candidateElement.getFormInputs();
+		this.relatedFormInputs = new CopyOnWriteArrayList<>(candidateElement.getFormInputs());
 		this.relatedFrame = candidateElement.getRelatedFrame();
 	}
 
@@ -223,7 +222,7 @@
 	 * 
 	 * @return the formInputs
 	 */
-	public List<FormInput> getRelatedFormInputs() {
+	public CopyOnWriteArrayList<FormInput> getRelatedFormInputs() {
 		return relatedFormInputs;
 	}
 
@@ -233,7 +232,7 @@
 	 * @param relatedFormInputs
 	 *            the list of formInputs
 	 */
-	public void setRelatedFormInputs(List<FormInput> relatedFormInputs) {
+	public void setRelatedFormInputs(CopyOnWriteArrayList<FormInput> relatedFormInputs) {
 		this.relatedFormInputs = relatedFormInputs;
 	}
 
"
ea806f83274ba6ce0d7788a2b3edd03ff613ab5b,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 0cc6efe..dca372e 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -794,31 +794,40 @@
 		return crawlWaitReload;
 	}
 
-	private void takeScreenShotOnBrowser(WebDriver driver, File file) throws CrawljaxException {
-		if (driver instanceof TakesScreenshot) {
-			File tmpfile = ((TakesScreenshot) driver).getScreenshotAs(OutputType.FILE);
-
+	@Override
+	public void saveScreenShot(File file) throws CrawljaxException {
+		try {
+			File tmpfile = takeScreenShotOnBrowser(browser, OutputType.FILE);
 			try {
 				FileHandler.copy(tmpfile, file);
 			} catch (IOException e) {
 				throw new CrawljaxException(e);
 			}
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
 
+	private <T> T takeScreenShotOnBrowser(WebDriver driver, OutputType<T> outType)
+	        throws CrawljaxException {
+		if (driver instanceof TakesScreenshot) {
+			T screenshot = ((TakesScreenshot) driver).getScreenshotAs(outType);
 			removeCanvasGeneratedByFirefoxDriverForScreenshots();
+			return screenshot;
 		} else if (driver instanceof RemoteWebDriver) {
 			WebDriver augmentedWebdriver = new Augmenter().augment(driver);
-			takeScreenShotOnBrowser(augmentedWebdriver, file);
+			return takeScreenShotOnBrowser(augmentedWebdriver, outType);
 		} else if (driver instanceof WrapsDriver) {
-			takeScreenShotOnBrowser(((WrapsDriver) driver).getWrappedDriver(), file);
+			return takeScreenShotOnBrowser(((WrapsDriver) driver).getWrappedDriver(), outType);
 		} else {
 			throw new CrawljaxException(""Your current WebDriver doesn't support screenshots."");
 		}
 	}
 
 	@Override
-	public void saveScreenShot(File file) throws CrawljaxException {
+	public byte[] getScreenShot() throws CrawljaxException {
 		try {
-			takeScreenShotOnBrowser(browser, file);
+			return takeScreenShotOnBrowser(browser, OutputType.BYTES);
 		} catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
"
9e84e3035ea08c00cd1fef68219aafccff320b1b,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 0cc6efe..dca372e 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -794,31 +794,40 @@
 		return crawlWaitReload;
 	}
 
-	private void takeScreenShotOnBrowser(WebDriver driver, File file) throws CrawljaxException {
-		if (driver instanceof TakesScreenshot) {
-			File tmpfile = ((TakesScreenshot) driver).getScreenshotAs(OutputType.FILE);
-
+	@Override
+	public void saveScreenShot(File file) throws CrawljaxException {
+		try {
+			File tmpfile = takeScreenShotOnBrowser(browser, OutputType.FILE);
 			try {
 				FileHandler.copy(tmpfile, file);
 			} catch (IOException e) {
 				throw new CrawljaxException(e);
 			}
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
 
+	private <T> T takeScreenShotOnBrowser(WebDriver driver, OutputType<T> outType)
+	        throws CrawljaxException {
+		if (driver instanceof TakesScreenshot) {
+			T screenshot = ((TakesScreenshot) driver).getScreenshotAs(outType);
 			removeCanvasGeneratedByFirefoxDriverForScreenshots();
+			return screenshot;
 		} else if (driver instanceof RemoteWebDriver) {
 			WebDriver augmentedWebdriver = new Augmenter().augment(driver);
-			takeScreenShotOnBrowser(augmentedWebdriver, file);
+			return takeScreenShotOnBrowser(augmentedWebdriver, outType);
 		} else if (driver instanceof WrapsDriver) {
-			takeScreenShotOnBrowser(((WrapsDriver) driver).getWrappedDriver(), file);
+			return takeScreenShotOnBrowser(((WrapsDriver) driver).getWrappedDriver(), outType);
 		} else {
 			throw new CrawljaxException(""Your current WebDriver doesn't support screenshots."");
 		}
 	}
 
 	@Override
-	public void saveScreenShot(File file) throws CrawljaxException {
+	public byte[] getScreenShot() throws CrawljaxException {
 		try {
-			takeScreenShotOnBrowser(browser, file);
+			return takeScreenShotOnBrowser(browser, OutputType.BYTES);
 		} catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
"
771c0bdcd72945cc43a232884f10c90c633ee5ec,DavidRLee,CandidateElementExtractor.java,MODIFY,"addElement -> [Element element, Builder builder, TagElement tagElement] | [Element element, Builder builder, CrawlElement crawlElement]","diff --git a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
index f77a564..c39cc26 100644
--- a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
+++ b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
@@ -34,7 +34,6 @@
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableList.Builder;
 import com.google.common.collect.ImmutableMultimap;
-import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.ImmutableSortedSet;
 
 /**
@@ -101,7 +100,7 @@
 			builder.add(new CrawlElement(crawlElement));
 		}
 		for (CrawlElement crawlElement : inputSpecification.getCrawlElements()) {
-			builder.add(new TagElement(crawlElement));
+			builder.add(new CrawlElement(crawlElement));
 		}
 		return builder.build();
 	}
@@ -252,8 +251,8 @@
 		// performance problems.
 		ImmutableList<String> expressions = getFullXpathForGivenXpath(dom, eventableCondition);
 
-		NodeList nodeList = dom.getElementsByTagName(tag.getName());
-		ImmutableSet<TagAttribute> attributes = tag.getAttributes();
+		NodeList nodeList = dom.getElementsByTagName(tag.getTagName());
+		ImmutableList<CrawlAttribute> attributes = tag.getCrawlAttributes();
 
 		for (int k = 0; k < nodeList.getLength(); k++) {
 
@@ -312,8 +311,8 @@
 		return ImmutableList.<String> of();
 	}
 
-	private void addElement(Element element, Builder<Element> builder, TagElement tagElement) {
-		if (""A"".equalsIgnoreCase(tagElement.getName())) {
+	private void addElement(Element element, Builder<Element> builder, CrawlElement crawlElement) {
+		if (""A"".equalsIgnoreCase(crawlElement.getTagName())) {
 			String href = element.getAttribute(""href"");
 			if (!Strings.isNullOrEmpty(href)) {
 				boolean isExternal = UrlUtils.isLinkExternal(browser.getCurrentUrl(), href);
"
e1e702c219a847781d23bd64f79058e01a9ec4ed,Gord Larson,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index f38d691..6a2a5ae 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -4,7 +4,6 @@
 
 import net.jcip.annotations.GuardedBy;
 
-import org.apache.commons.configuration.ConfigurationException;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
"
e1e702c219a847781d23bd64f79058e01a9ec4ed,Gord Larson,CrawlActionsBuilder.java,MODIFY,click -> [String tagNames] | [String tagName],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
index 0c6b6b3..c6b5a4e 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
@@ -6,7 +6,6 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.crawljax.condition.Condition;
 import com.crawljax.core.state.Eventable.EventType;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
"
e1e702c219a847781d23bd64f79058e01a9ec4ed,Gord Larson,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 679244f..f631880 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -3,11 +3,11 @@
 import static com.google.common.base.Preconditions.checkArgument;
 
 import java.net.MalformedURLException;
+import java.net.URISyntaxException;
 import java.net.URL;
 import java.util.concurrent.TimeUnit;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
-import com.crawljax.core.Crawler;
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
@@ -223,7 +223,11 @@
 		result =
 		        prime * result
 		                + ((proxyConfiguration == null) ? 0 : proxyConfiguration.hashCode());
-		result = prime * result + ((url == null) ? 0 : url.hashCode());
+		try {
+			result = prime * result + ((url == null) ? 0 : url.toURI().hashCode());
+		} catch (URISyntaxException e) {
+			result = prime * result;
+		}
 		return result;
 	}
 
@@ -232,13 +236,17 @@
 		if (this == obj) {
 			return true;
 		}
+		
 		if (obj == null) {
 			return false;
 		}
+		
 		if (getClass() != obj.getClass()) {
 			return false;
 		}
+		
 		CrawljaxConfiguration other = (CrawljaxConfiguration) obj;
+		
 		if (browserConfig == null) {
 			if (other.browserConfig != null) {
 				return false;
@@ -246,6 +254,7 @@
 		} else if (!browserConfig.equals(other.browserConfig)) {
 			return false;
 		}
+		
 		if (crawlRules == null) {
 			if (other.crawlRules != null) {
 				return false;
@@ -253,15 +262,19 @@
 		} else if (!crawlRules.equals(other.crawlRules)) {
 			return false;
 		}
+		
 		if (maximumDepth != other.maximumDepth) {
 			return false;
 		}
+		
 		if (maximumRuntime != other.maximumRuntime) {
 			return false;
 		}
+		
 		if (maximumStates != other.maximumStates) {
 			return false;
 		}
+		
 		if (plugins == null) {
 			if (other.plugins != null) {
 				return false;
@@ -269,6 +282,7 @@
 		} else if (!plugins.equals(other.plugins)) {
 			return false;
 		}
+		
 		if (proxyConfiguration == null) {
 			if (other.proxyConfiguration != null) {
 				return false;
@@ -276,13 +290,19 @@
 		} else if (!proxyConfiguration.equals(other.proxyConfiguration)) {
 			return false;
 		}
-		if (url == null) {
-			if (other.url != null) {
+		
+		try {
+			if (url == null) {
+				if (other.url != null) {
+					return false;
+				}
+			} else if (!url.toURI().equals(other.url.toURI())) {
 				return false;
 			}
-		} else if (!url.equals(other.url)) {
-			return false;
+		} catch( URISyntaxException e) {
+			return false; 
 		}
+		
 		return true;
 	}
 
"
e1e702c219a847781d23bd64f79058e01a9ec4ed,Gord Larson,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index e9c9b51..2918262 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -281,8 +281,9 @@
 	 */
 	public static String getTextValue(Element element) {
 		String ret = """";
-		if (element.getTextContent() != null) {
-			ret = element.getTextContent();
+		String textContent = element.getTextContent(); 
+		if (textContent != null && !textContent.equals("""") ) {
+			ret = textContent;
 		} else if (element.hasAttribute(""title"")) {
 			ret = element.getAttribute(""title"");
 		} else if (element.hasAttribute(""alt"")) {
@@ -409,8 +410,8 @@
 	 */
 	private static String getFileNameInPath(String path) {
 		String fname;
-		if (path.indexOf(""/"") != -1) {
-			fname = path.substring(path.lastIndexOf(""/"") + 1);
+		if (path.indexOf('/') != -1) {
+			fname = path.substring(path.lastIndexOf('/') + 1);
 		} else {
 			fname = path;
 		}
"
e1e702c219a847781d23bd64f79058e01a9ec4ed,Gord Larson,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index 8d44723..85af1cd 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -22,9 +22,6 @@
 public class ElementResolver {
 	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class.getName());
 
-	// private ElementResolverSettings settings = new
-	// ElementResolverSettings();
-
 	private final EmbeddedBrowser browser;
 	private final Eventable eventable;
 
"
e1e702c219a847781d23bd64f79058e01a9ec4ed,Gord Larson,PrettyHTML.java,MODIFY,"prettyHTML -> [String html] | [String html, String strIndent]","diff --git a/core/src/main/java/com/crawljax/util/PrettyHTML.java b/core/src/main/java/com/crawljax/util/PrettyHTML.java
index d67a0eb..ebb128e 100644
--- a/core/src/main/java/com/crawljax/util/PrettyHTML.java
+++ b/core/src/main/java/com/crawljax/util/PrettyHTML.java
@@ -13,9 +13,6 @@
 
 	}
 
-	// private static final Logger LOGGER =
-	// LoggerFactory.getLogger(PrettyHTML.class.getName());
-
 	/**
 	 * Pretty print HTML string.
 	 * 
@@ -97,10 +94,10 @@
 	 * @return wheter element has a seperate closing element
 	 */
 	private static boolean elementsRelated(String openElement, String closeElement) {
-		openElement = openElement.split("">"")[0];
-		openElement = openElement.split("" "")[0];
-		closeElement = closeElement.split("">"")[0];
-		return closeElement.startsWith(""/"" + openElement);
+		String testOpen = openElement.split("">"")[0];
+		testOpen = testOpen.split("" "")[0];
+		String testClose = closeElement.split("">"")[0];
+		return testClose.startsWith(""/"" + testOpen);
 	}
 
 	/**
@@ -145,14 +142,14 @@
 						// stack
 						int index = stackIndexElements.peek();
 						if (!isSingleElement(elements[index])
-						        && elements[index].lastIndexOf("">"") != -1) {
+						        && elements[index].lastIndexOf('>') != -1) {
 							// close this element
 							elements[index] =
 							        elements[index]
-							                .substring(0, elements[index].lastIndexOf("">""))
+							                .substring(0, elements[index].lastIndexOf('>'))
 							                + ""/""
 							                + elements[index].substring(elements[index]
-							                        .lastIndexOf("">""));
+							                        .lastIndexOf('>'));
 						}
 						stackElements.pop();
 						stackIndexElements.pop();
"
e1e702c219a847781d23bd64f79058e01a9ec4ed,Gord Larson,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 05cdb79..0bc8d5f 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -237,9 +237,9 @@
 	 * @return position of xpath element, if fails returns -1
 	 **/
 	public static int getXPathLocation(String dom, String xpath) {
-		dom = dom.toLowerCase();
-		xpath = xpath.toLowerCase();
-		String[] elements = xpath.split(""/"");
+		String dom_lower = dom.toLowerCase();
+		String xpath_lower = xpath.toLowerCase();
+		String[] elements = xpath_lower.split(""/"");
 		int pos = 0;
 		int temp;
 		int number;
@@ -258,7 +258,7 @@
 				}
 				for (int i = 0; i < number; i++) {
 					// find new open element
-					temp = dom.indexOf(""<"" + stripEndSquareBrackets(element), pos);
+					temp = dom_lower.indexOf(""<"" + stripEndSquareBrackets(element), pos);
 
 					if (temp > -1) {
 						pos = temp + 1;
@@ -266,7 +266,7 @@
 						// if depth>1 then goto end of current element
 						if (number > 1 && i < number - 1) {
 							pos =
-							        getCloseElementLocation(dom, pos,
+							        getCloseElementLocation(dom_lower, pos,
 							                stripEndSquareBrackets(element));
 						}
 
@@ -290,34 +290,35 @@
 		String[] elements = { ""LINK"", ""META"", ""INPUT"", ""BR"" };
 		List<String> singleElements = Arrays.asList(elements);
 		if (singleElements.contains(element.toUpperCase())) {
-			return dom.indexOf("">"", pos) + 1;
+			return dom.indexOf('>', pos) + 1;
 		}
 		// make sure not before the node
 		int openElements = 1;
 		int i = 0;
-		dom = dom.toLowerCase();
-		element = element.toLowerCase();
-		String openElement = ""<"" + element;
-		String closeElement = ""</"" + element;
+		int position = pos; 
+		String dom_lower = dom.toLowerCase();
+		String element_lower = element.toLowerCase();
+		String openElement = ""<"" + element_lower;
+		String closeElement = ""</"" + element_lower;
 		while (i < MAX_SEARCH_LOOPS) {
-			if (dom.indexOf(openElement, pos) == -1 && dom.indexOf(closeElement, pos) == -1) {
+			if (dom_lower.indexOf(openElement, position) == -1 && dom_lower.indexOf(closeElement, position) == -1) {
 				return -1;
 			}
-			if (dom.indexOf(openElement, pos) < dom.indexOf(closeElement, pos)
-			        && dom.indexOf(openElement, pos) != -1) {
+			if (dom_lower.indexOf(openElement, position) < dom_lower.indexOf(closeElement, position)
+			        && dom_lower.indexOf(openElement, position) != -1) {
 				openElements++;
-				pos = dom.indexOf(openElement, pos) + 1;
+				position = dom_lower.indexOf(openElement, position) + 1;
 			} else {
 
 				openElements--;
-				pos = dom.indexOf(closeElement, pos) + 1;
+				position = dom_lower.indexOf(closeElement, position) + 1;
 			}
 			if (openElements == 0) {
 				break;
 			}
 			i++;
 		}
-		return pos - 1;
+		return position - 1;
 
 	}
 
@@ -340,19 +341,21 @@
 	 *         text()
 	 */
 	public static String stripXPathToElement(String xpath) {
-		if (!Strings.isNullOrEmpty(xpath)) {
-			if (xpath.toLowerCase().contains(""/text()"")) {
-				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/text()""));
+		String xpathStripped = xpath; 
+		
+		if (!Strings.isNullOrEmpty(xpathStripped)) {
+			if (xpathStripped.toLowerCase().contains(""/text()"")) {
+				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/text()""));
 			}
-			if (xpath.toLowerCase().contains(""/comment()"")) {
-				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/comment()""));
+			if (xpathStripped.toLowerCase().contains(""/comment()"")) {
+				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/comment()""));
 			}
-			if (xpath.contains(""@"")) {
-				xpath = xpath.substring(0, xpath.indexOf(""@"") - 1);
+			if (xpathStripped.contains(""@"")) {
+				xpathStripped = xpathStripped.substring(0, xpathStripped.indexOf(""@"") - 1);
 			}
 		}
 
-		return xpath;
+		return xpathStripped;
 	}
 
 	private XPathHelper() {
"
eaaa4aebe99abc72465b6f0c27ac66de9c64a259,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index f38d691..15c169c 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -26,12 +26,7 @@
  */
 public class CrawljaxController implements CrawlQueueManager {
 
-	private static final Logger LOGGER = LoggerFactory.getLogger(CrawljaxController.class
-	        .getName());
-
-	private CrawlSession session;
-
-	private long startCrawl;
+	private static final Logger LOGGER = LoggerFactory.getLogger(CrawljaxController.class);
 
 	private final StateComparator stateComparator;
 	private final ConditionTypeChecker<CrawlCondition> crawlConditionChecker;
@@ -39,9 +34,6 @@
 
 	private final WaitConditionChecker waitConditionChecker = new WaitConditionChecker();
 
-	// TODO Stefan, Can not be final because, must be created after the loading of the plugins
-	private Crawler initialCrawler;
-
 	private final CrawljaxConfiguration configuration;
 
 	private final ImmutableList<Invariant> invariantList;
@@ -55,6 +47,12 @@
 
 	private final BrowserPool browserPool;
 
+	// TODO Stefan, Can not be final because, must be created after the loading of the plugins
+	private Crawler initialCrawler;
+	private CrawlSession session;
+
+	private long startCrawl;
+
 	/**
 	 * @param config
 	 *            the crawljax configuration.
"
eaaa4aebe99abc72465b6f0c27ac66de9c64a259,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 679244f..7bcc74b 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -7,13 +7,18 @@
 import java.util.concurrent.TimeUnit;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
+import com.crawljax.core.CrawlController;
 import com.crawljax.core.Crawler;
+import com.crawljax.core.CrawljaxController;
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.core.plugin.Plugins;
+import com.crawljax.di.CoreModule;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
+import com.google.inject.Guice;
+import com.google.inject.Injector;
 
 /**
  * Configures the {@link Crawler}. Set it up using the {@link #builderFor(String)} function.
@@ -138,6 +143,11 @@
 			return config;
 		}
 
+		public CrawlController buildControl() {
+			Injector injector = Guice.createInjector(new CoreModule(build()));
+			return injector.getInstance(CrawlController.class);
+		}
+
 	}
 
 	/**
"
711f06ec572bc76f5d97206d5064a19ad6779f30,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index f38d691..6a2a5ae 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -4,7 +4,6 @@
 
 import net.jcip.annotations.GuardedBy;
 
-import org.apache.commons.configuration.ConfigurationException;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
"
711f06ec572bc76f5d97206d5064a19ad6779f30,Alex Nederlof,CrawlActionsBuilder.java,MODIFY,click -> [String tagNames] | [String tagName],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
index 0c6b6b3..c6b5a4e 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
@@ -6,7 +6,6 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.crawljax.condition.Condition;
 import com.crawljax.core.state.Eventable.EventType;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
"
711f06ec572bc76f5d97206d5064a19ad6779f30,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 679244f..f631880 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -3,11 +3,11 @@
 import static com.google.common.base.Preconditions.checkArgument;
 
 import java.net.MalformedURLException;
+import java.net.URISyntaxException;
 import java.net.URL;
 import java.util.concurrent.TimeUnit;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
-import com.crawljax.core.Crawler;
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
@@ -223,7 +223,11 @@
 		result =
 		        prime * result
 		                + ((proxyConfiguration == null) ? 0 : proxyConfiguration.hashCode());
-		result = prime * result + ((url == null) ? 0 : url.hashCode());
+		try {
+			result = prime * result + ((url == null) ? 0 : url.toURI().hashCode());
+		} catch (URISyntaxException e) {
+			result = prime * result;
+		}
 		return result;
 	}
 
@@ -232,13 +236,17 @@
 		if (this == obj) {
 			return true;
 		}
+		
 		if (obj == null) {
 			return false;
 		}
+		
 		if (getClass() != obj.getClass()) {
 			return false;
 		}
+		
 		CrawljaxConfiguration other = (CrawljaxConfiguration) obj;
+		
 		if (browserConfig == null) {
 			if (other.browserConfig != null) {
 				return false;
@@ -246,6 +254,7 @@
 		} else if (!browserConfig.equals(other.browserConfig)) {
 			return false;
 		}
+		
 		if (crawlRules == null) {
 			if (other.crawlRules != null) {
 				return false;
@@ -253,15 +262,19 @@
 		} else if (!crawlRules.equals(other.crawlRules)) {
 			return false;
 		}
+		
 		if (maximumDepth != other.maximumDepth) {
 			return false;
 		}
+		
 		if (maximumRuntime != other.maximumRuntime) {
 			return false;
 		}
+		
 		if (maximumStates != other.maximumStates) {
 			return false;
 		}
+		
 		if (plugins == null) {
 			if (other.plugins != null) {
 				return false;
@@ -269,6 +282,7 @@
 		} else if (!plugins.equals(other.plugins)) {
 			return false;
 		}
+		
 		if (proxyConfiguration == null) {
 			if (other.proxyConfiguration != null) {
 				return false;
@@ -276,13 +290,19 @@
 		} else if (!proxyConfiguration.equals(other.proxyConfiguration)) {
 			return false;
 		}
-		if (url == null) {
-			if (other.url != null) {
+		
+		try {
+			if (url == null) {
+				if (other.url != null) {
+					return false;
+				}
+			} else if (!url.toURI().equals(other.url.toURI())) {
 				return false;
 			}
-		} else if (!url.equals(other.url)) {
-			return false;
+		} catch( URISyntaxException e) {
+			return false; 
 		}
+		
 		return true;
 	}
 
"
711f06ec572bc76f5d97206d5064a19ad6779f30,Alex Nederlof,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index e9c9b51..2918262 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -281,8 +281,9 @@
 	 */
 	public static String getTextValue(Element element) {
 		String ret = """";
-		if (element.getTextContent() != null) {
-			ret = element.getTextContent();
+		String textContent = element.getTextContent(); 
+		if (textContent != null && !textContent.equals("""") ) {
+			ret = textContent;
 		} else if (element.hasAttribute(""title"")) {
 			ret = element.getAttribute(""title"");
 		} else if (element.hasAttribute(""alt"")) {
@@ -409,8 +410,8 @@
 	 */
 	private static String getFileNameInPath(String path) {
 		String fname;
-		if (path.indexOf(""/"") != -1) {
-			fname = path.substring(path.lastIndexOf(""/"") + 1);
+		if (path.indexOf('/') != -1) {
+			fname = path.substring(path.lastIndexOf('/') + 1);
 		} else {
 			fname = path;
 		}
"
711f06ec572bc76f5d97206d5064a19ad6779f30,Alex Nederlof,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index 8d44723..85af1cd 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -22,9 +22,6 @@
 public class ElementResolver {
 	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class.getName());
 
-	// private ElementResolverSettings settings = new
-	// ElementResolverSettings();
-
 	private final EmbeddedBrowser browser;
 	private final Eventable eventable;
 
"
711f06ec572bc76f5d97206d5064a19ad6779f30,Alex Nederlof,PrettyHTML.java,MODIFY,"prettyHTML -> [String html] | [String html, String strIndent]","diff --git a/core/src/main/java/com/crawljax/util/PrettyHTML.java b/core/src/main/java/com/crawljax/util/PrettyHTML.java
index d67a0eb..ebb128e 100644
--- a/core/src/main/java/com/crawljax/util/PrettyHTML.java
+++ b/core/src/main/java/com/crawljax/util/PrettyHTML.java
@@ -13,9 +13,6 @@
 
 	}
 
-	// private static final Logger LOGGER =
-	// LoggerFactory.getLogger(PrettyHTML.class.getName());
-
 	/**
 	 * Pretty print HTML string.
 	 * 
@@ -97,10 +94,10 @@
 	 * @return wheter element has a seperate closing element
 	 */
 	private static boolean elementsRelated(String openElement, String closeElement) {
-		openElement = openElement.split("">"")[0];
-		openElement = openElement.split("" "")[0];
-		closeElement = closeElement.split("">"")[0];
-		return closeElement.startsWith(""/"" + openElement);
+		String testOpen = openElement.split("">"")[0];
+		testOpen = testOpen.split("" "")[0];
+		String testClose = closeElement.split("">"")[0];
+		return testClose.startsWith(""/"" + testOpen);
 	}
 
 	/**
@@ -145,14 +142,14 @@
 						// stack
 						int index = stackIndexElements.peek();
 						if (!isSingleElement(elements[index])
-						        && elements[index].lastIndexOf("">"") != -1) {
+						        && elements[index].lastIndexOf('>') != -1) {
 							// close this element
 							elements[index] =
 							        elements[index]
-							                .substring(0, elements[index].lastIndexOf("">""))
+							                .substring(0, elements[index].lastIndexOf('>'))
 							                + ""/""
 							                + elements[index].substring(elements[index]
-							                        .lastIndexOf("">""));
+							                        .lastIndexOf('>'));
 						}
 						stackElements.pop();
 						stackIndexElements.pop();
"
711f06ec572bc76f5d97206d5064a19ad6779f30,Alex Nederlof,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 05cdb79..0bc8d5f 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -237,9 +237,9 @@
 	 * @return position of xpath element, if fails returns -1
 	 **/
 	public static int getXPathLocation(String dom, String xpath) {
-		dom = dom.toLowerCase();
-		xpath = xpath.toLowerCase();
-		String[] elements = xpath.split(""/"");
+		String dom_lower = dom.toLowerCase();
+		String xpath_lower = xpath.toLowerCase();
+		String[] elements = xpath_lower.split(""/"");
 		int pos = 0;
 		int temp;
 		int number;
@@ -258,7 +258,7 @@
 				}
 				for (int i = 0; i < number; i++) {
 					// find new open element
-					temp = dom.indexOf(""<"" + stripEndSquareBrackets(element), pos);
+					temp = dom_lower.indexOf(""<"" + stripEndSquareBrackets(element), pos);
 
 					if (temp > -1) {
 						pos = temp + 1;
@@ -266,7 +266,7 @@
 						// if depth>1 then goto end of current element
 						if (number > 1 && i < number - 1) {
 							pos =
-							        getCloseElementLocation(dom, pos,
+							        getCloseElementLocation(dom_lower, pos,
 							                stripEndSquareBrackets(element));
 						}
 
@@ -290,34 +290,35 @@
 		String[] elements = { ""LINK"", ""META"", ""INPUT"", ""BR"" };
 		List<String> singleElements = Arrays.asList(elements);
 		if (singleElements.contains(element.toUpperCase())) {
-			return dom.indexOf("">"", pos) + 1;
+			return dom.indexOf('>', pos) + 1;
 		}
 		// make sure not before the node
 		int openElements = 1;
 		int i = 0;
-		dom = dom.toLowerCase();
-		element = element.toLowerCase();
-		String openElement = ""<"" + element;
-		String closeElement = ""</"" + element;
+		int position = pos; 
+		String dom_lower = dom.toLowerCase();
+		String element_lower = element.toLowerCase();
+		String openElement = ""<"" + element_lower;
+		String closeElement = ""</"" + element_lower;
 		while (i < MAX_SEARCH_LOOPS) {
-			if (dom.indexOf(openElement, pos) == -1 && dom.indexOf(closeElement, pos) == -1) {
+			if (dom_lower.indexOf(openElement, position) == -1 && dom_lower.indexOf(closeElement, position) == -1) {
 				return -1;
 			}
-			if (dom.indexOf(openElement, pos) < dom.indexOf(closeElement, pos)
-			        && dom.indexOf(openElement, pos) != -1) {
+			if (dom_lower.indexOf(openElement, position) < dom_lower.indexOf(closeElement, position)
+			        && dom_lower.indexOf(openElement, position) != -1) {
 				openElements++;
-				pos = dom.indexOf(openElement, pos) + 1;
+				position = dom_lower.indexOf(openElement, position) + 1;
 			} else {
 
 				openElements--;
-				pos = dom.indexOf(closeElement, pos) + 1;
+				position = dom_lower.indexOf(closeElement, position) + 1;
 			}
 			if (openElements == 0) {
 				break;
 			}
 			i++;
 		}
-		return pos - 1;
+		return position - 1;
 
 	}
 
@@ -340,19 +341,21 @@
 	 *         text()
 	 */
 	public static String stripXPathToElement(String xpath) {
-		if (!Strings.isNullOrEmpty(xpath)) {
-			if (xpath.toLowerCase().contains(""/text()"")) {
-				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/text()""));
+		String xpathStripped = xpath; 
+		
+		if (!Strings.isNullOrEmpty(xpathStripped)) {
+			if (xpathStripped.toLowerCase().contains(""/text()"")) {
+				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/text()""));
 			}
-			if (xpath.toLowerCase().contains(""/comment()"")) {
-				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/comment()""));
+			if (xpathStripped.toLowerCase().contains(""/comment()"")) {
+				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/comment()""));
 			}
-			if (xpath.contains(""@"")) {
-				xpath = xpath.substring(0, xpath.indexOf(""@"") - 1);
+			if (xpathStripped.contains(""@"")) {
+				xpathStripped = xpathStripped.substring(0, xpathStripped.indexOf(""@"") - 1);
 			}
 		}
 
-		return xpath;
+		return xpathStripped;
 	}
 
 	private XPathHelper() {
"
6741efc5f4ee27271b15350f36b977688609b3fb,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index 15c169c..ba3acd0 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -4,7 +4,6 @@
 
 import net.jcip.annotations.GuardedBy;
 
-import org.apache.commons.configuration.ConfigurationException;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
"
6741efc5f4ee27271b15350f36b977688609b3fb,Alex Nederlof,CrawlActionsBuilder.java,MODIFY,click -> [String tagNames] | [String tagName],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
index 0c6b6b3..c6b5a4e 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
@@ -6,7 +6,6 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.crawljax.condition.Condition;
 import com.crawljax.core.state.Eventable.EventType;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
"
6741efc5f4ee27271b15350f36b977688609b3fb,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 7bcc74b..b748731 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -3,12 +3,12 @@
 import static com.google.common.base.Preconditions.checkArgument;
 
 import java.net.MalformedURLException;
+import java.net.URISyntaxException;
 import java.net.URL;
 import java.util.concurrent.TimeUnit;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.core.CrawlController;
-import com.crawljax.core.Crawler;
 import com.crawljax.core.CrawljaxController;
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
@@ -233,7 +233,11 @@
 		result =
 		        prime * result
 		                + ((proxyConfiguration == null) ? 0 : proxyConfiguration.hashCode());
-		result = prime * result + ((url == null) ? 0 : url.hashCode());
+		try {
+			result = prime * result + ((url == null) ? 0 : url.toURI().hashCode());
+		} catch (URISyntaxException e) {
+			result = prime * result;
+		}
 		return result;
 	}
 
@@ -242,13 +246,17 @@
 		if (this == obj) {
 			return true;
 		}
+		
 		if (obj == null) {
 			return false;
 		}
+		
 		if (getClass() != obj.getClass()) {
 			return false;
 		}
+		
 		CrawljaxConfiguration other = (CrawljaxConfiguration) obj;
+		
 		if (browserConfig == null) {
 			if (other.browserConfig != null) {
 				return false;
@@ -256,6 +264,7 @@
 		} else if (!browserConfig.equals(other.browserConfig)) {
 			return false;
 		}
+		
 		if (crawlRules == null) {
 			if (other.crawlRules != null) {
 				return false;
@@ -263,15 +272,19 @@
 		} else if (!crawlRules.equals(other.crawlRules)) {
 			return false;
 		}
+		
 		if (maximumDepth != other.maximumDepth) {
 			return false;
 		}
+		
 		if (maximumRuntime != other.maximumRuntime) {
 			return false;
 		}
+		
 		if (maximumStates != other.maximumStates) {
 			return false;
 		}
+		
 		if (plugins == null) {
 			if (other.plugins != null) {
 				return false;
@@ -279,6 +292,7 @@
 		} else if (!plugins.equals(other.plugins)) {
 			return false;
 		}
+		
 		if (proxyConfiguration == null) {
 			if (other.proxyConfiguration != null) {
 				return false;
@@ -286,13 +300,19 @@
 		} else if (!proxyConfiguration.equals(other.proxyConfiguration)) {
 			return false;
 		}
-		if (url == null) {
-			if (other.url != null) {
+		
+		try {
+			if (url == null) {
+				if (other.url != null) {
+					return false;
+				}
+			} else if (!url.toURI().equals(other.url.toURI())) {
 				return false;
 			}
-		} else if (!url.equals(other.url)) {
-			return false;
+		} catch( URISyntaxException e) {
+			return false; 
 		}
+		
 		return true;
 	}
 
"
6741efc5f4ee27271b15350f36b977688609b3fb,Alex Nederlof,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index e9c9b51..2918262 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -281,8 +281,9 @@
 	 */
 	public static String getTextValue(Element element) {
 		String ret = """";
-		if (element.getTextContent() != null) {
-			ret = element.getTextContent();
+		String textContent = element.getTextContent(); 
+		if (textContent != null && !textContent.equals("""") ) {
+			ret = textContent;
 		} else if (element.hasAttribute(""title"")) {
 			ret = element.getAttribute(""title"");
 		} else if (element.hasAttribute(""alt"")) {
@@ -409,8 +410,8 @@
 	 */
 	private static String getFileNameInPath(String path) {
 		String fname;
-		if (path.indexOf(""/"") != -1) {
-			fname = path.substring(path.lastIndexOf(""/"") + 1);
+		if (path.indexOf('/') != -1) {
+			fname = path.substring(path.lastIndexOf('/') + 1);
 		} else {
 			fname = path;
 		}
"
6741efc5f4ee27271b15350f36b977688609b3fb,Alex Nederlof,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index 8d44723..85af1cd 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -22,9 +22,6 @@
 public class ElementResolver {
 	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class.getName());
 
-	// private ElementResolverSettings settings = new
-	// ElementResolverSettings();
-
 	private final EmbeddedBrowser browser;
 	private final Eventable eventable;
 
"
6741efc5f4ee27271b15350f36b977688609b3fb,Alex Nederlof,PrettyHTML.java,MODIFY,"prettyHTML -> [String html] | [String html, String strIndent]","diff --git a/core/src/main/java/com/crawljax/util/PrettyHTML.java b/core/src/main/java/com/crawljax/util/PrettyHTML.java
index d67a0eb..ebb128e 100644
--- a/core/src/main/java/com/crawljax/util/PrettyHTML.java
+++ b/core/src/main/java/com/crawljax/util/PrettyHTML.java
@@ -13,9 +13,6 @@
 
 	}
 
-	// private static final Logger LOGGER =
-	// LoggerFactory.getLogger(PrettyHTML.class.getName());
-
 	/**
 	 * Pretty print HTML string.
 	 * 
@@ -97,10 +94,10 @@
 	 * @return wheter element has a seperate closing element
 	 */
 	private static boolean elementsRelated(String openElement, String closeElement) {
-		openElement = openElement.split("">"")[0];
-		openElement = openElement.split("" "")[0];
-		closeElement = closeElement.split("">"")[0];
-		return closeElement.startsWith(""/"" + openElement);
+		String testOpen = openElement.split("">"")[0];
+		testOpen = testOpen.split("" "")[0];
+		String testClose = closeElement.split("">"")[0];
+		return testClose.startsWith(""/"" + testOpen);
 	}
 
 	/**
@@ -145,14 +142,14 @@
 						// stack
 						int index = stackIndexElements.peek();
 						if (!isSingleElement(elements[index])
-						        && elements[index].lastIndexOf("">"") != -1) {
+						        && elements[index].lastIndexOf('>') != -1) {
 							// close this element
 							elements[index] =
 							        elements[index]
-							                .substring(0, elements[index].lastIndexOf("">""))
+							                .substring(0, elements[index].lastIndexOf('>'))
 							                + ""/""
 							                + elements[index].substring(elements[index]
-							                        .lastIndexOf("">""));
+							                        .lastIndexOf('>'));
 						}
 						stackElements.pop();
 						stackIndexElements.pop();
"
6741efc5f4ee27271b15350f36b977688609b3fb,Alex Nederlof,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 05cdb79..0bc8d5f 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -237,9 +237,9 @@
 	 * @return position of xpath element, if fails returns -1
 	 **/
 	public static int getXPathLocation(String dom, String xpath) {
-		dom = dom.toLowerCase();
-		xpath = xpath.toLowerCase();
-		String[] elements = xpath.split(""/"");
+		String dom_lower = dom.toLowerCase();
+		String xpath_lower = xpath.toLowerCase();
+		String[] elements = xpath_lower.split(""/"");
 		int pos = 0;
 		int temp;
 		int number;
@@ -258,7 +258,7 @@
 				}
 				for (int i = 0; i < number; i++) {
 					// find new open element
-					temp = dom.indexOf(""<"" + stripEndSquareBrackets(element), pos);
+					temp = dom_lower.indexOf(""<"" + stripEndSquareBrackets(element), pos);
 
 					if (temp > -1) {
 						pos = temp + 1;
@@ -266,7 +266,7 @@
 						// if depth>1 then goto end of current element
 						if (number > 1 && i < number - 1) {
 							pos =
-							        getCloseElementLocation(dom, pos,
+							        getCloseElementLocation(dom_lower, pos,
 							                stripEndSquareBrackets(element));
 						}
 
@@ -290,34 +290,35 @@
 		String[] elements = { ""LINK"", ""META"", ""INPUT"", ""BR"" };
 		List<String> singleElements = Arrays.asList(elements);
 		if (singleElements.contains(element.toUpperCase())) {
-			return dom.indexOf("">"", pos) + 1;
+			return dom.indexOf('>', pos) + 1;
 		}
 		// make sure not before the node
 		int openElements = 1;
 		int i = 0;
-		dom = dom.toLowerCase();
-		element = element.toLowerCase();
-		String openElement = ""<"" + element;
-		String closeElement = ""</"" + element;
+		int position = pos; 
+		String dom_lower = dom.toLowerCase();
+		String element_lower = element.toLowerCase();
+		String openElement = ""<"" + element_lower;
+		String closeElement = ""</"" + element_lower;
 		while (i < MAX_SEARCH_LOOPS) {
-			if (dom.indexOf(openElement, pos) == -1 && dom.indexOf(closeElement, pos) == -1) {
+			if (dom_lower.indexOf(openElement, position) == -1 && dom_lower.indexOf(closeElement, position) == -1) {
 				return -1;
 			}
-			if (dom.indexOf(openElement, pos) < dom.indexOf(closeElement, pos)
-			        && dom.indexOf(openElement, pos) != -1) {
+			if (dom_lower.indexOf(openElement, position) < dom_lower.indexOf(closeElement, position)
+			        && dom_lower.indexOf(openElement, position) != -1) {
 				openElements++;
-				pos = dom.indexOf(openElement, pos) + 1;
+				position = dom_lower.indexOf(openElement, position) + 1;
 			} else {
 
 				openElements--;
-				pos = dom.indexOf(closeElement, pos) + 1;
+				position = dom_lower.indexOf(closeElement, position) + 1;
 			}
 			if (openElements == 0) {
 				break;
 			}
 			i++;
 		}
-		return pos - 1;
+		return position - 1;
 
 	}
 
@@ -340,19 +341,21 @@
 	 *         text()
 	 */
 	public static String stripXPathToElement(String xpath) {
-		if (!Strings.isNullOrEmpty(xpath)) {
-			if (xpath.toLowerCase().contains(""/text()"")) {
-				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/text()""));
+		String xpathStripped = xpath; 
+		
+		if (!Strings.isNullOrEmpty(xpathStripped)) {
+			if (xpathStripped.toLowerCase().contains(""/text()"")) {
+				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/text()""));
 			}
-			if (xpath.toLowerCase().contains(""/comment()"")) {
-				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/comment()""));
+			if (xpathStripped.toLowerCase().contains(""/comment()"")) {
+				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/comment()""));
 			}
-			if (xpath.contains(""@"")) {
-				xpath = xpath.substring(0, xpath.indexOf(""@"") - 1);
+			if (xpathStripped.contains(""@"")) {
+				xpathStripped = xpathStripped.substring(0, xpathStripped.indexOf(""@"") - 1);
 			}
 		}
 
-		return xpath;
+		return xpathStripped;
 	}
 
 	private XPathHelper() {
"
77a5b0da22f80a908885c34c6c1d88c64b727adb,Alex Nederlof,BrowserConfiguration.java,MODIFY,equals -> [Object obj] | [Object object],"diff --git a/core/src/main/java/com/crawljax/core/configuration/BrowserConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/BrowserConfiguration.java
index ac686a1..9f57f7b 100644
--- a/core/src/main/java/com/crawljax/core/configuration/BrowserConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/BrowserConfiguration.java
@@ -7,6 +7,7 @@
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.browser.EmbeddedBrowserBuilder;
 import com.crawljax.browser.WebDriverBrowserBuilder;
+import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
 
 @Immutable
@@ -117,53 +118,6 @@
 		return bootstrap;
 	}
 
-	@Override
-	public int hashCode() {
-		final int prime = 31;
-		int result = 1;
-		result = prime * result + (bootstrap ? 1231 : 1237);
-		result = prime * result + ((browsertype == null) ? 0 : browsertype.hashCode());
-		result = prime * result + numberOfBrowsers;
-		return result;
-	}
-
-	@Override
-	public boolean equals(Object obj) {
-		if (this == obj) {
-			return true;
-		}
-		if (obj == null) {
-			return false;
-		}
-		if (getClass() != obj.getClass()) {
-			return false;
-		}
-		BrowserConfiguration other = (BrowserConfiguration) obj;
-		if (bootstrap != other.bootstrap) {
-			return false;
-		}
-		if (browsertype != other.browsertype) {
-			return false;
-		}
-		if (numberOfBrowsers != other.numberOfBrowsers) {
-			return false;
-		}
-		return true;
-	}
-
-	@Override
-	public String toString() {
-		StringBuilder builder = new StringBuilder();
-		builder.append(""BrowserConfiguration [browsertype="");
-		builder.append(browsertype);
-		builder.append("", numberOfBrowsers="");
-		builder.append(numberOfBrowsers);
-		builder.append("", bootstrap="");
-		builder.append(bootstrap);
-		builder.append(""]"");
-		return builder.toString();
-	}
-
 	public EmbeddedBrowserBuilder getBrowserBuilder() {
 		return browserBuilder;
 	}
@@ -172,4 +126,34 @@
 		return remoteHubUrl;
 	}
 
+	@Override
+	public String toString() {
+		return Objects.toStringHelper(this)
+		        .add(""browsertype"", browsertype)
+		        .add(""numberOfBrowsers"", numberOfBrowsers)
+		        .add(""bootstrap"", bootstrap)
+		        .add(""browserBuilder"", browserBuilder)
+		        .add(""remoteHubUrl"", remoteHubUrl)
+		        .toString();
+	}
+
+	@Override
+	public int hashCode() {
+		return Objects.hashCode(browsertype, numberOfBrowsers, bootstrap, browserBuilder,
+		        remoteHubUrl);
+	}
+
+	@Override
+	public boolean equals(Object object) {
+		if (object instanceof BrowserConfiguration) {
+			BrowserConfiguration that = (BrowserConfiguration) object;
+			return Objects.equal(this.browsertype, that.browsertype)
+			        && Objects.equal(this.numberOfBrowsers, that.numberOfBrowsers)
+			        && Objects.equal(this.bootstrap, that.bootstrap)
+			        && Objects.equal(this.browserBuilder, that.browserBuilder)
+			        && Objects.equal(this.remoteHubUrl, that.remoteHubUrl);
+		}
+		return false;
+	}
+
 }
"
77a5b0da22f80a908885c34c6c1d88c64b727adb,Alex Nederlof,CrawlRules.java,MODIFY,equals -> [Object obj] | [Object object],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlRules.java b/core/src/main/java/com/crawljax/core/configuration/CrawlRules.java
index 4d5d1b8..640abd6 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlRules.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlRules.java
@@ -16,6 +16,7 @@
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableList.Builder;
 import com.google.common.collect.ImmutableSortedSet;
+import com.google.common.base.Objects;
 
 public class CrawlRules {
 
@@ -343,156 +344,6 @@
 		return ignoredFrameIdentifiers;
 	}
 
-	/*
-	 * (non-Javadoc)
-	 * @see java.lang.Object#hashCode()
-	 */
-	@Override
-	public int hashCode() {
-		final int prime = 31;
-		int result = 1;
-		result = prime * result + (clickOnce ? 1231 : 1237);
-		result = prime * result + ((crawlEvents == null) ? 0 : crawlEvents.hashCode());
-		result = prime * result + (crawlFrames ? 1231 : 1237);
-		result = prime * result + (crawlHiddenAnchors ? 1231 : 1237);
-		result =
-		        prime
-		                * result
-		                + ((ignoredFrameIdentifiers == null) ? 0 : ignoredFrameIdentifiers
-		                        .hashCode());
-		result =
-		        prime * result
-		                + ((inputSpecification == null) ? 0 : inputSpecification.hashCode());
-		result = prime * result + ((invariants == null) ? 0 : invariants.hashCode());
-		result =
-		        prime * result + ((oracleComparators == null) ? 0 : oracleComparators.hashCode());
-		result = prime * result + ((preCrawlConfig == null) ? 0 : preCrawlConfig.hashCode());
-		result = prime * result + (randomInputInForms ? 1231 : 1237);
-		result = prime * result + (testInvariantsWhileCrawling ? 1231 : 1237);
-		result = prime * result + (int) (waitAfterEvent ^ (waitAfterEvent >>> 32));
-		result = prime * result + (int) (waitAfterReloadUrl ^ (waitAfterReloadUrl >>> 32));
-		return result;
-	}
-
-	/*
-	 * (non-Javadoc)
-	 * @see java.lang.Object#equals(java.lang.Object)
-	 */
-	@Override
-	public boolean equals(Object obj) {
-		if (this == obj) {
-			return true;
-		}
-		if (obj == null) {
-			return false;
-		}
-		if (getClass() != obj.getClass()) {
-			return false;
-		}
-		CrawlRules other = (CrawlRules) obj;
-		if (clickOnce != other.clickOnce) {
-			return false;
-		}
-		if (crawlEvents == null) {
-			if (other.crawlEvents != null) {
-				return false;
-			}
-		} else if (!crawlEvents.equals(other.crawlEvents)) {
-			return false;
-		}
-		if (crawlFrames != other.crawlFrames) {
-			return false;
-		}
-		if (crawlHiddenAnchors != other.crawlHiddenAnchors) {
-			return false;
-		}
-		if (ignoredFrameIdentifiers == null) {
-			if (other.ignoredFrameIdentifiers != null) {
-				return false;
-			}
-		} else if (!ignoredFrameIdentifiers.equals(other.ignoredFrameIdentifiers)) {
-			return false;
-		}
-		if (inputSpecification == null) {
-			if (other.inputSpecification != null) {
-				return false;
-			}
-		} else if (!inputSpecification.equals(other.inputSpecification)) {
-			return false;
-		}
-		if (invariants == null) {
-			if (other.invariants != null) {
-				return false;
-			}
-		} else if (!invariants.equals(other.invariants)) {
-			return false;
-		}
-		if (oracleComparators == null) {
-			if (other.oracleComparators != null) {
-				return false;
-			}
-		} else if (!oracleComparators.equals(other.oracleComparators)) {
-			return false;
-		}
-		if (preCrawlConfig == null) {
-			if (other.preCrawlConfig != null) {
-				return false;
-			}
-		} else if (!preCrawlConfig.equals(other.preCrawlConfig)) {
-			return false;
-		}
-		if (randomInputInForms != other.randomInputInForms) {
-			return false;
-		}
-		if (testInvariantsWhileCrawling != other.testInvariantsWhileCrawling) {
-			return false;
-		}
-		if (waitAfterEvent != other.waitAfterEvent) {
-			return false;
-		}
-		if (waitAfterReloadUrl != other.waitAfterReloadUrl) {
-			return false;
-		}
-		return true;
-	}
-
-	/*
-	 * (non-Javadoc)
-	 * @see java.lang.Object#toString()
-	 */
-	@Override
-	public String toString() {
-		StringBuilder builder = new StringBuilder();
-		builder.append(""CrawlRules [crawlEvents="");
-		builder.append(crawlEvents);
-		builder.append("", invariants="");
-		builder.append(invariants);
-		builder.append("", oracleComparators="");
-		builder.append(oracleComparators);
-		builder.append("", ignoredFrameIdentifiers="");
-		builder.append(ignoredFrameIdentifiers);
-		builder.append("", preCrawlConfig="");
-		builder.append(preCrawlConfig);
-		builder.append("", randomInputInForms="");
-		builder.append(randomInputInForms);
-		builder.append("", inputSpecification="");
-		builder.append(inputSpecification);
-		builder.append("", testInvariantsWhileCrawling="");
-		builder.append(testInvariantsWhileCrawling);
-		builder.append("", clickOnce="");
-		builder.append(clickOnce);
-		builder.append("", crawlFrames="");
-		builder.append(crawlFrames);
-		builder.append("", crawlHiddenAnchors="");
-		builder.append(crawlHiddenAnchors);
-		builder.append("", waitAfterReloadUrlMillis="");
-		builder.append(waitAfterReloadUrl);
-		builder.append("", waitAfterEvent="");
-		builder.append(waitAfterEvent);
-		builder.append(""]"");
-		return builder.toString();
-	}
-
 	/**
 	 * @return All Crawl elements: {@link PreCrawlConfiguration#getIncludedElements()},
 	 *         {@link PreCrawlConfiguration#getExcludedElements()} and
@@ -506,4 +357,55 @@
 
 	}
 
+	@Override
+	public int hashCode() {
+		return Objects.hashCode(crawlEvents, invariants, oracleComparators,
+		        ignoredFrameIdentifiers, preCrawlConfig, randomInputInForms, inputSpecification,
+		        testInvariantsWhileCrawling, clickOnce, crawlFrames, crawlHiddenAnchors,
+		        waitAfterReloadUrl, waitAfterEvent);
+	}
+
+	@Override
+	public boolean equals(Object object) {
+		if (object instanceof CrawlRules) {
+			CrawlRules that = (CrawlRules) object;
+			return Objects.equal(this.crawlEvents, that.crawlEvents)
+			        && Objects.equal(this.invariants, that.invariants)
+			        && Objects.equal(this.oracleComparators, that.oracleComparators)
+			        && Objects.equal(this.ignoredFrameIdentifiers, that.ignoredFrameIdentifiers)
+			        && Objects.equal(this.preCrawlConfig, that.preCrawlConfig)
+			        && Objects.equal(this.randomInputInForms, that.randomInputInForms)
+			        && Objects.equal(this.inputSpecification, that.inputSpecification)
+			        && Objects.equal(this.testInvariantsWhileCrawling,
+			                that.testInvariantsWhileCrawling)
+			        && Objects.equal(this.clickOnce, that.clickOnce)
+			        && Objects.equal(this.crawlFrames, that.crawlFrames)
+			        && Objects.equal(this.crawlHiddenAnchors, that.crawlHiddenAnchors)
+			        && Objects.equal(this.waitAfterReloadUrl, that.waitAfterReloadUrl)
+			        && Objects.equal(this.waitAfterEvent, that.waitAfterEvent);
+		}
+		return false;
+	}
+
+	@Override
+	public String toString() {
+		return Objects.toStringHelper(this)
+		        .add(""DEFAULT_WAIT_AFTER_RELOAD"", DEFAULT_WAIT_AFTER_RELOAD)
+		        .add(""DEFAULT_WAIT_AFTER_EVENT"", DEFAULT_WAIT_AFTER_EVENT)
+		        .add(""crawlEvents"", crawlEvents)
+		        .add(""invariants"", invariants)
+		        .add(""oracleComparators"", oracleComparators)
+		        .add(""ignoredFrameIdentifiers"", ignoredFrameIdentifiers)
+		        .add(""preCrawlConfig"", preCrawlConfig)
+		        .add(""randomInputInForms"", randomInputInForms)
+		        .add(""inputSpecification"", inputSpecification)
+		        .add(""testInvariantsWhileCrawling"", testInvariantsWhileCrawling)
+		        .add(""clickOnce"", clickOnce)
+		        .add(""crawlFrames"", crawlFrames)
+		        .add(""crawlHiddenAnchors"", crawlHiddenAnchors)
+		        .add(""waitAfterReloadUrl"", waitAfterReloadUrl)
+		        .add(""waitAfterEvent"", waitAfterEvent)
+		        .toString();
+	}
+
 }
"
77a5b0da22f80a908885c34c6c1d88c64b727adb,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index f631880..b40d407 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -3,15 +3,16 @@
 import static com.google.common.base.Preconditions.checkArgument;
 
 import java.net.MalformedURLException;
-import java.net.URISyntaxException;
 import java.net.URL;
 import java.util.concurrent.TimeUnit;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
+import com.crawljax.core.Crawler;
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.core.plugin.Plugins;
+import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
 
@@ -212,121 +213,38 @@
 
 	@Override
 	public int hashCode() {
-		final int prime = 31;
-		int result = 1;
-		result = prime * result + ((browserConfig == null) ? 0 : browserConfig.hashCode());
-		result = prime * result + ((crawlRules == null) ? 0 : crawlRules.hashCode());
-		result = prime * result + maximumDepth;
-		result = prime * result + (int) (maximumRuntime ^ (maximumRuntime >>> 32));
-		result = prime * result + maximumStates;
-		result = prime * result + ((plugins == null) ? 0 : plugins.hashCode());
-		result =
-		        prime * result
-		                + ((proxyConfiguration == null) ? 0 : proxyConfiguration.hashCode());
-		try {
-			result = prime * result + ((url == null) ? 0 : url.toURI().hashCode());
-		} catch (URISyntaxException e) {
-			result = prime * result;
-		}
-		return result;
+		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
+		        maximumStates, maximumRuntime, maximumDepth);
 	}
 
 	@Override
-	public boolean equals(Object obj) {
-		if (this == obj) {
-			return true;
+	public boolean equals(Object object) {
+		if (object instanceof CrawljaxConfiguration) {
+			CrawljaxConfiguration that = (CrawljaxConfiguration) object;
+			return Objects.equal(this.url, that.url)
+			        && Objects.equal(this.browserConfig, that.browserConfig)
+			        && Objects.equal(this.plugins, that.plugins)
+			        && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
+			        && Objects.equal(this.crawlRules, that.crawlRules)
+			        && Objects.equal(this.maximumStates, that.maximumStates)
+			        && Objects.equal(this.maximumRuntime, that.maximumRuntime)
+			        && Objects.equal(this.maximumDepth, that.maximumDepth);
 		}
-		
-		if (obj == null) {
-			return false;
-		}
-		
-		if (getClass() != obj.getClass()) {
-			return false;
-		}
-		
-		CrawljaxConfiguration other = (CrawljaxConfiguration) obj;
-		
-		if (browserConfig == null) {
-			if (other.browserConfig != null) {
-				return false;
-			}
-		} else if (!browserConfig.equals(other.browserConfig)) {
-			return false;
-		}
-		
-		if (crawlRules == null) {
-			if (other.crawlRules != null) {
-				return false;
-			}
-		} else if (!crawlRules.equals(other.crawlRules)) {
-			return false;
-		}
-		
-		if (maximumDepth != other.maximumDepth) {
-			return false;
-		}
-		
-		if (maximumRuntime != other.maximumRuntime) {
-			return false;
-		}
-		
-		if (maximumStates != other.maximumStates) {
-			return false;
-		}
-		
-		if (plugins == null) {
-			if (other.plugins != null) {
-				return false;
-			}
-		} else if (!plugins.equals(other.plugins)) {
-			return false;
-		}
-		
-		if (proxyConfiguration == null) {
-			if (other.proxyConfiguration != null) {
-				return false;
-			}
-		} else if (!proxyConfiguration.equals(other.proxyConfiguration)) {
-			return false;
-		}
-		
-		try {
-			if (url == null) {
-				if (other.url != null) {
-					return false;
-				}
-			} else if (!url.toURI().equals(other.url.toURI())) {
-				return false;
-			}
-		} catch( URISyntaxException e) {
-			return false; 
-		}
-		
-		return true;
+		return false;
 	}
 
 	@Override
 	public String toString() {
-		StringBuilder builder = new StringBuilder();
-		builder.append(""CrawljaxConfiguration [url="");
-		builder.append(url);
-		builder.append("", browserConfig="");
-		builder.append(browserConfig);
-		builder.append("", plugins="");
-		builder.append(plugins);
-		builder.append("", proxyConfiguration="");
-		builder.append(proxyConfiguration);
-		builder.append("", crawlRules="");
-		builder.append(crawlRules);
-		builder.append("", maximumStates="");
-		builder.append(maximumStates);
-		builder.append("", maximumRuntime="");
-		builder.append(maximumRuntime);
-		builder.append("", maximumDepth="");
-		builder.append(maximumDepth);
-		builder.append(""]"");
-		return builder.toString();
+		return Objects.toStringHelper(this)
+		        .add(""url"", url)
+		        .add(""browserConfig"", browserConfig)
+		        .add(""plugins"", plugins)
+		        .add(""proxyConfiguration"", proxyConfiguration)
+		        .add(""crawlRules"", crawlRules)
+		        .add(""maximumStates"", maximumStates)
+		        .add(""maximumRuntime"", maximumRuntime)
+		        .add(""maximumDepth"", maximumDepth)
+		        .toString();
 	}
 
 }
\ No newline at end of file
"
77a5b0da22f80a908885c34c6c1d88c64b727adb,Alex Nederlof,PreCrawlConfiguration.java,MODIFY,equals -> [Object obj] | [Object object],"diff --git a/core/src/main/java/com/crawljax/core/configuration/PreCrawlConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/PreCrawlConfiguration.java
index 0e6817b..92d5197 100644
--- a/core/src/main/java/com/crawljax/core/configuration/PreCrawlConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/PreCrawlConfiguration.java
@@ -6,6 +6,7 @@
 import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableSortedSet;
+import com.google.common.base.Objects;
 
 public class PreCrawlConfiguration {
 
@@ -106,83 +107,32 @@
 
 	@Override
 	public String toString() {
-		StringBuilder builder = new StringBuilder();
-		builder.append(""PreCrawlConfiguration [waitConditions="");
-		builder.append(waitConditions);
-		builder.append("", crawlConditions="");
-		builder.append(crawlConditions);
-		builder.append("", includedElements="");
-		builder.append(includedElements);
-		builder.append("", excludedElements="");
-		builder.append(excludedElements);
-		builder.append("", filterAttributeNames="");
-		builder.append(filterAttributeNames);
-		builder.append(""]"");
-		return builder.toString();
+		return Objects.toStringHelper(this)
+		        .add(""waitConditions"", waitConditions)
+		        .add(""crawlConditions"", crawlConditions)
+		        .add(""includedElements"", includedElements)
+		        .add(""excludedElements"", excludedElements)
+		        .add(""filterAttributeNames"", filterAttributeNames)
+		        .toString();
 	}
 
 	@Override
 	public int hashCode() {
-		final int prime = 31;
-		int result = 1;
-		result = prime * result + ((crawlConditions == null) ? 0 : crawlConditions.hashCode());
-		result = prime * result + ((excludedElements == null) ? 0 : excludedElements.hashCode());
-		result =
-		        prime * result
-		                + ((filterAttributeNames == null) ? 0 : filterAttributeNames.hashCode());
-		result = prime * result + ((includedElements == null) ? 0 : includedElements.hashCode());
-		result = prime * result + ((waitConditions == null) ? 0 : waitConditions.hashCode());
-		return result;
+		return Objects.hashCode(waitConditions, crawlConditions, includedElements,
+		        excludedElements, filterAttributeNames);
 	}
 
 	@Override
-	public boolean equals(Object obj) {
-		if (this == obj) {
-			return true;
+	public boolean equals(Object object) {
+		if (object instanceof PreCrawlConfiguration) {
+			PreCrawlConfiguration that = (PreCrawlConfiguration) object;
+			return Objects.equal(this.waitConditions, that.waitConditions)
+			        && Objects.equal(this.crawlConditions, that.crawlConditions)
+			        && Objects.equal(this.includedElements, that.includedElements)
+			        && Objects.equal(this.excludedElements, that.excludedElements)
+			        && Objects.equal(this.filterAttributeNames, that.filterAttributeNames);
 		}
-		if (obj == null) {
-			return false;
-		}
-		if (getClass() != obj.getClass()) {
-			return false;
-		}
-		PreCrawlConfiguration other = (PreCrawlConfiguration) obj;
-		if (crawlConditions == null) {
-			if (other.crawlConditions != null) {
-				return false;
-			}
-		} else if (!crawlConditions.equals(other.crawlConditions)) {
-			return false;
-		}
-		if (excludedElements == null) {
-			if (other.excludedElements != null) {
-				return false;
-			}
-		} else if (!excludedElements.equals(other.excludedElements)) {
-			return false;
-		}
-		if (filterAttributeNames == null) {
-			if (other.filterAttributeNames != null) {
-				return false;
-			}
-		} else if (!filterAttributeNames.equals(other.filterAttributeNames)) {
-			return false;
-		}
-		if (includedElements == null) {
-			if (other.includedElements != null) {
-				return false;
-			}
-		} else if (!includedElements.equals(other.includedElements)) {
-			return false;
-		}
-		if (waitConditions == null) {
-			if (other.waitConditions != null) {
-				return false;
-			}
-		} else if (!waitConditions.equals(other.waitConditions)) {
-			return false;
-		}
-		return true;
+		return false;
 	}
 
 }
\ No newline at end of file
"
44b5b66de619c8111032f357424b5c6b238b1905,Alex Nederlof,Crawler.java,MODIFY,goToInitialURL -> [] | [boolean runPlugins],"diff --git a/core/src/main/java/com/crawljax/core/Crawler.java b/core/src/main/java/com/crawljax/core/Crawler.java
index 9bfa44c..6e82d3e 100644
--- a/core/src/main/java/com/crawljax/core/Crawler.java
+++ b/core/src/main/java/com/crawljax/core/Crawler.java
@@ -19,6 +19,7 @@
 import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.core.exception.CrawlPathToException;
+import com.crawljax.core.plugin.OnUrlLoadPlugin;
 import com.crawljax.core.plugin.Plugins;
 import com.crawljax.core.state.CrawlPath;
 import com.crawljax.core.state.Element;
@@ -35,18 +36,20 @@
 
 /**
  * Class that performs crawl actions. It is designed to run inside a Thread.
- * 
- * @see #run()
  */
 public class Crawler implements Runnable {
 
-	private static final Logger LOG = LoggerFactory.getLogger(Crawler.class.getName());
+	private static final Logger LOG = LoggerFactory.getLogger(Crawler.class);
 
 	/**
-	 * The main browser window 1 to 1 relation; Every Thread will get on browser assigned in the run
-	 * function.
+	 * Enum for describing what has happened after a {@link Crawler#clickTag(Eventable)} has been
+	 * performed.
+	 * 
+	 * @see Crawler#clickTag(Eventable)
 	 */
-	private EmbeddedBrowser browser;
+	private static enum ClickResult {
+		CLONE_DETECTED, NEW_STATE, DOM_UNCHANGED, LEFT_DOMAIN
+	}
 
 	/**
 	 * The central DataController. This is a multiple to 1 relation Every Thread shares an instance
@@ -70,8 +73,6 @@
 	 */
 	private CandidateElementExtractor candidateExtractor;
 
-	private boolean fired = false;
-
 	/**
 	 * The name of this Crawler when not default (automatic) this will be added to the Thread name
 	 * in the thread as (name). In the {@link CrawlerExecutor#beforeExecute(Thread, Runnable)} the
@@ -80,7 +81,7 @@
 	 * @see Crawler#toString()
 	 * @see CrawlerExecutor#beforeExecute(Thread, Runnable)
 	 */
-	private String name = """";
+	private final String name;
 
 	/**
 	 * The sateMachine for this Crawler, keeping track of the path crawled by this Crawler.
@@ -89,8 +90,6 @@
 
 	private final CrawljaxConfiguration config;
 
-	private FormHandler formHandler;
-
 	/**
 	 * The object to places calls to add new Crawlers or to remove one.
 	 */
@@ -98,15 +97,15 @@
 
 	private final Plugins plugins;
 
+	private FormHandler formHandler;
+
+	private boolean fired = false;
+
 	/**
-	 * Enum for describing what has happened after a {@link Crawler#clickTag(Eventable)} has been
-	 * performed.
-	 * 
-	 * @see Crawler#clickTag(Eventable)
+	 * The main browser window 1 to 1 relation; Every Thread will get on browser assigned in the run
+	 * function.
 	 */
-	private enum ClickResult {
-		CLONE_DETECTED, NEW_STATE, DOM_UNCHANGED, LEFT_DOMAIN
-	}
+	private EmbeddedBrowser browser;
 
 	/**
 	 * @param mother
@@ -116,10 +115,8 @@
 	 * @param name
 	 *            a name for this crawler (default is empty).
 	 */
-	public Crawler(CrawljaxController mother, List<Eventable> exactEventPath, String name,
-	        Plugins plugins) {
-		this(mother, new CrawlPath(exactEventPath), plugins);
-		this.name = name;
+	public Crawler(CrawljaxController mother, List<Eventable> exactEventPath, String name) {
+		this(mother, new CrawlPath(exactEventPath), name);
 	}
 
 	/**
@@ -130,11 +127,12 @@
 	 * @param returnPath
 	 *            the path used to return to the last state, this can be a empty list
 	 */
-	protected Crawler(CrawljaxController mother, CrawlPath returnPath, Plugins plugins) {
+	protected Crawler(CrawljaxController mother, CrawlPath returnPath, String name) {
 		this.backTrackPath = returnPath;
+		this.name = name;
 		this.controller = mother;
-		this.plugins = plugins;
 		this.config = controller.getConfiguration();
+		this.plugins = config.getPlugins();
 		this.crawlQueueManager = mother.getCrawlQueueManager();
 		if (controller.getSession() != null) {
 			this.stateMachine =
@@ -151,22 +149,128 @@
 	}
 
 	/**
-	 * Brings the browser to the initial state.
+	 * The main function stated by the ExecutorService. Crawlers add themselves to the list by
+	 * calling {@link CrawlQueueManager#addWorkToQueue(Crawler)}. When the ExecutorService finds a
+	 * free thread this method is called and when this method ends the Thread is released again and
+	 * a new Thread is started
+	 * 
+	 * @see java.util.concurrent.Executors#newFixedThreadPool(int)
+	 * @see java.util.concurrent.ExecutorService
 	 */
-	public void goToInitialURL() {
+	@Override
+	public void run() {
+		if (!shouldContinueCrawling()) {
+			return;
+		}
+
+		try {
+			if (backTrackPath.last() != null
+			        && !backTrackPath.last().getTargetStateVertex().startWorking(this)) {
+				LOG.warn(""Could not register crawler. Quitting"");
+				return;
+			}
+
+			try {
+				this.init();
+			} catch (InterruptedException e) {
+				LOG.debug(""Could not fetch a browser from the pool"");
+				return;
+			}
+
+			// Hand over the main crawling
+			if (!this.crawl()) {
+				controller.terminate(false);
+			}
+
+			// Crawling is done; so the crawlPath of the current branch is known
+			if (!fired) {
+				controller.getSession().removeCrawlPath();
+			}
+		} catch (BrowserConnectionException e) {
+			// The connection of the browser has gone down, most of the times it
+			// means that the browser process has crashed.
+			LOG.error(""Crawler failed because the used browser died during Crawling"",
+			        new CrawlPathToException(""Crawler failed due to browser crash"", controller
+			                .getSession().getCurrentCrawlPath(), e));
+			// removeBrowser will throw a RuntimeException if the current browser
+			// is the last
+			// browser in the pool.
+			this.controller.getBrowserPool().removeBrowser(this.getBrowser(),
+			        this.controller.getCrawlQueueManager());
+			return;
+		} catch (CrawljaxException e) {
+			LOG.error(""Crawl failed!"", e);
+		}
+		/**
+		 * At last failure or non shutdown the Crawler.
+		 */
+		this.shutdown();
+	}
+
+	/**
+	 * Initialize the Crawler, retrieve a Browser and go to the initial URL when no browser was
+	 * present. rewind the state machine and goBack to the state if there is exactEventPath is
+	 * specified.
+	 * 
+	 * @throws InterruptedException
+	 *             when the request for a browser is interrupted.
+	 */
+	public void init() throws InterruptedException {
+		// Start a new CrawlPath for this Crawler
+		controller.getSession().startNewPath();
+
+		this.browser = this.getBrowser();
+		if (this.browser == null) {
+			/**
+			 * As the browser is null, request one and got to the initial URL, if the browser is
+			 * Already set the browser will be in the initial URL.
+			 */
+			this.browser = controller.getBrowserPool().requestBrowser();
+			LOG.info(""Reloading page for navigating back"");
+			this.goToInitialURL(true);
+		}
+		// TODO Stefan ideally this should be placed in the constructor
+		this.formHandler =
+		        new FormHandler(getBrowser(), config.getCrawlRules().getInputSpecification(),
+		                config.getCrawlRules().isRandomInputInForms());
+
+		this.candidateExtractor =
+		        new CandidateElementExtractor(controller.getElementChecker(), this.getBrowser(),
+		                formHandler, config);
+		/**
+		 * go back into the previous state.
+		 */
+		try {
+			this.goBackExact(backTrackPath);
+		} catch (CrawljaxException e) {
+			LOG.error(""Failed to backtrack"", e);
+		}
+	}
+
+	/**
+	 * Brings the browser to the initial state.
+	 * 
+	 * @param runPlugins
+	 *            To run the {@link OnUrlLoadPlugin} plugins.
+	 */
+	public void goToInitialURL(boolean runPlugins) {
 		LOG.info(""Loading Page {}"", config.getUrl());
 		getBrowser().goToUrl(config.getUrl());
 		controller.doBrowserWait(getBrowser());
-		plugins.runOnUrlLoadPlugins(getBrowser());
+		if (runPlugins) {
+			plugins.runOnUrlLoadPlugins(getBrowser());
+		}
 	}
 
 	/**
 	 * Reload the browser following the {@link #backTrackPath} to the given currentEvent.
 	 * 
+	 * @param b
+	 * @param backTrackPath2
 	 * @throws CrawljaxException
 	 *             if the {@link Eventable#getTargetStateVertex()} encounters an error.
 	 */
-	private void goBackExact() throws CrawljaxException {
+	private void goBackExact(CrawlPath path) throws CrawljaxException {
 		StateVertex curState = controller.getSession().getInitialState();
 
 		for (Eventable clickable : backTrackPath) {
@@ -279,8 +383,8 @@
 		} else {
 			LOG.info(""Found an invisible link with href={}"", href);
 			try {
-				URL url = UrlUtils.extractNewUrl(browser.getCurrentUrl(), href);
-				browser.goToUrl(url);
+				URL url = UrlUtils.extractNewUrl(getBrowser().getCurrentUrl(), href);
+				getBrowser().goToUrl(url);
 				return true;
 			} catch (MalformedURLException e) {
 				LOG.info(""Could not visit invisible illegal URL {}"", e.getMessage());
@@ -412,19 +516,19 @@
 	}
 
 	private boolean crawlerLeftDomain() {
-		return !browser.getCurrentUrl().toLowerCase()
+		return !getBrowser().getCurrentUrl().toLowerCase()
 		        .contains(config.getUrl().getHost().toLowerCase());
 	}
 
 	private void spawnThreads(StateVertex state) {
-		Crawler c = null;
+		Crawler crawler = null;
 		do {
-			if (c != null) {
-				this.crawlQueueManager.addWorkToQueue(c);
+			if (crawler != null) {
+				this.crawlQueueManager.addWorkToQueue(crawler);
 			}
-			c = new Crawler(this.controller, controller.getSession().getCurrentCrawlPath()
-			        .immutableCopy(true), config.getPlugins());
-		} while (state.registerCrawler(c));
+			crawler = new Crawler(this.controller, controller.getSession().getCurrentCrawlPath()
+			        .immutableCopy(true), """");
+		} while (state.registerCrawler(crawler));
 	}
 
 	/**
@@ -455,6 +559,10 @@
 			orrigionalState.filterCandidateActions(candidateElements);
 		}
 
+		return crawlThroughActions(orrigionalState);
+	}
+
+	private boolean crawlThroughActions(StateVertex orrigionalState) {
 		CandidateCrawlAction action =
 		        orrigionalState.pollCandidateCrawlAction(this, crawlQueueManager);
 		while (action != null) {
@@ -473,7 +581,7 @@
 				case CLONE_DETECTED:
 					return true;
 				case LEFT_DOMAIN:
-					getBrowser().goBack();
+					goBackOneState();
 				default:
 					break;
 			}
@@ -482,6 +590,14 @@
 		return true;
 	}
 
+	private void goBackOneState() {
+		LOG.debug(""Going back one state"");
+		goToInitialURL(false);
+		stateMachine.rewind();
+		controller.getSession().startNewPath();
+		goBackExact(controller.getSession().getCurrentCrawlPath().immutableCopy(false));
+	}
+
 	/**
 	 * Have we reached the depth limit?
 	 * 
@@ -523,46 +639,6 @@
 	}
 
 	/**
-	 * Initialize the Crawler, retrieve a Browser and go to the initial URL when no browser was
-	 * present. rewind the state machine and goBack to the state if there is exactEventPath is
-	 * specified.
-	 * 
-	 * @throws InterruptedException
-	 *             when the request for a browser is interrupted.
-	 */
-	public void init() throws InterruptedException {
-		// Start a new CrawlPath for this Crawler
-		controller.getSession().startNewPath();
-
-		this.browser = this.getBrowser();
-		if (this.browser == null) {
-			/**
-			 * As the browser is null, request one and got to the initial URL, if the browser is
-			 * Already set the browser will be in the initial URL.
-			 */
-			this.browser = controller.getBrowserPool().requestBrowser();
-			LOG.info(""Reloading page for navigating back"");
-			this.goToInitialURL();
-		}
-		// TODO Stefan ideally this should be placed in the constructor
-		this.formHandler =
-		        new FormHandler(getBrowser(), config.getCrawlRules().getInputSpecification(),
-		                config.getCrawlRules().isRandomInputInForms());
-
-		this.candidateExtractor =
-		        new CandidateElementExtractor(controller.getElementChecker(), this.getBrowser(),
-		                formHandler, config);
-		/**
-		 * go back into the previous state.
-		 */
-		try {
-			this.goBackExact();
-		} catch (CrawljaxException e) {
-			LOG.error(""Failed to backtrack"", e);
-		}
-	}
-
-	/**
 	 * Terminate and clean up this Crawler, release the acquired browser. Notice that other Crawlers
 	 * might still be active. So this function does NOT shutdown all Crawlers active that should be
 	 * done with {@link CrawlerExecutor#shutdown()}
@@ -572,78 +648,6 @@
 	}
 
 	/**
-	 * The main function stated by the ExecutorService. Crawlers add themselves to the list by
-	 * calling {@link CrawlQueueManager#addWorkToQueue(Crawler)}. When the ExecutorService finds a
-	 * free thread this method is called and when this method ends the Thread is released again and
-	 * a new Thread is started
-	 * 
-	 * @see java.util.concurrent.Executors#newFixedThreadPool(int)
-	 * @see java.util.concurrent.ExecutorService
-	 */
-	@Override
-	public void run() {
-		if (!shouldContinueCrawling()) {
-			// Constrains are not met at start of this Crawler, so stop immediately
-			return;
-		}
-		if (backTrackPath.last() != null) {
-			try {
-				if (!backTrackPath.last().getTargetStateVertex().startWorking(this)) {
-					return;
-				}
-			} catch (CrawljaxException e) {
-				LOG.error(""Received Crawljax exception"", e);
-			}
-		}
-
-		try {
-			/**
-			 * Init the Crawler
-			 */
-			try {
-				this.init();
-			} catch (InterruptedException e) {
-				if (this.getBrowser() == null) {
-					return;
-				}
-			}
-
-			/**
-			 * Hand over the main crawling
-			 */
-			if (!this.crawl()) {
-				controller.terminate(false);
-			}
-
-			/**
-			 * Crawling is done; so the crawlPath of the current branch is known
-			 */
-			if (!fired) {
-				controller.getSession().removeCrawlPath();
-			}
-		} catch (BrowserConnectionException e) {
-			// The connection of the browser has gone down, most of the times it
-			// means that the
-			// browser process has crashed.
-			LOG.error(""Crawler failed because the used browser died during Crawling"",
-			        new CrawlPathToException(""Crawler failed due to browser crash"", controller
-			                .getSession().getCurrentCrawlPath(), e));
-			// removeBrowser will throw a RuntimeException if the current browser
-			// is the last
-			// browser in the pool.
-			this.controller.getBrowserPool().removeBrowser(this.getBrowser(),
-			        this.controller.getCrawlQueueManager());
-			return;
-		} catch (CrawljaxException e) {
-			LOG.error(""Crawl failed!"", e);
-		}
-		/**
-		 * At last failure or non shutdown the Crawler.
-		 */
-		this.shutdown();
-	}
-
-	/**
 	 * Return the browser used in this Crawler Thread.
 	 * 
 	 * @return the browser used in this Crawler Thread
"
44b5b66de619c8111032f357424b5c6b238b1905,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index 6a2a5ae..509f64d 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -111,8 +111,6 @@
 	 * 
 	 * @throws CrawljaxException
 	 *             If the browser cannot be instantiated.
-	 * @throws ConfigurationException
-	 *             if crawljax configuration fails.
 	 * @NotThreadSafe
 	 */
 	public final void run() throws CrawljaxException {
@@ -123,7 +121,7 @@
 		        .getPreCrawlConfig().getIncludedElements());
 
 		// Create the initailCrawler
-		initialCrawler = new InitialCrawler(this, configuration.getPlugins());
+		initialCrawler = new InitialCrawler(this);
 
 		// Start the Crawling by adding the initialCrawler to the the workQueue.
 		addWorkToQueue(initialCrawler);
"
44b5b66de619c8111032f357424b5c6b238b1905,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index f631880..bdea1d3 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -8,6 +8,7 @@
 import java.util.concurrent.TimeUnit;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
+import com.crawljax.core.Crawler;
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
@@ -236,17 +237,17 @@
 		if (this == obj) {
 			return true;
 		}
-		
+
 		if (obj == null) {
 			return false;
 		}
-		
+
 		if (getClass() != obj.getClass()) {
 			return false;
 		}
-		
+
 		CrawljaxConfiguration other = (CrawljaxConfiguration) obj;
-		
+
 		if (browserConfig == null) {
 			if (other.browserConfig != null) {
 				return false;
@@ -254,7 +255,7 @@
 		} else if (!browserConfig.equals(other.browserConfig)) {
 			return false;
 		}
-		
+
 		if (crawlRules == null) {
 			if (other.crawlRules != null) {
 				return false;
@@ -262,19 +263,19 @@
 		} else if (!crawlRules.equals(other.crawlRules)) {
 			return false;
 		}
-		
+
 		if (maximumDepth != other.maximumDepth) {
 			return false;
 		}
-		
+
 		if (maximumRuntime != other.maximumRuntime) {
 			return false;
 		}
-		
+
 		if (maximumStates != other.maximumStates) {
 			return false;
 		}
-		
+
 		if (plugins == null) {
 			if (other.plugins != null) {
 				return false;
@@ -282,7 +283,7 @@
 		} else if (!plugins.equals(other.plugins)) {
 			return false;
 		}
-		
+
 		if (proxyConfiguration == null) {
 			if (other.proxyConfiguration != null) {
 				return false;
@@ -290,7 +291,7 @@
 		} else if (!proxyConfiguration.equals(other.proxyConfiguration)) {
 			return false;
 		}
-		
+
 		try {
 			if (url == null) {
 				if (other.url != null) {
@@ -299,10 +300,10 @@
 			} else if (!url.toURI().equals(other.url.toURI())) {
 				return false;
 			}
-		} catch( URISyntaxException e) {
-			return false; 
+		} catch (URISyntaxException e) {
+			return false;
 		}
-		
+
 		return true;
 	}
 
"
44b5b66de619c8111032f357424b5c6b238b1905,Alex Nederlof,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index 2918262..5ffafaf 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -281,8 +281,8 @@
 	 */
 	public static String getTextValue(Element element) {
 		String ret = """";
-		String textContent = element.getTextContent(); 
-		if (textContent != null && !textContent.equals("""") ) {
+		String textContent = element.getTextContent();
+		if (textContent != null && !textContent.equals("""")) {
 			ret = textContent;
 		} else if (element.hasAttribute(""title"")) {
 			ret = element.getAttribute(""title"");
"
44b5b66de619c8111032f357424b5c6b238b1905,Alex Nederlof,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 0bc8d5f..bdb6a53 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -295,16 +295,18 @@
 		// make sure not before the node
 		int openElements = 1;
 		int i = 0;
-		int position = pos; 
+		int position = pos;
 		String dom_lower = dom.toLowerCase();
 		String element_lower = element.toLowerCase();
 		String openElement = ""<"" + element_lower;
 		String closeElement = ""</"" + element_lower;
 		while (i < MAX_SEARCH_LOOPS) {
-			if (dom_lower.indexOf(openElement, position) == -1 && dom_lower.indexOf(closeElement, position) == -1) {
+			if (dom_lower.indexOf(openElement, position) == -1
+			        && dom_lower.indexOf(closeElement, position) == -1) {
 				return -1;
 			}
-			if (dom_lower.indexOf(openElement, position) < dom_lower.indexOf(closeElement, position)
+			if (dom_lower.indexOf(openElement, position) < dom_lower.indexOf(closeElement,
+			        position)
 			        && dom_lower.indexOf(openElement, position) != -1) {
 				openElements++;
 				position = dom_lower.indexOf(openElement, position) + 1;
@@ -341,14 +343,18 @@
 	 *         text()
 	 */
 	public static String stripXPathToElement(String xpath) {
-		String xpathStripped = xpath; 
-		
+		String xpathStripped = xpath;
+
 		if (!Strings.isNullOrEmpty(xpathStripped)) {
 			if (xpathStripped.toLowerCase().contains(""/text()"")) {
-				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/text()""));
+				xpathStripped =
+				        xpathStripped
+				                .substring(0, xpathStripped.toLowerCase().indexOf(""/text()""));
 			}
 			if (xpathStripped.toLowerCase().contains(""/comment()"")) {
-				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/comment()""));
+				xpathStripped =
+				        xpathStripped.substring(0,
+				                xpathStripped.toLowerCase().indexOf(""/comment()""));
 			}
 			if (xpathStripped.contains(""@"")) {
 				xpathStripped = xpathStripped.substring(0, xpathStripped.indexOf(""@"") - 1);
"
435d79619ceacd8d806528b67220115e3bef664e,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index dca372e..b680e39 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -367,10 +367,6 @@
 		m = p.matcher(html);
 		htmlFormatted = m.replaceAll("""");
 
-		// TODO (Stefan), Following lines are a serious performance bottle neck...
-		// Document doc = Helper.getDocument(htmlFormatted);
-		// htmlFormatted = Helper.getDocumentToString(doc);
-
 		htmlFormatted = filterAttributes(htmlFormatted);
 		return htmlFormatted;
 	}
@@ -383,15 +379,16 @@
 	 * @return The filtered HTML string.
 	 */
 	private String filterAttributes(String html) {
+		String filteredHtml = html;
 		if (this.filterAttributes != null) {
 			for (String attribute : this.filterAttributes) {
 				String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
 				Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
 				Matcher m = p.matcher(html);
-				html = m.replaceAll("""");
+				filteredHtml = m.replaceAll("""");
 			}
 		}
-		return html;
+		return filteredHtml;
 	}
 
 	@Override
@@ -415,12 +412,9 @@
 		try {
 			WebElement field = browser.findElement(identification.getWebDriverBy());
 			if (field != null) {
-				// first clear the field
 				field.clear();
-				// then fill in
 				field.sendKeys(text);
 
-				// this.activeElement = field;
 				return true;
 			}
 			return false;
"
440d18b1d1f2cd272ec21257f561d56289f4b1d5,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index dca372e..b680e39 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -367,10 +367,6 @@
 		m = p.matcher(html);
 		htmlFormatted = m.replaceAll("""");
 
-		// TODO (Stefan), Following lines are a serious performance bottle neck...
-		// Document doc = Helper.getDocument(htmlFormatted);
-		// htmlFormatted = Helper.getDocumentToString(doc);
-
 		htmlFormatted = filterAttributes(htmlFormatted);
 		return htmlFormatted;
 	}
@@ -383,15 +379,16 @@
 	 * @return The filtered HTML string.
 	 */
 	private String filterAttributes(String html) {
+		String filteredHtml = html;
 		if (this.filterAttributes != null) {
 			for (String attribute : this.filterAttributes) {
 				String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
 				Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
 				Matcher m = p.matcher(html);
-				html = m.replaceAll("""");
+				filteredHtml = m.replaceAll("""");
 			}
 		}
-		return html;
+		return filteredHtml;
 	}
 
 	@Override
@@ -415,12 +412,9 @@
 		try {
 			WebElement field = browser.findElement(identification.getWebDriverBy());
 			if (field != null) {
-				// first clear the field
 				field.clear();
-				// then fill in
 				field.sendKeys(text);
 
-				// this.activeElement = field;
 				return true;
 			}
 			return false;
"
440d18b1d1f2cd272ec21257f561d56289f4b1d5,Alex Nederlof,Crawler.java,MODIFY,goToInitialURL -> [boolean runPlugins] | [],"diff --git a/core/src/main/java/com/crawljax/core/Crawler.java b/core/src/main/java/com/crawljax/core/Crawler.java
index e1c5295..f160a0c 100644
--- a/core/src/main/java/com/crawljax/core/Crawler.java
+++ b/core/src/main/java/com/crawljax/core/Crawler.java
@@ -122,21 +122,6 @@
 		this.name = name;
 	}
 
-	//
-	// /**
-	// * Private Crawler constructor for a 'reload' crawler. Only used internally.
-	// *
-	// * @param mother
-	// * the main CrawljaxController
-	// * @param returnPath
-	// * the path used to return to the last state, this can be a empty list
-	// * @deprecated better to use {@link #Crawler(CrawljaxController, CrawlPath)}
-	// */
-	// @Deprecated
-	// protected Crawler(CrawljaxController mother, List<Eventable> returnPath) {
-	// this(mother, new CrawlPath(returnPath));
-	// }
-
 	/**
 	 * Private Crawler constructor for a 'reload' crawler. Only used internally.
 	 * 
"
440d18b1d1f2cd272ec21257f561d56289f4b1d5,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index f631880..b40d407 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -3,15 +3,16 @@
 import static com.google.common.base.Preconditions.checkArgument;
 
 import java.net.MalformedURLException;
-import java.net.URISyntaxException;
 import java.net.URL;
 import java.util.concurrent.TimeUnit;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
+import com.crawljax.core.Crawler;
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.core.plugin.Plugins;
+import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
 
@@ -212,121 +213,38 @@
 
 	@Override
 	public int hashCode() {
-		final int prime = 31;
-		int result = 1;
-		result = prime * result + ((browserConfig == null) ? 0 : browserConfig.hashCode());
-		result = prime * result + ((crawlRules == null) ? 0 : crawlRules.hashCode());
-		result = prime * result + maximumDepth;
-		result = prime * result + (int) (maximumRuntime ^ (maximumRuntime >>> 32));
-		result = prime * result + maximumStates;
-		result = prime * result + ((plugins == null) ? 0 : plugins.hashCode());
-		result =
-		        prime * result
-		                + ((proxyConfiguration == null) ? 0 : proxyConfiguration.hashCode());
-		try {
-			result = prime * result + ((url == null) ? 0 : url.toURI().hashCode());
-		} catch (URISyntaxException e) {
-			result = prime * result;
-		}
-		return result;
+		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
+		        maximumStates, maximumRuntime, maximumDepth);
 	}
 
 	@Override
-	public boolean equals(Object obj) {
-		if (this == obj) {
-			return true;
+	public boolean equals(Object object) {
+		if (object instanceof CrawljaxConfiguration) {
+			CrawljaxConfiguration that = (CrawljaxConfiguration) object;
+			return Objects.equal(this.url, that.url)
+			        && Objects.equal(this.browserConfig, that.browserConfig)
+			        && Objects.equal(this.plugins, that.plugins)
+			        && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
+			        && Objects.equal(this.crawlRules, that.crawlRules)
+			        && Objects.equal(this.maximumStates, that.maximumStates)
+			        && Objects.equal(this.maximumRuntime, that.maximumRuntime)
+			        && Objects.equal(this.maximumDepth, that.maximumDepth);
 		}
-		
-		if (obj == null) {
-			return false;
-		}
-		
-		if (getClass() != obj.getClass()) {
-			return false;
-		}
-		
-		CrawljaxConfiguration other = (CrawljaxConfiguration) obj;
-		
-		if (browserConfig == null) {
-			if (other.browserConfig != null) {
-				return false;
-			}
-		} else if (!browserConfig.equals(other.browserConfig)) {
-			return false;
-		}
-		
-		if (crawlRules == null) {
-			if (other.crawlRules != null) {
-				return false;
-			}
-		} else if (!crawlRules.equals(other.crawlRules)) {
-			return false;
-		}
-		
-		if (maximumDepth != other.maximumDepth) {
-			return false;
-		}
-		
-		if (maximumRuntime != other.maximumRuntime) {
-			return false;
-		}
-		
-		if (maximumStates != other.maximumStates) {
-			return false;
-		}
-		
-		if (plugins == null) {
-			if (other.plugins != null) {
-				return false;
-			}
-		} else if (!plugins.equals(other.plugins)) {
-			return false;
-		}
-		
-		if (proxyConfiguration == null) {
-			if (other.proxyConfiguration != null) {
-				return false;
-			}
-		} else if (!proxyConfiguration.equals(other.proxyConfiguration)) {
-			return false;
-		}
-		
-		try {
-			if (url == null) {
-				if (other.url != null) {
-					return false;
-				}
-			} else if (!url.toURI().equals(other.url.toURI())) {
-				return false;
-			}
-		} catch( URISyntaxException e) {
-			return false; 
-		}
-		
-		return true;
+		return false;
 	}
 
 	@Override
 	public String toString() {
-		StringBuilder builder = new StringBuilder();
-		builder.append(""CrawljaxConfiguration [url="");
-		builder.append(url);
-		builder.append("", browserConfig="");
-		builder.append(browserConfig);
-		builder.append("", plugins="");
-		builder.append(plugins);
-		builder.append("", proxyConfiguration="");
-		builder.append(proxyConfiguration);
-		builder.append("", crawlRules="");
-		builder.append(crawlRules);
-		builder.append("", maximumStates="");
-		builder.append(maximumStates);
-		builder.append("", maximumRuntime="");
-		builder.append(maximumRuntime);
-		builder.append("", maximumDepth="");
-		builder.append(maximumDepth);
-		builder.append(""]"");
-		return builder.toString();
+		return Objects.toStringHelper(this)
+		        .add(""url"", url)
+		        .add(""browserConfig"", browserConfig)
+		        .add(""plugins"", plugins)
+		        .add(""proxyConfiguration"", proxyConfiguration)
+		        .add(""crawlRules"", crawlRules)
+		        .add(""maximumStates"", maximumStates)
+		        .add(""maximumRuntime"", maximumRuntime)
+		        .add(""maximumDepth"", maximumDepth)
+		        .toString();
 	}
 
 }
\ No newline at end of file
"
91b09d6c814565cf2cfc6a1f606eeefe00d469e1,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index dca372e..b680e39 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -367,10 +367,6 @@
 		m = p.matcher(html);
 		htmlFormatted = m.replaceAll("""");
 
-		// TODO (Stefan), Following lines are a serious performance bottle neck...
-		// Document doc = Helper.getDocument(htmlFormatted);
-		// htmlFormatted = Helper.getDocumentToString(doc);
-
 		htmlFormatted = filterAttributes(htmlFormatted);
 		return htmlFormatted;
 	}
@@ -383,15 +379,16 @@
 	 * @return The filtered HTML string.
 	 */
 	private String filterAttributes(String html) {
+		String filteredHtml = html;
 		if (this.filterAttributes != null) {
 			for (String attribute : this.filterAttributes) {
 				String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
 				Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
 				Matcher m = p.matcher(html);
-				html = m.replaceAll("""");
+				filteredHtml = m.replaceAll("""");
 			}
 		}
-		return html;
+		return filteredHtml;
 	}
 
 	@Override
@@ -415,12 +412,9 @@
 		try {
 			WebElement field = browser.findElement(identification.getWebDriverBy());
 			if (field != null) {
-				// first clear the field
 				field.clear();
-				// then fill in
 				field.sendKeys(text);
 
-				// this.activeElement = field;
 				return true;
 			}
 			return false;
"
91b09d6c814565cf2cfc6a1f606eeefe00d469e1,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index bdea1d3..b40d407 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -3,7 +3,6 @@
 import static com.google.common.base.Preconditions.checkArgument;
 
 import java.net.MalformedURLException;
-import java.net.URISyntaxException;
 import java.net.URL;
 import java.util.concurrent.TimeUnit;
 
@@ -13,6 +12,7 @@
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.core.plugin.Plugins;
+import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
 
@@ -213,121 +213,38 @@
 
 	@Override
 	public int hashCode() {
-		final int prime = 31;
-		int result = 1;
-		result = prime * result + ((browserConfig == null) ? 0 : browserConfig.hashCode());
-		result = prime * result + ((crawlRules == null) ? 0 : crawlRules.hashCode());
-		result = prime * result + maximumDepth;
-		result = prime * result + (int) (maximumRuntime ^ (maximumRuntime >>> 32));
-		result = prime * result + maximumStates;
-		result = prime * result + ((plugins == null) ? 0 : plugins.hashCode());
-		result =
-		        prime * result
-		                + ((proxyConfiguration == null) ? 0 : proxyConfiguration.hashCode());
-		try {
-			result = prime * result + ((url == null) ? 0 : url.toURI().hashCode());
-		} catch (URISyntaxException e) {
-			result = prime * result;
-		}
-		return result;
+		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
+		        maximumStates, maximumRuntime, maximumDepth);
 	}
 
 	@Override
-	public boolean equals(Object obj) {
-		if (this == obj) {
-			return true;
+	public boolean equals(Object object) {
+		if (object instanceof CrawljaxConfiguration) {
+			CrawljaxConfiguration that = (CrawljaxConfiguration) object;
+			return Objects.equal(this.url, that.url)
+			        && Objects.equal(this.browserConfig, that.browserConfig)
+			        && Objects.equal(this.plugins, that.plugins)
+			        && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
+			        && Objects.equal(this.crawlRules, that.crawlRules)
+			        && Objects.equal(this.maximumStates, that.maximumStates)
+			        && Objects.equal(this.maximumRuntime, that.maximumRuntime)
+			        && Objects.equal(this.maximumDepth, that.maximumDepth);
 		}
-
-		if (obj == null) {
-			return false;
-		}
-
-		if (getClass() != obj.getClass()) {
-			return false;
-		}
-
-		CrawljaxConfiguration other = (CrawljaxConfiguration) obj;
-
-		if (browserConfig == null) {
-			if (other.browserConfig != null) {
-				return false;
-			}
-		} else if (!browserConfig.equals(other.browserConfig)) {
-			return false;
-		}
-
-		if (crawlRules == null) {
-			if (other.crawlRules != null) {
-				return false;
-			}
-		} else if (!crawlRules.equals(other.crawlRules)) {
-			return false;
-		}
-
-		if (maximumDepth != other.maximumDepth) {
-			return false;
-		}
-
-		if (maximumRuntime != other.maximumRuntime) {
-			return false;
-		}
-
-		if (maximumStates != other.maximumStates) {
-			return false;
-		}
-
-		if (plugins == null) {
-			if (other.plugins != null) {
-				return false;
-			}
-		} else if (!plugins.equals(other.plugins)) {
-			return false;
-		}
-
-		if (proxyConfiguration == null) {
-			if (other.proxyConfiguration != null) {
-				return false;
-			}
-		} else if (!proxyConfiguration.equals(other.proxyConfiguration)) {
-			return false;
-		}
-
-		try {
-			if (url == null) {
-				if (other.url != null) {
-					return false;
-				}
-			} else if (!url.toURI().equals(other.url.toURI())) {
-				return false;
-			}
-		} catch (URISyntaxException e) {
-			return false;
-		}
-
-		return true;
+		return false;
 	}
 
 	@Override
 	public String toString() {
-		StringBuilder builder = new StringBuilder();
-		builder.append(""CrawljaxConfiguration [url="");
-		builder.append(url);
-		builder.append("", browserConfig="");
-		builder.append(browserConfig);
-		builder.append("", plugins="");
-		builder.append(plugins);
-		builder.append("", proxyConfiguration="");
-		builder.append(proxyConfiguration);
-		builder.append("", crawlRules="");
-		builder.append(crawlRules);
-		builder.append("", maximumStates="");
-		builder.append(maximumStates);
-		builder.append("", maximumRuntime="");
-		builder.append(maximumRuntime);
-		builder.append("", maximumDepth="");
-		builder.append(maximumDepth);
-		builder.append(""]"");
-		return builder.toString();
+		return Objects.toStringHelper(this)
+		        .add(""url"", url)
+		        .add(""browserConfig"", browserConfig)
+		        .add(""plugins"", plugins)
+		        .add(""proxyConfiguration"", proxyConfiguration)
+		        .add(""crawlRules"", crawlRules)
+		        .add(""maximumStates"", maximumStates)
+		        .add(""maximumRuntime"", maximumRuntime)
+		        .add(""maximumDepth"", maximumDepth)
+		        .toString();
 	}
 
 }
\ No newline at end of file
"
91b09d6c814565cf2cfc6a1f606eeefe00d469e1,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index 287b05d..aef2647 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -67,88 +67,87 @@
 	private void setInputElementValue(Node element, FormInput input) {
 
 		LOGGER.debug(""INPUTFIELD: {} ({})"", input.getIdentification(), input.getType());
-		if (element == null) {
+		if (element == null || input.getInputValues().isEmpty()) {
 			return;
 		}
-		if (input.getInputValues().iterator().hasNext()) {
-			try {
-				// fill in text fields, textareas, password fields and hidden
-				// fields
-				if (input.getType().toLowerCase().startsWith(""text"")
-				        || input.getType().equalsIgnoreCase(""password"")
-				        || input.getType().equalsIgnoreCase(""hidden"")) {
-					String text = input.getInputValues().iterator().next().getValue();
-					if ("""".equals(text)) {
-						return;
-					}
-					String js = DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-					js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
-					browser.executeJavaScript(js);
-				}
+		try {
+			if (input.getType().toLowerCase().startsWith(""text"")
+			        || input.getType().equalsIgnoreCase(""password"")
+			        || input.getType().equalsIgnoreCase(""hidden"")) {
+				handleText(element, input);
+			} else if (""checkbox"".equals(input.getType())) {
+				handleCheckBoxes(element, input);
+			} else if (input.getType().equals(""radio"")) {
+				handleRadioSwitches(element, input);
+			} else if (input.getType().startsWith(""select"")) {
+				handleSelectBoxes(element, input);
+			}
+		} catch (BrowserConnectionException e) {
+			throw e;
+		} catch (RuntimeException e) {
+			LOGGER.error(""Could not input element values"", e);
+		}
+	}
 
-				// check/uncheck checkboxes
-				if (""checkbox"".equals(input.getType())) {
-					for (InputValue inputValue : input.getInputValues()) {
-						String js =
-						        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-						boolean check;
-						if (!randomFieldValue) {
-							check = inputValue.isChecked();
-						} else {
+	private void handleCheckBoxes(Node element, FormInput input) {
+		for (InputValue inputValue : input.getInputValues()) {
+			String js =
+			        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
+			boolean check;
+			if (!randomFieldValue) {
+				check = inputValue.isChecked();
+			} else {
 
-							check = Math.random() >= HALF;
-						}
-						String value;
-						if (check) {
-							value = ""true"";
-						} else {
-							value = ""false"";
-						}
-						js += ""try{ATUSA_element.checked="" + value + "";}catch(e){}"";
-						browser.executeJavaScript(js);
+				check = Math.random() >= HALF;
+			}
+			String value;
+			if (check) {
+				value = ""true"";
+			} else {
+				value = ""false"";
+			}
+			js += ""try{ATUSA_element.checked="" + value + "";}catch(e){}"";
+			browser.executeJavaScript(js);
 
-					}
-				}
+		}
+	}
 
-				// check radio button
-				if (input.getType().equals(""radio"")) {
-					for (InputValue inputValue : input.getInputValues()) {
-						if (inputValue.isChecked()) {
-							String js =
-							        DomUtils.getJSGetElement(XPathHelper
-							                .getXPathExpression(element));
-							js += ""try{ATUSA_element.checked=true;}catch(e){}"";
-							browser.executeJavaScript(js);
-						}
-					}
-				}
-
-				// select options
-				if (input.getType().startsWith(""select"")) {
-					for (InputValue inputValue : input.getInputValues()) {
-						// if(browser.getDriver()==null){
-						String js =
-						        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-						js +=
-						        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
-						                + ""if(ATUSA_element.options[i].value=='""
-						                + inputValue.getValue()
-						                + ""' || ATUSA_element.options[i].text=='""
-						                + inputValue.getValue() + ""'){""
-						                + ""ATUSA_element.options[i].selected=true;"" + ""break;""
-						                + ""}"" + ""};"" + ""}catch(e){}"";
-						browser.executeJavaScript(js);
-					}
-				}
-			} catch (Exception e) {
-				// TODO Stefan; refactor this catch
-				if (e instanceof BrowserConnectionException) {
-					throw (BrowserConnectionException) e;
-				}
-				LOGGER.error(e.getMessage(), e);
+	private void handleRadioSwitches(Node element, FormInput input) {
+		for (InputValue inputValue : input.getInputValues()) {
+			if (inputValue.isChecked()) {
+				String js =
+				        DomUtils.getJSGetElement(XPathHelper
+				                .getXPathExpression(element));
+				js += ""try{ATUSA_element.checked=true;}catch(e){}"";
+				browser.executeJavaScript(js);
 			}
 		}
+	}
 
+	private void handleSelectBoxes(Node element, FormInput input) {
+		for (InputValue inputValue : input.getInputValues()) {
+			String js =
+			        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
+			js +=
+			        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
+			                + ""if(ATUSA_element.options[i].value=='""
+			                + inputValue.getValue()
+			                + ""' || ATUSA_element.options[i].text=='""
+			                + inputValue.getValue() + ""'){""
+			                + ""ATUSA_element.options[i].selected=true;"" + ""break;""
+			                + ""}"" + ""};"" + ""}catch(e){}"";
+			browser.executeJavaScript(js);
+		}
+	}
+
+	private void handleText(Node element, FormInput input) {
+		String text = input.getInputValues().iterator().next().getValue();
+		if ("""".equals(text)) {
+			return;
+		}
+		String js = DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
+		js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
+		browser.executeJavaScript(js);
 	}
 
 	/**
"
91b09d6c814565cf2cfc6a1f606eeefe00d469e1,Alex Nederlof,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index 5ffafaf..d0d3edd 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -30,7 +30,6 @@
 import org.custommonkey.xmlunit.DetailedDiff;
 import org.custommonkey.xmlunit.Diff;
 import org.custommonkey.xmlunit.Difference;
-import org.custommonkey.xmlunit.DifferenceListener;
 import org.cyberneko.html.parsers.DOMParser;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -44,6 +43,7 @@
 import org.xml.sax.SAXException;
 
 import com.crawljax.core.CrawljaxException;
+import com.google.common.base.Strings;
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Lists;
 
@@ -118,23 +118,27 @@
 	 */
 	public static String getElementAttributes(Element element, ImmutableSet<String> exclude) {
 		StringBuilder buffer = new StringBuilder();
-
 		if (element != null) {
 			NamedNodeMap attributes = element.getAttributes();
 			if (attributes != null) {
-				for (int i = 0; i < attributes.getLength(); i++) {
-					Attr attr = (Attr) attributes.item(i);
-					if (!exclude.contains(attr.getNodeName())) {
-						buffer.append(attr.getNodeName()).append('=');
-						buffer.append(attr.getNodeValue()).append(' ');
-					}
-				}
+				addAttributesToString(exclude, buffer, attributes);
 			}
 		}
 
 		return buffer.toString().trim();
 	}
 
+	private static void addAttributesToString(ImmutableSet<String> exclude, StringBuilder buffer,
+	        NamedNodeMap attributes) {
+		for (int i = 0; i < attributes.getLength(); i++) {
+			Attr attr = (Attr) attributes.item(i);
+			if (!exclude.contains(attr.getNodeName())) {
+				buffer.append(attr.getNodeName()).append('=');
+				buffer.append(attr.getNodeValue()).append(' ');
+			}
+		}
+	}
+
 	/**
 	 * @param element
 	 *            the element.
@@ -142,17 +146,17 @@
 	 */
 	public static String getElementString(Element element) {
 		String text = DomUtils.removeNewLines(DomUtils.getTextValue(element)).trim();
-		String info = """";
-		if (!text.equals("""")) {
-			info += ""\"""" + text + ""\"" "";
+		StringBuilder info = new StringBuilder();
+		if (!Strings.isNullOrEmpty(text)) {
+			info.append(""\"""").append(text).append(""\"" "");
 		}
 		if (element != null) {
 			if (element.hasAttribute(""id"")) {
-				info += ""ID: "" + element.getAttribute(""id"") + "" "";
+				info.append(""ID: "").append(element.getAttribute(""id"")).append("" "");
 			}
-			info += DomUtils.getAllElementAttributes(element) + "" "";
+			info.append(DomUtils.getAllElementAttributes(element)).append("" "");
 		}
-		return info;
+		return info.toString();
 	}
 
 	/**
@@ -326,29 +330,7 @@
 		try {
 			Diff d = new Diff(DomUtils.asDocument(controlDom), DomUtils.asDocument(testDom));
 			DetailedDiff dd = new DetailedDiff(d);
-			dd.overrideDifferenceListener(new DifferenceListener() {
-
-				@Override
-				public void skippedComparison(Node control, Node test) {
-				}
-
-				@Override
-				public int differenceFound(Difference difference) {
-					if (difference.getControlNodeDetail() == null
-					        || difference.getControlNodeDetail().getNode() == null
-					        || difference.getTestNodeDetail() == null
-					        || difference.getTestNodeDetail().getNode() == null) {
-						return RETURN_ACCEPT_DIFFERENCE;
-					}
-					if (ignoreAttributes.contains(difference.getTestNodeDetail().getNode()
-					        .getNodeName())
-					        || ignoreAttributes.contains(difference.getControlNodeDetail()
-					                .getNode().getNodeName())) {
-						return RETURN_IGNORE_DIFFERENCE_NODES_IDENTICAL;
-					}
-					return RETURN_ACCEPT_DIFFERENCE;
-				}
-			});
+			dd.overrideDifferenceListener(new DomDifferenceListener(ignoreAttributes));
 
 			return dd.getAllDifferences();
 		} catch (IOException e) {
@@ -394,7 +376,7 @@
 	 * @return The new, correct path.
 	 */
 	public static String addFolderSlashIfNeeded(String folderName) {
-		if (!folderName.equals("""") && !folderName.endsWith(""/"")) {
+		if (!"""".equals(folderName) && !folderName.endsWith(""/"")) {
 			return folderName + ""/"";
 		} else {
 			return folderName;
@@ -461,8 +443,7 @@
 	 */
 	public static String getJSGetElement(String xpath) {
 		String js =
-		        """"
-		                + ""function ATUSA_getElementInNodes(nodes, tagName, number){""
+		        ""function ATUSA_getElementInNodes(nodes, tagName, number){""
 		                + ""try{""
 		                + ""var pos = 1;""
 		                + ""for(i=0; i<nodes.length; i++){""
"
ca45ee647f621a48786b07f4ec4ef337dc136319,Alex Nederlof,Crawler.java,MODIFY,goToInitialURL -> [] | [boolean runPlugins],"diff --git a/core/src/main/java/com/crawljax/core/Crawler.java b/core/src/main/java/com/crawljax/core/Crawler.java
index 6e82d3e..78ed5b3 100644
--- a/core/src/main/java/com/crawljax/core/Crawler.java
+++ b/core/src/main/java/com/crawljax/core/Crawler.java
@@ -593,7 +593,9 @@
 	private void goBackOneState() {
 		LOG.debug(""Going back one state"");
 		goToInitialURL(false);
-		stateMachine.rewind();
+		if (stateMachine != null) {
+			stateMachine.rewind();
+		}
 		controller.getSession().startNewPath();
 		goBackExact(controller.getSession().getCurrentCrawlPath().immutableCopy(false));
 	}
"
52d9c7b94c09433d36afc5e2eb03e7387487864b,Alex Nederlof,Crawler.java,MODIFY,goBackExact -> [CrawlPath path] | [],"diff --git a/core/src/main/java/com/crawljax/core/Crawler.java b/core/src/main/java/com/crawljax/core/Crawler.java
index 9bfa44c..0cea9ce 100644
--- a/core/src/main/java/com/crawljax/core/Crawler.java
+++ b/core/src/main/java/com/crawljax/core/Crawler.java
@@ -19,6 +19,7 @@
 import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.core.exception.CrawlPathToException;
+import com.crawljax.core.plugin.OnUrlLoadPlugin;
 import com.crawljax.core.plugin.Plugins;
 import com.crawljax.core.state.CrawlPath;
 import com.crawljax.core.state.Element;
@@ -35,18 +36,20 @@
 
 /**
  * Class that performs crawl actions. It is designed to run inside a Thread.
- * 
- * @see #run()
  */
 public class Crawler implements Runnable {
 
-	private static final Logger LOG = LoggerFactory.getLogger(Crawler.class.getName());
+	private static final Logger LOG = LoggerFactory.getLogger(Crawler.class);
 
 	/**
-	 * The main browser window 1 to 1 relation; Every Thread will get on browser assigned in the run
-	 * function.
+	 * Enum for describing what has happened after a {@link Crawler#clickTag(Eventable)} has been
+	 * performed.
+	 * 
+	 * @see Crawler#clickTag(Eventable)
 	 */
-	private EmbeddedBrowser browser;
+	private static enum ClickResult {
+		CLONE_DETECTED, NEW_STATE, DOM_UNCHANGED, LEFT_DOMAIN
+	}
 
 	/**
 	 * The central DataController. This is a multiple to 1 relation Every Thread shares an instance
@@ -70,8 +73,6 @@
 	 */
 	private CandidateElementExtractor candidateExtractor;
 
-	private boolean fired = false;
-
 	/**
 	 * The name of this Crawler when not default (automatic) this will be added to the Thread name
 	 * in the thread as (name). In the {@link CrawlerExecutor#beforeExecute(Thread, Runnable)} the
@@ -80,7 +81,7 @@
 	 * @see Crawler#toString()
 	 * @see CrawlerExecutor#beforeExecute(Thread, Runnable)
 	 */
-	private String name = """";
+	private final String name;
 
 	/**
 	 * The sateMachine for this Crawler, keeping track of the path crawled by this Crawler.
@@ -89,8 +90,6 @@
 
 	private final CrawljaxConfiguration config;
 
-	private FormHandler formHandler;
-
 	/**
 	 * The object to places calls to add new Crawlers or to remove one.
 	 */
@@ -98,15 +97,15 @@
 
 	private final Plugins plugins;
 
+	private FormHandler formHandler;
+
+	private boolean fired = false;
+
 	/**
-	 * Enum for describing what has happened after a {@link Crawler#clickTag(Eventable)} has been
-	 * performed.
-	 * 
-	 * @see Crawler#clickTag(Eventable)
+	 * The main browser window 1 to 1 relation; Every Thread will get on browser assigned in the run
+	 * function.
 	 */
-	private enum ClickResult {
-		CLONE_DETECTED, NEW_STATE, DOM_UNCHANGED, LEFT_DOMAIN
-	}
+	private EmbeddedBrowser browser;
 
 	/**
 	 * @param mother
@@ -116,10 +115,8 @@
 	 * @param name
 	 *            a name for this crawler (default is empty).
 	 */
-	public Crawler(CrawljaxController mother, List<Eventable> exactEventPath, String name,
-	        Plugins plugins) {
-		this(mother, new CrawlPath(exactEventPath), plugins);
-		this.name = name;
+	public Crawler(CrawljaxController mother, List<Eventable> exactEventPath, String name) {
+		this(mother, new CrawlPath(exactEventPath), name);
 	}
 
 	/**
@@ -130,11 +127,12 @@
 	 * @param returnPath
 	 *            the path used to return to the last state, this can be a empty list
 	 */
-	protected Crawler(CrawljaxController mother, CrawlPath returnPath, Plugins plugins) {
+	protected Crawler(CrawljaxController mother, CrawlPath returnPath, String name) {
 		this.backTrackPath = returnPath;
+		this.name = name;
 		this.controller = mother;
-		this.plugins = plugins;
 		this.config = controller.getConfiguration();
+		this.plugins = config.getPlugins();
 		this.crawlQueueManager = mother.getCrawlQueueManager();
 		if (controller.getSession() != null) {
 			this.stateMachine =
@@ -151,13 +149,162 @@
 	}
 
 	/**
-	 * Brings the browser to the initial state.
+	 * The main function stated by the ExecutorService. Crawlers add themselves to the list by
+	 * calling {@link CrawlQueueManager#addWorkToQueue(Crawler)}. When the ExecutorService finds a
+	 * free thread this method is called and when this method ends the Thread is released again and
+	 * a new Thread is started
+	 * 
+	 * @see java.util.concurrent.Executors#newFixedThreadPool(int)
+	 * @see java.util.concurrent.ExecutorService
 	 */
-	public void goToInitialURL() {
+	@Override
+	public void run() {
+		if (!shouldContinueCrawling()) {
+			return;
+		}
+
+		try {
+			if (backTrackPath.last() != null
+			        && !backTrackPath.last().getTargetStateVertex().startWorking(this)) {
+				LOG.warn(""Could not register crawler. Quitting"");
+				return;
+			}
+
+			try {
+				this.init();
+			} catch (InterruptedException e) {
+				LOG.debug(""Could not fetch a browser from the pool"");
+				return;
+			}
+
+			// Hand over the main crawling
+			if (!this.crawl()) {
+				controller.terminate(false);
+			}
+
+			// Crawling is done; so the crawlPath of the current branch is known
+			if (!fired) {
+				controller.getSession().removeCrawlPath();
+			}
+		} catch (BrowserConnectionException e) {
+			// The connection of the browser has gone down, most of the times it
+			// means that the browser process has crashed.
+			LOG.error(""Crawler failed because the used browser died during Crawling"",
+			        new CrawlPathToException(""Crawler failed due to browser crash"", controller
+			                .getSession().getCurrentCrawlPath(), e));
+			// removeBrowser will throw a RuntimeException if the current browser
+			// is the last
+			// browser in the pool.
+			this.controller.getBrowserPool().removeBrowser(this.getBrowser(),
+			        this.controller.getCrawlQueueManager());
+			return;
+		} catch (CrawljaxException e) {
+			LOG.error(""Crawl failed!"", e);
+		}
+		/**
+		 * At last failure or non shutdown the Crawler.
+		 */
+		this.shutdown();
+	}
+
+	/**
+	 * Initialize the Crawler, retrieve a Browser and go to the initial URL when no browser was
+	 * present. rewind the state machine and goBack to the state if there is exactEventPath is
+	 * specified.
+	 * 
+	 * @throws InterruptedException
+	 *             when the request for a browser is interrupted.
+	 */
+	public void init() throws InterruptedException {
+		// Start a new CrawlPath for this Crawler
+		controller.getSession().startNewPath();
+
+		this.browser = this.getBrowser();
+		if (this.browser == null) {
+			/**
+			 * As the browser is null, request one and got to the initial URL, if the browser is
+			 * Already set the browser will be in the initial URL.
+			 */
+			this.browser = controller.getBrowserPool().requestBrowser();
+			LOG.info(""Reloading page for navigating back"");
+			this.goToInitialURL(true);
+		}
+		// TODO Stefan ideally this should be placed in the constructor
+		this.formHandler =
+		        new FormHandler(getBrowser(), config.getCrawlRules().getInputSpecification(),
+		                config.getCrawlRules().isRandomInputInForms());
+
+		this.candidateExtractor =
+		        new CandidateElementExtractor(controller.getElementChecker(), this.getBrowser(),
+		                formHandler, config);
+		/**
+		 * go back into the previous state.
+		 */
+		try {
+			this.goBackExact(backTrackPath);
+		} catch (CrawljaxException e) {
+			LOG.error(""Failed to backtrack"", e);
+		}
+	}
+
+	/**
+	 * Brings the browser to the initial state.
+	 * 
+	 * @param runPlugins
+	 *            To run the {@link OnUrlLoadPlugin} plugins.
+	 */
+	public void goToInitialURL(boolean runPlugins) {
 		LOG.info(""Loading Page {}"", config.getUrl());
 		getBrowser().goToUrl(config.getUrl());
 		controller.doBrowserWait(getBrowser());
-		plugins.runOnUrlLoadPlugins(getBrowser());
+		if (runPlugins) {
+			plugins.runOnUrlLoadPlugins(getBrowser());
+		}
+	}
+
+	/**
+	 * Reload the browser following the {@link #backTrackPath} to the given currentEvent.
+	 * 
+	 * @param b
+	 * @param backTrackPath2
+	 * @throws CrawljaxException
+	 *             if the {@link Eventable#getTargetStateVertex()} encounters an error.
+	 */
+	private void goBackExact(CrawlPath path) throws CrawljaxException {
+		StateVertex curState = controller.getSession().getInitialState();
+
+		for (Eventable clickable : backTrackPath) {
+
+			if (!controller.getElementChecker().checkCrawlCondition(getBrowser())) {
+				return;
+			}
+
+			LOG.info(""Backtracking by executing {} on element: {}"", clickable.getEventType(),
+			        clickable);
+
+			this.getStateMachine().changeState(clickable.getTargetStateVertex());
+
+			curState = clickable.getTargetStateVertex();
+
+			controller.getSession().addEventableToCrawlPath(clickable);
+
+			this.handleInputElements(clickable);
+
+			if (this.fireEvent(clickable)) {
+
+				int d = depth.incrementAndGet();
+				LOG.debug(""Crawl depth now {}"", d);
+
+				/*
+				 * Run the onRevisitStateValidator(s)
+				 */
+				plugins.runOnRevisitStatePlugins(this.controller.getSession(), curState);
+			}
+
+			if (!controller.getElementChecker().checkCrawlCondition(getBrowser())) {
+				return;
+			}
+		}
 	}
 
 	/**
@@ -279,8 +426,8 @@
 		} else {
 			LOG.info(""Found an invisible link with href={}"", href);
 			try {
-				URL url = UrlUtils.extractNewUrl(browser.getCurrentUrl(), href);
-				browser.goToUrl(url);
+				URL url = UrlUtils.extractNewUrl(getBrowser().getCurrentUrl(), href);
+				getBrowser().goToUrl(url);
 				return true;
 			} catch (MalformedURLException e) {
 				LOG.info(""Could not visit invisible illegal URL {}"", e.getMessage());
@@ -412,19 +559,19 @@
 	}
 
 	private boolean crawlerLeftDomain() {
-		return !browser.getCurrentUrl().toLowerCase()
+		return !getBrowser().getCurrentUrl().toLowerCase()
 		        .contains(config.getUrl().getHost().toLowerCase());
 	}
 
 	private void spawnThreads(StateVertex state) {
-		Crawler c = null;
+		Crawler crawler = null;
 		do {
-			if (c != null) {
-				this.crawlQueueManager.addWorkToQueue(c);
+			if (crawler != null) {
+				this.crawlQueueManager.addWorkToQueue(crawler);
 			}
-			c = new Crawler(this.controller, controller.getSession().getCurrentCrawlPath()
-			        .immutableCopy(true), config.getPlugins());
-		} while (state.registerCrawler(c));
+			crawler = new Crawler(this.controller, controller.getSession().getCurrentCrawlPath()
+			        .immutableCopy(true), """");
+		} while (state.registerCrawler(crawler));
 	}
 
 	/**
@@ -455,6 +602,10 @@
 			orrigionalState.filterCandidateActions(candidateElements);
 		}
 
+		return crawlThroughActions(orrigionalState);
+	}
+
+	private boolean crawlThroughActions(StateVertex orrigionalState) {
 		CandidateCrawlAction action =
 		        orrigionalState.pollCandidateCrawlAction(this, crawlQueueManager);
 		while (action != null) {
@@ -473,7 +624,7 @@
 				case CLONE_DETECTED:
 					return true;
 				case LEFT_DOMAIN:
-					getBrowser().goBack();
+					goBackOneState();
 				default:
 					break;
 			}
@@ -482,6 +633,16 @@
 		return true;
 	}
 
+	private void goBackOneState() {
+		LOG.debug(""Going back one state"");
+		goToInitialURL(false);
+		if (stateMachine != null) {
+			stateMachine.rewind();
+		}
+		controller.getSession().startNewPath();
+		goBackExact(controller.getSession().getCurrentCrawlPath().immutableCopy(false));
+	}
+
 	/**
 	 * Have we reached the depth limit?
 	 * 
@@ -523,46 +684,6 @@
 	}
 
 	/**
-	 * Initialize the Crawler, retrieve a Browser and go to the initial URL when no browser was
-	 * present. rewind the state machine and goBack to the state if there is exactEventPath is
-	 * specified.
-	 * 
-	 * @throws InterruptedException
-	 *             when the request for a browser is interrupted.
-	 */
-	public void init() throws InterruptedException {
-		// Start a new CrawlPath for this Crawler
-		controller.getSession().startNewPath();
-
-		this.browser = this.getBrowser();
-		if (this.browser == null) {
-			/**
-			 * As the browser is null, request one and got to the initial URL, if the browser is
-			 * Already set the browser will be in the initial URL.
-			 */
-			this.browser = controller.getBrowserPool().requestBrowser();
-			LOG.info(""Reloading page for navigating back"");
-			this.goToInitialURL();
-		}
-		// TODO Stefan ideally this should be placed in the constructor
-		this.formHandler =
-		        new FormHandler(getBrowser(), config.getCrawlRules().getInputSpecification(),
-		                config.getCrawlRules().isRandomInputInForms());
-
-		this.candidateExtractor =
-		        new CandidateElementExtractor(controller.getElementChecker(), this.getBrowser(),
-		                formHandler, config);
-		/**
-		 * go back into the previous state.
-		 */
-		try {
-			this.goBackExact();
-		} catch (CrawljaxException e) {
-			LOG.error(""Failed to backtrack"", e);
-		}
-	}
-
-	/**
 	 * Terminate and clean up this Crawler, release the acquired browser. Notice that other Crawlers
 	 * might still be active. So this function does NOT shutdown all Crawlers active that should be
 	 * done with {@link CrawlerExecutor#shutdown()}
@@ -572,78 +693,6 @@
 	}
 
 	/**
-	 * The main function stated by the ExecutorService. Crawlers add themselves to the list by
-	 * calling {@link CrawlQueueManager#addWorkToQueue(Crawler)}. When the ExecutorService finds a
-	 * free thread this method is called and when this method ends the Thread is released again and
-	 * a new Thread is started
-	 * 
-	 * @see java.util.concurrent.Executors#newFixedThreadPool(int)
-	 * @see java.util.concurrent.ExecutorService
-	 */
-	@Override
-	public void run() {
-		if (!shouldContinueCrawling()) {
-			// Constrains are not met at start of this Crawler, so stop immediately
-			return;
-		}
-		if (backTrackPath.last() != null) {
-			try {
-				if (!backTrackPath.last().getTargetStateVertex().startWorking(this)) {
-					return;
-				}
-			} catch (CrawljaxException e) {
-				LOG.error(""Received Crawljax exception"", e);
-			}
-		}
-
-		try {
-			/**
-			 * Init the Crawler
-			 */
-			try {
-				this.init();
-			} catch (InterruptedException e) {
-				if (this.getBrowser() == null) {
-					return;
-				}
-			}
-
-			/**
-			 * Hand over the main crawling
-			 */
-			if (!this.crawl()) {
-				controller.terminate(false);
-			}
-
-			/**
-			 * Crawling is done; so the crawlPath of the current branch is known
-			 */
-			if (!fired) {
-				controller.getSession().removeCrawlPath();
-			}
-		} catch (BrowserConnectionException e) {
-			// The connection of the browser has gone down, most of the times it
-			// means that the
-			// browser process has crashed.
-			LOG.error(""Crawler failed because the used browser died during Crawling"",
-			        new CrawlPathToException(""Crawler failed due to browser crash"", controller
-			                .getSession().getCurrentCrawlPath(), e));
-			// removeBrowser will throw a RuntimeException if the current browser
-			// is the last
-			// browser in the pool.
-			this.controller.getBrowserPool().removeBrowser(this.getBrowser(),
-			        this.controller.getCrawlQueueManager());
-			return;
-		} catch (CrawljaxException e) {
-			LOG.error(""Crawl failed!"", e);
-		}
-		/**
-		 * At last failure or non shutdown the Crawler.
-		 */
-		this.shutdown();
-	}
-
-	/**
 	 * Return the browser used in this Crawler Thread.
 	 * 
 	 * @return the browser used in this Crawler Thread
"
52d9c7b94c09433d36afc5e2eb03e7387487864b,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index 6a2a5ae..509f64d 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -111,8 +111,6 @@
 	 * 
 	 * @throws CrawljaxException
 	 *             If the browser cannot be instantiated.
-	 * @throws ConfigurationException
-	 *             if crawljax configuration fails.
 	 * @NotThreadSafe
 	 */
 	public final void run() throws CrawljaxException {
@@ -123,7 +121,7 @@
 		        .getPreCrawlConfig().getIncludedElements());
 
 		// Create the initailCrawler
-		initialCrawler = new InitialCrawler(this, configuration.getPlugins());
+		initialCrawler = new InitialCrawler(this);
 
 		// Start the Crawling by adding the initialCrawler to the the workQueue.
 		addWorkToQueue(initialCrawler);
"
52d9c7b94c09433d36afc5e2eb03e7387487864b,Alex Nederlof,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 0bc8d5f..bdb6a53 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -295,16 +295,18 @@
 		// make sure not before the node
 		int openElements = 1;
 		int i = 0;
-		int position = pos; 
+		int position = pos;
 		String dom_lower = dom.toLowerCase();
 		String element_lower = element.toLowerCase();
 		String openElement = ""<"" + element_lower;
 		String closeElement = ""</"" + element_lower;
 		while (i < MAX_SEARCH_LOOPS) {
-			if (dom_lower.indexOf(openElement, position) == -1 && dom_lower.indexOf(closeElement, position) == -1) {
+			if (dom_lower.indexOf(openElement, position) == -1
+			        && dom_lower.indexOf(closeElement, position) == -1) {
 				return -1;
 			}
-			if (dom_lower.indexOf(openElement, position) < dom_lower.indexOf(closeElement, position)
+			if (dom_lower.indexOf(openElement, position) < dom_lower.indexOf(closeElement,
+			        position)
 			        && dom_lower.indexOf(openElement, position) != -1) {
 				openElements++;
 				position = dom_lower.indexOf(openElement, position) + 1;
@@ -341,14 +343,18 @@
 	 *         text()
 	 */
 	public static String stripXPathToElement(String xpath) {
-		String xpathStripped = xpath; 
-		
+		String xpathStripped = xpath;
+
 		if (!Strings.isNullOrEmpty(xpathStripped)) {
 			if (xpathStripped.toLowerCase().contains(""/text()"")) {
-				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/text()""));
+				xpathStripped =
+				        xpathStripped
+				                .substring(0, xpathStripped.toLowerCase().indexOf(""/text()""));
 			}
 			if (xpathStripped.toLowerCase().contains(""/comment()"")) {
-				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/comment()""));
+				xpathStripped =
+				        xpathStripped.substring(0,
+				                xpathStripped.toLowerCase().indexOf(""/comment()""));
 			}
 			if (xpathStripped.contains(""@"")) {
 				xpathStripped = xpathStripped.substring(0, xpathStripped.indexOf(""@"") - 1);
"
dff8b60ac72b0099ab6f6bc8765c60e6b7b6946f,Alex Nederlof,Crawler.java,MODIFY,goToInitialURL -> [boolean runPlugins] | [],"diff --git a/core/src/main/java/com/crawljax/core/Crawler.java b/core/src/main/java/com/crawljax/core/Crawler.java
index e1c5295..a3d2d5b 100644
--- a/core/src/main/java/com/crawljax/core/Crawler.java
+++ b/core/src/main/java/com/crawljax/core/Crawler.java
@@ -458,20 +458,20 @@
 		}
 
 		// Store the currentState to be able to 'back-track' later.
-		StateVertex orrigionalState = this.getStateMachine().getCurrentState();
+		StateVertex originalState = this.getStateMachine().getCurrentState();
 
-		if (orrigionalState.searchForCandidateElements(candidateExtractor)) {
+		if (originalState.searchForCandidateElements(candidateExtractor)) {
 			// Only execute the preStateCrawlingPlugins when it's the first time
 			LOG.info(""Starting preStateCrawlingPlugins..."");
 			List<CandidateElement> candidateElements =
-			        orrigionalState.getUnprocessedCandidateElements();
+			        originalState.getUnprocessedCandidateElements();
 			plugins.runPreStateCrawlingPlugins(controller.getSession(), candidateElements);
 			// update crawlActions
-			orrigionalState.filterCandidateActions(candidateElements);
+			originalState.filterCandidateActions(candidateElements);
 		}
 
 		CandidateCrawlAction action =
-		        orrigionalState.pollCandidateCrawlAction(this, crawlQueueManager);
+		        originalState.pollCandidateCrawlAction(this, crawlQueueManager);
 		while (action != null) {
 			if (depthLimitReached()) {
 				return true;
@@ -481,16 +481,16 @@
 				return false;
 			}
 			ClickResult result = this.crawlAction(action);
-			orrigionalState.finishedWorking(this, action);
+			originalState.finishedWorking(this, action);
 			switch (result) {
 				case NEW_STATE:
-					return newStateDetected(orrigionalState);
+					return newStateDetected(originalState);
 				case CLONE_DETECTED:
 					return true;
 				default:
 					break;
 			}
-			action = orrigionalState.pollCandidateCrawlAction(this, crawlQueueManager);
+			action = originalState.pollCandidateCrawlAction(this, crawlQueueManager);
 		}
 		return true;
 	}
"
7a483a5d9ac3fcc83c9c0661c0c8c7b5df6bc780,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index 287b05d..aef2647 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -67,88 +67,87 @@
 	private void setInputElementValue(Node element, FormInput input) {
 
 		LOGGER.debug(""INPUTFIELD: {} ({})"", input.getIdentification(), input.getType());
-		if (element == null) {
+		if (element == null || input.getInputValues().isEmpty()) {
 			return;
 		}
-		if (input.getInputValues().iterator().hasNext()) {
-			try {
-				// fill in text fields, textareas, password fields and hidden
-				// fields
-				if (input.getType().toLowerCase().startsWith(""text"")
-				        || input.getType().equalsIgnoreCase(""password"")
-				        || input.getType().equalsIgnoreCase(""hidden"")) {
-					String text = input.getInputValues().iterator().next().getValue();
-					if ("""".equals(text)) {
-						return;
-					}
-					String js = DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-					js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
-					browser.executeJavaScript(js);
-				}
+		try {
+			if (input.getType().toLowerCase().startsWith(""text"")
+			        || input.getType().equalsIgnoreCase(""password"")
+			        || input.getType().equalsIgnoreCase(""hidden"")) {
+				handleText(element, input);
+			} else if (""checkbox"".equals(input.getType())) {
+				handleCheckBoxes(element, input);
+			} else if (input.getType().equals(""radio"")) {
+				handleRadioSwitches(element, input);
+			} else if (input.getType().startsWith(""select"")) {
+				handleSelectBoxes(element, input);
+			}
+		} catch (BrowserConnectionException e) {
+			throw e;
+		} catch (RuntimeException e) {
+			LOGGER.error(""Could not input element values"", e);
+		}
+	}
 
-				// check/uncheck checkboxes
-				if (""checkbox"".equals(input.getType())) {
-					for (InputValue inputValue : input.getInputValues()) {
-						String js =
-						        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-						boolean check;
-						if (!randomFieldValue) {
-							check = inputValue.isChecked();
-						} else {
+	private void handleCheckBoxes(Node element, FormInput input) {
+		for (InputValue inputValue : input.getInputValues()) {
+			String js =
+			        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
+			boolean check;
+			if (!randomFieldValue) {
+				check = inputValue.isChecked();
+			} else {
 
-							check = Math.random() >= HALF;
-						}
-						String value;
-						if (check) {
-							value = ""true"";
-						} else {
-							value = ""false"";
-						}
-						js += ""try{ATUSA_element.checked="" + value + "";}catch(e){}"";
-						browser.executeJavaScript(js);
+				check = Math.random() >= HALF;
+			}
+			String value;
+			if (check) {
+				value = ""true"";
+			} else {
+				value = ""false"";
+			}
+			js += ""try{ATUSA_element.checked="" + value + "";}catch(e){}"";
+			browser.executeJavaScript(js);
 
-					}
-				}
+		}
+	}
 
-				// check radio button
-				if (input.getType().equals(""radio"")) {
-					for (InputValue inputValue : input.getInputValues()) {
-						if (inputValue.isChecked()) {
-							String js =
-							        DomUtils.getJSGetElement(XPathHelper
-							                .getXPathExpression(element));
-							js += ""try{ATUSA_element.checked=true;}catch(e){}"";
-							browser.executeJavaScript(js);
-						}
-					}
-				}
-
-				// select options
-				if (input.getType().startsWith(""select"")) {
-					for (InputValue inputValue : input.getInputValues()) {
-						// if(browser.getDriver()==null){
-						String js =
-						        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-						js +=
-						        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
-						                + ""if(ATUSA_element.options[i].value=='""
-						                + inputValue.getValue()
-						                + ""' || ATUSA_element.options[i].text=='""
-						                + inputValue.getValue() + ""'){""
-						                + ""ATUSA_element.options[i].selected=true;"" + ""break;""
-						                + ""}"" + ""};"" + ""}catch(e){}"";
-						browser.executeJavaScript(js);
-					}
-				}
-			} catch (Exception e) {
-				// TODO Stefan; refactor this catch
-				if (e instanceof BrowserConnectionException) {
-					throw (BrowserConnectionException) e;
-				}
-				LOGGER.error(e.getMessage(), e);
+	private void handleRadioSwitches(Node element, FormInput input) {
+		for (InputValue inputValue : input.getInputValues()) {
+			if (inputValue.isChecked()) {
+				String js =
+				        DomUtils.getJSGetElement(XPathHelper
+				                .getXPathExpression(element));
+				js += ""try{ATUSA_element.checked=true;}catch(e){}"";
+				browser.executeJavaScript(js);
 			}
 		}
+	}
 
+	private void handleSelectBoxes(Node element, FormInput input) {
+		for (InputValue inputValue : input.getInputValues()) {
+			String js =
+			        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
+			js +=
+			        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
+			                + ""if(ATUSA_element.options[i].value=='""
+			                + inputValue.getValue()
+			                + ""' || ATUSA_element.options[i].text=='""
+			                + inputValue.getValue() + ""'){""
+			                + ""ATUSA_element.options[i].selected=true;"" + ""break;""
+			                + ""}"" + ""};"" + ""}catch(e){}"";
+			browser.executeJavaScript(js);
+		}
+	}
+
+	private void handleText(Node element, FormInput input) {
+		String text = input.getInputValues().iterator().next().getValue();
+		if ("""".equals(text)) {
+			return;
+		}
+		String js = DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
+		js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
+		browser.executeJavaScript(js);
 	}
 
 	/**
"
7a483a5d9ac3fcc83c9c0661c0c8c7b5df6bc780,Alex Nederlof,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index 2918262..d0d3edd 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -30,7 +30,6 @@
 import org.custommonkey.xmlunit.DetailedDiff;
 import org.custommonkey.xmlunit.Diff;
 import org.custommonkey.xmlunit.Difference;
-import org.custommonkey.xmlunit.DifferenceListener;
 import org.cyberneko.html.parsers.DOMParser;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -44,6 +43,7 @@
 import org.xml.sax.SAXException;
 
 import com.crawljax.core.CrawljaxException;
+import com.google.common.base.Strings;
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Lists;
 
@@ -118,23 +118,27 @@
 	 */
 	public static String getElementAttributes(Element element, ImmutableSet<String> exclude) {
 		StringBuilder buffer = new StringBuilder();
-
 		if (element != null) {
 			NamedNodeMap attributes = element.getAttributes();
 			if (attributes != null) {
-				for (int i = 0; i < attributes.getLength(); i++) {
-					Attr attr = (Attr) attributes.item(i);
-					if (!exclude.contains(attr.getNodeName())) {
-						buffer.append(attr.getNodeName()).append('=');
-						buffer.append(attr.getNodeValue()).append(' ');
-					}
-				}
+				addAttributesToString(exclude, buffer, attributes);
 			}
 		}
 
 		return buffer.toString().trim();
 	}
 
+	private static void addAttributesToString(ImmutableSet<String> exclude, StringBuilder buffer,
+	        NamedNodeMap attributes) {
+		for (int i = 0; i < attributes.getLength(); i++) {
+			Attr attr = (Attr) attributes.item(i);
+			if (!exclude.contains(attr.getNodeName())) {
+				buffer.append(attr.getNodeName()).append('=');
+				buffer.append(attr.getNodeValue()).append(' ');
+			}
+		}
+	}
+
 	/**
 	 * @param element
 	 *            the element.
@@ -142,17 +146,17 @@
 	 */
 	public static String getElementString(Element element) {
 		String text = DomUtils.removeNewLines(DomUtils.getTextValue(element)).trim();
-		String info = """";
-		if (!text.equals("""")) {
-			info += ""\"""" + text + ""\"" "";
+		StringBuilder info = new StringBuilder();
+		if (!Strings.isNullOrEmpty(text)) {
+			info.append(""\"""").append(text).append(""\"" "");
 		}
 		if (element != null) {
 			if (element.hasAttribute(""id"")) {
-				info += ""ID: "" + element.getAttribute(""id"") + "" "";
+				info.append(""ID: "").append(element.getAttribute(""id"")).append("" "");
 			}
-			info += DomUtils.getAllElementAttributes(element) + "" "";
+			info.append(DomUtils.getAllElementAttributes(element)).append("" "");
 		}
-		return info;
+		return info.toString();
 	}
 
 	/**
@@ -281,8 +285,8 @@
 	 */
 	public static String getTextValue(Element element) {
 		String ret = """";
-		String textContent = element.getTextContent(); 
-		if (textContent != null && !textContent.equals("""") ) {
+		String textContent = element.getTextContent();
+		if (textContent != null && !textContent.equals("""")) {
 			ret = textContent;
 		} else if (element.hasAttribute(""title"")) {
 			ret = element.getAttribute(""title"");
@@ -326,29 +330,7 @@
 		try {
 			Diff d = new Diff(DomUtils.asDocument(controlDom), DomUtils.asDocument(testDom));
 			DetailedDiff dd = new DetailedDiff(d);
-			dd.overrideDifferenceListener(new DifferenceListener() {
-
-				@Override
-				public void skippedComparison(Node control, Node test) {
-				}
-
-				@Override
-				public int differenceFound(Difference difference) {
-					if (difference.getControlNodeDetail() == null
-					        || difference.getControlNodeDetail().getNode() == null
-					        || difference.getTestNodeDetail() == null
-					        || difference.getTestNodeDetail().getNode() == null) {
-						return RETURN_ACCEPT_DIFFERENCE;
-					}
-					if (ignoreAttributes.contains(difference.getTestNodeDetail().getNode()
-					        .getNodeName())
-					        || ignoreAttributes.contains(difference.getControlNodeDetail()
-					                .getNode().getNodeName())) {
-						return RETURN_IGNORE_DIFFERENCE_NODES_IDENTICAL;
-					}
-					return RETURN_ACCEPT_DIFFERENCE;
-				}
-			});
+			dd.overrideDifferenceListener(new DomDifferenceListener(ignoreAttributes));
 
 			return dd.getAllDifferences();
 		} catch (IOException e) {
@@ -394,7 +376,7 @@
 	 * @return The new, correct path.
 	 */
 	public static String addFolderSlashIfNeeded(String folderName) {
-		if (!folderName.equals("""") && !folderName.endsWith(""/"")) {
+		if (!"""".equals(folderName) && !folderName.endsWith(""/"")) {
 			return folderName + ""/"";
 		} else {
 			return folderName;
@@ -461,8 +443,7 @@
 	 */
 	public static String getJSGetElement(String xpath) {
 		String js =
-		        """"
-		                + ""function ATUSA_getElementInNodes(nodes, tagName, number){""
+		        ""function ATUSA_getElementInNodes(nodes, tagName, number){""
 		                + ""try{""
 		                + ""var pos = 1;""
 		                + ""for(i=0; i<nodes.length; i++){""
"
4c6dbae80ea4c5d3aa99c68ccde7805f3fba0482,Alex Nederlof,Crawler.java,MODIFY,goToInitialURL -> [] | [boolean runPlugins],"diff --git a/core/src/main/java/com/crawljax/core/Crawler.java b/core/src/main/java/com/crawljax/core/Crawler.java
index 0cea9ce..b4dde84 100644
--- a/core/src/main/java/com/crawljax/core/Crawler.java
+++ b/core/src/main/java/com/crawljax/core/Crawler.java
@@ -273,50 +273,7 @@
 	private void goBackExact(CrawlPath path) throws CrawljaxException {
 		StateVertex curState = controller.getSession().getInitialState();
 
-		for (Eventable clickable : backTrackPath) {
-
-			if (!controller.getElementChecker().checkCrawlCondition(getBrowser())) {
-				return;
-			}
-
-			LOG.info(""Backtracking by executing {} on element: {}"", clickable.getEventType(),
-			        clickable);
-
-			this.getStateMachine().changeState(clickable.getTargetStateVertex());
-
-			curState = clickable.getTargetStateVertex();
-
-			controller.getSession().addEventableToCrawlPath(clickable);
-
-			this.handleInputElements(clickable);
-
-			if (this.fireEvent(clickable)) {
-
-				int d = depth.incrementAndGet();
-				LOG.debug(""Crawl depth now {}"", d);
-
-				/*
-				 * Run the onRevisitStateValidator(s)
-				 */
-				plugins.runOnRevisitStatePlugins(this.controller.getSession(), curState);
-			}
-
-			if (!controller.getElementChecker().checkCrawlCondition(getBrowser())) {
-				return;
-			}
-		}
-	}
-
-	/**
-	 * Reload the browser following the {@link #backTrackPath} to the given currentEvent.
-	 * 
-	 * @throws CrawljaxException
-	 *             if the {@link Eventable#getTargetStateVertex()} encounters an error.
-	 */
-	private void goBackExact() throws CrawljaxException {
-		StateVertex curState = controller.getSession().getInitialState();
-
-		for (Eventable clickable : backTrackPath) {
+		for (Eventable clickable : path) {
 
 			if (!controller.getElementChecker().checkCrawlCondition(getBrowser())) {
 				return;
@@ -500,7 +457,7 @@
 	}
 
 	private void waitForRefreshTagIfAny(final Eventable eventable) {
-		if (eventable.getElement().getTag().toLowerCase().equals(""meta"")) {
+		if (eventable.getElement().getTag().equalsIgnoreCase(""meta"")) {
 			Pattern p = Pattern.compile(""(\\d+);\\s+URL=(.*)"");
 			for (Entry<String, String> e : eventable.getElement().getAttributes().entrySet()) {
 				Matcher m = p.matcher(e.getValue());
@@ -635,12 +592,14 @@
 
 	private void goBackOneState() {
 		LOG.debug(""Going back one state"");
+		CrawlPath currentPath =
+		        controller.getSession().getCurrentCrawlPath().immutableCopy(false);
 		goToInitialURL(false);
 		if (stateMachine != null) {
 			stateMachine.rewind();
 		}
 		controller.getSession().startNewPath();
-		goBackExact(controller.getSession().getCurrentCrawlPath().immutableCopy(false));
+		goBackExact(currentPath);
 	}
 
 	/**
"
10b294065127ff80980dc7d41f0882a968e4cfb6,Alex Nederlof,Crawler.java,MODIFY,crawlThroughActions -> [StateVertex orrigionalState] | [StateVertex originalState],"diff --git a/core/src/main/java/com/crawljax/core/Crawler.java b/core/src/main/java/com/crawljax/core/Crawler.java
index b4dde84..e73b41e 100644
--- a/core/src/main/java/com/crawljax/core/Crawler.java
+++ b/core/src/main/java/com/crawljax/core/Crawler.java
@@ -547,24 +547,24 @@
 		}
 
 		// Store the currentState to be able to 'back-track' later.
-		StateVertex orrigionalState = this.getStateMachine().getCurrentState();
+		StateVertex originalState = this.getStateMachine().getCurrentState();
 
-		if (orrigionalState.searchForCandidateElements(candidateExtractor)) {
+		if (originalState.searchForCandidateElements(candidateExtractor)) {
 			// Only execute the preStateCrawlingPlugins when it's the first time
 			LOG.info(""Starting preStateCrawlingPlugins..."");
 			List<CandidateElement> candidateElements =
-			        orrigionalState.getUnprocessedCandidateElements();
+			        originalState.getUnprocessedCandidateElements();
 			plugins.runPreStateCrawlingPlugins(controller.getSession(), candidateElements);
 			// update crawlActions
-			orrigionalState.filterCandidateActions(candidateElements);
+			originalState.filterCandidateActions(candidateElements);
 		}
 
-		return crawlThroughActions(orrigionalState);
+		return crawlThroughActions(originalState);
 	}
 
-	private boolean crawlThroughActions(StateVertex orrigionalState) {
+	private boolean crawlThroughActions(StateVertex originalState) {
 		CandidateCrawlAction action =
-		        orrigionalState.pollCandidateCrawlAction(this, crawlQueueManager);
+		        originalState.pollCandidateCrawlAction(this, crawlQueueManager);
 		while (action != null) {
 			if (depthLimitReached()) {
 				return true;
@@ -574,10 +574,11 @@
 				return false;
 			}
 			ClickResult result = this.crawlAction(action);
-			orrigionalState.markAsFinished(this, action);
+			originalState.markAsFinished(this, action);
+
 			switch (result) {
 				case NEW_STATE:
-					return newStateDetected(orrigionalState);
+					return newStateDetected(originalState);
 				case CLONE_DETECTED:
 					return true;
 				case LEFT_DOMAIN:
@@ -585,7 +586,7 @@
 				default:
 					break;
 			}
-			action = orrigionalState.pollCandidateCrawlAction(this, crawlQueueManager);
+			action = originalState.pollCandidateCrawlAction(this, crawlQueueManager);
 		}
 		return true;
 	}
"
10b294065127ff80980dc7d41f0882a968e4cfb6,Alex Nederlof,StateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index a9d3c2b..a2291d7 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -38,6 +38,7 @@
 	 * Thread-safety.
 	 */
 	private final AtomicInteger stateCounter = new AtomicInteger();
+	private final AtomicInteger nextStateNameCounter = new AtomicInteger();
 
 	private final StateVertex initialState;
 
@@ -53,6 +54,7 @@
 		sfg.addVertex(initialState);
 		stateCounter.incrementAndGet();
 		this.initialState = initialState;
+		LOG.debug(""Initialized the stateflowgraph with an initial state"");
 	}
 
 	/**
@@ -69,8 +71,8 @@
 	 * @return the clone if one is detected null otherwise.
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
-	public StateVertex addState(StateVertex stateVertix) {
-		return addState(stateVertix, true);
+	public StateVertex putIfAbsent(StateVertex stateVertix) {
+		return putIfAbsent(stateVertix, true);
 	}
 
 	/**
@@ -90,19 +92,20 @@
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
 	@GuardedBy(""sfg"")
-	public StateVertex addState(StateVertex stateVertix, boolean correctName) {
+	public StateVertex putIfAbsent(StateVertex stateVertix, boolean correctName) {
 		synchronized (sfg) {
-			if (!sfg.addVertex(stateVertix)) {
-				// Graph already contained the vertix
-				LOG.debug(""Graph already contained vertex {}"", stateVertix);
-				return this.getStateInGraph(stateVertix);
-			} else {
+			boolean added = sfg.addVertex(stateVertix);
+			if (added) {
 				int count = stateCounter.incrementAndGet();
 				LOG.debug(""Number of states is now {}"", count);
 				if (correctName) {
 					correctStateName(stateVertix);
 				}
 				return null;
+			} else {
+				// Graph already contained the vertix
+				LOG.debug(""Graph already contained vertex {}"", stateVertix);
+				return this.getStateInGraph(stateVertix);
 			}
 		}
 	}
@@ -369,8 +372,7 @@
 	 * @return State name the name of the state
 	 */
 	public String getNewStateName() {
-		stateCounter.getAndIncrement();
-		String state = makeStateName(stateCounter.get(), false);
+		String state = makeStateName(nextStateNameCounter.incrementAndGet(), false);
 		return state;
 	}
 
"
cf2b94fb7d12b943e20068128494adc41e1f088d,Ryan Carniato,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 3f21f86..b680e39 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -38,7 +38,7 @@
 
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.AcceptAllFramesChecker;
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.crawljax.core.configuration.IgnoreFrameChecker;
 import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.core.state.Eventable;
@@ -48,6 +48,7 @@
 import com.crawljax.forms.InputValue;
 import com.crawljax.forms.RandomInputValueGenerator;
 import com.crawljax.util.DomUtils;
+import com.google.common.collect.ImmutableSortedSet;
 
 /**
  * @author mesbah
@@ -61,7 +62,7 @@
 	        .getLogger(WebDriverBackedEmbeddedBrowser.class);
 	private final WebDriver browser;
 
-	private List<String> filterAttributes;
+	private ImmutableSortedSet<String> filterAttributes;
 	private long crawlWaitReload;
 	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
 
@@ -88,8 +89,8 @@
 	 * @param crawlWaitEvent
 	 *            the period to wait after an event is fired.
 	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent) {
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload, long crawlWaitEvent) {
 		this(driver);
 		this.filterAttributes = filterAttributes;
 		this.crawlWaitEvent = crawlWaitEvent;
@@ -110,8 +111,9 @@
 	 * @param ignoreFrameChecker
 	 *            the checker used to determine if a certain frame must be ignored.
 	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver, List<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload,
+	        long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
 		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
 		this.ignoreFrameChecker = ignoreFrameChecker;
 	}
@@ -130,7 +132,7 @@
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
 		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
 		        filterAttributes, crawlWaitEvent, crawlWaitReload);
 	}
@@ -151,8 +153,8 @@
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-	        IgnoreFrameChecker ignoreFrameChecker) {
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent,
+	        long crawlWaitReload, IgnoreFrameChecker ignoreFrameChecker) {
 		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
 		        filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
 	}
@@ -171,7 +173,7 @@
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
 		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
 		        crawlWaitReload);
 	}
@@ -192,8 +194,8 @@
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        List<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload,
-	        IgnoreFrameChecker ignoreFrameChecker) {
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent,
+	        long crawlWaitReload, IgnoreFrameChecker ignoreFrameChecker) {
 		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
 		        crawlWaitReload, ignoreFrameChecker);
 	}
@@ -365,10 +367,6 @@
 		m = p.matcher(html);
 		htmlFormatted = m.replaceAll("""");
 
-		// TODO (Stefan), Following lines are a serious performance bottle neck...
-		// Document doc = Helper.getDocument(htmlFormatted);
-		// htmlFormatted = Helper.getDocumentToString(doc);
-
 		htmlFormatted = filterAttributes(htmlFormatted);
 		return htmlFormatted;
 	}
@@ -381,15 +379,16 @@
 	 * @return The filtered HTML string.
 	 */
 	private String filterAttributes(String html) {
+		String filteredHtml = html;
 		if (this.filterAttributes != null) {
 			for (String attribute : this.filterAttributes) {
 				String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
 				Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
 				Matcher m = p.matcher(html);
-				html = m.replaceAll("""");
+				filteredHtml = m.replaceAll("""");
 			}
 		}
-		return html;
+		return filteredHtml;
 	}
 
 	@Override
@@ -413,12 +412,9 @@
 		try {
 			WebElement field = browser.findElement(identification.getWebDriverBy());
 			if (field != null) {
-				// first clear the field
 				field.clear();
-				// then fill in
 				field.sendKeys(text);
 
-				// this.activeElement = field;
 				return true;
 			}
 			return false;
@@ -781,7 +777,7 @@
 	/**
 	 * @return the list of attributes to be filtered from DOM.
 	 */
-	protected List<String> getFilterAttributes() {
+	protected ImmutableSortedSet<String> getFilterAttributes() {
 		return filterAttributes;
 	}
 
@@ -792,31 +788,40 @@
 		return crawlWaitReload;
 	}
 
-	private void takeScreenShotOnBrowser(WebDriver driver, File file) throws CrawljaxException {
-		if (driver instanceof TakesScreenshot) {
-			File tmpfile = ((TakesScreenshot) driver).getScreenshotAs(OutputType.FILE);
-
+	@Override
+	public void saveScreenShot(File file) throws CrawljaxException {
+		try {
+			File tmpfile = takeScreenShotOnBrowser(browser, OutputType.FILE);
 			try {
 				FileHandler.copy(tmpfile, file);
 			} catch (IOException e) {
 				throw new CrawljaxException(e);
 			}
+		} catch (WebDriverException e) {
+			throw wrapWebDriverExceptionIfConnectionException(e);
+		}
+	}
 
+	private <T> T takeScreenShotOnBrowser(WebDriver driver, OutputType<T> outType)
+	        throws CrawljaxException {
+		if (driver instanceof TakesScreenshot) {
+			T screenshot = ((TakesScreenshot) driver).getScreenshotAs(outType);
 			removeCanvasGeneratedByFirefoxDriverForScreenshots();
+			return screenshot;
 		} else if (driver instanceof RemoteWebDriver) {
 			WebDriver augmentedWebdriver = new Augmenter().augment(driver);
-			takeScreenShotOnBrowser(augmentedWebdriver, file);
+			return takeScreenShotOnBrowser(augmentedWebdriver, outType);
 		} else if (driver instanceof WrapsDriver) {
-			takeScreenShotOnBrowser(((WrapsDriver) driver).getWrappedDriver(), file);
+			return takeScreenShotOnBrowser(((WrapsDriver) driver).getWrappedDriver(), outType);
 		} else {
 			throw new CrawljaxException(""Your current WebDriver doesn't support screenshots."");
 		}
 	}
 
 	@Override
-	public void saveScreenShot(File file) throws CrawljaxException {
+	public byte[] getScreenShot() throws CrawljaxException {
 		try {
-			takeScreenShotOnBrowser(browser, file);
+			return takeScreenShotOnBrowser(browser, OutputType.BYTES);
 		} catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
@@ -844,13 +849,12 @@
 	}
 
 	@Override
-	public void updateConfiguration(CrawljaxConfigurationReader configuration) {
+	public void updateConfiguration(CrawljaxConfiguration configuration) {
 		// Retrieve the config values used
-		this.filterAttributes = configuration.getFilterAttributeNames();
-		this.crawlWaitReload =
-		        configuration.getCrawlSpecificationReader().getWaitAfterReloadUrl();
-		this.crawlWaitEvent = configuration.getCrawlSpecificationReader().getWaitAfterEvent();
-		this.ignoreFrameChecker = configuration.getCrawlSpecificationReader();
+		this.filterAttributes =
+		        configuration.getCrawlRules().getPreCrawlConfig().getFilterAttributeNames();
+		this.crawlWaitReload = configuration.getCrawlRules().getWaitAfterReloadUrl();
+		this.crawlWaitEvent = configuration.getCrawlRules().getWaitAfterEvent();
 	}
 
 	private boolean exceptionIsConnectionException(WebDriverException exception) {
"
cf2b94fb7d12b943e20068128494adc41e1f088d,Ryan Carniato,Crawler.java,MODIFY,goToInitialURL -> [boolean runPlugins] | [],"diff --git a/core/src/main/java/com/crawljax/core/Crawler.java b/core/src/main/java/com/crawljax/core/Crawler.java
index e340cc1..e3db471 100644
--- a/core/src/main/java/com/crawljax/core/Crawler.java
+++ b/core/src/main/java/com/crawljax/core/Crawler.java
@@ -4,7 +4,9 @@
 import java.net.URL;
 import java.util.List;
 import java.util.Map.Entry;
+import java.util.concurrent.CopyOnWriteArrayList;
 import java.util.concurrent.TimeUnit;
+import java.util.concurrent.atomic.AtomicInteger;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
@@ -14,10 +16,10 @@
 import org.slf4j.LoggerFactory;
 
 import com.crawljax.browser.EmbeddedBrowser;
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.core.exception.CrawlPathToException;
-import com.crawljax.core.plugin.CrawljaxPluginsUtil;
+import com.crawljax.core.plugin.Plugins;
 import com.crawljax.core.state.CrawlPath;
 import com.crawljax.core.state.Element;
 import com.crawljax.core.state.Eventable;
@@ -38,7 +40,7 @@
  */
 public class Crawler implements Runnable {
 
-	private static final Logger LOGGER = LoggerFactory.getLogger(Crawler.class.getName());
+	private static final Logger LOG = LoggerFactory.getLogger(Crawler.class.getName());
 
 	/**
 	 * The main browser window 1 to 1 relation; Every Thread will get on browser assigned in the run
@@ -56,7 +58,7 @@
 	/**
 	 * Depth register.
 	 */
-	private int depth = 0;
+	private AtomicInteger depth = new AtomicInteger();
 
 	/**
 	 * The path followed from the index to the current state.
@@ -85,7 +87,7 @@
 	 */
 	private final StateMachine stateMachine;
 
-	private final CrawljaxConfigurationReader configurationReader;
+	private final CrawljaxConfiguration config;
 
 	private FormHandler formHandler;
 
@@ -94,6 +96,8 @@
 	 */
 	private final CrawlQueueManager crawlQueueManager;
 
+	private final Plugins plugins;
+
 	/**
 	 * Enum for describing what has happened after a {@link Crawler#clickTag(Eventable)} has been
 	 * performed.
@@ -101,7 +105,7 @@
 	 * @see Crawler#clickTag(Eventable)
 	 */
 	private enum ClickResult {
-		cloneDetected, newState, domUnChanged
+		CLONE_DETECTED, NEW_STATE, DOM_UNCHANGED
 	}
 
 	/**
@@ -112,8 +116,9 @@
 	 * @param name
 	 *            a name for this crawler (default is empty).
 	 */
-	public Crawler(CrawljaxController mother, List<Eventable> exactEventPath, String name) {
-		this(mother, new CrawlPath(exactEventPath));
+	public Crawler(CrawljaxController mother, List<Eventable> exactEventPath, String name,
+	        Plugins plugins) {
+		this(mother, new CrawlPath(exactEventPath), plugins);
 		this.name = name;
 	}
 
@@ -124,32 +129,20 @@
 	 *            the main CrawljaxController
 	 * @param returnPath
 	 *            the path used to return to the last state, this can be a empty list
-	 * @deprecated better to use {@link #Crawler(CrawljaxController, CrawlPath)}
 	 */
-	@Deprecated
-	protected Crawler(CrawljaxController mother, List<Eventable> returnPath) {
-		this(mother, new CrawlPath(returnPath));
-	}
-
-	/**
-	 * Private Crawler constructor for a 'reload' crawler. Only used internally.
-	 * 
-	 * @param mother
-	 *            the main CrawljaxController
-	 * @param returnPath
-	 *            the path used to return to the last state, this can be a empty list
-	 */
-	protected Crawler(CrawljaxController mother, CrawlPath returnPath) {
+	protected Crawler(CrawljaxController mother, CrawlPath returnPath, Plugins plugins) {
 		this.backTrackPath = returnPath;
 		this.controller = mother;
-		this.configurationReader = controller.getConfigurationReader();
+		this.plugins = plugins;
+		this.config = controller.getConfiguration();
 		this.crawlQueueManager = mother.getCrawlQueueManager();
 		if (controller.getSession() != null) {
 			this.stateMachine =
 			        new StateMachine(controller.getSession().getStateFlowGraph(), controller
-			                .getSession().getInitialState(), controller.getInvariantList());
+			                .getSession().getInitialState(), controller.getInvariantList(),
+			                plugins);
 		} else {
-			/**
+			/*
 			 * Reset the state machine to null, because there is no session where to load the
 			 * stateFlowGraph from.
 			 */
@@ -161,11 +154,10 @@
 	 * Brings the browser to the initial state.
 	 */
 	public void goToInitialURL() {
-		LOGGER.info(""Loading Page {}"", configurationReader.getCrawlSpecificationReader()
-		        .getSiteUrl());
-		getBrowser().goToUrl(configurationReader.getCrawlSpecificationReader().getSiteUrl());
+		LOG.info(""Loading Page {}"", config.getUrl());
+		getBrowser().goToUrl(config.getUrl());
 		controller.doBrowserWait(getBrowser());
-		CrawljaxPluginsUtil.runOnUrlLoadPlugins(getBrowser());
+		plugins.runOnUrlLoadPlugins(getBrowser());
 	}
 
 	/**
@@ -185,15 +177,16 @@
 		try {
 			fired = getBrowser().fireEvent(eventToFire);
 		} catch (ElementNotVisibleException | NoSuchElementException e) {
-			if (configurationReader.getCrawlSpecificationReader().crawlHiddenAnchors()
-			        && eventToFire.getElement() != null
+			if (config.getCrawlRules().isCrawlHiddenAnchors() && eventToFire.getElement() != null
 			        && ""A"".equals(eventToFire.getElement().getTag())) {
 				fired = visitAnchorHrefIfPossible(eventToFire);
 			} else {
-				LOGGER.debug(""Ignoring invisble element {}"", eventToFire.getElement());
+				LOG.debug(""Ignoring invisble element {}"", eventToFire.getElement());
 			}
 		}
 
+		LOG.debug(""Event fired={} for eventable {}"", fired, eventable);
+
 		if (fired) {
 
 			/*
@@ -201,9 +194,6 @@
 			 */
 			controller.doBrowserWait(getBrowser());
 
-			/*
-			 * Close opened windows
-			 */
 			getBrowser().closeOtherWindows();
 
 			return true; // An event fired
@@ -212,7 +202,7 @@
 			 * Execute the OnFireEventFailedPlugins with the current crawlPath with the crawlPath
 			 * removed 1 state to represent the path TO here.
 			 */
-			CrawljaxPluginsUtil.runOnFireEventFailedPlugins(eventable, controller.getSession()
+			plugins.runOnFireEventFailedPlugins(eventable, controller.getSession()
 			        .getCurrentCrawlPath().immutableCopy(true));
 			return false; // no event fired
 		}
@@ -229,7 +219,7 @@
 		// Try to find a 'better' / 'quicker' xpath
 		String newXPath = new ElementResolver(eventable, getBrowser()).resolve();
 		if (newXPath != null && !xpath.equals(newXPath)) {
-			LOGGER.info(""XPath changed from {} to {} relatedFrame: {}"", xpath, newXPath,
+			LOG.info(""XPath changed from {} to {} relatedFrame: {}"", xpath, newXPath,
 			        eventable.getRelatedFrame());
 			eventToFire =
 			        new Eventable(new Identification(Identification.How.xpath, newXPath),
@@ -242,9 +232,9 @@
 		Element element = eventable.getElement();
 		String href = element.getAttributeOrNull(""href"");
 		if (href == null) {
-			LOGGER.info(""Anchor {} has no href and is invisble so it will be ignored"", element);
+			LOG.info(""Anchor {} has no href and is invisble so it will be ignored"", element);
 		} else {
-			LOGGER.info(""Found an invisible link with href={}"", href);
+			LOG.info(""Found an invisible link with href={}"", href);
 			try {
 				if (!UrlUtils.isLinkExternal(browser.getCurrentUrl(), href)) {
 					URL url = UrlUtils.extractNewUrl(browser.getCurrentUrl(), href);
@@ -252,7 +242,7 @@
 					return true;
 				}
 			} catch (MalformedURLException e) {
-				LOGGER.info(""Could not visit invisible illegal URL {}"", e.getMessage());
+				LOG.info(""Could not visit invisible illegal URL {}"", e.getMessage());
 			}
 		}
 		return false;
@@ -266,14 +256,13 @@
 	 *            the eventable element.
 	 */
 	private void handleInputElements(Eventable eventable) {
-		List<FormInput> formInputs = eventable.getRelatedFormInputs();
+		CopyOnWriteArrayList<FormInput> formInputs = eventable.getRelatedFormInputs();
 
 		for (FormInput formInput : formHandler.getFormInputs()) {
 			if (!formInputs.contains(formInput)) {
 				formInputs.add(formInput);
 			}
 		}
-		eventable.setRelatedFormInputs(formInputs);
 		formHandler.handleFormElements(formInputs);
 	}
 
@@ -292,7 +281,7 @@
 				return;
 			}
 
-			LOGGER.info(""Backtracking by executing {} on element: {}"", clickable.getEventType(),
+			LOG.info(""Backtracking by executing {} on element: {}"", clickable.getEventType(),
 			        clickable);
 
 			this.getStateMachine().changeState(clickable.getTargetStateVertex());
@@ -305,13 +294,13 @@
 
 			if (this.fireEvent(clickable)) {
 
-				depth++;
+				int d = depth.incrementAndGet();
+				LOG.debug(""Crawl depth now {}"", d);
 
 				/*
 				 * Run the onRevisitStateValidator(s)
 				 */
-				CrawljaxPluginsUtil.runOnRevisitStatePlugins(this.controller.getSession(),
-				        curState);
+				plugins.runOnRevisitStatePlugins(this.controller.getSession(), curState);
 			}
 
 			if (!controller.getElementChecker().checkCrawlCondition(getBrowser())) {
@@ -337,20 +326,20 @@
 			for (Entry<String, String> e : eventable.getElement().getAttributes().entrySet()) {
 				Matcher m = p.matcher(e.getValue());
 				if (m.find()) {
-					if (LOGGER.isDebugEnabled()) {
-						LOGGER.debug(""URL: {}"", m.group(2));
+					if (LOG.isDebugEnabled()) {
+						LOG.debug(""URL: {}"", m.group(2));
 					}
 					try {
 						// seconds*1000=ms
 						Thread.sleep(Integer.parseInt(m.group(1)) * 1000);
 					} catch (Exception ex) {
-						LOGGER.error(ex.getLocalizedMessage(), ex);
+						LOG.error(ex.getLocalizedMessage(), ex);
 					}
 				}
 			}
 		}
 
-		LOGGER.debug(""Executing {} on element: {}; State: {}"", eventable.getEventType(),
+		LOG.debug(""Executing {} on element: {}; State: {}"", eventable.getEventType(),
 		        eventable, this.getStateMachine().getCurrentState().getName());
 		if (this.fireEvent(eventable)) {
 			StateVertex newState =
@@ -364,25 +353,20 @@
 				if (this.getStateMachine().updateAndCheckIfClone(eventable, newState,
 				        this.getBrowser(), this.controller.getSession())) {
 
-					// Change is no clone
-					CrawljaxPluginsUtil.runGuidedCrawlingPlugins(controller, controller
-					        .getSession(), controller.getSession().getCurrentCrawlPath(), this
-					        .getStateMachine());
-
-					return ClickResult.newState;
+					return ClickResult.NEW_STATE;
 				} else {
 					// Dom changed; Clone
-					return ClickResult.cloneDetected;
+					return ClickResult.CLONE_DETECTED;
 				}
 			}
 		}
 		// Event not fired or, Dom not changed
-		return ClickResult.domUnChanged;
+		return ClickResult.DOM_UNCHANGED;
 	}
 
 	private boolean domChanged(final Eventable eventable, StateVertex newState) {
-		return CrawljaxPluginsUtil.runDomChangeNotifierPlugins(this.getStateMachine()
-		        .getCurrentState(), eventable, newState, getBrowser());
+		return plugins.runDomChangeNotifierPlugins(this.getStateMachine().getCurrentState(),
+		        eventable, newState, getBrowser());
 	}
 
 	/**
@@ -396,25 +380,6 @@
 		return controller.getSession().getCurrentCrawlPath();
 	}
 
-	/**
-	 * Have we reached the depth limit?
-	 * 
-	 * @param depth
-	 *            the current depth. Added as argument so this call can be moved out if desired.
-	 * @return true if the limit has been reached
-	 */
-	private boolean depthLimitReached(int depth) {
-
-		if (this.depth >= configurationReader.getCrawlSpecificationReader().getDepth()
-		        && configurationReader.getCrawlSpecificationReader().getDepth() != 0) {
-			LOGGER.info(""DEPTH "" + depth + "" reached returning from rec call. Given depth: ""
-			        + configurationReader.getCrawlSpecificationReader().getDepth());
-			return true;
-		} else {
-			return false;
-		}
-	}
-
 	private void spawnThreads(StateVertex state) {
 		Crawler c = null;
 		do {
@@ -423,7 +388,7 @@
 			}
 			c =
 			        new Crawler(this.controller, controller.getSession().getCurrentCrawlPath()
-			                .immutableCopy(true));
+			                .immutableCopy(true), config.getPlugins());
 		} while (state.registerCrawler(c));
 	}
 
@@ -436,7 +401,7 @@
 		if (candidateElement.allConditionsSatisfied(getBrowser())) {
 			ClickResult clickResult = clickTag(new Eventable(candidateElement, eventType));
 			switch (clickResult) {
-				case cloneDetected:
+				case CLONE_DETECTED:
 					fired = false;
 					// We are in the clone state so we continue with the cloned
 					// version to search
@@ -444,24 +409,22 @@
 					this.controller.getSession().branchCrawlPath();
 					spawnThreads(orrigionalState);
 					break;
-				case newState:
+				case NEW_STATE:
 					fired = true;
 					// Recurse because new state found
 					spawnThreads(orrigionalState);
 					break;
-				case domUnChanged:
-					// Dom not updated, continue with the next
+				case DOM_UNCHANGED:
 					break;
 				default:
-					break;
+					throw new IllegalStateException(""Unrecognized click result "" + clickResult);
 			}
 			return clickResult;
 		} else {
-
-			LOGGER.info(""Conditions not satisfied for element: "" + candidateElement + ""; State: ""
-			        + this.getStateMachine().getCurrentState().getName());
+			LOG.info(""Conditions not satisfied for element: {}; State: {}"", candidateElement,
+			        this.getStateMachine().getCurrentState().getName());
 		}
-		return ClickResult.domUnChanged;
+		return ClickResult.DOM_UNCHANGED;
 	}
 
 	/**
@@ -471,7 +434,7 @@
 	 *             if an exception is thrown.
 	 */
 	private boolean crawl() throws CrawljaxException {
-		if (depthLimitReached(depth)) {
+		if (depthLimitReached()) {
 			return true;
 		}
 
@@ -480,25 +443,22 @@
 		}
 
 		// Store the currentState to be able to 'back-track' later.
-		StateVertex orrigionalState = this.getStateMachine().getCurrentState();
+		StateVertex originalState = this.getStateMachine().getCurrentState();
 
-		if (orrigionalState.searchForCandidateElements(candidateExtractor, configurationReader
-		        .getTagElements(), configurationReader.getExcludeTagElements(),
-		        configurationReader.getCrawlSpecificationReader().getClickOnce())) {
+		if (originalState.searchForCandidateElements(candidateExtractor)) {
 			// Only execute the preStateCrawlingPlugins when it's the first time
-			LOGGER.info(""Starting preStateCrawlingPlugins..."");
+			LOG.info(""Starting preStateCrawlingPlugins..."");
 			List<CandidateElement> candidateElements =
-			        orrigionalState.getUnprocessedCandidateElements();
-			CrawljaxPluginsUtil.runPreStateCrawlingPlugins(controller.getSession(),
-			        candidateElements);
+			        originalState.getUnprocessedCandidateElements();
+			plugins.runPreStateCrawlingPlugins(controller.getSession(), candidateElements);
 			// update crawlActions
-			orrigionalState.filterCandidateActions(candidateElements);
+			originalState.filterCandidateActions(candidateElements);
 		}
 
 		CandidateCrawlAction action =
-		        orrigionalState.pollCandidateCrawlAction(this, crawlQueueManager);
+		        originalState.pollCandidateCrawlAction(this, crawlQueueManager);
 		while (action != null) {
-			if (depthLimitReached(depth)) {
+			if (depthLimitReached()) {
 				return true;
 			}
 
@@ -506,21 +466,39 @@
 				return false;
 			}
 			ClickResult result = this.crawlAction(action);
-			orrigionalState.finishedWorking(this, action);
+			originalState.finishedWorking(this, action);
 			switch (result) {
-				case newState:
-					return newStateDetected(orrigionalState);
-				case cloneDetected:
+				case NEW_STATE:
+					return newStateDetected(originalState);
+				case CLONE_DETECTED:
 					return true;
 				default:
 					break;
 			}
-			action = orrigionalState.pollCandidateCrawlAction(this, crawlQueueManager);
+			action = originalState.pollCandidateCrawlAction(this, crawlQueueManager);
 		}
 		return true;
 	}
 
 	/**
+	 * Have we reached the depth limit?
+	 * 
+	 * @param depth
+	 *            the current depth. Added as argument so this call can be moved out if desired.
+	 * @return true if the limit has been reached
+	 */
+	private boolean depthLimitReached() {
+		int maxDepth = config.getMaximumDepth();
+		if (this.depth.get() >= maxDepth && maxDepth != 0) {
+			LOG.info(""DEPTH {} reached returning from rec call. Given depth: {}"", maxDepth,
+			        depth);
+			return true;
+		} else {
+			return false;
+		}
+	}
+
+	/**
 	 * A new state has been found!
 	 * 
 	 * @param orrigionalState
@@ -530,11 +508,9 @@
 	 */
 	private boolean newStateDetected(StateVertex orrigionalState) throws CrawljaxException {
 
-		/**
-		 * An event has been fired so we are one level deeper
-		 */
-		depth++;
-		LOGGER.info(""RECURSIVE Call crawl; Current DEPTH= "" + depth);
+		// An event has been fired so we are one level deeper
+		int d = depth.incrementAndGet();
+		LOG.info(""RECURSIVE Call crawl; Current DEPTH= {}"", d);
 		if (!this.crawl()) {
 			// Crawling has stopped
 			controller.terminate(false);
@@ -563,24 +539,24 @@
 			 * Already set the browser will be in the initial URL.
 			 */
 			this.browser = controller.getBrowserPool().requestBrowser();
-			LOGGER.info(""Reloading page for navigating back"");
+			LOG.info(""Reloading page for navigating back"");
 			this.goToInitialURL();
 		}
 		// TODO Stefan ideally this should be placed in the constructor
 		this.formHandler =
-		        new FormHandler(getBrowser(), configurationReader.getInputSpecification(),
-		                configurationReader.getCrawlSpecificationReader().getRandomInputInForms());
+		        new FormHandler(getBrowser(), config.getCrawlRules().getInputSpecification(),
+		                config.getCrawlRules().isRandomInputInForms());
 
 		this.candidateExtractor =
 		        new CandidateElementExtractor(controller.getElementChecker(), this.getBrowser(),
-		                formHandler, configurationReader);
+		                formHandler, config);
 		/**
 		 * go back into the previous state.
 		 */
 		try {
 			this.goBackExact();
 		} catch (CrawljaxException e) {
-			LOGGER.error(""Failed to backtrack"", e);
+			LOG.error(""Failed to backtrack"", e);
 		}
 	}
 
@@ -614,7 +590,7 @@
 					return;
 				}
 			} catch (CrawljaxException e) {
-				LOGGER.error(""Received Crawljax exception"", e);
+				LOG.error(""Received Crawljax exception"", e);
 			}
 		}
 
@@ -647,7 +623,7 @@
 			// The connection of the browser has gone down, most of the times it
 			// means that the
 			// browser process has crashed.
-			LOGGER.error(""Crawler failed because the used browser died during Crawling"",
+			LOG.error(""Crawler failed because the used browser died during Crawling"",
 			        new CrawlPathToException(""Crawler failed due to browser crash"", controller
 			                .getSession().getCurrentCrawlPath(), e));
 			// removeBrowser will throw a RuntimeException if the current browser
@@ -657,7 +633,7 @@
 			        this.controller.getCrawlQueueManager());
 			return;
 		} catch (CrawljaxException e) {
-			LOGGER.error(""Crawl failed!"", e);
+			LOG.error(""Crawl failed!"", e);
 		}
 		/**
 		 * At last failure or non shutdown the Crawler.
@@ -687,21 +663,30 @@
 	}
 
 	private boolean shouldContinueCrawling() {
+		return !maximumCrawlTimePassed() && !maximumStatesReached();
+	}
+
+	private boolean maximumCrawlTimePassed() {
 		long timePassed = System.currentTimeMillis() - controller.getSession().getStartTime();
-		long maxCrawlTime = configurationReader.getCrawlSpecificationReader().getMaximumRunTime();
+		long maxCrawlTime = config.getMaximumRuntime();
 		if (maxCrawlTime != 0 && timePassed > maxCrawlTime) {
-			LOGGER.info(""Max time "" + TimeUnit.MILLISECONDS.toSeconds(maxCrawlTime)
-			        + "" seconds passed!"");
+			LOG.info(""Max time {} seconds passed!"",
+			        TimeUnit.MILLISECONDS.toSeconds(maxCrawlTime));
+			return true;
+		} else {
 			return false;
 		}
+	}
+
+	private boolean maximumStatesReached() {
 		StateFlowGraph graph = controller.getSession().getStateFlowGraph();
-		int maxNumberOfStates =
-		        configurationReader.getCrawlSpecificationReader().getMaxNumberOfStates();
-		if ((maxNumberOfStates != 0) && (graph.getAllStates().size() >= maxNumberOfStates)) {
-			LOGGER.info(""Max number of states {} reached!"", maxNumberOfStates);
+		int maxNumberOfStates = config.getMaximumStates();
+		if ((maxNumberOfStates != 0) && (graph.getNumberOfStates() >= maxNumberOfStates)) {
+			LOG.info(""Max number of states {} reached!"", maxNumberOfStates);
+			return true;
+		} else {
 			return false;
 		}
-		return true;
 	}
 
 }
"
cf2b94fb7d12b943e20068128494adc41e1f088d,Ryan Carniato,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index aca2a42..6a2a5ae 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -4,7 +4,6 @@
 
 import net.jcip.annotations.GuardedBy;
 
-import org.apache.commons.configuration.ConfigurationException;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -15,10 +14,7 @@
 import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.eventablecondition.EventableConditionChecker;
 import com.crawljax.condition.invariant.Invariant;
-import com.crawljax.core.configuration.CrawlSpecificationReader;
 import com.crawljax.core.configuration.CrawljaxConfiguration;
-import com.crawljax.core.configuration.CrawljaxConfigurationReader;
-import com.crawljax.core.plugin.CrawljaxPluginsUtil;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateFlowGraph;
 import com.crawljax.oraclecomparator.StateComparator;
@@ -26,8 +22,6 @@
 
 /**
  * The Crawljax Controller class is the core of Crawljax.
- * 
- * @author mesbah
  */
 public class CrawljaxController implements CrawlQueueManager {
 
@@ -47,7 +41,7 @@
 	// TODO Stefan, Can not be final because, must be created after the loading of the plugins
 	private Crawler initialCrawler;
 
-	private final CrawljaxConfigurationReader configurationReader;
+	private final CrawljaxConfiguration configuration;
 
 	private final ImmutableList<Invariant> invariantList;
 
@@ -67,22 +61,23 @@
 	 *             if the configuration fails.
 	 */
 	public CrawljaxController(final CrawljaxConfiguration config) throws CrawljaxException {
-		configurationReader = new CrawljaxConfigurationReader(config);
-		CrawlSpecificationReader crawlerReader =
-		        configurationReader.getCrawlSpecificationReader();
+		configuration = config;
 
-		stateComparator = new StateComparator(crawlerReader.getOracleComparators());
-		invariantList = crawlerReader.getInvariants();
+		stateComparator = new StateComparator(config.getCrawlRules().getOracleComparators());
+		invariantList = config.getCrawlRules().getInvariants();
 
-		waitConditionChecker.setWaitConditions(crawlerReader.getWaitConditions());
+		waitConditionChecker.setWaitConditions(config.getCrawlRules().getPreCrawlConfig()
+		        .getWaitConditions());
 		eventableConditionChecker =
-		        new EventableConditionChecker(configurationReader.getEventableConditions());
+		        new EventableConditionChecker(config.getCrawlRules());
 
-		crawlConditionChecker = new ConditionTypeChecker<>(crawlerReader.getCrawlConditions());
+		crawlConditionChecker =
+		        new ConditionTypeChecker<>(config.getCrawlRules().getPreCrawlConfig()
+		                .getCrawlConditions());
 		elementChecker =
 		        new CandidateElementManager(eventableConditionChecker, crawlConditionChecker);
 
-		browserPool = new BrowserPool(configurationReader);
+		browserPool = new BrowserPool(config);
 
 		workQueue = init();
 	}
@@ -96,24 +91,19 @@
 		LOGGER.info(""Starting Crawljax..."");
 
 		LOGGER.info(""Used plugins:"");
-		CrawljaxPluginsUtil.loadPlugins(configurationReader.getPlugins());
 
-		if (configurationReader.getProxyConfiguration() != null) {
-			CrawljaxPluginsUtil
-			        .runProxyServerPlugins(configurationReader.getProxyConfiguration());
+		if (configuration.getProxyConfiguration() != null) {
+			configuration.getPlugins().runProxyServerPlugins(
+			        configuration.getProxyConfiguration());
 		}
 
-		LOGGER.info(""Embedded browser implementation: {}"", configurationReader.getBrowser());
+		LOGGER.info(""Embedded browser implementation: {}"", configuration.getBrowserConfig()
+		        .getBrowsertype());
 
-		LOGGER.info(""Number of threads: {}"", configurationReader.getThreadConfigurationReader()
-		        .getNumberThreads());
-
-		LOGGER.info(""Crawl depth: {}"", configurationReader.getCrawlSpecificationReader()
-		        .getDepth());
+		LOGGER.info(""Crawl depth: {}"", configuration.getMaximumDepth());
 		LOGGER.info(""Crawljax initialized!"");
 
-		return new CrawlerExecutor(configurationReader.getThreadConfigurationReader()
-		        .getNumberThreads());
+		return new CrawlerExecutor(configuration.getBrowserConfig());
 	}
 
 	/**
@@ -129,11 +119,11 @@
 
 		startCrawl = System.currentTimeMillis();
 
-		LOGGER.info(""Start crawling with {} crawl elements"", configurationReader
-		        .getAllIncludedCrawlElements().size());
+		LOGGER.info(""Start crawling with {} crawl elements"", configuration.getCrawlRules()
+		        .getPreCrawlConfig().getIncludedElements());
 
 		// Create the initailCrawler
-		initialCrawler = new InitialCrawler(this);
+		initialCrawler = new InitialCrawler(this, configuration.getPlugins());
 
 		// Start the Crawling by adding the initialCrawler to the the workQueue.
 		addWorkToQueue(initialCrawler);
@@ -167,7 +157,7 @@
 		} catch (InterruptedException e1) {
 			LOGGER.warn(""Re-Request for a browser was interrupted"", e1);
 		}
-		CrawljaxPluginsUtil.runPostCrawlingPlugins(session);
+		configuration.getPlugins().runPostCrawlingPlugins(session);
 		this.getBrowserPool().freeBrowser(b);
 
 		this.shutdown(timeCrawlCalc);
@@ -330,8 +320,8 @@
 	/**
 	 * @return the configurationReader
 	 */
-	public CrawljaxConfigurationReader getConfigurationReader() {
-		return configurationReader;
+	public CrawljaxConfiguration getConfiguration() {
+		return configuration;
 	}
 
 	/**
"
cf2b94fb7d12b943e20068128494adc41e1f088d,Ryan Carniato,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index c6c2008..b40d407 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -1,287 +1,250 @@
 package com.crawljax.core.configuration;
 
-import java.util.ArrayList;
-import java.util.List;
+import static com.google.common.base.Preconditions.checkArgument;
+
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.util.concurrent.TimeUnit;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
-import com.crawljax.browser.EmbeddedBrowserBuilder;
-import com.crawljax.browser.WebDriverBrowserBuilder;
-import com.crawljax.condition.eventablecondition.EventableCondition;
+import com.crawljax.core.Crawler;
+import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
-import com.crawljax.util.DomUtils;
+import com.crawljax.core.plugin.Plugins;
+import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
-import com.google.common.collect.ImmutableList.Builder;
 
 /**
- * Specifies the settings Crawljax. The methods in this class fall into two categories:Oz
- * <p/>
- * <ul>
- * <li>General properties of Crawljax</li>
- * <li>Properties for the crawling
- * {@link CrawljaxConfiguration#setCrawlSpecification(CrawlSpecification)}</li>
- * </ul>
- * DEFAULT VAlUES: Browser: webdriver firefox Project Full Path: empty Project Relative Path: empty
- * Filter attributes: closure_hashcode_(\\w)*, jquery[0-9]+ Test invariants while crawling: true
- * EXAMPLE: CrawljaxConfiguration crawljaxConfig = new CrawljaxConfiguration(); CrawlSpecification
- * crawler = new CrawlSpecification(""http://www.google.com""); crawler.click(""a"");
- * crawljaxConfig.setCrawlSpecification(crawler);
+ * Configures the {@link Crawler}. Set it up using the {@link #builderFor(String)} function.
  */
 public final class CrawljaxConfiguration {
 
-	private BrowserType browser = BrowserType.firefox;
+	public static class CrawljaxConfigurationBuilder {
 
-	private EmbeddedBrowserBuilder browserBuilder = new WebDriverBrowserBuilder();
+		private final ImmutableList.Builder<Plugin> pluginBuilder = ImmutableList.builder();
+		private final CrawljaxConfiguration config;
+		private final CrawlRulesBuilder crawlRules = CrawlRules.builder();
 
-	private String remoteHubUrl = """";
-
-	private String outputFolder = """";
-	private String projectRelativePath = """";
-
-	private List<String> filterAttributeNames = new ArrayList<String>();
-
-	private List<Plugin> plugins = new ArrayList<Plugin>();
-
-	private CrawlSpecification crawlSpecification = new CrawlSpecification(""http://localhost"");
-	private ProxyConfiguration proxyConfiguration = null;
-	private ThreadConfiguration threadConfiguration = new ThreadConfiguration();
-
-	/**
-	 * Constructor.
-	 */
-	public CrawljaxConfiguration() {
-		addFilterAttribute(""closure_hashcode_(\\w)*"");
-		addFilterAttribute(""jquery[0-9]+"");
-	}
-
-	/**
-	 * @return The crawlSpecification which contains all the crawl settings.
-	 */
-	protected CrawlSpecification getCrawlSpecification() {
-		return crawlSpecification;
-	}
-
-	/**
-	 * @param crawlSpecification
-	 *            Which contains all the crawl settings.
-	 */
-	public void setCrawlSpecification(CrawlSpecification crawlSpecification) {
-		Preconditions.checkNotNull(crawlSpecification);
-		this.crawlSpecification = crawlSpecification;
-	}
-
-	/**
-	 * @return The inputSpecification which contains information the data for setting input fields.
-	 */
-	protected InputSpecification getInputSpecification() {
-		return crawlSpecification.getInputSpecification();
-	}
-
-	/**
-	 * Enable the crawljax proxy extension.
-	 * 
-	 * @param proxyConfiguration
-	 *            The ProxyConfiguration to set.
-	 */
-	public void setProxyConfiguration(ProxyConfiguration proxyConfiguration) {
-		this.proxyConfiguration = proxyConfiguration;
-	}
-
-	/**
-	 * @return The proxyConfiguration to use.
-	 */
-	protected ProxyConfiguration getProxyConfiguration() {
-		return proxyConfiguration;
-	}
-
-	/**
-	 * @param threadConfiguration
-	 *            the threadConfiguration to set
-	 */
-	public void setThreadConfiguration(ThreadConfiguration threadConfiguration) {
-		this.threadConfiguration = threadConfiguration;
-	}
-
-	/**
-	 * @return the threadConfiguration
-	 */
-	protected ThreadConfiguration getThreadConfiguration() {
-		return threadConfiguration;
-	}
-
-	/**
-	 * @return All the included crawlTags.
-	 */
-	protected ImmutableList<CrawlElement> getAllIncludedCrawlElements() {
-		// first add elements for forms so that form action crawlTags are only
-		// clicked and not by another random crawlTag
-		return ImmutableList.<CrawlElement> builder()
-		        .addAll(getInputSpecification().getCrawlElements())
-		        .addAll(crawlSpecification.crawlActions().getCrawlElements()).build();
-	}
-
-	/**
-	 * @return All the added crawlTags.
-	 */
-	protected List<CrawlElement> getAllCrawlElements() {
-		return ImmutableList.<CrawlElement> builder()
-		        .addAll(getInputSpecification().getCrawlElements())
-		        .addAll(crawlSpecification.crawlActions().getCrawlElements())
-		        .addAll(getCrawlSpecification().crawlActions().getCrawlElementsExcluded())
-		        .build();
-	}
-
-	/**
-	 * @return The eventableConditions.
-	 */
-	protected ImmutableList<EventableCondition> getEventableConditions() {
-		Builder<EventableCondition> eventableConditions = ImmutableList.builder();
-		for (CrawlElement crawlTag : getAllCrawlElements()) {
-			EventableCondition eventableCondition = crawlTag.getEventableCondition();
-			if (eventableCondition != null) {
-				eventableConditions.add(eventableCondition);
-			}
+		private CrawljaxConfigurationBuilder(URL url) {
+			Preconditions.checkNotNull(url);
+			config = new CrawljaxConfiguration();
+			config.url = url;
 		}
-		return eventableConditions.build();
+
+		/**
+		 * @param states
+		 *            The maximum number of states the Crawler should crawl. The default is
+		 *            unlimited.
+		 */
+		public CrawljaxConfigurationBuilder setMaximumStates(int states) {
+			checkArgument(states > 1, ""Number of maximum states should be largen than 1"");
+			config.maximumStates = states;
+			return this;
+		}
+
+		/**
+		 * Crawl without a maximum state limit.
+		 */
+		public CrawljaxConfigurationBuilder setUnlimitedStates() {
+			config.maximumStates = 0;
+			return this;
+		}
+
+		/**
+		 * @param time
+		 *            The maximum time the crawler should run. Default is one hour.
+		 */
+		public CrawljaxConfigurationBuilder setMaximumRunTime(long time, TimeUnit unit) {
+			checkArgument(time >= 0, ""Time should be larger than 0, or 0 for infinate."");
+			config.maximumRuntime = unit.toMillis(time);
+			return this;
+		}
+
+		/**
+		 * Set the maximum runtime to unlimited.
+		 */
+		public CrawljaxConfigurationBuilder setUnlimitedRuntime() {
+			config.maximumRuntime = 0;
+			return this;
+		}
+
+		/**
+		 * @param time
+		 *            The maximum depth the crawler can reach. The default is <code>2</code>.
+		 */
+		public CrawljaxConfigurationBuilder setMaximumDepth(int depth) {
+			Preconditions.checkArgument(depth >= 0,
+			        ""Depth should be 0 for infinite, or larger for a certain depth."");
+			config.maximumDepth = depth;
+			return this;
+		}
+
+		/**
+		 * Set the crawl depth to unlimited.
+		 */
+		public CrawljaxConfigurationBuilder setUnlimitedCrawlDepth() {
+			config.maximumDepth = 0;
+			return this;
+		}
+
+		/**
+		 * Add plugins to Crawljax. Note that without plugins, Crawljax won't give any ouput. For
+		 * basic output at least enable the CrawlOverviewPlugin.
+		 * <p>
+		 * You can call this method several times to add multiple plugins
+		 * </p>
+		 * 
+		 * @param plugins
+		 *            the plugins you would like to enable.
+		 */
+		public CrawljaxConfigurationBuilder addPlugin(Plugin... plugins) {
+			pluginBuilder.add(plugins);
+			return this;
+		}
+
+		/**
+		 * @param configuration
+		 *            The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
+		 */
+		public CrawljaxConfigurationBuilder setProxyConfig(ProxyConfiguration configuration) {
+			Preconditions.checkNotNull(configuration);
+			config.proxyConfiguration = configuration;
+			return this;
+		}
+
+		/**
+		 * @return The {@link CrawlRulesBuilder} to define crawling rules. If no specified, Crawljax
+		 *         will do {@link CrawlRulesBuilder#}
+		 */
+		public CrawlRulesBuilder crawlRules() {
+			return crawlRules;
+		}
+
+		/**
+		 * @param configuration
+		 *            a custom {@link BrowserConfiguration}. The default is a single
+		 *            {@link BrowserType#firefox} browser.
+		 */
+		public CrawljaxConfigurationBuilder setBrowserConfig(BrowserConfiguration configuration) {
+			Preconditions.checkNotNull(configuration);
+			config.browserConfig = configuration;
+			return this;
+		}
+
+		public CrawljaxConfiguration build() {
+			config.plugins = new Plugins(pluginBuilder.build());
+			config.crawlRules = crawlRules.build();
+			return config;
+		}
+
 	}
 
 	/**
-	 * @return The browser used to crawl. By default firefox is used.
+	 * @param url
+	 *            The url you want to setup a configuration for
+	 * @return The builder to configure the crawler.
 	 */
-	protected BrowserType getBrowser() {
-		return browser;
+	public static CrawljaxConfigurationBuilder builderFor(URL url) {
+		Preconditions.checkNotNull(url, ""URL was null"");
+		return new CrawljaxConfigurationBuilder(url);
 	}
 
 	/**
-	 * @param browser
-	 *            The browser used to crawl.
+	 * @param url
+	 *            The url you want to setup a configuration for
+	 * @return The builder to configure the crawler.
 	 */
-	public void setBrowser(BrowserType browser) {
-		this.browser = browser;
-	}
-
-	/**
-	 * @return the browserBuilder
-	 */
-	protected EmbeddedBrowserBuilder getBrowserBuilder() {
-		return browserBuilder;
-	}
-
-	/**
-	 * Set the remote hub url that needs to be taken when using remote crawling.
-	 * 
-	 * @param remoteHubUrl
-	 *            the url of the remote hub
-	 */
-	public void setRemoteHubUrl(String remoteHubUrl) {
-		this.remoteHubUrl = remoteHubUrl;
-	}
-
-	/**
-	 * @return the remoteHubUrl
-	 */
-	protected String getRemoteHubUrl() {
-		return remoteHubUrl;
-	}
-
-	/**
-	 * @param browserBuilder
-	 *            the browserBuilder to set
-	 */
-	public void setBrowserBuilder(EmbeddedBrowserBuilder browserBuilder) {
-		this.browserBuilder = browserBuilder;
-	}
-
-	/**
-	 * @return The path of the outputFolder with a trailing slash.
-	 */
-	protected String getOutputFolder() {
-		return DomUtils.addFolderSlashIfNeeded(outputFolder);
-	}
-
-	/**
-	 * @param path
-	 *            The (absolute) path of the output folder.
-	 */
-	public void setOutputFolder(String path) {
-		this.outputFolder = DomUtils.addFolderSlashIfNeeded(path);
-	}
-
-	/**
-	 * @return The relative path of the project.
-	 */
-	protected String getProjectRelativePath() {
-		return projectRelativePath;
-	}
-
-	/**
-	 * @param projectRelativePath
-	 *            The relative path of the project.
-	 */
-	public void setProjectRelativePath(String projectRelativePath) {
-		this.projectRelativePath = projectRelativePath;
-	}
-
-	/**
-	 * @return The attributes which are filtered before the DOM is used.
-	 */
-	protected List<String> getFilterAttributeNames() {
-		return filterAttributeNames;
-	}
-
-	/**
-	 * @param filterAttributeNames
-	 *            The attributes which are filtered before the DOM is used.
-	 */
-	public void setFilterAttributeNames(List<String> filterAttributeNames) {
-		this.filterAttributeNames = filterAttributeNames;
-	}
-
-	/**
-	 * Sets filter attribute names.
-	 * 
-	 * @param filterAttributeNames
-	 *            The attribute names to filter.
-	 */
-	public void setFilterAttributeNames(String... filterAttributeNames) {
-		for (String name : filterAttributeNames) {
-			this.filterAttributeNames.add(name);
+	public static CrawljaxConfigurationBuilder builderFor(String url) {
+		try {
+			return new CrawljaxConfigurationBuilder(new URL(url));
+		} catch (MalformedURLException e) {
+			throw new CrawljaxException(""Could not read that URL"", e);
 		}
 	}
 
-	/**
-	 * @param attributeName
-	 *            The name of the attributes which should be filtered before the DOM is used.
-	 */
-	public void addFilterAttribute(String attributeName) {
-		this.filterAttributeNames.add(attributeName);
+	private URL url;
+
+	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.firefox);
+	private Plugins plugins;
+	private ProxyConfiguration proxyConfiguration = ProxyConfiguration.noProxy();
+
+	private CrawlRules crawlRules;
+
+	private int maximumStates = 0;
+	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);;
+	private int maximumDepth = 2;
+
+	private CrawljaxConfiguration() {
 	}
 
-	/**
-	 * @return The plugins See {@link Plugin}.
-	 */
-	protected List<Plugin> getPlugins() {
+	public URL getUrl() {
+		return url;
+	}
+
+	public BrowserConfiguration getBrowserConfig() {
+		return browserConfig;
+	}
+
+	public Plugins getPlugins() {
 		return plugins;
 	}
 
-	/**
-	 * @param plugins
-	 *            The plugins to set. See {@link Plugin}.
-	 */
-	public void setPlugins(List<Plugin> plugins) {
-		this.plugins = plugins;
+	public ProxyConfiguration getProxyConfiguration() {
+		return proxyConfiguration;
 	}
 
-	/**
-	 * Add a plugin to the execution. Note that the order of adding is the same as running for the
-	 * same type of plugin. This means that if you add a precrawling plugin p1 and next you add a
-	 * precrawling plugin p2, p1 will be executed before p2.
-	 * 
-	 * @param plugin
-	 *            Add a plugin. See {@link Plugin}.
-	 */
-	public void addPlugin(Plugin plugin) {
-		this.plugins.add(plugin);
+	public CrawlRules getCrawlRules() {
+		return crawlRules;
 	}
 
-}
+	public int getMaximumStates() {
+		return maximumStates;
+	}
+
+	public long getMaximumRuntime() {
+		return maximumRuntime;
+	}
+
+	public int getMaximumDepth() {
+		return maximumDepth;
+	}
+
+	@Override
+	public int hashCode() {
+		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
+		        maximumStates, maximumRuntime, maximumDepth);
+	}
+
+	@Override
+	public boolean equals(Object object) {
+		if (object instanceof CrawljaxConfiguration) {
+			CrawljaxConfiguration that = (CrawljaxConfiguration) object;
+			return Objects.equal(this.url, that.url)
+			        && Objects.equal(this.browserConfig, that.browserConfig)
+			        && Objects.equal(this.plugins, that.plugins)
+			        && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
+			        && Objects.equal(this.crawlRules, that.crawlRules)
+			        && Objects.equal(this.maximumStates, that.maximumStates)
+			        && Objects.equal(this.maximumRuntime, that.maximumRuntime)
+			        && Objects.equal(this.maximumDepth, that.maximumDepth);
+		}
+		return false;
+	}
+
+	@Override
+	public String toString() {
+		return Objects.toStringHelper(this)
+		        .add(""url"", url)
+		        .add(""browserConfig"", browserConfig)
+		        .add(""plugins"", plugins)
+		        .add(""proxyConfiguration"", proxyConfiguration)
+		        .add(""crawlRules"", crawlRules)
+		        .add(""maximumStates"", maximumStates)
+		        .add(""maximumRuntime"", maximumRuntime)
+		        .add(""maximumDepth"", maximumDepth)
+		        .toString();
+	}
+
+}
\ No newline at end of file
"
cf2b94fb7d12b943e20068128494adc41e1f088d,Ryan Carniato,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index 6854b96..aef2647 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -58,7 +58,7 @@
 	}
 
 	private static final String[] ALLOWED_INPUT_TYPES =
-	        { ""text"", ""radio"", ""checkbox"", ""password"" };
+	{ ""text"", ""radio"", ""checkbox"", ""password"" };
 
 	/**
 	 * Fills in the element with the InputValues for input TODO: improve this by using WebDriver
@@ -67,88 +67,87 @@
 	private void setInputElementValue(Node element, FormInput input) {
 
 		LOGGER.debug(""INPUTFIELD: {} ({})"", input.getIdentification(), input.getType());
-		if (element == null) {
+		if (element == null || input.getInputValues().isEmpty()) {
 			return;
 		}
-		if (input.getInputValues().iterator().hasNext()) {
-			try {
-				// fill in text fields, textareas, password fields and hidden
-				// fields
-				if (input.getType().toLowerCase().startsWith(""text"")
-				        || input.getType().equalsIgnoreCase(""password"")
-				        || input.getType().equalsIgnoreCase(""hidden"")) {
-					String text = input.getInputValues().iterator().next().getValue();
-					if ("""".equals(text)) {
-						return;
-					}
-					String js = DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-					js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
-					browser.executeJavaScript(js);
-				}
+		try {
+			if (input.getType().toLowerCase().startsWith(""text"")
+			        || input.getType().equalsIgnoreCase(""password"")
+			        || input.getType().equalsIgnoreCase(""hidden"")) {
+				handleText(element, input);
+			} else if (""checkbox"".equals(input.getType())) {
+				handleCheckBoxes(element, input);
+			} else if (input.getType().equals(""radio"")) {
+				handleRadioSwitches(element, input);
+			} else if (input.getType().startsWith(""select"")) {
+				handleSelectBoxes(element, input);
+			}
+		} catch (BrowserConnectionException e) {
+			throw e;
+		} catch (RuntimeException e) {
+			LOGGER.error(""Could not input element values"", e);
+		}
+	}
 
-				// check/uncheck checkboxes
-				if (""checkbox"".equals(input.getType())) {
-					for (InputValue inputValue : input.getInputValues()) {
-						String js =
-						        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-						boolean check;
-						if (!randomFieldValue) {
-							check = inputValue.isChecked();
-						} else {
+	private void handleCheckBoxes(Node element, FormInput input) {
+		for (InputValue inputValue : input.getInputValues()) {
+			String js =
+			        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
+			boolean check;
+			if (!randomFieldValue) {
+				check = inputValue.isChecked();
+			} else {
 
-							check = Math.random() >= HALF;
-						}
-						String value;
-						if (check) {
-							value = ""true"";
-						} else {
-							value = ""false"";
-						}
-						js += ""try{ATUSA_element.checked="" + value + "";}catch(e){}"";
-						browser.executeJavaScript(js);
+				check = Math.random() >= HALF;
+			}
+			String value;
+			if (check) {
+				value = ""true"";
+			} else {
+				value = ""false"";
+			}
+			js += ""try{ATUSA_element.checked="" + value + "";}catch(e){}"";
+			browser.executeJavaScript(js);
 
-					}
-				}
+		}
+	}
 
-				// check radio button
-				if (input.getType().equals(""radio"")) {
-					for (InputValue inputValue : input.getInputValues()) {
-						if (inputValue.isChecked()) {
-							String js =
-							        DomUtils.getJSGetElement(XPathHelper
-							                .getXPathExpression(element));
-							js += ""try{ATUSA_element.checked=true;}catch(e){}"";
-							browser.executeJavaScript(js);
-						}
-					}
-				}
-
-				// select options
-				if (input.getType().startsWith(""select"")) {
-					for (InputValue inputValue : input.getInputValues()) {
-						// if(browser.getDriver()==null){
-						String js =
-						        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-						js +=
-						        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
-						                + ""if(ATUSA_element.options[i].value=='""
-						                + inputValue.getValue()
-						                + ""' || ATUSA_element.options[i].text=='""
-						                + inputValue.getValue() + ""'){""
-						                + ""ATUSA_element.options[i].selected=true;"" + ""break;""
-						                + ""}"" + ""};"" + ""}catch(e){}"";
-						browser.executeJavaScript(js);
-					}
-				}
-			} catch (Exception e) {
-				// TODO Stefan; refactor this catch
-				if (e instanceof BrowserConnectionException) {
-					throw (BrowserConnectionException) e;
-				}
-				LOGGER.error(e.getMessage(), e);
+	private void handleRadioSwitches(Node element, FormInput input) {
+		for (InputValue inputValue : input.getInputValues()) {
+			if (inputValue.isChecked()) {
+				String js =
+				        DomUtils.getJSGetElement(XPathHelper
+				                .getXPathExpression(element));
+				js += ""try{ATUSA_element.checked=true;}catch(e){}"";
+				browser.executeJavaScript(js);
 			}
 		}
+	}
 
+	private void handleSelectBoxes(Node element, FormInput input) {
+		for (InputValue inputValue : input.getInputValues()) {
+			String js =
+			        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
+			js +=
+			        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
+			                + ""if(ATUSA_element.options[i].value=='""
+			                + inputValue.getValue()
+			                + ""' || ATUSA_element.options[i].text=='""
+			                + inputValue.getValue() + ""'){""
+			                + ""ATUSA_element.options[i].selected=true;"" + ""break;""
+			                + ""}"" + ""};"" + ""}catch(e){}"";
+			browser.executeJavaScript(js);
+		}
+	}
+
+	private void handleText(Node element, FormInput input) {
+		String text = input.getInputValues().iterator().next().getValue();
+		if ("""".equals(text)) {
+			return;
+		}
+		String js = DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
+		js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
+		browser.executeJavaScript(js);
 	}
 
 	/**
"
cf2b94fb7d12b943e20068128494adc41e1f088d,Ryan Carniato,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index e9c9b51..d0d3edd 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -30,7 +30,6 @@
 import org.custommonkey.xmlunit.DetailedDiff;
 import org.custommonkey.xmlunit.Diff;
 import org.custommonkey.xmlunit.Difference;
-import org.custommonkey.xmlunit.DifferenceListener;
 import org.cyberneko.html.parsers.DOMParser;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -44,6 +43,7 @@
 import org.xml.sax.SAXException;
 
 import com.crawljax.core.CrawljaxException;
+import com.google.common.base.Strings;
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Lists;
 
@@ -118,23 +118,27 @@
 	 */
 	public static String getElementAttributes(Element element, ImmutableSet<String> exclude) {
 		StringBuilder buffer = new StringBuilder();
-
 		if (element != null) {
 			NamedNodeMap attributes = element.getAttributes();
 			if (attributes != null) {
-				for (int i = 0; i < attributes.getLength(); i++) {
-					Attr attr = (Attr) attributes.item(i);
-					if (!exclude.contains(attr.getNodeName())) {
-						buffer.append(attr.getNodeName()).append('=');
-						buffer.append(attr.getNodeValue()).append(' ');
-					}
-				}
+				addAttributesToString(exclude, buffer, attributes);
 			}
 		}
 
 		return buffer.toString().trim();
 	}
 
+	private static void addAttributesToString(ImmutableSet<String> exclude, StringBuilder buffer,
+	        NamedNodeMap attributes) {
+		for (int i = 0; i < attributes.getLength(); i++) {
+			Attr attr = (Attr) attributes.item(i);
+			if (!exclude.contains(attr.getNodeName())) {
+				buffer.append(attr.getNodeName()).append('=');
+				buffer.append(attr.getNodeValue()).append(' ');
+			}
+		}
+	}
+
 	/**
 	 * @param element
 	 *            the element.
@@ -142,17 +146,17 @@
 	 */
 	public static String getElementString(Element element) {
 		String text = DomUtils.removeNewLines(DomUtils.getTextValue(element)).trim();
-		String info = """";
-		if (!text.equals("""")) {
-			info += ""\"""" + text + ""\"" "";
+		StringBuilder info = new StringBuilder();
+		if (!Strings.isNullOrEmpty(text)) {
+			info.append(""\"""").append(text).append(""\"" "");
 		}
 		if (element != null) {
 			if (element.hasAttribute(""id"")) {
-				info += ""ID: "" + element.getAttribute(""id"") + "" "";
+				info.append(""ID: "").append(element.getAttribute(""id"")).append("" "");
 			}
-			info += DomUtils.getAllElementAttributes(element) + "" "";
+			info.append(DomUtils.getAllElementAttributes(element)).append("" "");
 		}
-		return info;
+		return info.toString();
 	}
 
 	/**
@@ -281,8 +285,9 @@
 	 */
 	public static String getTextValue(Element element) {
 		String ret = """";
-		if (element.getTextContent() != null) {
-			ret = element.getTextContent();
+		String textContent = element.getTextContent();
+		if (textContent != null && !textContent.equals("""")) {
+			ret = textContent;
 		} else if (element.hasAttribute(""title"")) {
 			ret = element.getAttribute(""title"");
 		} else if (element.hasAttribute(""alt"")) {
@@ -325,29 +330,7 @@
 		try {
 			Diff d = new Diff(DomUtils.asDocument(controlDom), DomUtils.asDocument(testDom));
 			DetailedDiff dd = new DetailedDiff(d);
-			dd.overrideDifferenceListener(new DifferenceListener() {
-
-				@Override
-				public void skippedComparison(Node control, Node test) {
-				}
-
-				@Override
-				public int differenceFound(Difference difference) {
-					if (difference.getControlNodeDetail() == null
-					        || difference.getControlNodeDetail().getNode() == null
-					        || difference.getTestNodeDetail() == null
-					        || difference.getTestNodeDetail().getNode() == null) {
-						return RETURN_ACCEPT_DIFFERENCE;
-					}
-					if (ignoreAttributes.contains(difference.getTestNodeDetail().getNode()
-					        .getNodeName())
-					        || ignoreAttributes.contains(difference.getControlNodeDetail()
-					                .getNode().getNodeName())) {
-						return RETURN_IGNORE_DIFFERENCE_NODES_IDENTICAL;
-					}
-					return RETURN_ACCEPT_DIFFERENCE;
-				}
-			});
+			dd.overrideDifferenceListener(new DomDifferenceListener(ignoreAttributes));
 
 			return dd.getAllDifferences();
 		} catch (IOException e) {
@@ -393,7 +376,7 @@
 	 * @return The new, correct path.
 	 */
 	public static String addFolderSlashIfNeeded(String folderName) {
-		if (!folderName.equals("""") && !folderName.endsWith(""/"")) {
+		if (!"""".equals(folderName) && !folderName.endsWith(""/"")) {
 			return folderName + ""/"";
 		} else {
 			return folderName;
@@ -409,8 +392,8 @@
 	 */
 	private static String getFileNameInPath(String path) {
 		String fname;
-		if (path.indexOf(""/"") != -1) {
-			fname = path.substring(path.lastIndexOf(""/"") + 1);
+		if (path.indexOf('/') != -1) {
+			fname = path.substring(path.lastIndexOf('/') + 1);
 		} else {
 			fname = path;
 		}
@@ -460,8 +443,7 @@
 	 */
 	public static String getJSGetElement(String xpath) {
 		String js =
-		        """"
-		                + ""function ATUSA_getElementInNodes(nodes, tagName, number){""
+		        ""function ATUSA_getElementInNodes(nodes, tagName, number){""
 		                + ""try{""
 		                + ""var pos = 1;""
 		                + ""for(i=0; i<nodes.length; i++){""
"
cf2b94fb7d12b943e20068128494adc41e1f088d,Ryan Carniato,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index 8d44723..85af1cd 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -22,9 +22,6 @@
 public class ElementResolver {
 	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class.getName());
 
-	// private ElementResolverSettings settings = new
-	// ElementResolverSettings();
-
 	private final EmbeddedBrowser browser;
 	private final Eventable eventable;
 
"
cf2b94fb7d12b943e20068128494adc41e1f088d,Ryan Carniato,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 05cdb79..0bc8d5f 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -237,9 +237,9 @@
 	 * @return position of xpath element, if fails returns -1
 	 **/
 	public static int getXPathLocation(String dom, String xpath) {
-		dom = dom.toLowerCase();
-		xpath = xpath.toLowerCase();
-		String[] elements = xpath.split(""/"");
+		String dom_lower = dom.toLowerCase();
+		String xpath_lower = xpath.toLowerCase();
+		String[] elements = xpath_lower.split(""/"");
 		int pos = 0;
 		int temp;
 		int number;
@@ -258,7 +258,7 @@
 				}
 				for (int i = 0; i < number; i++) {
 					// find new open element
-					temp = dom.indexOf(""<"" + stripEndSquareBrackets(element), pos);
+					temp = dom_lower.indexOf(""<"" + stripEndSquareBrackets(element), pos);
 
 					if (temp > -1) {
 						pos = temp + 1;
@@ -266,7 +266,7 @@
 						// if depth>1 then goto end of current element
 						if (number > 1 && i < number - 1) {
 							pos =
-							        getCloseElementLocation(dom, pos,
+							        getCloseElementLocation(dom_lower, pos,
 							                stripEndSquareBrackets(element));
 						}
 
@@ -290,34 +290,35 @@
 		String[] elements = { ""LINK"", ""META"", ""INPUT"", ""BR"" };
 		List<String> singleElements = Arrays.asList(elements);
 		if (singleElements.contains(element.toUpperCase())) {
-			return dom.indexOf("">"", pos) + 1;
+			return dom.indexOf('>', pos) + 1;
 		}
 		// make sure not before the node
 		int openElements = 1;
 		int i = 0;
-		dom = dom.toLowerCase();
-		element = element.toLowerCase();
-		String openElement = ""<"" + element;
-		String closeElement = ""</"" + element;
+		int position = pos; 
+		String dom_lower = dom.toLowerCase();
+		String element_lower = element.toLowerCase();
+		String openElement = ""<"" + element_lower;
+		String closeElement = ""</"" + element_lower;
 		while (i < MAX_SEARCH_LOOPS) {
-			if (dom.indexOf(openElement, pos) == -1 && dom.indexOf(closeElement, pos) == -1) {
+			if (dom_lower.indexOf(openElement, position) == -1 && dom_lower.indexOf(closeElement, position) == -1) {
 				return -1;
 			}
-			if (dom.indexOf(openElement, pos) < dom.indexOf(closeElement, pos)
-			        && dom.indexOf(openElement, pos) != -1) {
+			if (dom_lower.indexOf(openElement, position) < dom_lower.indexOf(closeElement, position)
+			        && dom_lower.indexOf(openElement, position) != -1) {
 				openElements++;
-				pos = dom.indexOf(openElement, pos) + 1;
+				position = dom_lower.indexOf(openElement, position) + 1;
 			} else {
 
 				openElements--;
-				pos = dom.indexOf(closeElement, pos) + 1;
+				position = dom_lower.indexOf(closeElement, position) + 1;
 			}
 			if (openElements == 0) {
 				break;
 			}
 			i++;
 		}
-		return pos - 1;
+		return position - 1;
 
 	}
 
@@ -340,19 +341,21 @@
 	 *         text()
 	 */
 	public static String stripXPathToElement(String xpath) {
-		if (!Strings.isNullOrEmpty(xpath)) {
-			if (xpath.toLowerCase().contains(""/text()"")) {
-				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/text()""));
+		String xpathStripped = xpath; 
+		
+		if (!Strings.isNullOrEmpty(xpathStripped)) {
+			if (xpathStripped.toLowerCase().contains(""/text()"")) {
+				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/text()""));
 			}
-			if (xpath.toLowerCase().contains(""/comment()"")) {
-				xpath = xpath.substring(0, xpath.toLowerCase().indexOf(""/comment()""));
+			if (xpathStripped.toLowerCase().contains(""/comment()"")) {
+				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/comment()""));
 			}
-			if (xpath.contains(""@"")) {
-				xpath = xpath.substring(0, xpath.indexOf(""@"") - 1);
+			if (xpathStripped.contains(""@"")) {
+				xpathStripped = xpathStripped.substring(0, xpathStripped.indexOf(""@"") - 1);
 			}
 		}
 
-		return xpath;
+		return xpathStripped;
 	}
 
 	private XPathHelper() {
"
cf2b94fb7d12b943e20068128494adc41e1f088d,Ryan Carniato,RunWithWebServer.java,MODIFY,newConfigBuilder -> [String context] | [],"diff --git a/core/src/test/java/com/crawljax/test/RunWithWebServer.java b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
index 587d615..f64d1f8 100644
--- a/core/src/test/java/com/crawljax/test/RunWithWebServer.java
+++ b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
@@ -8,6 +8,8 @@
 import org.eclipse.jetty.util.resource.Resource;
 import org.junit.rules.ExternalResource;
 
+import com.crawljax.core.configuration.CrawljaxConfiguration;
+import com.crawljax.core.configuration.CrawljaxConfiguration.CrawljaxConfigurationBuilder;
 import com.google.common.base.Preconditions;
 
 public class RunWithWebServer extends ExternalResource {
@@ -60,6 +62,14 @@
 		return port;
 	}
 
+	public CrawljaxConfigurationBuilder newConfigBuilder() {
+		return CrawljaxConfiguration.builderFor(getSiteUrl());
+	}
+
+	public CrawljaxConfigurationBuilder newConfigBuilder(String context) {
+		return CrawljaxConfiguration.builderFor(getSiteUrl() + context);
+	}
+
 	public void stop() throws Exception {
 		checkServerStarted();
 		server.stop();
"
0f1270dddf831633389fd092c43a2c415a7b786c,Ryan Carniato,CrawlHistoryResource.java,MODIFY,"getHistory -> [String configId] | [String configId, Boolean active]","diff --git a/web/src/main/java/com/crawljax/web/jaxrs/CrawlHistoryResource.java b/web/src/main/java/com/crawljax/web/jaxrs/CrawlHistoryResource.java
index fc056e2..d459784 100644
--- a/web/src/main/java/com/crawljax/web/jaxrs/CrawlHistoryResource.java
+++ b/web/src/main/java/com/crawljax/web/jaxrs/CrawlHistoryResource.java
@@ -1,16 +1,21 @@
 package com.crawljax.web.jaxrs;
 
 import java.util.List;
+
+import javax.ws.rs.Consumes;
 import javax.ws.rs.GET;
 import javax.ws.rs.POST;
 import javax.ws.rs.Path;
 import javax.ws.rs.PathParam;
 import javax.ws.rs.Produces;
-import javax.ws.rs.Consumes;
 import javax.ws.rs.QueryParam;
 import javax.ws.rs.core.MediaType;
 import javax.ws.rs.core.Response;
-import com.crawljax.web.model.*;
+
+import com.crawljax.web.fs.WorkDirManager;
+import com.crawljax.web.model.CrawlRecord;
+import com.crawljax.web.model.CrawlRecords;
+import com.crawljax.web.runner.CrawlRunner;
 import com.google.inject.Inject;
 import com.google.inject.Singleton;
 
@@ -21,33 +26,59 @@
 public class CrawlHistoryResource {
 
 	private final CrawlRecords crawlRecords;
-	
+	private final WorkDirManager workDirManager;
+	private final CrawlRunner runner;
+
 	@Inject
-	CrawlHistoryResource(CrawlRecords crawlRecords) {
-        this.crawlRecords = crawlRecords;
-    }
-	
+	CrawlHistoryResource(CrawlRecords crawlRecords, WorkDirManager workDirManager,
+	        CrawlRunner runner) {
+		this.crawlRecords = crawlRecords;
+		this.workDirManager = workDirManager;
+		this.runner = runner;
+	}
+
 	@GET
-	public Response getHistory(@QueryParam(""config"") String configId ) {
+	public Response getHistory(@QueryParam(""config"") String configId,
+	        @QueryParam(""active"") Boolean active) {
 		List<CrawlRecord> list;
-		if (configId == null) list = crawlRecords.getCrawlList();
-		else list = crawlRecords.getCrawlListByConfigID(configId);
+		if (configId != null)
+			list = crawlRecords.getCrawlListByConfigID(configId);
+		else if (active != null && active)
+			list = crawlRecords.getActiveCrawlList();
+		else
+			list = crawlRecords.getCrawlList();
 		return Response.ok(list).build();
 	}
-	
+
 	@POST
-	public Response addCrawlRecord(String configId){
+	public Response addCrawlRecord(String configId) {
 		CrawlRecord record = crawlRecords.add(configId);
+		runner.queue(record);
 		return Response.ok(record).build();
 	}
-	
+
 	@GET
 	@Path(""{id}"")
 	public Response getCrawlRecord(@PathParam(""id"") int id) {
 		Response r;
 		CrawlRecord record = crawlRecords.findByID(id);
-		if (record != null) r = Response.ok(record).build();
-		else r = Response.serverError().build();
+		if (record != null)
+			r = Response.ok(record).build();
+		else
+			r = Response.serverError().build();
+		return r;
+	}
+
+	@GET
+	@Path(""{id}/log"")
+	public Response getCrawlRecordLog(@PathParam(""id"") int id) {
+		Response r;
+		CrawlRecord record = crawlRecords.findByID(id);
+		if (record != null) {
+			String content = workDirManager.readLog(id);
+			r = Response.ok(content).build();
+		} else
+			r = Response.serverError().build();
 		return r;
 	}
 }
"
acdcc4b4c9493d984dcd371a3f0f9b6dc299c627,Alex Nederlof,Crawler.java,MODIFY,goToInitialURL -> [] | [boolean runPlugins],"diff --git a/core/src/main/java/com/crawljax/core/Crawler.java b/core/src/main/java/com/crawljax/core/Crawler.java
index e3db471..e73b41e 100644
--- a/core/src/main/java/com/crawljax/core/Crawler.java
+++ b/core/src/main/java/com/crawljax/core/Crawler.java
@@ -19,6 +19,7 @@
 import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.core.exception.CrawlPathToException;
+import com.crawljax.core.plugin.OnUrlLoadPlugin;
 import com.crawljax.core.plugin.Plugins;
 import com.crawljax.core.state.CrawlPath;
 import com.crawljax.core.state.Element;
@@ -35,18 +36,20 @@
 
 /**
  * Class that performs crawl actions. It is designed to run inside a Thread.
- * 
- * @see #run()
  */
 public class Crawler implements Runnable {
 
-	private static final Logger LOG = LoggerFactory.getLogger(Crawler.class.getName());
+	private static final Logger LOG = LoggerFactory.getLogger(Crawler.class);
 
 	/**
-	 * The main browser window 1 to 1 relation; Every Thread will get on browser assigned in the run
-	 * function.
+	 * Enum for describing what has happened after a {@link Crawler#clickTag(Eventable)} has been
+	 * performed.
+	 * 
+	 * @see Crawler#clickTag(Eventable)
 	 */
-	private EmbeddedBrowser browser;
+	private static enum ClickResult {
+		CLONE_DETECTED, NEW_STATE, DOM_UNCHANGED, LEFT_DOMAIN
+	}
 
 	/**
 	 * The central DataController. This is a multiple to 1 relation Every Thread shares an instance
@@ -58,7 +61,7 @@
 	/**
 	 * Depth register.
 	 */
-	private AtomicInteger depth = new AtomicInteger();
+	private final AtomicInteger depth = new AtomicInteger();
 
 	/**
 	 * The path followed from the index to the current state.
@@ -70,8 +73,6 @@
 	 */
 	private CandidateElementExtractor candidateExtractor;
 
-	private boolean fired = false;
-
 	/**
 	 * The name of this Crawler when not default (automatic) this will be added to the Thread name
 	 * in the thread as (name). In the {@link CrawlerExecutor#beforeExecute(Thread, Runnable)} the
@@ -80,7 +81,7 @@
 	 * @see Crawler#toString()
 	 * @see CrawlerExecutor#beforeExecute(Thread, Runnable)
 	 */
-	private String name = """";
+	private final String name;
 
 	/**
 	 * The sateMachine for this Crawler, keeping track of the path crawled by this Crawler.
@@ -89,8 +90,6 @@
 
 	private final CrawljaxConfiguration config;
 
-	private FormHandler formHandler;
-
 	/**
 	 * The object to places calls to add new Crawlers or to remove one.
 	 */
@@ -98,15 +97,15 @@
 
 	private final Plugins plugins;
 
+	private FormHandler formHandler;
+
+	private boolean fired = false;
+
 	/**
-	 * Enum for describing what has happened after a {@link Crawler#clickTag(Eventable)} has been
-	 * performed.
-	 * 
-	 * @see Crawler#clickTag(Eventable)
+	 * The main browser window 1 to 1 relation; Every Thread will get on browser assigned in the run
+	 * function.
 	 */
-	private enum ClickResult {
-		CLONE_DETECTED, NEW_STATE, DOM_UNCHANGED
-	}
+	private EmbeddedBrowser browser;
 
 	/**
 	 * @param mother
@@ -116,10 +115,8 @@
 	 * @param name
 	 *            a name for this crawler (default is empty).
 	 */
-	public Crawler(CrawljaxController mother, List<Eventable> exactEventPath, String name,
-	        Plugins plugins) {
-		this(mother, new CrawlPath(exactEventPath), plugins);
-		this.name = name;
+	public Crawler(CrawljaxController mother, List<Eventable> exactEventPath, String name) {
+		this(mother, new CrawlPath(exactEventPath), name);
 	}
 
 	/**
@@ -130,11 +127,12 @@
 	 * @param returnPath
 	 *            the path used to return to the last state, this can be a empty list
 	 */
-	protected Crawler(CrawljaxController mother, CrawlPath returnPath, Plugins plugins) {
+	protected Crawler(CrawljaxController mother, CrawlPath returnPath, String name) {
 		this.backTrackPath = returnPath;
+		this.name = name;
 		this.controller = mother;
-		this.plugins = plugins;
 		this.config = controller.getConfiguration();
+		this.plugins = config.getPlugins();
 		this.crawlQueueManager = mother.getCrawlQueueManager();
 		if (controller.getSession() != null) {
 			this.stateMachine =
@@ -151,13 +149,162 @@
 	}
 
 	/**
-	 * Brings the browser to the initial state.
+	 * The main function stated by the ExecutorService. Crawlers add themselves to the list by
+	 * calling {@link CrawlQueueManager#addWorkToQueue(Crawler)}. When the ExecutorService finds a
+	 * free thread this method is called and when this method ends the Thread is released again and
+	 * a new Thread is started
+	 * 
+	 * @see java.util.concurrent.Executors#newFixedThreadPool(int)
+	 * @see java.util.concurrent.ExecutorService
 	 */
-	public void goToInitialURL() {
+	@Override
+	public void run() {
+		if (!shouldContinueCrawling()) {
+			return;
+		}
+
+		try {
+			if (backTrackPath.last() != null
+			        && !backTrackPath.last().getTargetStateVertex().startWorking(this)) {
+				LOG.warn(""Could not register crawler. Quitting"");
+				return;
+			}
+
+			try {
+				this.init();
+			} catch (InterruptedException e) {
+				LOG.debug(""Could not fetch a browser from the pool"");
+				return;
+			}
+
+			// Hand over the main crawling
+			if (!this.crawl()) {
+				controller.terminate(false);
+			}
+
+			// Crawling is done; so the crawlPath of the current branch is known
+			if (!fired) {
+				controller.getSession().removeCrawlPath();
+			}
+		} catch (BrowserConnectionException e) {
+			// The connection of the browser has gone down, most of the times it
+			// means that the browser process has crashed.
+			LOG.error(""Crawler failed because the used browser died during Crawling"",
+			        new CrawlPathToException(""Crawler failed due to browser crash"", controller
+			                .getSession().getCurrentCrawlPath(), e));
+			// removeBrowser will throw a RuntimeException if the current browser
+			// is the last
+			// browser in the pool.
+			this.controller.getBrowserPool().removeBrowser(this.getBrowser(),
+			        this.controller.getCrawlQueueManager());
+			return;
+		} catch (CrawljaxException e) {
+			LOG.error(""Crawl failed!"", e);
+		}
+		/**
+		 * At last failure or non shutdown the Crawler.
+		 */
+		this.shutdown();
+	}
+
+	/**
+	 * Initialize the Crawler, retrieve a Browser and go to the initial URL when no browser was
+	 * present. rewind the state machine and goBack to the state if there is exactEventPath is
+	 * specified.
+	 * 
+	 * @throws InterruptedException
+	 *             when the request for a browser is interrupted.
+	 */
+	public void init() throws InterruptedException {
+		// Start a new CrawlPath for this Crawler
+		controller.getSession().startNewPath();
+
+		this.browser = this.getBrowser();
+		if (this.browser == null) {
+			/**
+			 * As the browser is null, request one and got to the initial URL, if the browser is
+			 * Already set the browser will be in the initial URL.
+			 */
+			this.browser = controller.getBrowserPool().requestBrowser();
+			LOG.info(""Reloading page for navigating back"");
+			this.goToInitialURL(true);
+		}
+		// TODO Stefan ideally this should be placed in the constructor
+		this.formHandler =
+		        new FormHandler(getBrowser(), config.getCrawlRules().getInputSpecification(),
+		                config.getCrawlRules().isRandomInputInForms());
+
+		this.candidateExtractor =
+		        new CandidateElementExtractor(controller.getElementChecker(), this.getBrowser(),
+		                formHandler, config);
+		/**
+		 * go back into the previous state.
+		 */
+		try {
+			this.goBackExact(backTrackPath);
+		} catch (CrawljaxException e) {
+			LOG.error(""Failed to backtrack"", e);
+		}
+	}
+
+	/**
+	 * Brings the browser to the initial state.
+	 * 
+	 * @param runPlugins
+	 *            To run the {@link OnUrlLoadPlugin} plugins.
+	 */
+	public void goToInitialURL(boolean runPlugins) {
 		LOG.info(""Loading Page {}"", config.getUrl());
 		getBrowser().goToUrl(config.getUrl());
 		controller.doBrowserWait(getBrowser());
-		plugins.runOnUrlLoadPlugins(getBrowser());
+		if (runPlugins) {
+			plugins.runOnUrlLoadPlugins(getBrowser());
+		}
+	}
+
+	/**
+	 * Reload the browser following the {@link #backTrackPath} to the given currentEvent.
+	 * 
+	 * @param b
+	 * @param backTrackPath2
+	 * @throws CrawljaxException
+	 *             if the {@link Eventable#getTargetStateVertex()} encounters an error.
+	 */
+	private void goBackExact(CrawlPath path) throws CrawljaxException {
+		StateVertex curState = controller.getSession().getInitialState();
+
+		for (Eventable clickable : path) {
+
+			if (!controller.getElementChecker().checkCrawlCondition(getBrowser())) {
+				return;
+			}
+
+			LOG.info(""Backtracking by executing {} on element: {}"", clickable.getEventType(),
+			        clickable);
+
+			this.getStateMachine().changeState(clickable.getTargetStateVertex());
+
+			curState = clickable.getTargetStateVertex();
+
+			controller.getSession().addEventableToCrawlPath(clickable);
+
+			this.handleInputElements(clickable);
+
+			if (this.fireEvent(clickable)) {
+
+				int d = depth.incrementAndGet();
+				LOG.debug(""Crawl depth now {}"", d);
+
+				/*
+				 * Run the onRevisitStateValidator(s)
+				 */
+				plugins.runOnRevisitStatePlugins(this.controller.getSession(), curState);
+			}
+
+			if (!controller.getElementChecker().checkCrawlCondition(getBrowser())) {
+				return;
+			}
+		}
 	}
 
 	/**
@@ -173,21 +320,21 @@
 		        && eventable.getRelatedFrame().equals("""")) {
 			eventToFire = resolveByXpath(eventable, eventToFire);
 		}
-		boolean fired = false;
+		boolean isFired = false;
 		try {
-			fired = getBrowser().fireEvent(eventToFire);
+			isFired = getBrowser().fireEvent(eventToFire);
 		} catch (ElementNotVisibleException | NoSuchElementException e) {
 			if (config.getCrawlRules().isCrawlHiddenAnchors() && eventToFire.getElement() != null
 			        && ""A"".equals(eventToFire.getElement().getTag())) {
-				fired = visitAnchorHrefIfPossible(eventToFire);
+				isFired = visitAnchorHrefIfPossible(eventToFire);
 			} else {
 				LOG.debug(""Ignoring invisble element {}"", eventToFire.getElement());
 			}
 		}
 
-		LOG.debug(""Event fired={} for eventable {}"", fired, eventable);
+		LOG.debug(""Event fired={} for eventable {}"", isFired, eventable);
 
-		if (fired) {
+		if (isFired) {
 
 			/*
 			 * Let the controller execute its specified wait operation on the browser thread safe.
@@ -236,11 +383,9 @@
 		} else {
 			LOG.info(""Found an invisible link with href={}"", href);
 			try {
-				if (!UrlUtils.isLinkExternal(browser.getCurrentUrl(), href)) {
-					URL url = UrlUtils.extractNewUrl(browser.getCurrentUrl(), href);
-					browser.goToUrl(url);
-					return true;
-				}
+				URL url = UrlUtils.extractNewUrl(getBrowser().getCurrentUrl(), href);
+				getBrowser().goToUrl(url);
+				return true;
 			} catch (MalformedURLException e) {
 				LOG.info(""Could not visit invisible illegal URL {}"", e.getMessage());
 			}
@@ -266,46 +411,24 @@
 		formHandler.handleFormElements(formInputs);
 	}
 
-	/**
-	 * Reload the browser following the {@link #backTrackPath} to the given currentEvent.
-	 * 
-	 * @throws CrawljaxException
-	 *             if the {@link Eventable#getTargetStateVertex()} encounters an error.
-	 */
-	private void goBackExact() throws CrawljaxException {
-		StateVertex curState = controller.getSession().getInitialState();
+	private boolean domChanged(final Eventable eventable, StateVertex newState) {
+		return plugins.runDomChangeNotifierPlugins(this.getStateMachine().getCurrentState(),
+		        eventable, newState, getBrowser());
+	}
 
-		for (Eventable clickable : backTrackPath) {
+	private ClickResult crawlAction(CandidateCrawlAction action) throws CrawljaxException {
+		CandidateElement candidateElement = action.getCandidateElement();
+		EventType eventType = action.getEventType();
 
-			if (!controller.getElementChecker().checkCrawlCondition(getBrowser())) {
-				return;
-			}
+		if (candidateElement.allConditionsSatisfied(getBrowser())) {
 
-			LOG.info(""Backtracking by executing {} on element: {}"", clickable.getEventType(),
-			        clickable);
+			ClickResult clickResult = clickTag(new Eventable(candidateElement, eventType));
 
-			this.getStateMachine().changeState(clickable.getTargetStateVertex());
-
-			curState = clickable.getTargetStateVertex();
-
-			controller.getSession().addEventableToCrawlPath(clickable);
-
-			this.handleInputElements(clickable);
-
-			if (this.fireEvent(clickable)) {
-
-				int d = depth.incrementAndGet();
-				LOG.debug(""Crawl depth now {}"", d);
-
-				/*
-				 * Run the onRevisitStateValidator(s)
-				 */
-				plugins.runOnRevisitStatePlugins(this.controller.getSession(), curState);
-			}
-
-			if (!controller.getElementChecker().checkCrawlCondition(getBrowser())) {
-				return;
-			}
+			return clickResult;
+		} else {
+			LOG.info(""Conditions not satisfied for element: {}; State: {}"", candidateElement,
+			        this.getStateMachine().getCurrentState().getName());
+			return ClickResult.DOM_UNCHANGED;
 		}
 	}
 
@@ -317,114 +440,95 @@
 	 *             an exception.
 	 */
 	private ClickResult clickTag(final Eventable eventable) throws CrawljaxException {
+		StateVertex orrigionalState = this.getStateMachine().getCurrentState();
 		// load input element values
-		this.handleInputElements(eventable);
+		handleInputElements(eventable);
 
 		// support for meta refresh tags
-		if (eventable.getElement().getTag().toLowerCase().equals(""meta"")) {
-			Pattern p = Pattern.compile(""(\\d+);\\s+URL=(.*)"");
-			for (Entry<String, String> e : eventable.getElement().getAttributes().entrySet()) {
-				Matcher m = p.matcher(e.getValue());
-				if (m.find()) {
-					if (LOG.isDebugEnabled()) {
-						LOG.debug(""URL: {}"", m.group(2));
-					}
-					try {
-						// seconds*1000=ms
-						Thread.sleep(Integer.parseInt(m.group(1)) * 1000);
-					} catch (Exception ex) {
-						LOG.error(ex.getLocalizedMessage(), ex);
-					}
-				}
-			}
-		}
+		waitForRefreshTagIfAny(eventable);
 
 		LOG.debug(""Executing {} on element: {}; State: {}"", eventable.getEventType(),
 		        eventable, this.getStateMachine().getCurrentState().getName());
-		if (this.fireEvent(eventable)) {
-			StateVertex newState =
-			        new StateVertex(getBrowser().getCurrentUrl(), controller.getSession()
-			                .getStateFlowGraph().getNewStateName(), getBrowser().getDom(),
-			                this.controller.getStrippedDom(getBrowser()));
+		if (fireEvent(eventable)) {
+			return inspectPotentialNewStatus(eventable, orrigionalState);
+		} else {
+			return ClickResult.DOM_UNCHANGED;
+		}
+	}
 
-			if (domChanged(eventable, newState)) {
-
-				controller.getSession().addEventableToCrawlPath(eventable);
-				if (this.getStateMachine().updateAndCheckIfClone(eventable, newState,
-				        this.getBrowser(), this.controller.getSession())) {
-
-					return ClickResult.NEW_STATE;
-				} else {
-					// Dom changed; Clone
-					return ClickResult.CLONE_DETECTED;
+	private void waitForRefreshTagIfAny(final Eventable eventable) {
+		if (eventable.getElement().getTag().equalsIgnoreCase(""meta"")) {
+			Pattern p = Pattern.compile(""(\\d+);\\s+URL=(.*)"");
+			for (Entry<String, String> e : eventable.getElement().getAttributes().entrySet()) {
+				Matcher m = p.matcher(e.getValue());
+				long waitTime = parseWaitTimeOrReturnDefault(m);
+				try {
+					Thread.sleep(waitTime);
+				} catch (InterruptedException ex) {
+					LOG.info(""Crawler timed out while waiting for page to reload"");
 				}
 			}
 		}
-		// Event not fired or, Dom not changed
-		return ClickResult.DOM_UNCHANGED;
 	}
 
-	private boolean domChanged(final Eventable eventable, StateVertex newState) {
-		return plugins.runDomChangeNotifierPlugins(this.getStateMachine().getCurrentState(),
-		        eventable, newState, getBrowser());
+	private long parseWaitTimeOrReturnDefault(Matcher m) {
+		long waitTime = TimeUnit.SECONDS.toMillis(10);
+		if (m.find()) {
+			LOG.debug(""URL: {}"", m.group(2));
+			try {
+				waitTime = Integer.parseInt(m.group(1)) * 1000;
+			} catch (NumberFormatException ex) {
+				LOG.info(""Could parse the amount of time to wait for a META tag refresh. Waiting 10 seconds..."");
+			}
+		}
+		return waitTime;
 	}
 
-	/**
-	 * Return the Exacteventpath.
-	 * 
-	 * @return the exacteventpath
-	 * @deprecated use {@link CrawlSession#getCurrentCrawlPath()}
-	 */
-	@Deprecated
-	public final List<Eventable> getExacteventpath() {
-		return controller.getSession().getCurrentCrawlPath();
+	private ClickResult inspectPotentialNewStatus(final Eventable eventable,
+	        StateVertex orrigionalState) {
+		if (crawlerLeftDomain()) {
+			LOG.debug(""The browser left the domain"");
+			return ClickResult.LEFT_DOMAIN;
+		}
+		StateVertex newState =
+		        new StateVertex(getBrowser().getCurrentUrl(), controller.getSession()
+		                .getStateFlowGraph().getNewStateName(), getBrowser().getDom(),
+		                this.controller.getStrippedDom(getBrowser()));
+		if (domChanged(eventable, newState)) {
+			controller.getSession().addEventableToCrawlPath(eventable);
+			if (this.getStateMachine().updateAndCheckIfClone(eventable, newState,
+			        this.getBrowser(), this.controller.getSession())) {
+				fired = true;
+				// Recurse because new state found
+				spawnThreads(orrigionalState);
+				return ClickResult.NEW_STATE;
+			} else {
+				fired = false;
+				// We are in the clone state so we continue with the cloned
+				// version to search for work.
+				this.controller.getSession().branchCrawlPath();
+				spawnThreads(orrigionalState);
+				return ClickResult.CLONE_DETECTED;
+			}
+		} else {
+			return ClickResult.DOM_UNCHANGED;
+		}
+	}
+
+	private boolean crawlerLeftDomain() {
+		return !getBrowser().getCurrentUrl().toLowerCase()
+		        .contains(config.getUrl().getHost().toLowerCase());
 	}
 
 	private void spawnThreads(StateVertex state) {
-		Crawler c = null;
+		Crawler crawler = null;
 		do {
-			if (c != null) {
-				this.crawlQueueManager.addWorkToQueue(c);
+			if (crawler != null) {
+				this.crawlQueueManager.addWorkToQueue(crawler);
 			}
-			c =
-			        new Crawler(this.controller, controller.getSession().getCurrentCrawlPath()
-			                .immutableCopy(true), config.getPlugins());
-		} while (state.registerCrawler(c));
-	}
-
-	private ClickResult crawlAction(CandidateCrawlAction action) throws CrawljaxException {
-		CandidateElement candidateElement = action.getCandidateElement();
-		EventType eventType = action.getEventType();
-
-		StateVertex orrigionalState = this.getStateMachine().getCurrentState();
-
-		if (candidateElement.allConditionsSatisfied(getBrowser())) {
-			ClickResult clickResult = clickTag(new Eventable(candidateElement, eventType));
-			switch (clickResult) {
-				case CLONE_DETECTED:
-					fired = false;
-					// We are in the clone state so we continue with the cloned
-					// version to search
-					// for work.
-					this.controller.getSession().branchCrawlPath();
-					spawnThreads(orrigionalState);
-					break;
-				case NEW_STATE:
-					fired = true;
-					// Recurse because new state found
-					spawnThreads(orrigionalState);
-					break;
-				case DOM_UNCHANGED:
-					break;
-				default:
-					throw new IllegalStateException(""Unrecognized click result "" + clickResult);
-			}
-			return clickResult;
-		} else {
-			LOG.info(""Conditions not satisfied for element: {}; State: {}"", candidateElement,
-			        this.getStateMachine().getCurrentState().getName());
-		}
-		return ClickResult.DOM_UNCHANGED;
+			crawler = new Crawler(this.controller, controller.getSession().getCurrentCrawlPath()
+			        .immutableCopy(true), """");
+		} while (state.registerCrawler(crawler));
 	}
 
 	/**
@@ -455,6 +559,10 @@
 			originalState.filterCandidateActions(candidateElements);
 		}
 
+		return crawlThroughActions(originalState);
+	}
+
+	private boolean crawlThroughActions(StateVertex originalState) {
 		CandidateCrawlAction action =
 		        originalState.pollCandidateCrawlAction(this, crawlQueueManager);
 		while (action != null) {
@@ -466,12 +574,15 @@
 				return false;
 			}
 			ClickResult result = this.crawlAction(action);
-			originalState.finishedWorking(this, action);
+			originalState.markAsFinished(this, action);
+
 			switch (result) {
 				case NEW_STATE:
 					return newStateDetected(originalState);
 				case CLONE_DETECTED:
 					return true;
+				case LEFT_DOMAIN:
+					goBackOneState();
 				default:
 					break;
 			}
@@ -480,6 +591,18 @@
 		return true;
 	}
 
+	private void goBackOneState() {
+		LOG.debug(""Going back one state"");
+		CrawlPath currentPath =
+		        controller.getSession().getCurrentCrawlPath().immutableCopy(false);
+		goToInitialURL(false);
+		if (stateMachine != null) {
+			stateMachine.rewind();
+		}
+		controller.getSession().startNewPath();
+		goBackExact(currentPath);
+	}
+
 	/**
 	 * Have we reached the depth limit?
 	 * 
@@ -521,46 +644,6 @@
 	}
 
 	/**
-	 * Initialize the Crawler, retrieve a Browser and go to the initial URL when no browser was
-	 * present. rewind the state machine and goBack to the state if there is exactEventPath is
-	 * specified.
-	 * 
-	 * @throws InterruptedException
-	 *             when the request for a browser is interrupted.
-	 */
-	public void init() throws InterruptedException {
-		// Start a new CrawlPath for this Crawler
-		controller.getSession().startNewPath();
-
-		this.browser = this.getBrowser();
-		if (this.browser == null) {
-			/**
-			 * As the browser is null, request one and got to the initial URL, if the browser is
-			 * Already set the browser will be in the initial URL.
-			 */
-			this.browser = controller.getBrowserPool().requestBrowser();
-			LOG.info(""Reloading page for navigating back"");
-			this.goToInitialURL();
-		}
-		// TODO Stefan ideally this should be placed in the constructor
-		this.formHandler =
-		        new FormHandler(getBrowser(), config.getCrawlRules().getInputSpecification(),
-		                config.getCrawlRules().isRandomInputInForms());
-
-		this.candidateExtractor =
-		        new CandidateElementExtractor(controller.getElementChecker(), this.getBrowser(),
-		                formHandler, config);
-		/**
-		 * go back into the previous state.
-		 */
-		try {
-			this.goBackExact();
-		} catch (CrawljaxException e) {
-			LOG.error(""Failed to backtrack"", e);
-		}
-	}
-
-	/**
 	 * Terminate and clean up this Crawler, release the acquired browser. Notice that other Crawlers
 	 * might still be active. So this function does NOT shutdown all Crawlers active that should be
 	 * done with {@link CrawlerExecutor#shutdown()}
@@ -570,78 +653,6 @@
 	}
 
 	/**
-	 * The main function stated by the ExecutorService. Crawlers add themselves to the list by
-	 * calling {@link CrawlQueueManager#addWorkToQueue(Crawler)}. When the ExecutorService finds a
-	 * free thread this method is called and when this method ends the Thread is released again and
-	 * a new Thread is started
-	 * 
-	 * @see java.util.concurrent.Executors#newFixedThreadPool(int)
-	 * @see java.util.concurrent.ExecutorService
-	 */
-	@Override
-	public void run() {
-		if (!shouldContinueCrawling()) {
-			// Constrains are not met at start of this Crawler, so stop immediately
-			return;
-		}
-		if (backTrackPath.last() != null) {
-			try {
-				if (!backTrackPath.last().getTargetStateVertex().startWorking(this)) {
-					return;
-				}
-			} catch (CrawljaxException e) {
-				LOG.error(""Received Crawljax exception"", e);
-			}
-		}
-
-		try {
-			/**
-			 * Init the Crawler
-			 */
-			try {
-				this.init();
-			} catch (InterruptedException e) {
-				if (this.getBrowser() == null) {
-					return;
-				}
-			}
-
-			/**
-			 * Hand over the main crawling
-			 */
-			if (!this.crawl()) {
-				controller.terminate(false);
-			}
-
-			/**
-			 * Crawling is done; so the crawlPath of the current branch is known
-			 */
-			if (!fired) {
-				controller.getSession().removeCrawlPath();
-			}
-		} catch (BrowserConnectionException e) {
-			// The connection of the browser has gone down, most of the times it
-			// means that the
-			// browser process has crashed.
-			LOG.error(""Crawler failed because the used browser died during Crawling"",
-			        new CrawlPathToException(""Crawler failed due to browser crash"", controller
-			                .getSession().getCurrentCrawlPath(), e));
-			// removeBrowser will throw a RuntimeException if the current browser
-			// is the last
-			// browser in the pool.
-			this.controller.getBrowserPool().removeBrowser(this.getBrowser(),
-			        this.controller.getCrawlQueueManager());
-			return;
-		} catch (CrawljaxException e) {
-			LOG.error(""Crawl failed!"", e);
-		}
-		/**
-		 * At last failure or non shutdown the Crawler.
-		 */
-		this.shutdown();
-	}
-
-	/**
 	 * Return the browser used in this Crawler Thread.
 	 * 
 	 * @return the browser used in this Crawler Thread
"
acdcc4b4c9493d984dcd371a3f0f9b6dc299c627,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index 6a2a5ae..509f64d 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -111,8 +111,6 @@
 	 * 
 	 * @throws CrawljaxException
 	 *             If the browser cannot be instantiated.
-	 * @throws ConfigurationException
-	 *             if crawljax configuration fails.
 	 * @NotThreadSafe
 	 */
 	public final void run() throws CrawljaxException {
@@ -123,7 +121,7 @@
 		        .getPreCrawlConfig().getIncludedElements());
 
 		// Create the initailCrawler
-		initialCrawler = new InitialCrawler(this, configuration.getPlugins());
+		initialCrawler = new InitialCrawler(this);
 
 		// Start the Crawling by adding the initialCrawler to the the workQueue.
 		addWorkToQueue(initialCrawler);
"
acdcc4b4c9493d984dcd371a3f0f9b6dc299c627,Alex Nederlof,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 0bc8d5f..bdb6a53 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -295,16 +295,18 @@
 		// make sure not before the node
 		int openElements = 1;
 		int i = 0;
-		int position = pos; 
+		int position = pos;
 		String dom_lower = dom.toLowerCase();
 		String element_lower = element.toLowerCase();
 		String openElement = ""<"" + element_lower;
 		String closeElement = ""</"" + element_lower;
 		while (i < MAX_SEARCH_LOOPS) {
-			if (dom_lower.indexOf(openElement, position) == -1 && dom_lower.indexOf(closeElement, position) == -1) {
+			if (dom_lower.indexOf(openElement, position) == -1
+			        && dom_lower.indexOf(closeElement, position) == -1) {
 				return -1;
 			}
-			if (dom_lower.indexOf(openElement, position) < dom_lower.indexOf(closeElement, position)
+			if (dom_lower.indexOf(openElement, position) < dom_lower.indexOf(closeElement,
+			        position)
 			        && dom_lower.indexOf(openElement, position) != -1) {
 				openElements++;
 				position = dom_lower.indexOf(openElement, position) + 1;
@@ -341,14 +343,18 @@
 	 *         text()
 	 */
 	public static String stripXPathToElement(String xpath) {
-		String xpathStripped = xpath; 
-		
+		String xpathStripped = xpath;
+
 		if (!Strings.isNullOrEmpty(xpathStripped)) {
 			if (xpathStripped.toLowerCase().contains(""/text()"")) {
-				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/text()""));
+				xpathStripped =
+				        xpathStripped
+				                .substring(0, xpathStripped.toLowerCase().indexOf(""/text()""));
 			}
 			if (xpathStripped.toLowerCase().contains(""/comment()"")) {
-				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/comment()""));
+				xpathStripped =
+				        xpathStripped.substring(0,
+				                xpathStripped.toLowerCase().indexOf(""/comment()""));
 			}
 			if (xpathStripped.contains(""@"")) {
 				xpathStripped = xpathStripped.substring(0, xpathStripped.indexOf(""@"") - 1);
"
5fba0588e48411cdbd843b2156337ee9a75575fa,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index 509f64d..703b32a 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -294,7 +294,7 @@
 	private void shutdown(long timeCrawlCalc) {
 		StateFlowGraph stateFlowGraph = this.getSession().getStateFlowGraph();
 		for (Eventable c : stateFlowGraph.getAllEdges()) {
-			LOGGER.info(""Interaction Element= "" + c.toString());
+			LOGGER.trace(""Interaction Element= "" + c.toString());
 		}
 		LOGGER.info(""Total Crawling time("" + timeCrawlCalc + ""ms) ~= ""
 		        + formatRunningTime(timeCrawlCalc));
"
6f03678259d0cf0e3be55b14ee01609ae6cdd1fd,Alex Nederlof,CandidateElementPosition.java,MODIFY,equals -> [Object obj] | [Object object],"diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/model/CandidateElementPosition.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/model/CandidateElementPosition.java
index f494539..a1a838c 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/model/CandidateElementPosition.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/model/CandidateElementPosition.java
@@ -1,13 +1,12 @@
 package com.crawljax.plugins.crawloverview.model;
 
-import java.util.Objects;
-
 import javax.annotation.concurrent.Immutable;
 
 import org.openqa.selenium.Dimension;
 import org.openqa.selenium.Point;
 
 import com.crawljax.core.CandidateElement;
+import com.google.common.base.Objects;
 
 /**
  * Position of a candidate element of a state. This type is used to build the overlays of screenshot
@@ -65,28 +64,31 @@
 
 	@Override
 	public String toString() {
-		return ""CandidateElementPosition [top="" + top + "", left="" + left + "", xpath="" + xpath
-		        + "", width="" + width + "", height="" + height + ""]"";
+		return Objects.toStringHelper(this)
+		        .add(""top"", top)
+		        .add(""left"", left)
+		        .add(""xpath"", xpath)
+		        .add(""width"", width)
+		        .add(""height"", height)
+		        .toString();
 	}
 
 	@Override
 	public int hashCode() {
-		return Objects.hash(height, left, top, width, xpath);
+		return Objects.hashCode(top, left, xpath, width, height);
 	}
 
 	@Override
-	public boolean equals(Object obj) {
-		if (this == obj) {
-			return true;
+	public boolean equals(Object object) {
+		if (object instanceof CandidateElementPosition) {
+			CandidateElementPosition that = (CandidateElementPosition) object;
+			return Objects.equal(this.top, that.top)
+			        && Objects.equal(this.left, that.left)
+			        && Objects.equal(this.xpath, that.xpath)
+			        && Objects.equal(this.width, that.width)
+			        && Objects.equal(this.height, that.height);
 		}
-		if (obj == null || getClass() != obj.getClass()) {
-			return false;
-		}
-		CandidateElementPosition other = (CandidateElementPosition) obj;
-		return Objects.equals(height, other.height)
-		        && Objects.equals(left, other.left)
-		        && Objects.equals(top, other.top)
-		        && Objects.equals(width, other.width)
-		        && Objects.equals(xpath, other.xpath);
+		return false;
 	}
+
 }
"
6f03678259d0cf0e3be55b14ee01609ae6cdd1fd,Alex Nederlof,Edge.java,MODIFY,equals -> [Object obj] | [Object object],"diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/model/Edge.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/model/Edge.java
index f994eee..c5a0b2d 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/model/Edge.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/model/Edge.java
@@ -6,6 +6,7 @@
 import com.crawljax.core.state.Element;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.plugins.crawloverview.CrawlOverviewException;
+import com.google.common.base.Objects;
 
 /**
  * An {@link Edge} between two {@link State}s.
@@ -40,13 +41,11 @@
 		eventType = eventable.getEventType().toString();
 	}
 
+	/**
+	 * @return The pre-computed hashcode.
+	 */
 	private final int buildHash() {
-		final int prime = 31;
-		int result = 1;
-		result = prime * result + ((from == null) ? 0 : from.hashCode());
-		result = prime * result + ((to == null) ? 0 : to.hashCode());
-		result = prime * result + ((id == null) ? 0 : id.hashCode());
-		return result;
+		return Objects.hashCode(from, to, hash, text, id, element, eventType);
 	}
 
 	public String getFrom() {
@@ -62,26 +61,6 @@
 	}
 
 	@Override
-	public int hashCode() {
-		return hash;
-	}
-
-	@Override
-	public boolean equals(Object obj) {
-		if (this == obj) {
-			return true;
-		}
-		if (obj == null) {
-			return false;
-		}
-		if (getClass() != obj.getClass()) {
-			return false;
-		}
-		Edge other = (Edge) obj;
-		return other.hashCode() == hash;
-	}
-
-	@Override
 	public String toString() {
 		return ""Edge [from="" + from + "", to="" + to + "", text="" + text + ""]"";
 	}
@@ -98,4 +77,24 @@
 		return element;
 	}
 
+	@Override
+	public int hashCode() {
+		return hash;
+	}
+
+	@Override
+	public boolean equals(Object object) {
+		if (object instanceof Edge) {
+			Edge that = (Edge) object;
+			return Objects.equal(this.from, that.from)
+			        && Objects.equal(this.to, that.to)
+			        && Objects.equal(this.hash, that.hash)
+			        && Objects.equal(this.text, that.text)
+			        && Objects.equal(this.id, that.id)
+			        && Objects.equal(this.element, that.element)
+			        && Objects.equal(this.eventType, that.eventType);
+		}
+		return false;
+	}
+
 }
"
6f03678259d0cf0e3be55b14ee01609ae6cdd1fd,Alex Nederlof,OutPutModel.java,MODIFY,equals -> [Object obj] | [Object object],"diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/model/OutPutModel.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/model/OutPutModel.java
index 12fea5d..4aa225c 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/model/OutPutModel.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/model/OutPutModel.java
@@ -5,6 +5,7 @@
 import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableMap;
+import com.google.common.base.Objects;
 
 /**
  * Result of a Crawl session.
@@ -44,85 +45,31 @@
 		return configuration;
 	}
 
-	/*
-	 * (non-Javadoc)
-	 * @see java.lang.Object#toString()
-	 */
-	@Override
-	public String toString() {
-		StringBuilder builder = new StringBuilder();
-		builder.append(""OutPutModel [states="");
-		builder.append(states);
-		builder.append("", edges="");
-		builder.append(edges);
-		builder.append("", statistics="");
-		builder.append(statistics);
-		builder.append("", configuration="");
-		builder.append(configuration);
-		builder.append(""]"");
-		return builder.toString();
-	}
-
-	/*
-	 * (non-Javadoc)
-	 * @see java.lang.Object#hashCode()
-	 */
 	@Override
 	public int hashCode() {
-		final int prime = 31;
-		int result = 1;
-		result = prime * result + ((configuration == null) ? 0 : configuration.hashCode());
-		result = prime * result + ((edges == null) ? 0 : edges.hashCode());
-		result = prime * result + ((states == null) ? 0 : states.hashCode());
-		result = prime * result + ((statistics == null) ? 0 : statistics.hashCode());
-		return result;
+		return Objects.hashCode(states, edges, statistics, configuration);
 	}
 
-	/*
-	 * (non-Javadoc)
-	 * @see java.lang.Object#equals(java.lang.Object)
-	 */
 	@Override
-	public boolean equals(Object obj) {
-		if (this == obj) {
-			return true;
+	public boolean equals(Object object) {
+		if (object instanceof OutPutModel) {
+			OutPutModel that = (OutPutModel) object;
+			return Objects.equal(this.states, that.states)
+			        && Objects.equal(this.edges, that.edges)
+			        && Objects.equal(this.statistics, that.statistics)
+			        && Objects.equal(this.configuration, that.configuration);
 		}
-		if (obj == null) {
-			return false;
-		}
-		if (getClass() != obj.getClass()) {
-			return false;
-		}
-		OutPutModel other = (OutPutModel) obj;
-		if (configuration == null) {
-			if (other.configuration != null) {
-				return false;
-			}
-		} else if (!configuration.equals(other.configuration)) {
-			return false;
-		}
-		if (edges == null) {
-			if (other.edges != null) {
-				return false;
-			}
-		} else if (!edges.equals(other.edges)) {
-			return false;
-		}
-		if (states == null) {
-			if (other.states != null) {
-				return false;
-			}
-		} else if (!states.equals(other.states)) {
-			return false;
-		}
-		if (statistics == null) {
-			if (other.statistics != null) {
-				return false;
-			}
-		} else if (!statistics.equals(other.statistics)) {
-			return false;
-		}
-		return true;
+		return false;
+	}
+
+	@Override
+	public String toString() {
+		return Objects.toStringHelper(this)
+		        .add(""states"", states)
+		        .add(""edges"", edges)
+		        .add(""statistics"", statistics)
+		        .add(""configuration"", configuration)
+		        .toString();
 	}
 
 }
"
ea7fa1b5e10371ac881f4cee32e9cf7deee4abd0,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index dca372e..b680e39 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -367,10 +367,6 @@
 		m = p.matcher(html);
 		htmlFormatted = m.replaceAll("""");
 
-		// TODO (Stefan), Following lines are a serious performance bottle neck...
-		// Document doc = Helper.getDocument(htmlFormatted);
-		// htmlFormatted = Helper.getDocumentToString(doc);
-
 		htmlFormatted = filterAttributes(htmlFormatted);
 		return htmlFormatted;
 	}
@@ -383,15 +379,16 @@
 	 * @return The filtered HTML string.
 	 */
 	private String filterAttributes(String html) {
+		String filteredHtml = html;
 		if (this.filterAttributes != null) {
 			for (String attribute : this.filterAttributes) {
 				String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
 				Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
 				Matcher m = p.matcher(html);
-				html = m.replaceAll("""");
+				filteredHtml = m.replaceAll("""");
 			}
 		}
-		return html;
+		return filteredHtml;
 	}
 
 	@Override
@@ -415,12 +412,9 @@
 		try {
 			WebElement field = browser.findElement(identification.getWebDriverBy());
 			if (field != null) {
-				// first clear the field
 				field.clear();
-				// then fill in
 				field.sendKeys(text);
 
-				// this.activeElement = field;
 				return true;
 			}
 			return false;
"
ea7fa1b5e10371ac881f4cee32e9cf7deee4abd0,Alex Nederlof,CrawljaxController.java,MODIFY,formatRunningTime -> [long timeCrawlCalc] | [],"diff --git a/core/src/main/java/com/crawljax/core/CrawljaxController.java b/core/src/main/java/com/crawljax/core/CrawljaxController.java
index ba3acd0..17b28cb 100644
--- a/core/src/main/java/com/crawljax/core/CrawljaxController.java
+++ b/core/src/main/java/com/crawljax/core/CrawljaxController.java
@@ -109,8 +109,6 @@
 	 * 
 	 * @throws CrawljaxException
 	 *             If the browser cannot be instantiated.
-	 * @throws ConfigurationException
-	 *             if crawljax configuration fails.
 	 * @NotThreadSafe
 	 */
 	public final void run() throws CrawljaxException {
@@ -121,7 +119,7 @@
 		        .getPreCrawlConfig().getIncludedElements());
 
 		// Create the initailCrawler
-		initialCrawler = new InitialCrawler(this, configuration.getPlugins());
+		initialCrawler = new InitialCrawler(this);
 
 		// Start the Crawling by adding the initialCrawler to the the workQueue.
 		addWorkToQueue(initialCrawler);
@@ -294,7 +292,7 @@
 	private void shutdown(long timeCrawlCalc) {
 		StateFlowGraph stateFlowGraph = this.getSession().getStateFlowGraph();
 		for (Eventable c : stateFlowGraph.getAllEdges()) {
-			LOGGER.info(""Interaction Element= "" + c.toString());
+			LOGGER.trace(""Interaction Element= "" + c.toString());
 		}
 		LOGGER.info(""Total Crawling time("" + timeCrawlCalc + ""ms) ~= ""
 		        + formatRunningTime(timeCrawlCalc));
"
ea7fa1b5e10371ac881f4cee32e9cf7deee4abd0,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index b748731..115ce55 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -3,18 +3,18 @@
 import static com.google.common.base.Preconditions.checkArgument;
 
 import java.net.MalformedURLException;
-import java.net.URISyntaxException;
 import java.net.URL;
 import java.util.concurrent.TimeUnit;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.core.CrawlController;
-import com.crawljax.core.CrawljaxController;
+import com.crawljax.core.Crawler;
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.core.plugin.Plugins;
 import com.crawljax.di.CoreModule;
+import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
 import com.google.inject.Guice;
@@ -222,121 +222,38 @@
 
 	@Override
 	public int hashCode() {
-		final int prime = 31;
-		int result = 1;
-		result = prime * result + ((browserConfig == null) ? 0 : browserConfig.hashCode());
-		result = prime * result + ((crawlRules == null) ? 0 : crawlRules.hashCode());
-		result = prime * result + maximumDepth;
-		result = prime * result + (int) (maximumRuntime ^ (maximumRuntime >>> 32));
-		result = prime * result + maximumStates;
-		result = prime * result + ((plugins == null) ? 0 : plugins.hashCode());
-		result =
-		        prime * result
-		                + ((proxyConfiguration == null) ? 0 : proxyConfiguration.hashCode());
-		try {
-			result = prime * result + ((url == null) ? 0 : url.toURI().hashCode());
-		} catch (URISyntaxException e) {
-			result = prime * result;
-		}
-		return result;
+		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
+		        maximumStates, maximumRuntime, maximumDepth);
 	}
 
 	@Override
-	public boolean equals(Object obj) {
-		if (this == obj) {
-			return true;
+	public boolean equals(Object object) {
+		if (object instanceof CrawljaxConfiguration) {
+			CrawljaxConfiguration that = (CrawljaxConfiguration) object;
+			return Objects.equal(this.url, that.url)
+			        && Objects.equal(this.browserConfig, that.browserConfig)
+			        && Objects.equal(this.plugins, that.plugins)
+			        && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
+			        && Objects.equal(this.crawlRules, that.crawlRules)
+			        && Objects.equal(this.maximumStates, that.maximumStates)
+			        && Objects.equal(this.maximumRuntime, that.maximumRuntime)
+			        && Objects.equal(this.maximumDepth, that.maximumDepth);
 		}
-		
-		if (obj == null) {
-			return false;
-		}
-		
-		if (getClass() != obj.getClass()) {
-			return false;
-		}
-		
-		CrawljaxConfiguration other = (CrawljaxConfiguration) obj;
-		
-		if (browserConfig == null) {
-			if (other.browserConfig != null) {
-				return false;
-			}
-		} else if (!browserConfig.equals(other.browserConfig)) {
-			return false;
-		}
-		
-		if (crawlRules == null) {
-			if (other.crawlRules != null) {
-				return false;
-			}
-		} else if (!crawlRules.equals(other.crawlRules)) {
-			return false;
-		}
-		
-		if (maximumDepth != other.maximumDepth) {
-			return false;
-		}
-		
-		if (maximumRuntime != other.maximumRuntime) {
-			return false;
-		}
-		
-		if (maximumStates != other.maximumStates) {
-			return false;
-		}
-		
-		if (plugins == null) {
-			if (other.plugins != null) {
-				return false;
-			}
-		} else if (!plugins.equals(other.plugins)) {
-			return false;
-		}
-		
-		if (proxyConfiguration == null) {
-			if (other.proxyConfiguration != null) {
-				return false;
-			}
-		} else if (!proxyConfiguration.equals(other.proxyConfiguration)) {
-			return false;
-		}
-		
-		try {
-			if (url == null) {
-				if (other.url != null) {
-					return false;
-				}
-			} else if (!url.toURI().equals(other.url.toURI())) {
-				return false;
-			}
-		} catch( URISyntaxException e) {
-			return false; 
-		}
-		
-		return true;
+		return false;
 	}
 
 	@Override
 	public String toString() {
-		StringBuilder builder = new StringBuilder();
-		builder.append(""CrawljaxConfiguration [url="");
-		builder.append(url);
-		builder.append("", browserConfig="");
-		builder.append(browserConfig);
-		builder.append("", plugins="");
-		builder.append(plugins);
-		builder.append("", proxyConfiguration="");
-		builder.append(proxyConfiguration);
-		builder.append("", crawlRules="");
-		builder.append(crawlRules);
-		builder.append("", maximumStates="");
-		builder.append(maximumStates);
-		builder.append("", maximumRuntime="");
-		builder.append(maximumRuntime);
-		builder.append("", maximumDepth="");
-		builder.append(maximumDepth);
-		builder.append(""]"");
-		return builder.toString();
+		return Objects.toStringHelper(this)
+		        .add(""url"", url)
+		        .add(""browserConfig"", browserConfig)
+		        .add(""plugins"", plugins)
+		        .add(""proxyConfiguration"", proxyConfiguration)
+		        .add(""crawlRules"", crawlRules)
+		        .add(""maximumStates"", maximumStates)
+		        .add(""maximumRuntime"", maximumRuntime)
+		        .add(""maximumDepth"", maximumDepth)
+		        .toString();
 	}
 
 }
\ No newline at end of file
"
ea7fa1b5e10371ac881f4cee32e9cf7deee4abd0,Alex Nederlof,StateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index a9d3c2b..a2291d7 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -38,6 +38,7 @@
 	 * Thread-safety.
 	 */
 	private final AtomicInteger stateCounter = new AtomicInteger();
+	private final AtomicInteger nextStateNameCounter = new AtomicInteger();
 
 	private final StateVertex initialState;
 
@@ -53,6 +54,7 @@
 		sfg.addVertex(initialState);
 		stateCounter.incrementAndGet();
 		this.initialState = initialState;
+		LOG.debug(""Initialized the stateflowgraph with an initial state"");
 	}
 
 	/**
@@ -69,8 +71,8 @@
 	 * @return the clone if one is detected null otherwise.
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
-	public StateVertex addState(StateVertex stateVertix) {
-		return addState(stateVertix, true);
+	public StateVertex putIfAbsent(StateVertex stateVertix) {
+		return putIfAbsent(stateVertix, true);
 	}
 
 	/**
@@ -90,19 +92,20 @@
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
 	@GuardedBy(""sfg"")
-	public StateVertex addState(StateVertex stateVertix, boolean correctName) {
+	public StateVertex putIfAbsent(StateVertex stateVertix, boolean correctName) {
 		synchronized (sfg) {
-			if (!sfg.addVertex(stateVertix)) {
-				// Graph already contained the vertix
-				LOG.debug(""Graph already contained vertex {}"", stateVertix);
-				return this.getStateInGraph(stateVertix);
-			} else {
+			boolean added = sfg.addVertex(stateVertix);
+			if (added) {
 				int count = stateCounter.incrementAndGet();
 				LOG.debug(""Number of states is now {}"", count);
 				if (correctName) {
 					correctStateName(stateVertix);
 				}
 				return null;
+			} else {
+				// Graph already contained the vertix
+				LOG.debug(""Graph already contained vertex {}"", stateVertix);
+				return this.getStateInGraph(stateVertix);
 			}
 		}
 	}
@@ -369,8 +372,7 @@
 	 * @return State name the name of the state
 	 */
 	public String getNewStateName() {
-		stateCounter.getAndIncrement();
-		String state = makeStateName(stateCounter.get(), false);
+		String state = makeStateName(nextStateNameCounter.incrementAndGet(), false);
 		return state;
 	}
 
"
ea7fa1b5e10371ac881f4cee32e9cf7deee4abd0,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index 287b05d..aef2647 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -67,88 +67,87 @@
 	private void setInputElementValue(Node element, FormInput input) {
 
 		LOGGER.debug(""INPUTFIELD: {} ({})"", input.getIdentification(), input.getType());
-		if (element == null) {
+		if (element == null || input.getInputValues().isEmpty()) {
 			return;
 		}
-		if (input.getInputValues().iterator().hasNext()) {
-			try {
-				// fill in text fields, textareas, password fields and hidden
-				// fields
-				if (input.getType().toLowerCase().startsWith(""text"")
-				        || input.getType().equalsIgnoreCase(""password"")
-				        || input.getType().equalsIgnoreCase(""hidden"")) {
-					String text = input.getInputValues().iterator().next().getValue();
-					if ("""".equals(text)) {
-						return;
-					}
-					String js = DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-					js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
-					browser.executeJavaScript(js);
-				}
+		try {
+			if (input.getType().toLowerCase().startsWith(""text"")
+			        || input.getType().equalsIgnoreCase(""password"")
+			        || input.getType().equalsIgnoreCase(""hidden"")) {
+				handleText(element, input);
+			} else if (""checkbox"".equals(input.getType())) {
+				handleCheckBoxes(element, input);
+			} else if (input.getType().equals(""radio"")) {
+				handleRadioSwitches(element, input);
+			} else if (input.getType().startsWith(""select"")) {
+				handleSelectBoxes(element, input);
+			}
+		} catch (BrowserConnectionException e) {
+			throw e;
+		} catch (RuntimeException e) {
+			LOGGER.error(""Could not input element values"", e);
+		}
+	}
 
-				// check/uncheck checkboxes
-				if (""checkbox"".equals(input.getType())) {
-					for (InputValue inputValue : input.getInputValues()) {
-						String js =
-						        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-						boolean check;
-						if (!randomFieldValue) {
-							check = inputValue.isChecked();
-						} else {
+	private void handleCheckBoxes(Node element, FormInput input) {
+		for (InputValue inputValue : input.getInputValues()) {
+			String js =
+			        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
+			boolean check;
+			if (!randomFieldValue) {
+				check = inputValue.isChecked();
+			} else {
 
-							check = Math.random() >= HALF;
-						}
-						String value;
-						if (check) {
-							value = ""true"";
-						} else {
-							value = ""false"";
-						}
-						js += ""try{ATUSA_element.checked="" + value + "";}catch(e){}"";
-						browser.executeJavaScript(js);
+				check = Math.random() >= HALF;
+			}
+			String value;
+			if (check) {
+				value = ""true"";
+			} else {
+				value = ""false"";
+			}
+			js += ""try{ATUSA_element.checked="" + value + "";}catch(e){}"";
+			browser.executeJavaScript(js);
 
-					}
-				}
+		}
+	}
 
-				// check radio button
-				if (input.getType().equals(""radio"")) {
-					for (InputValue inputValue : input.getInputValues()) {
-						if (inputValue.isChecked()) {
-							String js =
-							        DomUtils.getJSGetElement(XPathHelper
-							                .getXPathExpression(element));
-							js += ""try{ATUSA_element.checked=true;}catch(e){}"";
-							browser.executeJavaScript(js);
-						}
-					}
-				}
-
-				// select options
-				if (input.getType().startsWith(""select"")) {
-					for (InputValue inputValue : input.getInputValues()) {
-						// if(browser.getDriver()==null){
-						String js =
-						        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-						js +=
-						        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
-						                + ""if(ATUSA_element.options[i].value=='""
-						                + inputValue.getValue()
-						                + ""' || ATUSA_element.options[i].text=='""
-						                + inputValue.getValue() + ""'){""
-						                + ""ATUSA_element.options[i].selected=true;"" + ""break;""
-						                + ""}"" + ""};"" + ""}catch(e){}"";
-						browser.executeJavaScript(js);
-					}
-				}
-			} catch (Exception e) {
-				// TODO Stefan; refactor this catch
-				if (e instanceof BrowserConnectionException) {
-					throw (BrowserConnectionException) e;
-				}
-				LOGGER.error(e.getMessage(), e);
+	private void handleRadioSwitches(Node element, FormInput input) {
+		for (InputValue inputValue : input.getInputValues()) {
+			if (inputValue.isChecked()) {
+				String js =
+				        DomUtils.getJSGetElement(XPathHelper
+				                .getXPathExpression(element));
+				js += ""try{ATUSA_element.checked=true;}catch(e){}"";
+				browser.executeJavaScript(js);
 			}
 		}
+	}
 
+	private void handleSelectBoxes(Node element, FormInput input) {
+		for (InputValue inputValue : input.getInputValues()) {
+			String js =
+			        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
+			js +=
+			        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
+			                + ""if(ATUSA_element.options[i].value=='""
+			                + inputValue.getValue()
+			                + ""' || ATUSA_element.options[i].text=='""
+			                + inputValue.getValue() + ""'){""
+			                + ""ATUSA_element.options[i].selected=true;"" + ""break;""
+			                + ""}"" + ""};"" + ""}catch(e){}"";
+			browser.executeJavaScript(js);
+		}
+	}
+
+	private void handleText(Node element, FormInput input) {
+		String text = input.getInputValues().iterator().next().getValue();
+		if ("""".equals(text)) {
+			return;
+		}
+		String js = DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
+		js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
+		browser.executeJavaScript(js);
 	}
 
 	/**
"
ea7fa1b5e10371ac881f4cee32e9cf7deee4abd0,Alex Nederlof,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index 2918262..d0d3edd 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -30,7 +30,6 @@
 import org.custommonkey.xmlunit.DetailedDiff;
 import org.custommonkey.xmlunit.Diff;
 import org.custommonkey.xmlunit.Difference;
-import org.custommonkey.xmlunit.DifferenceListener;
 import org.cyberneko.html.parsers.DOMParser;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -44,6 +43,7 @@
 import org.xml.sax.SAXException;
 
 import com.crawljax.core.CrawljaxException;
+import com.google.common.base.Strings;
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Lists;
 
@@ -118,23 +118,27 @@
 	 */
 	public static String getElementAttributes(Element element, ImmutableSet<String> exclude) {
 		StringBuilder buffer = new StringBuilder();
-
 		if (element != null) {
 			NamedNodeMap attributes = element.getAttributes();
 			if (attributes != null) {
-				for (int i = 0; i < attributes.getLength(); i++) {
-					Attr attr = (Attr) attributes.item(i);
-					if (!exclude.contains(attr.getNodeName())) {
-						buffer.append(attr.getNodeName()).append('=');
-						buffer.append(attr.getNodeValue()).append(' ');
-					}
-				}
+				addAttributesToString(exclude, buffer, attributes);
 			}
 		}
 
 		return buffer.toString().trim();
 	}
 
+	private static void addAttributesToString(ImmutableSet<String> exclude, StringBuilder buffer,
+	        NamedNodeMap attributes) {
+		for (int i = 0; i < attributes.getLength(); i++) {
+			Attr attr = (Attr) attributes.item(i);
+			if (!exclude.contains(attr.getNodeName())) {
+				buffer.append(attr.getNodeName()).append('=');
+				buffer.append(attr.getNodeValue()).append(' ');
+			}
+		}
+	}
+
 	/**
 	 * @param element
 	 *            the element.
@@ -142,17 +146,17 @@
 	 */
 	public static String getElementString(Element element) {
 		String text = DomUtils.removeNewLines(DomUtils.getTextValue(element)).trim();
-		String info = """";
-		if (!text.equals("""")) {
-			info += ""\"""" + text + ""\"" "";
+		StringBuilder info = new StringBuilder();
+		if (!Strings.isNullOrEmpty(text)) {
+			info.append(""\"""").append(text).append(""\"" "");
 		}
 		if (element != null) {
 			if (element.hasAttribute(""id"")) {
-				info += ""ID: "" + element.getAttribute(""id"") + "" "";
+				info.append(""ID: "").append(element.getAttribute(""id"")).append("" "");
 			}
-			info += DomUtils.getAllElementAttributes(element) + "" "";
+			info.append(DomUtils.getAllElementAttributes(element)).append("" "");
 		}
-		return info;
+		return info.toString();
 	}
 
 	/**
@@ -281,8 +285,8 @@
 	 */
 	public static String getTextValue(Element element) {
 		String ret = """";
-		String textContent = element.getTextContent(); 
-		if (textContent != null && !textContent.equals("""") ) {
+		String textContent = element.getTextContent();
+		if (textContent != null && !textContent.equals("""")) {
 			ret = textContent;
 		} else if (element.hasAttribute(""title"")) {
 			ret = element.getAttribute(""title"");
@@ -326,29 +330,7 @@
 		try {
 			Diff d = new Diff(DomUtils.asDocument(controlDom), DomUtils.asDocument(testDom));
 			DetailedDiff dd = new DetailedDiff(d);
-			dd.overrideDifferenceListener(new DifferenceListener() {
-
-				@Override
-				public void skippedComparison(Node control, Node test) {
-				}
-
-				@Override
-				public int differenceFound(Difference difference) {
-					if (difference.getControlNodeDetail() == null
-					        || difference.getControlNodeDetail().getNode() == null
-					        || difference.getTestNodeDetail() == null
-					        || difference.getTestNodeDetail().getNode() == null) {
-						return RETURN_ACCEPT_DIFFERENCE;
-					}
-					if (ignoreAttributes.contains(difference.getTestNodeDetail().getNode()
-					        .getNodeName())
-					        || ignoreAttributes.contains(difference.getControlNodeDetail()
-					                .getNode().getNodeName())) {
-						return RETURN_IGNORE_DIFFERENCE_NODES_IDENTICAL;
-					}
-					return RETURN_ACCEPT_DIFFERENCE;
-				}
-			});
+			dd.overrideDifferenceListener(new DomDifferenceListener(ignoreAttributes));
 
 			return dd.getAllDifferences();
 		} catch (IOException e) {
@@ -394,7 +376,7 @@
 	 * @return The new, correct path.
 	 */
 	public static String addFolderSlashIfNeeded(String folderName) {
-		if (!folderName.equals("""") && !folderName.endsWith(""/"")) {
+		if (!"""".equals(folderName) && !folderName.endsWith(""/"")) {
 			return folderName + ""/"";
 		} else {
 			return folderName;
@@ -461,8 +443,7 @@
 	 */
 	public static String getJSGetElement(String xpath) {
 		String js =
-		        """"
-		                + ""function ATUSA_getElementInNodes(nodes, tagName, number){""
+		        ""function ATUSA_getElementInNodes(nodes, tagName, number){""
 		                + ""try{""
 		                + ""var pos = 1;""
 		                + ""for(i=0; i<nodes.length; i++){""
"
ea7fa1b5e10371ac881f4cee32e9cf7deee4abd0,Alex Nederlof,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 0bc8d5f..bdb6a53 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -295,16 +295,18 @@
 		// make sure not before the node
 		int openElements = 1;
 		int i = 0;
-		int position = pos; 
+		int position = pos;
 		String dom_lower = dom.toLowerCase();
 		String element_lower = element.toLowerCase();
 		String openElement = ""<"" + element_lower;
 		String closeElement = ""</"" + element_lower;
 		while (i < MAX_SEARCH_LOOPS) {
-			if (dom_lower.indexOf(openElement, position) == -1 && dom_lower.indexOf(closeElement, position) == -1) {
+			if (dom_lower.indexOf(openElement, position) == -1
+			        && dom_lower.indexOf(closeElement, position) == -1) {
 				return -1;
 			}
-			if (dom_lower.indexOf(openElement, position) < dom_lower.indexOf(closeElement, position)
+			if (dom_lower.indexOf(openElement, position) < dom_lower.indexOf(closeElement,
+			        position)
 			        && dom_lower.indexOf(openElement, position) != -1) {
 				openElements++;
 				position = dom_lower.indexOf(openElement, position) + 1;
@@ -341,14 +343,18 @@
 	 *         text()
 	 */
 	public static String stripXPathToElement(String xpath) {
-		String xpathStripped = xpath; 
-		
+		String xpathStripped = xpath;
+
 		if (!Strings.isNullOrEmpty(xpathStripped)) {
 			if (xpathStripped.toLowerCase().contains(""/text()"")) {
-				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/text()""));
+				xpathStripped =
+				        xpathStripped
+				                .substring(0, xpathStripped.toLowerCase().indexOf(""/text()""));
 			}
 			if (xpathStripped.toLowerCase().contains(""/comment()"")) {
-				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/comment()""));
+				xpathStripped =
+				        xpathStripped.substring(0,
+				                xpathStripped.toLowerCase().indexOf(""/comment()""));
 			}
 			if (xpathStripped.contains(""@"")) {
 				xpathStripped = xpathStripped.substring(0, xpathStripped.indexOf(""@"") - 1);
"
32cd016996ea2ee415ca26bc19de7d487d2843f4,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index b680e39..898859f 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -270,6 +270,7 @@
 			return;
 		} catch (InterruptedException e) {
 			LOGGER.error(""goToUrl got interrupted while waiting for the page to be loaded"", e);
+			Thread.currentThread().interrupt();
 			return;
 		}
 	}
@@ -296,7 +297,7 @@
 	 *            The HTML event type (onclick, onmouseover, ...).
 	 * @return true if firing event is successful.
 	 */
-	protected boolean fireEventWait(WebElement webElement, Eventable eventable)
+	private boolean fireEventWait(WebElement webElement, Eventable eventable)
 	        throws ElementNotVisibleException {
 		switch (eventable.getEventType()) {
 			case click:
@@ -432,7 +433,7 @@
 	 * @return true if it is able to fire the event successfully on the element.
 	 */
 	@Override
-	public synchronized boolean fireEvent(Eventable eventable) throws ElementNotVisibleException,
+	public synchronized boolean fireEventAndWait(Eventable eventable) throws ElementNotVisibleException,
 	        NoSuchElementException {
 		try {
 
"
32cd016996ea2ee415ca26bc19de7d487d2843f4,Alex Nederlof,CrawlController.java,MODIFY,executeConsumers -> [] | [CrawlTaskConsumer firstConsumer],"diff --git a/core/src/main/java/com/crawljax/core/CrawlController.java b/core/src/main/java/com/crawljax/core/CrawlController.java
index 8723d18..c5b6144 100644
--- a/core/src/main/java/com/crawljax/core/CrawlController.java
+++ b/core/src/main/java/com/crawljax/core/CrawlController.java
@@ -11,9 +11,13 @@
 import org.slf4j.LoggerFactory;
 
 import com.crawljax.core.configuration.BrowserConfiguration;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
+import com.crawljax.core.plugin.Plugins;
 import com.crawljax.core.state.Eventable;
+import com.crawljax.core.state.StateVertex;
 import com.crawljax.di.CoreModule.ConsumersDoneLatch;
 import com.crawljax.di.CoreModule.CrawlQueue;
+import com.crawljax.di.CrawlSessionProvider;
 import com.google.common.collect.ImmutableList;
 import com.google.inject.Inject;
 import com.google.inject.Provider;
@@ -32,15 +36,22 @@
 	private final BlockingQueue<CrawlTask> tasks;
 	private final CountDownLatch consumersDoneLatch;
 
+	private final CrawlSessionProvider crawlSessionProvider;
+
+	private final Plugins plugins;
+
 	@Inject
 	CrawlController(ExecutorService executor, Provider<CrawlTaskConsumer> consumerFactory,
-	        BrowserConfiguration config, @CrawlQueue BlockingQueue<CrawlTask> tasks,
-	        @ConsumersDoneLatch CountDownLatch consumersDoneLatch) {
+	        CrawljaxConfiguration config, @CrawlQueue BlockingQueue<CrawlTask> tasks,
+	        @ConsumersDoneLatch CountDownLatch consumersDoneLatch,
+	        CrawlSessionProvider crawlSessionProvider) {
 		this.executor = executor;
 		this.consumerFactory = consumerFactory;
-		this.config = config;
+		this.config = config.getBrowserConfig();
+		this.plugins = config.getPlugins();
 		this.tasks = tasks;
 		this.consumersDoneLatch = consumersDoneLatch;
+		this.crawlSessionProvider = crawlSessionProvider;
 	}
 
 	/**
@@ -48,7 +59,11 @@
 	 */
 	public void run() {
 		tasks.add(initialTask());
-		executeConsumers();
+		CrawlTaskConsumer firstConsumer = consumerFactory.get();
+		StateVertex firstState = firstConsumer.crawlIndex();
+		crawlSessionProvider.setup(firstState);
+		plugins.runOnNewStatePlugins(crawlSessionProvider.get());
+		executeConsumers(firstConsumer);
 	}
 
 	private CrawlTask initialTask() {
@@ -56,15 +71,16 @@
 		return new CrawlTask(ImmutableList.of(event));
 	}
 
-	private void executeConsumers() {
-		LOG.debug(""Starting {} consumers"");
-		for (int i = 0; i < config.getNumberOfBrowsers(); i++) {
+	private void executeConsumers(CrawlTaskConsumer firstConsumer) {
+		LOG.debug(""Starting {} consumers"", config.getNumberOfBrowsers());
+		executor.execute(firstConsumer);
+		for (int i = 1; i < config.getNumberOfBrowsers(); i++) {
 			executor.execute(consumerFactory.get());
 		}
 		try {
 			consumersDoneLatch.await();
 		} catch (InterruptedException e) {
-			LOG.warn(""Interrupted before being finished. Shutting down..."");
+			LOG.warn(""The crawl was interrupted before it finished. Shutting down..."");
 		} finally {
 			shutDown();
 		}
"
32cd016996ea2ee415ca26bc19de7d487d2843f4,Alex Nederlof,CrawlQueueManager.java,MODIFY,addWorkToQueue -> [Crawler work] | [NewCrawler work],"diff --git a/core/src/main/java/com/crawljax/core/CrawlQueueManager.java b/core/src/main/java/com/crawljax/core/CrawlQueueManager.java
index 3b22f37..04470ca 100644
--- a/core/src/main/java/com/crawljax/core/CrawlQueueManager.java
+++ b/core/src/main/java/com/crawljax/core/CrawlQueueManager.java
@@ -13,7 +13,7 @@
 	 * @param work
 	 *            the work (Crawler) to add to the Queue
 	 */
-	void addWorkToQueue(Crawler work);
+	void addWorkToQueue(NewCrawler work);
 
 	/**
 	 * Removes this Crawler from the workQueue if it is present, thus causing it not to be run if it
"
32cd016996ea2ee415ca26bc19de7d487d2843f4,Alex Nederlof,CrawlSession.java,MODIFY,removeCrawlPath -> [] | [List path],"diff --git a/core/src/main/java/com/crawljax/core/CrawlSession.java b/core/src/main/java/com/crawljax/core/CrawlSession.java
index bca228b..d78dc3c 100644
--- a/core/src/main/java/com/crawljax/core/CrawlSession.java
+++ b/core/src/main/java/com/crawljax/core/CrawlSession.java
@@ -1,24 +1,28 @@
 package com.crawljax.core;
 
 import java.util.Collection;
+import java.util.Date;
 import java.util.List;
 import java.util.concurrent.ConcurrentLinkedQueue;
 
-import com.crawljax.browser.BrowserPool;
-import com.crawljax.browser.EmbeddedBrowser;
+import javax.inject.Inject;
+import javax.inject.Singleton;
+
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+
 import com.crawljax.core.configuration.CrawljaxConfiguration;
-import com.crawljax.core.state.CrawlPath;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateFlowGraph;
 import com.crawljax.core.state.StateVertex;
 
 /**
  * The data about the crawlsession.
- * 
- * @author mesbah
  */
+@Singleton
 public class CrawlSession {
 
+	private static final Logger LOG = LoggerFactory.getLogger(CrawlSession.class);
 	/**
 	 * This variable holds the current stateFlowGraph.
 	 */
@@ -46,41 +50,6 @@
 	 */
 	private final long startTime;
 
-	private final ThreadLocal<CrawlPath> crawlPath = new ThreadLocal<CrawlPath>();
-
-	/**
-	 * ThreadLocal store the have a Thread<->Current State relation.
-	 */
-	private final ThreadLocal<StateVertex> tlState = new ThreadLocal<StateVertex>();
-
-	/**
-	 * The main BrowserPool where the current Browser is stored.
-	 */
-	private final BrowserPool browserPool;
-
-	/**
-	 * @param pool
-	 *            the Embedded browser pool that is in use
-	 */
-	public CrawlSession(BrowserPool pool) {
-		this(pool, null, null, 0);
-	}
-
-	/**
-	 * @param pool
-	 *            the embedded browser pool that is in use.
-	 * @param stateFlowGraph
-	 *            the state flow graph.
-	 * @param state
-	 *            the current state.
-	 * @param startTime
-	 *            the time this session started in milliseconds.
-	 */
-	public CrawlSession(BrowserPool pool, StateFlowGraph stateFlowGraph, StateVertex state,
-	        long startTime) {
-		this(pool, stateFlowGraph, state, startTime, null);
-	}
-
 	/**
 	 * @param pool
 	 *            the embedded browser instance pool that is in use.
@@ -93,21 +62,13 @@
 	 * @param crawljaxConfiguration
 	 *            the configuration.
 	 */
-	public CrawlSession(BrowserPool pool, StateFlowGraph stateFlowGraph, StateVertex state,
-	        long startTime, CrawljaxConfiguration crawljaxConfiguration) {
+	@Inject
+	public CrawlSession(StateFlowGraph stateFlowGraph, StateVertex state,
+	        CrawljaxConfiguration crawljaxConfiguration) {
 		this.crawljaxConfiguration = crawljaxConfiguration;
-		this.browserPool = pool;
 		this.stateFlowGraph = stateFlowGraph;
 		this.initialState = state;
-		this.startTime = startTime;
-		tlState.set(state);
-	}
-
-	/**
-	 * @return the browser or null if there is none
-	 */
-	public EmbeddedBrowser getBrowser() {
-		return browserPool.getCurrentBrowser();
+		this.startTime = new Date().getTime();
 	}
 
 	/**
@@ -118,27 +79,6 @@
 	}
 
 	/**
-	 * @return the currentState
-	 */
-	public StateVertex getCurrentState() {
-		StateVertex sv = tlState.get();
-		if (sv == null) {
-			tlState.set(getInitialState());
-		} else {
-			return sv;
-		}
-		return tlState.get();
-	}
-
-	/**
-	 * @param currentState
-	 *            the currentState to set
-	 */
-	public void setCurrentState(StateVertex currentState) {
-		this.tlState.set(currentState);
-	}
-
-	/**
 	 * @return the crawlPaths
 	 */
 	public Collection<List<Eventable>> getCrawlPaths() {
@@ -175,83 +115,21 @@
 	}
 
 	/**
-	 * @return the exactEventPath
-	 * @deprecated use the {@link #getCurrentCrawlPath()}
-	 */
-	@Deprecated
-	public List<Eventable> getExactEventPath() {
-		return this.getCurrentCrawlPath();
-	}
-
-	/**
-	 * @param exactEventPath
-	 *            the exactEventPath to set
-	 * @deprecated not used anymore...
-	 */
-	@Deprecated
-	public void setExactEventPath(List<Eventable> exactEventPath) {
-	}
-
-	/**
 	 * Remove the current path from the set of crawlPaths.
 	 */
-	protected final void removeCrawlPath() {
-		List<Eventable> path = crawlPath.get();
-		if (path == null) {
-			return;
-		}
+	protected final void removeCrawlPath(List<Eventable> path) {
 		this.crawlPaths.remove(path);
 	}
 
-	/**
-	 * branch the current crawl path, save the old-one and continue with the current.
-	 */
-	protected final void branchCrawlPath() {
-		CrawlPath path = crawlPath.get();
-		if (path == null) {
-			return;
-		}
-		this.addCrawlPath(path.immutableCopy(false));
-	}
-
-	/**
-	 * Add an eventable to the current crawl path.
-	 * 
-	 * @param clickable
-	 *            the clickable to add to the current path.
-	 */
-	protected final void addEventableToCrawlPath(Eventable clickable) {
-		CrawlPath path = crawlPath.get();
-		if (path == null) {
-			path = startNewPath();
-		}
-		path.add(clickable);
-	}
-
-	/**
-	 * Get the current crawl path.
-	 * 
-	 * @return the current current crawl path.
-	 */
-	public CrawlPath getCurrentCrawlPath() {
-		CrawlPath path = this.crawlPath.get();
-		if (path == null) {
-			return new CrawlPath();
-		}
-		return path;
-	}
-
-	/**
-	 * start a new Path, because of the thread local every crawlPath is saved on the thread instead
-	 * of on the Crawler, so without (re)starting a new Path the old path continues.
-	 * 
-	 * @return the new empty path.
-	 */
-	protected final CrawlPath startNewPath() {
-		CrawlPath path = new CrawlPath();
-		crawlPath.set(path);
-		crawlPaths.add(path);
-		return path;
-	}
+	// /**
+	// * branch the current crawl path, save the old-one and continue with the current.
+	// */
+	// protected final void branchCrawlPath() {
+	// CrawlPath path = crawlPath.get();
+	// if (path == null) {
+	// return;
+	// }
+	// this.addCrawlPath(path.immutableCopy(false));
+	// }
 
 }
"
32cd016996ea2ee415ca26bc19de7d487d2843f4,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index aef2647..5551a72 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -8,6 +8,7 @@
 import java.util.Arrays;
 import java.util.List;
 
+import javax.inject.Inject;
 import javax.xml.xpath.XPathExpressionException;
 
 import org.slf4j.Logger;
@@ -20,10 +21,11 @@
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.CandidateElement;
-import com.crawljax.core.configuration.InputSpecification;
+import com.crawljax.core.configuration.CrawlRules;
 import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.util.DomUtils;
 import com.crawljax.util.XPathHelper;
+import com.google.inject.assistedinject.Assisted;
 
 /**
  * Handles form values and fills in the form input elements with random values of the defined
@@ -39,7 +41,7 @@
 
 	private static final double HALF = 0.5;
 
-	private FormInputValueHelper formInputValueHelper;
+	private final FormInputValueHelper formInputValueHelper;
 
 	/**
 	 * Public constructor.
@@ -51,10 +53,12 @@
 	 * @param randomInput
 	 *            if random data should be generated on the input fields.
 	 */
-	public FormHandler(EmbeddedBrowser browser, InputSpecification inputSpecification,
-	        boolean randomInput) {
+	@Inject
+	public FormHandler(@Assisted EmbeddedBrowser browser, CrawlRules config) {
 		this.browser = browser;
-		this.formInputValueHelper = new FormInputValueHelper(inputSpecification, randomInput);
+		this.formInputValueHelper =
+		        new FormInputValueHelper(config.getInputSpecification(),
+		                config.isRandomInputInForms());
 	}
 
 	private static final String[] ALLOWED_INPUT_TYPES =
"
64cb18485e0b3744bece397b42f7f0688491b507,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 898859f..a3ffe31 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -433,7 +433,8 @@
 	 * @return true if it is able to fire the event successfully on the element.
 	 */
 	@Override
-	public synchronized boolean fireEventAndWait(Eventable eventable) throws ElementNotVisibleException,
+	public synchronized boolean fireEventAndWait(Eventable eventable)
+	        throws ElementNotVisibleException,
 	        NoSuchElementException {
 		try {
 
"
64cb18485e0b3744bece397b42f7f0688491b507,Alex Nederlof,UnhandledCandidatActionCache.java,MODIFY,pollActionOrNull -> [String state] | [StateVertex state],"diff --git a/core/src/main/java/com/crawljax/core/UnhandledCandidatActionCache.java b/core/src/main/java/com/crawljax/core/UnhandledCandidatActionCache.java
index 4dbe4a5..e99a07f 100644
--- a/core/src/main/java/com/crawljax/core/UnhandledCandidatActionCache.java
+++ b/core/src/main/java/com/crawljax/core/UnhandledCandidatActionCache.java
@@ -6,13 +6,17 @@
 import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.locks.Lock;
 
+import javax.inject.Provider;
 import javax.inject.Singleton;
 
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
 import com.crawljax.core.configuration.BrowserConfiguration;
-import com.crawljax.di.CoreModule.CrawlQueue;
+import com.crawljax.core.state.Eventable;
+import com.crawljax.core.state.StateFlowGraph;
+import com.crawljax.core.state.StateVertex;
+import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Queues;
 import com.google.common.util.concurrent.Striped;
@@ -22,16 +26,15 @@
 
 	private static final Logger LOG = LoggerFactory.getLogger(UnhandledCandidatActionCache.class);
 
-	private final Map<String, Queue<CandidateCrawlAction>> cache;
-	private Striped<Lock> locks;
+	private final Map<Integer, Queue<CandidateCrawlAction>> cache;
+	private final BlockingQueue<Integer> statesWithCandidates;
+	private final Striped<Lock> locks;
+	private final Provider<StateFlowGraph> sfg;
 
-	private final BlockingQueue<CrawlTask> taskQueue;
-
-	UnhandledCandidatActionCache(BrowserConfiguration config,
-	        @CrawlQueue BlockingQueue<CrawlTask> taskQueue) {
-		this.taskQueue = taskQueue;
+	UnhandledCandidatActionCache(BrowserConfiguration config, Provider<StateFlowGraph> sfg) {
+		this.sfg = sfg;
 		cache = Maps.newHashMap();
-
+		statesWithCandidates = Queues.newLinkedBlockingQueue();
 		// Every browser gets a lock.
 		locks = Striped.lock(config.getNumberOfBrowsers());
 	}
@@ -41,20 +44,21 @@
 	 *            The state you want to poll an {@link CandidateCrawlAction} for.
 	 * @return The next to-be-crawled action or <code>null</code> if none available.
 	 */
-	CandidateCrawlAction pollActionOrNull(String state) {
-		Lock lock = locks.get(state);
+	CandidateCrawlAction pollActionOrNull(StateVertex state) {
+		Lock lock = locks.get(state.getId());
 		try {
 			lock.lock();
-			Queue<CandidateCrawlAction> queue = cache.get(state);
+			Queue<CandidateCrawlAction> queue = cache.get(state.getId());
 			if (queue == null) {
 				return null;
 			} else {
 				CandidateCrawlAction action = queue.poll();
 				if (action == null) {
-					LOG.debug(""All actions polled for state {}"", state);
+					LOG.debug(""All actions polled for state {}"", state.getName());
 					cache.remove(queue);
 					LOG.debug(""There are now {} states with unfinished actions"", cache.size());
 				}
+				removeStateFromQueue(state.getId());
 				return action;
 			}
 		} finally {
@@ -62,23 +66,46 @@
 		}
 	}
 
+	private void removeStateFromQueue(int id) {
+		while (statesWithCandidates.remove(id)) {
+			LOG.trace(""Removed id {} from the queue"", id);
+		}
+	}
+
 	/**
 	 * @param actions
 	 *            The actions you want to add to a state.
 	 * @param state
 	 *            The state name. This should be unique per state.
 	 */
-	void addActions(Collection<CandidateCrawlAction> actions, String state) {
-		Lock lock = locks.get(state);
+	void addActions(Collection<CandidateCrawlAction> actions, StateVertex state) {
+		Lock lock = locks.get(state.getId());
 		try {
 			lock.lock();
-			if (cache.containsKey(state)) {
-				cache.get(state).addAll(actions);
+			LOG.debug(""Adding crawl actions for state {}"", state.getId());
+			if (cache.containsKey(state.getId())) {
+				cache.get(state.getId()).addAll(actions);
 			} else {
-				cache.put(state, Queues.newConcurrentLinkedQueue(actions));
+				cache.put(state.getId(), Queues.newConcurrentLinkedQueue(actions));
 			}
+			statesWithCandidates.add(state.getId());
 		} finally {
 			lock.unlock();
 		}
+
+	}
+
+	/**
+	 * @return A new crawl task as soon as one is ready. Until then, it blocks.
+	 * @throws InterruptedException
+	 *             when taking from the queue is interrupted.
+	 */
+	public CrawlTask awaitNewTask() throws InterruptedException {
+		int id = statesWithCandidates.take();
+		StateFlowGraph graph = sfg.get();
+		ImmutableList<Eventable> shortestPath =
+		        graph.getShortestPath(graph.getInitialState(), graph.getById(id));
+		LOG.debug(""New task available over path {}"", shortestPath);
+		return new CrawlTask(shortestPath);
 	}
 }
"
64cb18485e0b3744bece397b42f7f0688491b507,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 115ce55..bea5077 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -8,7 +8,6 @@
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.core.CrawlController;
-import com.crawljax.core.Crawler;
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
"
64cb18485e0b3744bece397b42f7f0688491b507,Alex Nederlof,Plugins.java,MODIFY,"runPreStateCrawlingPlugins -> [CrawlSession session, List candidateElements] | [CrawlSession session, ImmutableList candidateElements]","diff --git a/core/src/main/java/com/crawljax/core/plugin/Plugins.java b/core/src/main/java/com/crawljax/core/plugin/Plugins.java
index 5949e24..186ae9b 100644
--- a/core/src/main/java/com/crawljax/core/plugin/Plugins.java
+++ b/core/src/main/java/com/crawljax/core/plugin/Plugins.java
@@ -246,7 +246,7 @@
 	 *            the elements which crawljax is about to crawl
 	 */
 	public void runPreStateCrawlingPlugins(CrawlSession session,
-	        List<CandidateElement> candidateElements) {
+	        ImmutableList<CandidateElement> candidateElements) {
 		LOGGER.debug(""Running PreStateCrawlingPlugins..."");
 		for (Plugin plugin : plugins.get(PreStateCrawlingPlugin.class)) {
 			if (plugin instanceof PreStateCrawlingPlugin) {
"
64cb18485e0b3744bece397b42f7f0688491b507,Alex Nederlof,PreStateCrawlingPlugin.java,MODIFY,"preStateCrawling -> [CrawlSession session, List candidateElements] | [CrawlSession session, ImmutableList candidateElements]","diff --git a/core/src/main/java/com/crawljax/core/plugin/PreStateCrawlingPlugin.java b/core/src/main/java/com/crawljax/core/plugin/PreStateCrawlingPlugin.java
index fcd7757..9fd9fbd 100644
--- a/core/src/main/java/com/crawljax/core/plugin/PreStateCrawlingPlugin.java
+++ b/core/src/main/java/com/crawljax/core/plugin/PreStateCrawlingPlugin.java
@@ -1,15 +1,11 @@
 package com.crawljax.core.plugin;
 
-import java.util.List;
-
 import com.crawljax.core.CandidateElement;
 import com.crawljax.core.CrawlSession;
+import com.google.common.collect.ImmutableList;
 
 /**
- * Plugin type that is called before firing events on the current DOM state. Example: filter
- * candidate elements.
- * 
- * @author dannyroest@gmail.com (Danny Roest)
+ * Plugin type that is called before firing events on the current DOM state.
  */
 public interface PreStateCrawlingPlugin extends Plugin {
 
@@ -23,6 +19,6 @@
 	 * @param candidateElements
 	 *            the candidates for the current state.
 	 */
-	void preStateCrawling(CrawlSession session, List<CandidateElement> candidateElements);
+	void preStateCrawling(CrawlSession session, ImmutableList<CandidateElement> candidateElements);
 
 }
"
64cb18485e0b3744bece397b42f7f0688491b507,Alex Nederlof,CrawlPath.java,MODIFY,immutableCopy -> [boolean removeLast] | [],"diff --git a/core/src/main/java/com/crawljax/core/state/CrawlPath.java b/core/src/main/java/com/crawljax/core/state/CrawlPath.java
index 8aaf8dd..565b288 100644
--- a/core/src/main/java/com/crawljax/core/state/CrawlPath.java
+++ b/core/src/main/java/com/crawljax/core/state/CrawlPath.java
@@ -55,7 +55,15 @@
 	 *            should the last element be removed?
 	 * @return the CrawlPath based on an immutable list.
 	 */
-	public CrawlPath immutableCopy(boolean removeLast) {
+	public CrawlPath immutableCopy() {
+		return immutableCopy(false);
+	}
+
+	public CrawlPath immutableCopyWithoutLast() {
+		return immutableCopy(true);
+	}
+
+	private CrawlPath immutableCopy(boolean removeLast) {
 		if (isEmpty()) {
 			return new CrawlPath();
 		}
"
64cb18485e0b3744bece397b42f7f0688491b507,Alex Nederlof,StateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index a2291d7..bdabca9 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -5,8 +5,11 @@
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
+import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.atomic.AtomicInteger;
 
+import javax.inject.Singleton;
+
 import net.jcip.annotations.GuardedBy;
 
 import org.apache.commons.math.stat.descriptive.moment.Mean;
@@ -18,14 +21,16 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.google.common.base.Preconditions;
+import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Lists;
+import com.google.common.collect.Maps;
 
 /**
  * The State-Flow Graph is a multi-edge directed graph with states (StateVetex) on the vertices and
  * clickables (Eventable) on the edges.
  */
+@Singleton
 @SuppressWarnings(""serial"")
 public class StateFlowGraph implements Serializable {
 
@@ -39,8 +44,7 @@
 	 */
 	private final AtomicInteger stateCounter = new AtomicInteger();
 	private final AtomicInteger nextStateNameCounter = new AtomicInteger();
-
-	private final StateVertex initialState;
+	private final ConcurrentMap<Integer, StateVertex> stateById;
 
 	/**
 	 * The constructor.
@@ -48,13 +52,11 @@
 	 * @param initialState
 	 *            the state to start from.
 	 */
-	public StateFlowGraph(StateVertex initialState) {
-		Preconditions.checkNotNull(initialState);
+	public StateFlowGraph() {
 		sfg = new DirectedMultigraph<>(Eventable.class);
-		sfg.addVertex(initialState);
 		stateCounter.incrementAndGet();
-		this.initialState = initialState;
-		LOG.debug(""Initialized the stateflowgraph with an initial state"");
+		stateById = Maps.newConcurrentMap();
+		LOG.debug(""Initialized the stateflowgraph"");
 	}
 
 	/**
@@ -88,7 +90,7 @@
 	 * @param correctName
 	 *            if true the name of the state will be corrected according to the internal state
 	 *            counter.
-	 * @return the clone if one is detected null otherwise.
+	 * @return the clone if one is detected <code>null</code> otherwise.
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
 	@GuardedBy(""sfg"")
@@ -97,6 +99,7 @@
 			boolean added = sfg.addVertex(stateVertix);
 			if (added) {
 				int count = stateCounter.incrementAndGet();
+				stateById.put(stateVertix.getId(), stateVertix);
 				LOG.debug(""Number of states is now {}"", count);
 				if (correctName) {
 					correctStateName(stateVertix);
@@ -113,7 +116,7 @@
 	private void correctStateName(StateVertex stateVertix) {
 		// the -1 is for the ""index"" state.
 		int totalNumberOfStates = this.getAllStates().size() - 1;
-		String correctedName = makeStateName(totalNumberOfStates, stateVertix.isGuidedCrawling());
+		String correctedName = makeStateName(totalNumberOfStates);
 		if (!""index"".equals(stateVertix.getName())
 		        && !stateVertix.getName().equals(correctedName)) {
 			LOG.info(""Correcting state name from {}  to {}"", stateVertix.getName(), correctedName);
@@ -122,6 +125,19 @@
 	}
 
 	/**
+	 * @param id
+	 *            The ID of the state
+	 * @return The state if found or <code>null</code>.
+	 */
+	public StateVertex getById(int id) {
+		return stateById.get(id);
+	}
+
+	public StateVertex getInitialState() {
+		return stateById.get(StateVertex.FIRST_STATE_ID);
+	}
+
+	/**
 	 * Adds the specified edge to this graph, going from the source vertex to the target vertex.
 	 * More formally, adds the specified edge, e, to this graph if this graph contains no edge e2
 	 * such that e2.equals(e). If this graph already contains such an edge, the call leaves this
@@ -238,8 +254,8 @@
 	 *            the end state.
 	 * @return a list of shortest path of clickables from the state to the end
 	 */
-	public List<Eventable> getShortestPath(StateVertex start, StateVertex end) {
-		return DijkstraShortestPath.findPathBetween(sfg, start, end);
+	public ImmutableList<Eventable> getShortestPath(StateVertex start, StateVertex end) {
+		return ImmutableList.copyOf(DijkstraShortestPath.findPathBetween(sfg, start, end));
 	}
 
 	/**
@@ -372,7 +388,7 @@
 	 * @return State name the name of the state
 	 */
 	public String getNewStateName() {
-		String state = makeStateName(nextStateNameCounter.incrementAndGet(), false);
+		String state = makeStateName(nextStateNameCounter.incrementAndGet());
 		return state;
 	}
 
@@ -384,19 +400,10 @@
 	 *            the id where this name needs to be for.
 	 * @return the String containing the new name.
 	 */
-	private String makeStateName(int id, boolean guided) {
-
-		if (guided) {
-			return ""guided"" + id;
-		}
-
+	private String makeStateName(int id) {
 		return ""state"" + id;
 	}
 
-	public boolean isInitialState(StateVertex state) {
-		return initialState.equals(state);
-	}
-
 	/**
 	 * @return The number of states, currently in the graph.
 	 */
"
cf1c884c80ead3e25384a0c434f8486fd960d56a,Alex Nederlof,NewCrawler.java,MODIFY,execute -> [CrawlTask crawlTask] | [StateVertex crawlTask],"diff --git a/core/src/main/java/com/crawljax/core/NewCrawler.java b/core/src/main/java/com/crawljax/core/NewCrawler.java
index 2e5f42c..1667aaf 100644
--- a/core/src/main/java/com/crawljax/core/NewCrawler.java
+++ b/core/src/main/java/com/crawljax/core/NewCrawler.java
@@ -26,6 +26,7 @@
 import com.crawljax.core.state.CrawlPath;
 import com.crawljax.core.state.Element;
 import com.crawljax.core.state.Eventable;
+import com.crawljax.core.state.StateFlowGraph;
 import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.core.state.Identification;
 import com.crawljax.core.state.StateMachine;
@@ -106,13 +107,20 @@
 	 * @param crawlTask
 	 *            The {@link CrawlTask} this {@link NewCrawler} should execute.
 	 */
-	public void execute(CrawlTask crawlTask) {
+	public void execute(StateVertex crawlTask) {
+		LOG.debug(""Restting the crawler and going to state {}"", crawlTask.getName());
 		reset();
-		follow(CrawlPath.copyOf(crawlTask.getEventables()));
+		ImmutableList<Eventable> eventables = shortestPathTo(crawlTask);
+		follow(CrawlPath.copyOf(eventables));
 		parseCurrentPageForCandidateElements();
 		crawlThroughActions();
 	}
 
+	private ImmutableList<Eventable> shortestPathTo(StateVertex crawlTask) {
+		StateFlowGraph graph = session.get().getStateFlowGraph();
+		return graph.getShortestPath(graph.getInitialState(), crawlTask);
+	}
+
 	private void parseCurrentPageForCandidateElements() {
 		StateVertex currentState = stateMachine.getCurrentState();
 		LOG.debug(""Parsing DOM of state {} for candidate elements"", currentState.getName());
@@ -317,6 +325,7 @@
 					Thread.sleep(waitTime);
 				} catch (InterruptedException ex) {
 					LOG.info(""Crawler timed out while waiting for page to reload"");
+					Thread.currentThread().interrupt();
 				}
 			}
 		}
"
ebf29056055b4dbe40ea3e1d202a0c43f83faf0d,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index a3ffe31..4b8ae34 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -322,6 +322,7 @@
 			Thread.sleep(this.crawlWaitEvent);
 		} catch (InterruptedException e) {
 			LOGGER.error(""fireEventWait got interrupted during wait process"", e);
+			Thread.currentThread().interrupt();
 			return false;
 		}
 		return true;
"
ebf29056055b4dbe40ea3e1d202a0c43f83faf0d,Alex Nederlof,OnInvariantViolationPlugin.java,MODIFY,"onInvariantViolation -> [Invariant invariant, CrawlSession session] | [Invariant invariant, CrawlSession session, EmbeddedBrowser browser]","diff --git a/core/src/main/java/com/crawljax/core/plugin/OnInvariantViolationPlugin.java b/core/src/main/java/com/crawljax/core/plugin/OnInvariantViolationPlugin.java
index 61aa368..be45056 100644
--- a/core/src/main/java/com/crawljax/core/plugin/OnInvariantViolationPlugin.java
+++ b/core/src/main/java/com/crawljax/core/plugin/OnInvariantViolationPlugin.java
@@ -1,13 +1,12 @@
 package com.crawljax.core.plugin;
 
+import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.invariant.Invariant;
 import com.crawljax.core.CrawlSession;
 
 /**
  * Plugin type that is called every time an invariant is violated. Invariants are checked after each
  * detected state change.
- * 
- * @author dannyroest@gmail.com (Danny Roest)
  */
 public interface OnInvariantViolationPlugin extends Plugin {
 
@@ -19,7 +18,9 @@
 	 *            the failed invariant.
 	 * @param session
 	 *            the current session.
+	 * @param browser
+	 *            The current browser.
 	 */
-	void onInvariantViolation(Invariant invariant, CrawlSession session);
+	void onInvariantViolation(Invariant invariant, CrawlSession session, EmbeddedBrowser browser);
 
 }
"
ebf29056055b4dbe40ea3e1d202a0c43f83faf0d,Alex Nederlof,OnNewStatePlugin.java,MODIFY,"onNewState -> [CrawlSession session] | [CrawlSession session, StateVertex newState]","diff --git a/core/src/main/java/com/crawljax/core/plugin/OnNewStatePlugin.java b/core/src/main/java/com/crawljax/core/plugin/OnNewStatePlugin.java
index 40eea51..20b6909 100644
--- a/core/src/main/java/com/crawljax/core/plugin/OnNewStatePlugin.java
+++ b/core/src/main/java/com/crawljax/core/plugin/OnNewStatePlugin.java
@@ -1,12 +1,11 @@
 package com.crawljax.core.plugin;
 
 import com.crawljax.core.CrawlSession;
+import com.crawljax.core.state.StateVertex;
 
 /**
  * Plugin type that is called every time a new state is found by Crawljax. This also happens for the
  * Index State. Example: DOM validation.
- * 
- * @author dannyroest@gmail.com (Danny Roest)
  */
 public interface OnNewStatePlugin extends Plugin {
 
@@ -16,7 +15,9 @@
 	 * 
 	 * @param session
 	 *            the current session.
+	 * @param newState
+	 *            The new state
 	 */
-	void onNewState(CrawlSession session);
+	void onNewState(CrawlSession session, StateVertex newState);
 
 }
"
ebf29056055b4dbe40ea3e1d202a0c43f83faf0d,Alex Nederlof,Plugins.java,MODIFY,"runOnNewStatePlugins -> [CrawlSession session] | [CrawlSession session, StateVertex newState]","diff --git a/core/src/main/java/com/crawljax/core/plugin/Plugins.java b/core/src/main/java/com/crawljax/core/plugin/Plugins.java
index 75938e7..418c923 100644
--- a/core/src/main/java/com/crawljax/core/plugin/Plugins.java
+++ b/core/src/main/java/com/crawljax/core/plugin/Plugins.java
@@ -147,14 +147,16 @@
 	 * 
 	 * @param session
 	 *            the session to load in the plugin
+	 * @param newState
+	 *            The new state
 	 */
-	public void runOnNewStatePlugins(CrawlSession session) {
+	public void runOnNewStatePlugins(CrawlSession session, StateVertex newState) {
 		LOGGER.debug(""Running OnNewStatePlugins..."");
 		for (Plugin plugin : plugins.get(OnNewStatePlugin.class)) {
 			if (plugin instanceof OnNewStatePlugin) {
 				try {
 					LOGGER.debug(""Calling plugin {}"", plugin);
-					((OnNewStatePlugin) plugin).onNewState(session);
+					((OnNewStatePlugin) plugin).onNewState(session, newState);
 				} catch (RuntimeException e) {
 					reportFailingPlugin(plugin, e);
 				}
@@ -172,15 +174,19 @@
 	 *            the failed invariants
 	 * @param session
 	 *            the session to load in the plugin
+	 * @param browser
+	 * @param state
+	 *            The state containing the violations.
 	 */
-	public void runOnInvriantViolationPlugins(Invariant invariant, CrawlSession session) {
+	public void runOnInvriantViolationPlugins(Invariant invariant, CrawlSession session,
+	        EmbeddedBrowser browser) {
 		LOGGER.debug(""Running OnInvriantViolationPlugins..."");
 		for (Plugin plugin : plugins.get(OnInvariantViolationPlugin.class)) {
 			if (plugin instanceof OnInvariantViolationPlugin) {
 				try {
 					LOGGER.debug(""Calling plugin {}"", plugin);
 					((OnInvariantViolationPlugin) plugin)
-					        .onInvariantViolation(invariant, session);
+					        .onInvariantViolation(invariant, session, browser);
 				} catch (RuntimeException e) {
 					reportFailingPlugin(plugin, e);
 				}
@@ -244,16 +250,18 @@
 	 *            the crawl session.
 	 * @param candidateElements
 	 *            the elements which crawljax is about to crawl
+	 * @param state
+	 *            The state being violated.
 	 */
 	public void runPreStateCrawlingPlugins(CrawlSession session,
-	        ImmutableList<CandidateElement> candidateElements) {
+	        ImmutableList<CandidateElement> candidateElements, StateVertex state) {
 		LOGGER.debug(""Running PreStateCrawlingPlugins..."");
 		for (Plugin plugin : plugins.get(PreStateCrawlingPlugin.class)) {
 			if (plugin instanceof PreStateCrawlingPlugin) {
 				LOGGER.debug(""Calling plugin {}"", plugin);
 				try {
 					((PreStateCrawlingPlugin) plugin)
-					        .preStateCrawling(session, candidateElements);
+					        .preStateCrawling(session, candidateElements, state);
 				} catch (RuntimeException e) {
 					reportFailingPlugin(plugin, e);
 				}
"
ebf29056055b4dbe40ea3e1d202a0c43f83faf0d,Alex Nederlof,PreStateCrawlingPlugin.java,MODIFY,"preStateCrawling -> [CrawlSession session, ImmutableList candidateElements] | [CrawlSession session, ImmutableList candidateElements, StateVertex state]","diff --git a/core/src/main/java/com/crawljax/core/plugin/PreStateCrawlingPlugin.java b/core/src/main/java/com/crawljax/core/plugin/PreStateCrawlingPlugin.java
index 9fd9fbd..f35952d 100644
--- a/core/src/main/java/com/crawljax/core/plugin/PreStateCrawlingPlugin.java
+++ b/core/src/main/java/com/crawljax/core/plugin/PreStateCrawlingPlugin.java
@@ -2,6 +2,7 @@
 
 import com.crawljax.core.CandidateElement;
 import com.crawljax.core.CrawlSession;
+import com.crawljax.core.state.StateVertex;
 import com.google.common.collect.ImmutableList;
 
 /**
@@ -10,15 +11,17 @@
 public interface PreStateCrawlingPlugin extends Plugin {
 
 	/**
-	 * Method that is called before firing events on the current DOM state. Example: filter
-	 * candidate elements. Warning the session and candidateElements are not clones, changes will
-	 * result in changed behaviour.
+	 * Method that is called before firing events on the current DOM state. Warning the session and
+	 * candidateElements are not clones, changes will result in changed behavior.
 	 * 
 	 * @param session
 	 *            the current session data.
 	 * @param candidateElements
 	 *            the candidates for the current state.
+	 * @param state
+	 *            The state being crawled
 	 */
-	void preStateCrawling(CrawlSession session, ImmutableList<CandidateElement> candidateElements);
+	void preStateCrawling(CrawlSession session,
+	        ImmutableList<CandidateElement> candidateElements, StateVertex state);
 
 }
"
ebf29056055b4dbe40ea3e1d202a0c43f83faf0d,Alex Nederlof,CrawlOverview.java,MODIFY,"onNewState -> [CrawlSession session] | [CrawlSession session, StateVertex vertex]","diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java
index 84376a5..4035ece 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java
@@ -59,12 +59,11 @@
 	 * Saves a screenshot of every new state.
 	 */
 	@Override
-	public void onNewState(CrawlSession session) {
+	public void onNewState(CrawlSession session, StateVertex vertex) {
 		LOG.debug(""onNewState"");
-		StateVertex vertex = session.getCurrentState();
 		StateBuilder state = outModelCache.addStateIfAbsent(vertex);
 		saveScreenshot(session, state.getName(), vertex);
-		outputBuilder.persistDom(state.getName(), session.getBrowser().getDom());
+		outputBuilder.persistDom(state.getName(), vertex.getDom());
 		Point point = getOffSet(session.getBrowser());
 		state.setScreenShotOffset(point);
 		LOG.debug(""{} has a body offset of {}"", vertex.getName(), point);
"
9a85090646e97643f12271934b940cb50890bd8d,Alex Nederlof,UnfiredCandidateActions.java,MODIFY,"addActions -> [Collection actions, StateVertex state] | [ImmutableList extract, StateVertex currentState]","diff --git a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
index 1a851bb..e61e613 100644
--- a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
+++ b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
@@ -1,11 +1,14 @@
 package com.crawljax.core;
 
+import java.util.ArrayList;
 import java.util.Collection;
+import java.util.List;
 import java.util.Map;
 import java.util.Queue;
 import java.util.concurrent.BlockingQueue;
 import java.util.concurrent.locks.Lock;
 
+import javax.inject.Inject;
 import javax.inject.Provider;
 import javax.inject.Singleton;
 
@@ -15,6 +18,8 @@
 import com.crawljax.core.configuration.BrowserConfiguration;
 import com.crawljax.core.state.StateFlowGraph;
 import com.crawljax.core.state.StateVertex;
+import com.crawljax.core.state.Eventable.EventType;
+import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Queues;
 import com.google.common.util.concurrent.Striped;
@@ -32,6 +37,7 @@
 	private final Striped<Lock> locks;
 	private final Provider<StateFlowGraph> sfg;
 
+	@Inject
 	UnfiredCandidateActions(BrowserConfiguration config, Provider<StateFlowGraph> sfg) {
 		this.sfg = sfg;
 		cache = Maps.newHashMap();
@@ -46,6 +52,7 @@
 	 * @return The next to-be-crawled action or <code>null</code> if none available.
 	 */
 	CandidateCrawlAction pollActionOrNull(StateVertex state) {
+		LOG.debug(""Polling actino for state {}"", state.getName());
 		Lock lock = locks.get(state.getId());
 		try {
 			lock.lock();
@@ -57,9 +64,9 @@
 				if (action == null) {
 					LOG.debug(""All actions polled for state {}"", state.getName());
 					cache.remove(state.getId());
+					removeStateFromQueue(state.getId());
 					LOG.debug(""There are now {} states with unfinished actions"", cache.size());
 				}
-				removeStateFromQueue(state.getId());
 				return action;
 			}
 		} finally {
@@ -74,6 +81,20 @@
 	}
 
 	/**
+	 * @param extract
+	 *            The actions you want to add to a state.
+	 * @param currentState
+	 *            The state you are in.
+	 */
+	public void addActions(ImmutableList<CandidateElement> extract, StateVertex currentState) {
+		List<CandidateCrawlAction> actions = new ArrayList<>(extract.size());
+		for (CandidateElement candidateElement : extract) {
+			actions.add(new CandidateCrawlAction(candidateElement, EventType.click));
+		}
+		addActions(actions, currentState);
+	}
+
+	/**
 	 * @param actions
 	 *            The actions you want to add to a state.
 	 * @param state
@@ -83,13 +104,14 @@
 		Lock lock = locks.get(state.getId());
 		try {
 			lock.lock();
-			LOG.debug(""Adding crawl actions for state {}"", state.getId());
+			LOG.debug(""Adding {} crawl actions for state {}"", actions.size(), state.getId());
 			if (cache.containsKey(state.getId())) {
 				cache.get(state.getId()).addAll(actions);
 			} else {
 				cache.put(state.getId(), Queues.newConcurrentLinkedQueue(actions));
 			}
 			statesWithCandidates.add(state.getId());
+			LOG.info(""There are {} states with unfired actions"", statesWithCandidates.size());
 		} finally {
 			lock.unlock();
 		}
@@ -117,4 +139,5 @@
 		LOG.info(""There are {} states with unfired actions"", statesWithCandidates.size());
 		return sfg.get().getById(id);
 	}
+
 }
"
9a85090646e97643f12271934b940cb50890bd8d,Alex Nederlof,StateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index bdabca9..623dfc6 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -54,7 +54,6 @@
 	 */
 	public StateFlowGraph() {
 		sfg = new DirectedMultigraph<>(Eventable.class);
-		stateCounter.incrementAndGet();
 		stateById = Maps.newConcurrentMap();
 		LOG.debug(""Initialized the stateflowgraph"");
 	}
"
1bc382c84b28c98131e576d9808cc58558411d92,Alex Nederlof,StateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index 623dfc6..7620c7c 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -133,7 +133,7 @@
 	}
 
 	public StateVertex getInitialState() {
-		return stateById.get(StateVertex.FIRST_STATE_ID);
+		return stateById.get(StateVertex.INDEX_ID);
 	}
 
 	/**
@@ -386,11 +386,15 @@
 	 * 
 	 * @return State name the name of the state
 	 */
-	public String getNewStateName() {
-		String state = makeStateName(nextStateNameCounter.incrementAndGet());
+	public String getNewStateName(int id) {
+		String state = makeStateName(id);
 		return state;
 	}
 
+	public int getNextStateId() {
+		return nextStateNameCounter.incrementAndGet();
+	}
+
 	/**
 	 * Make a new state name given its id. Separated to get a central point when changing the names
 	 * of states. The automatic state names start with ""state"" and guided ones with ""guide"".
@@ -409,4 +413,5 @@
 	public int getNumberOfStates() {
 		return stateCounter.get();
 	}
+
 }
"
133756737fb60dd941c5ad4e38edb2748aae83d6,Alex Nederlof,UnfiredCandidateActions.java,MODIFY,"addActions -> [Collection actions, StateVertex state] | [ImmutableList extract, StateVertex currentState]","diff --git a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
index e61e613..9e438d1 100644
--- a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
+++ b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
@@ -52,7 +52,7 @@
 	 * @return The next to-be-crawled action or <code>null</code> if none available.
 	 */
 	CandidateCrawlAction pollActionOrNull(StateVertex state) {
-		LOG.debug(""Polling actino for state {}"", state.getName());
+		LOG.debug(""Polling action for state {}"", state.getName());
 		Lock lock = locks.get(state.getId());
 		try {
 			lock.lock();
"
38d72af3dec63f9aa3aca76a7fff67df46526996,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 4b8ae34..0e424e0 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -269,7 +269,7 @@
 			throwIfConnectionException(e);
 			return;
 		} catch (InterruptedException e) {
-			LOGGER.error(""goToUrl got interrupted while waiting for the page to be loaded"", e);
+			LOGGER.debug(""goToUrl got interrupted while waiting for the page to be loaded"", e);
 			Thread.currentThread().interrupt();
 			return;
 		}
@@ -296,9 +296,11 @@
 	 * @param eventable
 	 *            The HTML event type (onclick, onmouseover, ...).
 	 * @return true if firing event is successful.
+	 * @throws InterruptedException
+	 *             when interrupted during the wait.
 	 */
 	private boolean fireEventWait(WebElement webElement, Eventable eventable)
-	        throws ElementNotVisibleException {
+	        throws ElementNotVisibleException, InterruptedException {
 		switch (eventable.getEventType()) {
 			case click:
 				try {
@@ -318,13 +320,7 @@
 				return false;
 		}
 
-		try {
-			Thread.sleep(this.crawlWaitEvent);
-		} catch (InterruptedException e) {
-			LOGGER.error(""fireEventWait got interrupted during wait process"", e);
-			Thread.currentThread().interrupt();
-			return false;
-		}
+		Thread.sleep(this.crawlWaitEvent);
 		return true;
 	}
 
@@ -337,6 +333,7 @@
 		} catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
+		LOGGER.debug(""Browser closed..."");
 	}
 
 	@Override
@@ -432,11 +429,13 @@
 	 * @param eventable
 	 *            The eventable.
 	 * @return true if it is able to fire the event successfully on the element.
+	 * @throws InterruptedException
+	 *             when interrupted during the wait.
 	 */
 	@Override
 	public synchronized boolean fireEventAndWait(Eventable eventable)
 	        throws ElementNotVisibleException,
-	        NoSuchElementException {
+	        NoSuchElementException, InterruptedException {
 		try {
 
 			boolean handleChanged = false;
"
38d72af3dec63f9aa3aca76a7fff67df46526996,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index bea5077..22c46e2 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -85,7 +85,7 @@
 		}
 
 		/**
-		 * Set the crawl depth to unlimited.
+		 * Set the crawl depth to unlimited. The default depth is <code>2</code>.
 		 */
 		public CrawljaxConfigurationBuilder setUnlimitedCrawlDepth() {
 			config.maximumDepth = 0;
"
ab5b368ac4a524e395d0bebaa9e509b38509c874,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 22c46e2..20fb8f9 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -22,7 +22,7 @@
 /**
  * Configures the {@link Crawler}. Set it up using the {@link #builderFor(String)} function.
  */
-public final class CrawljaxConfiguration {
+public class CrawljaxConfiguration {
 
 	public static class CrawljaxConfigurationBuilder {
 
"
ab5b368ac4a524e395d0bebaa9e509b38509c874,Alex Nederlof,StateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index 7620c7c..1312ab2 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -8,6 +8,7 @@
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.atomic.AtomicInteger;
 
+import javax.inject.Inject;
 import javax.inject.Singleton;
 
 import net.jcip.annotations.GuardedBy;
@@ -21,6 +22,7 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import com.crawljax.core.ExitNotifier;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Lists;
@@ -46,13 +48,17 @@
 	private final AtomicInteger nextStateNameCounter = new AtomicInteger();
 	private final ConcurrentMap<Integer, StateVertex> stateById;
 
+	private final ExitNotifier exitNotifier;
+
 	/**
 	 * The constructor.
 	 * 
 	 * @param initialState
 	 *            the state to start from.
 	 */
-	public StateFlowGraph() {
+	@Inject
+	public StateFlowGraph(ExitNotifier exitNotifier) {
+		this.exitNotifier = exitNotifier;
 		sfg = new DirectedMultigraph<>(Eventable.class);
 		stateById = Maps.newConcurrentMap();
 		LOG.debug(""Initialized the stateflowgraph"");
@@ -97,8 +103,9 @@
 		synchronized (sfg) {
 			boolean added = sfg.addVertex(stateVertix);
 			if (added) {
-				int count = stateCounter.incrementAndGet();
 				stateById.put(stateVertix.getId(), stateVertix);
+				int count = stateCounter.incrementAndGet();
+				exitNotifier.incrementNumberOfStates();
 				LOG.debug(""Number of states is now {}"", count);
 				if (correctName) {
 					correctStateName(stateVertix);
"
b086e56e9deb4d611a413e226d72c501dcb5ea93,Alex Nederlof,UnfiredCandidateActions.java,MODIFY,"addActions -> [Collection actions, StateVertex state] | [ImmutableList extract, StateVertex currentState]","diff --git a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
index 9e438d1..695be5c 100644
--- a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
+++ b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
@@ -16,9 +16,9 @@
 import org.slf4j.LoggerFactory;
 
 import com.crawljax.core.configuration.BrowserConfiguration;
+import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.core.state.StateFlowGraph;
 import com.crawljax.core.state.StateVertex;
-import com.crawljax.core.state.Eventable.EventType;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Queues;
"
b086e56e9deb4d611a413e226d72c501dcb5ea93,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 20fb8f9..bfd9ba1 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -8,6 +8,7 @@
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 import com.crawljax.core.CrawlController;
+import com.crawljax.core.Crawler;
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
"
b086e56e9deb4d611a413e226d72c501dcb5ea93,Alex Nederlof,DomChangeNotifierPlugin.java,MODIFY,"isDomChanged -> [String domBefore, Eventable e, String domAfter, EmbeddedBrowser browser] | [CrawlerContext context, String domBefore, Eventable e, String domAfter]","diff --git a/core/src/main/java/com/crawljax/core/plugin/DomChangeNotifierPlugin.java b/core/src/main/java/com/crawljax/core/plugin/DomChangeNotifierPlugin.java
index e5a513f..e89e4dd 100644
--- a/core/src/main/java/com/crawljax/core/plugin/DomChangeNotifierPlugin.java
+++ b/core/src/main/java/com/crawljax/core/plugin/DomChangeNotifierPlugin.java
@@ -6,21 +6,25 @@
  */
 package com.crawljax.core.plugin;
 
-import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.core.CrawlerContext;
 import com.crawljax.core.state.Eventable;
 
 public interface DomChangeNotifierPlugin extends Plugin {
 
 	/**
 	 * Check to see if the (new) DOM is changed with regards to the old DOM.
+	 * <p>
+	 * This method can be called from multiple threads with different {@link CrawlerContext}
+	 * </p>
 	 * 
+	 * @param context
+	 *            The Crawler context.
 	 * @param stateBefore
 	 *            the state before the event.
 	 * @param stateAfter
 	 *            the state after the event.
 	 * @return true if the state is changed according to the compare method of the oracle.
 	 */
-	boolean isDomChanged(final String domBefore, final Eventable e, final String domAfter,
-	        EmbeddedBrowser browser);
+	boolean isDomChanged(CrawlerContext context, String domBefore, Eventable e, String domAfter);
 
 }
"
b086e56e9deb4d611a413e226d72c501dcb5ea93,Alex Nederlof,OnFireEventFailedPlugin.java,MODIFY,"onFireEventFailed -> [Eventable eventable, List pathToFailure] | [CrawlerContext context, Eventable eventable, List pathToFailure]","diff --git a/core/src/main/java/com/crawljax/core/plugin/OnFireEventFailedPlugin.java b/core/src/main/java/com/crawljax/core/plugin/OnFireEventFailedPlugin.java
index 271ec84..f2715af 100644
--- a/core/src/main/java/com/crawljax/core/plugin/OnFireEventFailedPlugin.java
+++ b/core/src/main/java/com/crawljax/core/plugin/OnFireEventFailedPlugin.java
@@ -2,23 +2,28 @@
 
 import java.util.List;
 
+import com.crawljax.core.CrawlerContext;
 import com.crawljax.core.state.Eventable;
 
 /**
  * Plugin type that is called every time event that was requested to fire failed firing.
- * 
- * @author Stefan Lenselink <S.R.Lenselink@student.tudelft.nl>
  */
 public interface OnFireEventFailedPlugin extends Plugin {
 
 	/**
 	 * Method that is called when an event that was requested to fire failed firing.
+	 * <p>
+	 * This method can be called from multiple threads with different {@link CrawlerContext}
+	 * </p>
 	 * 
+	 * @param context
+	 *            The per crawler context.
 	 * @param eventable
 	 *            the eventable that failed to execute
 	 * @param pathToFailure
 	 *            the list of eventable lead TO this failed eventable, the eventable excluded.
 	 */
-	void onFireEventFailed(Eventable eventable, List<Eventable> pathToFailure);
+	void onFireEventFailed(CrawlerContext context, Eventable eventable,
+	        List<Eventable> pathToFailure);
 
 }
"
b086e56e9deb4d611a413e226d72c501dcb5ea93,Alex Nederlof,OnInvariantViolationPlugin.java,MODIFY,"onInvariantViolation -> [Invariant invariant, CrawlSession session, EmbeddedBrowser browser] | [Invariant invariant, CrawlerContext context]","diff --git a/core/src/main/java/com/crawljax/core/plugin/OnInvariantViolationPlugin.java b/core/src/main/java/com/crawljax/core/plugin/OnInvariantViolationPlugin.java
index be45056..6213a07 100644
--- a/core/src/main/java/com/crawljax/core/plugin/OnInvariantViolationPlugin.java
+++ b/core/src/main/java/com/crawljax/core/plugin/OnInvariantViolationPlugin.java
@@ -1,8 +1,7 @@
 package com.crawljax.core.plugin;
 
-import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.invariant.Invariant;
-import com.crawljax.core.CrawlSession;
+import com.crawljax.core.CrawlerContext;
 
 /**
  * Plugin type that is called every time an invariant is violated. Invariants are checked after each
@@ -11,16 +10,16 @@
 public interface OnInvariantViolationPlugin extends Plugin {
 
 	/**
-	 * Method that is called when an invariant is violated. Warning: changing the session can change
-	 * the behavior of Crawljax. It is not a copy!
+	 * Method that is called when an invariant is violated.
+	 * <p>
+	 * This method can be called from multiple threads with different {@link CrawlerContext}
+	 * </p>
 	 * 
 	 * @param invariant
 	 *            the failed invariant.
-	 * @param session
-	 *            the current session.
-	 * @param browser
-	 *            The current browser.
+	 * @param context
+	 *            the browsers context
 	 */
-	void onInvariantViolation(Invariant invariant, CrawlSession session, EmbeddedBrowser browser);
+	void onInvariantViolation(Invariant invariant, CrawlerContext context);
 
 }
"
b086e56e9deb4d611a413e226d72c501dcb5ea93,Alex Nederlof,OnNewStatePlugin.java,MODIFY,"onNewState -> [CrawlSession session, StateVertex newState] | [CrawlerContext context, StateVertex newState]","diff --git a/core/src/main/java/com/crawljax/core/plugin/OnNewStatePlugin.java b/core/src/main/java/com/crawljax/core/plugin/OnNewStatePlugin.java
index 20b6909..aef173a 100644
--- a/core/src/main/java/com/crawljax/core/plugin/OnNewStatePlugin.java
+++ b/core/src/main/java/com/crawljax/core/plugin/OnNewStatePlugin.java
@@ -1,6 +1,6 @@
 package com.crawljax.core.plugin;
 
-import com.crawljax.core.CrawlSession;
+import com.crawljax.core.CrawlerContext;
 import com.crawljax.core.state.StateVertex;
 
 /**
@@ -11,13 +11,16 @@
 
 	/**
 	 * Method that is called when a new state is found. Warning: changing the session can change the
-	 * behavior of Crawljax. It is not a copy!
+	 * behavior of Crawljax. It is not a copy! *
+	 * <p>
+	 * This method can be called from multiple threads with different {@link CrawlerContext}
+	 * </p>
 	 * 
-	 * @param session
-	 *            the current session.
+	 * @param context
+	 *            the current context.
 	 * @param newState
 	 *            The new state
 	 */
-	void onNewState(CrawlSession session, StateVertex newState);
+	void onNewState(CrawlerContext context, StateVertex newState);
 
 }
"
b086e56e9deb4d611a413e226d72c501dcb5ea93,Alex Nederlof,OnRevisitStatePlugin.java,MODIFY,"onRevisitState -> [CrawlSession session, StateVertex currentState] | [CrawlerContext context, StateVertex currentState]","diff --git a/core/src/main/java/com/crawljax/core/plugin/OnRevisitStatePlugin.java b/core/src/main/java/com/crawljax/core/plugin/OnRevisitStatePlugin.java
index c0b95f2..04da085 100644
--- a/core/src/main/java/com/crawljax/core/plugin/OnRevisitStatePlugin.java
+++ b/core/src/main/java/com/crawljax/core/plugin/OnRevisitStatePlugin.java
@@ -1,26 +1,27 @@
 package com.crawljax.core.plugin;
 
-import com.crawljax.core.CrawlSession;
+import com.crawljax.core.CrawlerContext;
 import com.crawljax.core.state.StateVertex;
 
 /**
  * Plugin type that is called every time a state is revisited by Crawljax. Example: Benchmarking.
  * This plugin needs an explicit current state because the session.getCurrentState() does not
  * contain the correct current state since we are in back-tracking phase.
- * 
- * @author Stefan Lenselink <S.R.Lenselink@student.tudelft.nl>
  */
 public interface OnRevisitStatePlugin extends Plugin {
 
 	/**
 	 * Method that is called every time a state is revisited by Crawljax. Warning: changing the
 	 * state can influence crawljax, it is not a copy.
+	 * <p>
+	 * This method can be called from multiple threads with different {@link CrawlerContext}
+	 * </p>
 	 * 
-	 * @param session
+	 * @param context
 	 *            the crawlSession
 	 * @param currentState
 	 *            the state revisited
 	 */
-	void onRevisitState(CrawlSession session, StateVertex currentState);
+	void onRevisitState(CrawlerContext context, StateVertex currentState);
 
 }
"
b086e56e9deb4d611a413e226d72c501dcb5ea93,Alex Nederlof,OnUrlLoadPlugin.java,MODIFY,onUrlLoad -> [EmbeddedBrowser browser] | [CrawlerContext context],"diff --git a/core/src/main/java/com/crawljax/core/plugin/OnUrlLoadPlugin.java b/core/src/main/java/com/crawljax/core/plugin/OnUrlLoadPlugin.java
index 1bad416..74200a2 100644
--- a/core/src/main/java/com/crawljax/core/plugin/OnUrlLoadPlugin.java
+++ b/core/src/main/java/com/crawljax/core/plugin/OnUrlLoadPlugin.java
@@ -1,23 +1,24 @@
 package com.crawljax.core.plugin;
 
-import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.core.CrawlerContext;
 
 /**
  * Plugin type that is called after the initial URL is (re)loaded. Example: refreshing the page
  * (clear the browser cache). The OnURLloadPlugins are run just after the Browser has gone to the
  * initial URL. Not only the first time but also every time the Core navigates back (back-tracking).
- * 
- * @author dannyroest@gmail.com (Danny Roest)
  */
 public interface OnUrlLoadPlugin extends Plugin {
 
 	/**
 	 * Method that is called after the url is (re) loaded. Warning: changing the browser can change
 	 * the behaviour of Crawljax. It is not a copy!
+	 * <p>
+	 * This method can be called from multiple threads with different {@link CrawlerContext}
+	 * </p>
 	 * 
-	 * @param browser
-	 *            the current browser instance
+	 * @param context
+	 *            the current crawler context.
 	 */
-	void onUrlLoad(EmbeddedBrowser browser);
+	void onUrlLoad(CrawlerContext context);
 
 }
\ No newline at end of file
"
b086e56e9deb4d611a413e226d72c501dcb5ea93,Alex Nederlof,Plugins.java,MODIFY,runOnUrlLoadPlugins -> [EmbeddedBrowser browser] | [CrawlerContext context],"diff --git a/core/src/main/java/com/crawljax/core/plugin/Plugins.java b/core/src/main/java/com/crawljax/core/plugin/Plugins.java
index 418c923..9c674e0 100644
--- a/core/src/main/java/com/crawljax/core/plugin/Plugins.java
+++ b/core/src/main/java/com/crawljax/core/plugin/Plugins.java
@@ -12,6 +12,7 @@
 import com.crawljax.condition.invariant.Invariant;
 import com.crawljax.core.CandidateElement;
 import com.crawljax.core.CrawlSession;
+import com.crawljax.core.CrawlerContext;
 import com.crawljax.core.configuration.ProxyConfiguration;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateVertex;
@@ -38,7 +39,7 @@
 	                OnInvariantViolationPlugin.class, OnNewStatePlugin.class,
 	                OnRevisitStatePlugin.class, OnUrlLoadPlugin.class,
 	                PostCrawlingPlugin.class, PreStateCrawlingPlugin.class,
-	                PreCrawlingPlugin.class, ProxyServerPlugin.class);
+	                ProxyServerPlugin.class);
 
 	/**
 	 * @return An empty {@link Plugins} configuration.
@@ -87,32 +88,6 @@
 		}
 	}
 
-	/**
-	 * load and run the PreCrawlingPlugins. PreCrawlingPlugins are plugins that are ran before the
-	 * crawling starts and before the initial url has been loaded. This kind of plugins can be used
-	 * to do for example 'once in a crawlsession' operations like logging in or reset the database
-	 * to a 'clean' state. The argument offered to the Plugin is a the current running instance of
-	 * EmbeddedBrowser. Warning the instance of the browser offered is not a clone but the current
-	 * and after wards used browser instance, changes and operations may cause 'strange' behaviour.
-	 * 
-	 * @see EmbeddedBrowser
-	 * @param browser
-	 *            the browser instance to load to the plugin.
-	 */
-	public void runPreCrawlingPlugins(EmbeddedBrowser browser) {
-		LOGGER.debug(""Running PreCrawlingPlugins..."");
-		for (Plugin plugin : plugins.get(PreCrawlingPlugin.class)) {
-			if (plugin instanceof PreCrawlingPlugin) {
-				try {
-					LOGGER.debug(""Calling plugin {}"", plugin);
-					((PreCrawlingPlugin) plugin).preCrawling(browser);
-				} catch (RuntimeException e) {
-					reportFailingPlugin(plugin, e);
-				}
-			}
-		}
-	}
-
 	private void reportFailingPlugin(Plugin plugin, RuntimeException e) {
 		LOGGER.error(""Plugin {} errored while running. {}"", plugin, e.getMessage(), e);
 	}
@@ -122,17 +97,20 @@
 	 * gone to the initial url. Not only the first time but also every time the Core navigates back.
 	 * Warning the instance of the browser offered is not a clone but the current and after wards
 	 * used browser instance, changes and operations may cause 'strange' behaviour.
+	 * <p>
+	 * This method can be called from multiple threads with different {@link CrawlerContext}
+	 * </p>
 	 * 
 	 * @param browser
 	 *            the embedded browser instance to load in the plugin.
 	 */
-	public void runOnUrlLoadPlugins(EmbeddedBrowser browser) {
+	public void runOnUrlLoadPlugins(CrawlerContext context) {
 		LOGGER.debug(""Running OnUrlLoadPlugins..."");
 		for (Plugin plugin : plugins.get(OnUrlLoadPlugin.class)) {
 			if (plugin instanceof OnUrlLoadPlugin) {
 				try {
 					LOGGER.debug(""Calling plugin {}"", plugin);
-					((OnUrlLoadPlugin) plugin).onUrlLoad(browser);
+					((OnUrlLoadPlugin) plugin).onUrlLoad(context);
 				} catch (RuntimeException e) {
 					reportFailingPlugin(plugin, e);
 				}
@@ -144,19 +122,22 @@
 	 * load and run the OnNewStatePlugins. OnNewStatePlugins are plugins that are ran when a new
 	 * state was found. This also happens for the Index State. Warning the session is not a clone,
 	 * chaning the session can cause strange behaviour of Crawljax.
+	 * <p>
+	 * This method can be called from multiple threads with different {@link CrawlerContext}
+	 * </p>
 	 * 
 	 * @param session
 	 *            the session to load in the plugin
 	 * @param newState
 	 *            The new state
 	 */
-	public void runOnNewStatePlugins(CrawlSession session, StateVertex newState) {
+	public void runOnNewStatePlugins(CrawlerContext context, StateVertex newState) {
 		LOGGER.debug(""Running OnNewStatePlugins..."");
 		for (Plugin plugin : plugins.get(OnNewStatePlugin.class)) {
 			if (plugin instanceof OnNewStatePlugin) {
 				try {
 					LOGGER.debug(""Calling plugin {}"", plugin);
-					((OnNewStatePlugin) plugin).onNewState(session, newState);
+					((OnNewStatePlugin) plugin).onNewState(context, newState);
 				} catch (RuntimeException e) {
 					reportFailingPlugin(plugin, e);
 				}
@@ -172,21 +153,17 @@
 	 * 
 	 * @param invariant
 	 *            the failed invariants
-	 * @param session
+	 * @param context
 	 *            the session to load in the plugin
-	 * @param browser
-	 * @param state
-	 *            The state containing the violations.
 	 */
-	public void runOnInvriantViolationPlugins(Invariant invariant, CrawlSession session,
-	        EmbeddedBrowser browser) {
+	public void runOnInvriantViolationPlugins(Invariant invariant, CrawlerContext context) {
 		LOGGER.debug(""Running OnInvriantViolationPlugins..."");
 		for (Plugin plugin : plugins.get(OnInvariantViolationPlugin.class)) {
 			if (plugin instanceof OnInvariantViolationPlugin) {
 				try {
 					LOGGER.debug(""Calling plugin {}"", plugin);
 					((OnInvariantViolationPlugin) plugin)
-					        .onInvariantViolation(invariant, session, browser);
+					        .onInvariantViolation(invariant, context);
 				} catch (RuntimeException e) {
 					reportFailingPlugin(plugin, e);
 				}
@@ -199,7 +176,7 @@
 	 * finished Warning: changing the session can change the behavior of other post crawl plugins.
 	 * It is not a clone!
 	 * 
-	 * @param session
+	 * @param context
 	 *            the session to load in the plugin
 	 */
 	public void runPostCrawlingPlugins(CrawlSession session) {
@@ -221,18 +198,18 @@
 	 * needs an explicit current state because the session.getCurrentState() does not contain the
 	 * correct current state because we are in back-tracking
 	 * 
-	 * @param session
+	 * @param context
 	 *            the session to load in the plugin
 	 * @param currentState
 	 *            the state the 'back tracking' operation is currently in
 	 */
-	public void runOnRevisitStatePlugins(CrawlSession session, StateVertex currentState) {
+	public void runOnRevisitStatePlugins(CrawlerContext context, StateVertex currentState) {
 		LOGGER.debug(""Running OnRevisitStatePlugins..."");
 		for (Plugin plugin : plugins.get(OnRevisitStatePlugin.class)) {
 			if (plugin instanceof OnRevisitStatePlugin) {
 				LOGGER.debug(""Calling plugin {}"", plugin);
 				try {
-					((OnRevisitStatePlugin) plugin).onRevisitState(session, currentState);
+					((OnRevisitStatePlugin) plugin).onRevisitState(context, currentState);
 				} catch (RuntimeException e) {
 					reportFailingPlugin(plugin, e);
 				}
@@ -253,7 +230,7 @@
 	 * @param state
 	 *            The state being violated.
 	 */
-	public void runPreStateCrawlingPlugins(CrawlSession session,
+	public void runPreStateCrawlingPlugins(CrawlerContext context,
 	        ImmutableList<CandidateElement> candidateElements, StateVertex state) {
 		LOGGER.debug(""Running PreStateCrawlingPlugins..."");
 		for (Plugin plugin : plugins.get(PreStateCrawlingPlugin.class)) {
@@ -261,7 +238,7 @@
 				LOGGER.debug(""Calling plugin {}"", plugin);
 				try {
 					((PreStateCrawlingPlugin) plugin)
-					        .preStateCrawling(session, candidateElements, state);
+					        .preStateCrawling(context, candidateElements, state);
 				} catch (RuntimeException e) {
 					reportFailingPlugin(plugin, e);
 				}
@@ -301,13 +278,15 @@
 	 * @param path
 	 *            the path TO this eventable.
 	 */
-	public void runOnFireEventFailedPlugins(Eventable eventable, List<Eventable> path) {
+	public void runOnFireEventFailedPlugins(CrawlerContext context, Eventable eventable,
+	        List<Eventable> path) {
 		LOGGER.debug(""Running OnFireEventFailedPlugins..."");
 		for (Plugin plugin : plugins.get(OnFireEventFailedPlugin.class)) {
 			if (plugin instanceof OnFireEventFailedPlugin) {
 				LOGGER.debug(""Calling plugin {}"", plugin);
 				try {
-					((OnFireEventFailedPlugin) plugin).onFireEventFailed(eventable, path);
+					((OnFireEventFailedPlugin) plugin)
+					        .onFireEventFailed(context, eventable, path);
 				} catch (RuntimeException e) {
 					reportFailingPlugin(plugin, e);
 				}
@@ -341,9 +320,10 @@
 	/**
 	 * Load and run the DomChangeNotifierPlugin.
 	 */
-	public boolean runDomChangeNotifierPlugins(final StateVertex stateBefore,
+	public boolean runDomChangeNotifierPlugins(final CrawlerContext context,
+	        final StateVertex stateBefore,
 	        final Eventable event,
-	        final StateVertex stateAfter, final EmbeddedBrowser browser) {
+	        final StateVertex stateAfter) {
 		if (plugins.get(DomChangeNotifierPlugin.class).isEmpty()) {
 			LOGGER.debug(""No DomChangeNotifierPlugin found. Performing default DOM comparison..."");
 			return defaultDomComparison(stateBefore, stateAfter);
@@ -352,8 +332,8 @@
 			        (DomChangeNotifierPlugin) plugins.get(DomChangeNotifierPlugin.class).get(0);
 			LOGGER.debug(""Calling plugin {}"", domChange);
 			try {
-				return domChange.isDomChanged(stateBefore.getDom(), event, stateAfter.getDom(),
-				        browser);
+				return domChange.isDomChanged(context, stateBefore.getDom(), event,
+				        stateAfter.getDom());
 			} catch (RuntimeException ex) {
 				LOGGER.error(
 				        ""Could not run {} because of error {}. Now running default DOM comparison"",
"
b086e56e9deb4d611a413e226d72c501dcb5ea93,Alex Nederlof,PreStateCrawlingPlugin.java,MODIFY,"preStateCrawling -> [CrawlSession session, ImmutableList candidateElements, StateVertex state] | [CrawlerContext context, ImmutableList candidateElements, StateVertex state]","diff --git a/core/src/main/java/com/crawljax/core/plugin/PreStateCrawlingPlugin.java b/core/src/main/java/com/crawljax/core/plugin/PreStateCrawlingPlugin.java
index f35952d..ad45366 100644
--- a/core/src/main/java/com/crawljax/core/plugin/PreStateCrawlingPlugin.java
+++ b/core/src/main/java/com/crawljax/core/plugin/PreStateCrawlingPlugin.java
@@ -1,7 +1,7 @@
 package com.crawljax.core.plugin;
 
 import com.crawljax.core.CandidateElement;
-import com.crawljax.core.CrawlSession;
+import com.crawljax.core.CrawlerContext;
 import com.crawljax.core.state.StateVertex;
 import com.google.common.collect.ImmutableList;
 
@@ -13,15 +13,18 @@
 	/**
 	 * Method that is called before firing events on the current DOM state. Warning the session and
 	 * candidateElements are not clones, changes will result in changed behavior.
+	 * <p>
+	 * This method can be called from multiple threads with different {@link CrawlerContext}
+	 * </p>
 	 * 
-	 * @param session
+	 * @param context
 	 *            the current session data.
 	 * @param candidateElements
 	 *            the candidates for the current state.
 	 * @param state
 	 *            The state being crawled
 	 */
-	void preStateCrawling(CrawlSession session,
+	void preStateCrawling(CrawlerContext context,
 	        ImmutableList<CandidateElement> candidateElements, StateVertex state);
 
 }
"
b086e56e9deb4d611a413e226d72c501dcb5ea93,Alex Nederlof,StateMachine.java,MODIFY,"swithToStateAndCheckIfClone -> [Eventable event, StateVertex newState, EmbeddedBrowser browser, CrawlSession session] | [Eventable event, StateVertex newState, CrawlerContext context]","diff --git a/core/src/main/java/com/crawljax/core/state/StateMachine.java b/core/src/main/java/com/crawljax/core/state/StateMachine.java
index ad468fb..4b91534 100644
--- a/core/src/main/java/com/crawljax/core/state/StateMachine.java
+++ b/core/src/main/java/com/crawljax/core/state/StateMachine.java
@@ -6,7 +6,7 @@
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.ConditionTypeChecker;
 import com.crawljax.condition.invariant.Invariant;
-import com.crawljax.core.CrawlSession;
+import com.crawljax.core.CrawlerContext;
 import com.crawljax.core.plugin.Plugins;
 import com.crawljax.oraclecomparator.StateComparator;
 import com.google.common.collect.ImmutableList;
@@ -144,7 +144,7 @@
 	}
 
 	/**
-	 * Adds an edge between teh current and new state.
+	 * Adds an edge between the current and new state.
 	 * 
 	 * @param event
 	 *            the event edge.
@@ -157,15 +157,14 @@
 	 * @return true if the new state is not found in the state machine.
 	 */
 	public boolean swithToStateAndCheckIfClone(final Eventable event, StateVertex newState,
-	        EmbeddedBrowser browser,
-	        CrawlSession session) {
+	        CrawlerContext context) {
 		StateVertex cloneState = this.addStateToCurrentState(newState, event);
 
-		runOnInvriantViolationPlugins(browser, session);
+		runOnInvriantViolationPlugins(context);
 
 		if (cloneState == null) {
 			this.changeState(newState);
-			plugins.runOnNewStatePlugins(session, newState);
+			plugins.runOnNewStatePlugins(context, newState);
 			return true;
 		} else {
 			this.changeState(cloneState);
@@ -173,9 +172,10 @@
 		}
 	}
 
-	private void runOnInvriantViolationPlugins(EmbeddedBrowser browser, CrawlSession session) {
-		for (Invariant failedInvariant : invariantChecker.getFailedConditions(browser)) {
-			plugins.runOnInvriantViolationPlugins(failedInvariant, session, browser);
+	private void runOnInvriantViolationPlugins(CrawlerContext context) {
+		for (Invariant failedInvariant : invariantChecker.getFailedConditions(context
+		        .getBrowser())) {
+			plugins.runOnInvriantViolationPlugins(failedInvariant, context);
 		}
 	}
 }
"
b086e56e9deb4d611a413e226d72c501dcb5ea93,Alex Nederlof,CrawlOverview.java,MODIFY,"onNewState -> [CrawlSession session, StateVertex vertex] | [CrawlerContext context, StateVertex vertex]","diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java
index 4035ece..df60b88 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java
@@ -14,6 +14,7 @@
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.core.CandidateElement;
 import com.crawljax.core.CrawlSession;
+import com.crawljax.core.CrawlerContext;
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.plugin.OnNewStatePlugin;
 import com.crawljax.core.plugin.PostCrawlingPlugin;
@@ -26,6 +27,7 @@
 import com.crawljax.plugins.crawloverview.model.OutPutModel;
 import com.crawljax.plugins.crawloverview.model.State;
 import com.google.common.base.Preconditions;
+import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
 
@@ -59,12 +61,12 @@
 	 * Saves a screenshot of every new state.
 	 */
 	@Override
-	public void onNewState(CrawlSession session, StateVertex vertex) {
+	public void onNewState(CrawlerContext context, StateVertex vertex) {
 		LOG.debug(""onNewState"");
 		StateBuilder state = outModelCache.addStateIfAbsent(vertex);
-		saveScreenshot(session, state.getName(), vertex);
+		saveScreenshot(context.getBrowser(), state.getName(), vertex);
 		outputBuilder.persistDom(state.getName(), vertex.getDom());
-		Point point = getOffSet(session.getBrowser());
+		Point point = getOffSet(context.getBrowser());
 		state.setScreenShotOffset(point);
 		LOG.debug(""{} has a body offset of {}"", vertex.getName(), point);
 	}
@@ -94,7 +96,7 @@
 		return ""relative"".equals(position);
 	}
 
-	private void saveScreenshot(CrawlSession session, String name, StateVertex vertex) {
+	private void saveScreenshot(EmbeddedBrowser browser, String name, StateVertex vertex) {
 		LOG.trace(""Saving screenshot"");
 		synchronized (visitedStates) {
 			if (!visitedStates.containsKey(name)) {
@@ -105,10 +107,10 @@
 		File jpg = outputBuilder.newScreenShotFile(name);
 		File thumb = outputBuilder.newThumbNail(name);
 		try {
-			byte[] screenshot = session.getBrowser().getScreenShot();
+			byte[] screenshot = browser.getScreenShot();
 			ImageWriter.writeScreenShotAndThumbnail(screenshot, jpg, thumb);
 		} catch (CrawljaxException e) {
-			LOG.warn(""Screenshots are not supported for {}"", session.getBrowser());
+			LOG.warn(""Screenshots are not supported for {}"", browser);
 		}
 		LOG.trace(""Screenshot saved"");
 	}
@@ -118,29 +120,29 @@
 	 * elements.
 	 */
 	@Override
-	public void preStateCrawling(CrawlSession session, List<CandidateElement> candidateElements) {
+	public void preStateCrawling(CrawlerContext context,
+	        ImmutableList<CandidateElement> candidateElements, StateVertex state) {
 		LOG.debug(""preStateCrawling"");
 		List<CandidateElementPosition> newElements = Lists.newLinkedList();
-		StateVertex state = session.getCurrentState();
 		LOG.info(""Prestate found new state {} with {} candidates"", state.getName(),
 		        candidateElements.size());
 		for (CandidateElement element : candidateElements) {
-			WebElement webElement = getWebElement(session, element);
+			WebElement webElement = getWebElement(context.getBrowser(), element);
 			if (webElement != null) {
 				newElements.add(findElement(webElement, element));
 			}
 		}
 
-		StateBuilder stateOut = outModelCache.addStateIfAbsent(session.getCurrentState());
+		StateBuilder stateOut = outModelCache.addStateIfAbsent(state);
 		stateOut.addCandidates(newElements);
 		LOG.trace(""preState finished, elements added to state"");
 	}
 
-	private WebElement getWebElement(CrawlSession session, CandidateElement element) {
+	private WebElement getWebElement(EmbeddedBrowser browser, CandidateElement element) {
 		try {
 			// TODO Check if element.getIdentification().getValue() is correct replacement for
 			// element.getXpath()
-			return session.getBrowser().getWebElement(element.getIdentification());
+			return browser.getWebElement(element.getIdentification());
 		} catch (WebDriverException e) {
 			LOG.info(""Could not locate element for positioning {}"", element.getElement());
 			return null;
"
b1f94d9feeea2c6399e171788bac95f9f0130c19,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 0e424e0..399759d 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -331,6 +331,11 @@
 			// close browser and close every associated window.
 			browser.quit();
 		} catch (WebDriverException e) {
+			if (e.getCause() instanceof InterruptedException) {
+				LOGGER.info(""Interrupted while waiting for the browser to close. It might not close correctly"");
+				Thread.currentThread().interrupt();
+				return;
+			}
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
 		LOGGER.debug(""Browser closed..."");
"
d65b9c40466dc053ec1a51a9f54bb75eb8182e07,Alex Nederlof,AbstractComparator.java,MODIFY,"getDifferences -> [] | [String oldDom, String newDom]","diff --git a/core/src/main/java/com/crawljax/oraclecomparator/AbstractComparator.java b/core/src/main/java/com/crawljax/oraclecomparator/AbstractComparator.java
index 6c36d8f..b37e7fc 100644
--- a/core/src/main/java/com/crawljax/oraclecomparator/AbstractComparator.java
+++ b/core/src/main/java/com/crawljax/oraclecomparator/AbstractComparator.java
@@ -11,93 +11,34 @@
 /**
  * The Abstract base class of all the Comparators. All comparators are not Thread safe as
  * comparators are shared between Threads and the origionalDom and newDom can not be final.
- * 
- * @author Danny
  */
 @NotThreadSafe
 public abstract class AbstractComparator implements Comparator {
 
-	private String originalDom;
-	private String newDom;
-
-	/**
-	 * Constructor.
-	 */
-	public AbstractComparator() {
-
+	@Override
+	public List<Difference> getDifferences(String oldDom, String newDom) {
+		return DomUtils.getDifferences(normalize(oldDom), normalize(newDom));
 	}
 
-	/**
-	 * @param originalDom
-	 *            The original DOM.
-	 * @param newDom
-	 *            The new DOM.
-	 */
-	public AbstractComparator(String originalDom, String newDom) {
-		this.originalDom = originalDom;
-		this.newDom = newDom;
-	}
-
-	/**
-	 * @return If the original DOM and the new DOM are equal. Note: Via
-	 *         OracleControllerConfiguration ignore case can be set
-	 */
-	protected boolean compare() {
+	@Override
+	public boolean isEquivalent(String oldDom, String newDom) {
 		boolean equivalent = false;
 		if (StateComparator.COMPARE_IGNORE_CASE) {
-			equivalent = getOriginalDom().equalsIgnoreCase(getNewDom());
+			equivalent = normalize(oldDom).equalsIgnoreCase(normalize(newDom));
 		} else {
-			equivalent = getOriginalDom().equals(getNewDom());
+			equivalent = normalize(oldDom).equals(normalize(newDom));
 		}
 		return equivalent;
 	}
 
 	/**
-	 * @return Whether they are equivalent.
+	 * Override this method to apply normalization to the comparison.
+	 * 
+	 * @param dom
+	 *            The original DOM
+	 * @return the normalized DOM.
 	 */
-	@Override
-	public abstract boolean isEquivalent();
-
-	/**
-	 * @return Differences between the DOMs.
-	 */
-	@Override
-	public List<Difference> getDifferences() {
-		return DomUtils.getDifferences(getOriginalDom(), getNewDom());
+	protected String normalize(String dom) {
+		return dom;
 	}
-
-	/**
-	 * @return The original DOM.
-	 */
-	@Override
-	public String getOriginalDom() {
-		return originalDom;
-	}
-
-	/**
-	 * @param originalDom
-	 *            The new original DOM.
-	 */
-	@Override
-	public void setOriginalDom(String originalDom) {
-		this.originalDom = originalDom;
-	}
-
-	/**
-	 * @return The new DOM.
-	 */
-	@Override
-	public String getNewDom() {
-		return newDom;
-	}
-
-	/**
-	 * @param newDom
-	 *            The new DOM.
-	 */
-	@Override
-	public void setNewDom(String newDom) {
-		this.newDom = newDom;
-	}
-
 }
"
d65b9c40466dc053ec1a51a9f54bb75eb8182e07,Alex Nederlof,EditDistanceComparator.java,MODIFY,"isEquivalent -> [] | [String oldDom, String newDom]","diff --git a/core/src/main/java/com/crawljax/oraclecomparator/comparators/EditDistanceComparator.java b/core/src/main/java/com/crawljax/oraclecomparator/comparators/EditDistanceComparator.java
index 7be8bfa..80280f8 100644
--- a/core/src/main/java/com/crawljax/oraclecomparator/comparators/EditDistanceComparator.java
+++ b/core/src/main/java/com/crawljax/oraclecomparator/comparators/EditDistanceComparator.java
@@ -7,8 +7,6 @@
 /**
  * Oracle Comparator that uses the Levenshtein Edit Distance to determince wheter two states are
  * equivalent.
- * 
- * @author dannyroest@gmail.com (Danny Roest)
  */
 public class EditDistanceComparator extends AbstractComparator {
 
@@ -33,8 +31,8 @@
 	 * @return true if and only if the edit distance threshold is >= the specified treshold
 	 */
 	@Override
-	public boolean isEquivalent() {
-		return isClone(getOriginalDom(), getNewDom(), getTreshold());
+	public boolean isEquivalent(String oldDom, String newDom) {
+		return isClone(oldDom, newDom, getTreshold());
 	}
 
 	/**
"
d65b9c40466dc053ec1a51a9f54bb75eb8182e07,Alex Nederlof,ScriptComparator.java,MODIFY,"isEquivalent -> [] | [String oldDom, String newDom]","diff --git a/core/src/main/java/com/crawljax/oraclecomparator/comparators/ScriptComparator.java b/core/src/main/java/com/crawljax/oraclecomparator/comparators/ScriptComparator.java
index cbc7b47..7243262 100644
--- a/core/src/main/java/com/crawljax/oraclecomparator/comparators/ScriptComparator.java
+++ b/core/src/main/java/com/crawljax/oraclecomparator/comparators/ScriptComparator.java
@@ -18,36 +18,20 @@
 	private static final Logger LOGGER = LoggerFactory.getLogger(AbstractComparator.class
 	        .getName());
 
-	/**
-	 * Default argument less constructor.
-	 */
-	public ScriptComparator() {
-	}
-
-	/**
-	 * @param originalDom
-	 *            The original DOM.
-	 * @param newDom
-	 *            The new DOM.
-	 */
-	public ScriptComparator(String originalDom, String newDom) {
-		super(originalDom, newDom);
-	}
-
 	@Override
-	public boolean isEquivalent() {
+	public boolean isEquivalent(String oldDom, String newDom) {
 		try {
-			Document orgDoc = DomUtils.asDocument(getOriginalDom());
+			Document orgDoc = DomUtils.asDocument(oldDom);
 			orgDoc = DomUtils.removeScriptTags(orgDoc);
-			setOriginalDom(DomUtils.getDocumentToString(orgDoc));
+			String normalizedOld = DomUtils.getDocumentToString(orgDoc);
 
-			Document newDoc = DomUtils.asDocument(getNewDom());
+			Document newDoc = DomUtils.asDocument(newDom);
 			newDoc = DomUtils.removeScriptTags(newDoc);
-			setNewDom(DomUtils.getDocumentToString(newDoc));
+			String normalizedNew = DomUtils.getDocumentToString(newDoc);
+			return super.compare(normalizedOld, normalizedNew);
 		} catch (IOException | CrawljaxException e) {
 			LOGGER.error(""Exception with creating DOM document"", e);
 			return false;
 		}
-		return super.compare();
 	}
 }
"
bda6e186947f5dcf7894057ee2c6b12aa394b3b4,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index b680e39..399759d 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -269,7 +269,8 @@
 			throwIfConnectionException(e);
 			return;
 		} catch (InterruptedException e) {
-			LOGGER.error(""goToUrl got interrupted while waiting for the page to be loaded"", e);
+			LOGGER.debug(""goToUrl got interrupted while waiting for the page to be loaded"", e);
+			Thread.currentThread().interrupt();
 			return;
 		}
 	}
@@ -295,9 +296,11 @@
 	 * @param eventable
 	 *            The HTML event type (onclick, onmouseover, ...).
 	 * @return true if firing event is successful.
+	 * @throws InterruptedException
+	 *             when interrupted during the wait.
 	 */
-	protected boolean fireEventWait(WebElement webElement, Eventable eventable)
-	        throws ElementNotVisibleException {
+	private boolean fireEventWait(WebElement webElement, Eventable eventable)
+	        throws ElementNotVisibleException, InterruptedException {
 		switch (eventable.getEventType()) {
 			case click:
 				try {
@@ -317,12 +320,7 @@
 				return false;
 		}
 
-		try {
-			Thread.sleep(this.crawlWaitEvent);
-		} catch (InterruptedException e) {
-			LOGGER.error(""fireEventWait got interrupted during wait process"", e);
-			return false;
-		}
+		Thread.sleep(this.crawlWaitEvent);
 		return true;
 	}
 
@@ -333,8 +331,14 @@
 			// close browser and close every associated window.
 			browser.quit();
 		} catch (WebDriverException e) {
+			if (e.getCause() instanceof InterruptedException) {
+				LOGGER.info(""Interrupted while waiting for the browser to close. It might not close correctly"");
+				Thread.currentThread().interrupt();
+				return;
+			}
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
+		LOGGER.debug(""Browser closed..."");
 	}
 
 	@Override
@@ -430,10 +434,13 @@
 	 * @param eventable
 	 *            The eventable.
 	 * @return true if it is able to fire the event successfully on the element.
+	 * @throws InterruptedException
+	 *             when interrupted during the wait.
 	 */
 	@Override
-	public synchronized boolean fireEvent(Eventable eventable) throws ElementNotVisibleException,
-	        NoSuchElementException {
+	public synchronized boolean fireEventAndWait(Eventable eventable)
+	        throws ElementNotVisibleException,
+	        NoSuchElementException, InterruptedException {
 		try {
 
 			boolean handleChanged = false;
"
bda6e186947f5dcf7894057ee2c6b12aa394b3b4,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 115ce55..bfd9ba1 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -23,7 +23,7 @@
 /**
  * Configures the {@link Crawler}. Set it up using the {@link #builderFor(String)} function.
  */
-public final class CrawljaxConfiguration {
+public class CrawljaxConfiguration {
 
 	public static class CrawljaxConfigurationBuilder {
 
@@ -86,7 +86,7 @@
 		}
 
 		/**
-		 * Set the crawl depth to unlimited.
+		 * Set the crawl depth to unlimited. The default depth is <code>2</code>.
 		 */
 		public CrawljaxConfigurationBuilder setUnlimitedCrawlDepth() {
 			config.maximumDepth = 0;
"
bda6e186947f5dcf7894057ee2c6b12aa394b3b4,Alex Nederlof,CrawlPath.java,MODIFY,immutableCopy -> [boolean removeLast] | [],"diff --git a/core/src/main/java/com/crawljax/core/state/CrawlPath.java b/core/src/main/java/com/crawljax/core/state/CrawlPath.java
index 8aaf8dd..af8ad19 100644
--- a/core/src/main/java/com/crawljax/core/state/CrawlPath.java
+++ b/core/src/main/java/com/crawljax/core/state/CrawlPath.java
@@ -13,6 +13,10 @@
 
 	private final List<Eventable> eventablePath;
 
+	public static CrawlPath copyOf(List<Eventable> eventable) {
+		return new CrawlPath(Lists.newLinkedList(eventable));
+	}
+
 	/**
 	 * Start a new empty CrawlPath.
 	 */
@@ -55,7 +59,15 @@
 	 *            should the last element be removed?
 	 * @return the CrawlPath based on an immutable list.
 	 */
-	public CrawlPath immutableCopy(boolean removeLast) {
+	public CrawlPath immutableCopy() {
+		return immutableCopy(false);
+	}
+
+	public CrawlPath immutableCopyWithoutLast() {
+		return immutableCopy(true);
+	}
+
+	private CrawlPath immutableCopy(boolean removeLast) {
 		if (isEmpty()) {
 			return new CrawlPath();
 		}
"
bda6e186947f5dcf7894057ee2c6b12aa394b3b4,Alex Nederlof,StateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index a2291d7..1312ab2 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -5,8 +5,12 @@
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
+import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.atomic.AtomicInteger;
 
+import javax.inject.Inject;
+import javax.inject.Singleton;
+
 import net.jcip.annotations.GuardedBy;
 
 import org.apache.commons.math.stat.descriptive.moment.Mean;
@@ -18,14 +22,17 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.google.common.base.Preconditions;
+import com.crawljax.core.ExitNotifier;
+import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Lists;
+import com.google.common.collect.Maps;
 
 /**
  * The State-Flow Graph is a multi-edge directed graph with states (StateVetex) on the vertices and
  * clickables (Eventable) on the edges.
  */
+@Singleton
 @SuppressWarnings(""serial"")
 public class StateFlowGraph implements Serializable {
 
@@ -39,8 +46,9 @@
 	 */
 	private final AtomicInteger stateCounter = new AtomicInteger();
 	private final AtomicInteger nextStateNameCounter = new AtomicInteger();
+	private final ConcurrentMap<Integer, StateVertex> stateById;
 
-	private final StateVertex initialState;
+	private final ExitNotifier exitNotifier;
 
 	/**
 	 * The constructor.
@@ -48,13 +56,12 @@
 	 * @param initialState
 	 *            the state to start from.
 	 */
-	public StateFlowGraph(StateVertex initialState) {
-		Preconditions.checkNotNull(initialState);
+	@Inject
+	public StateFlowGraph(ExitNotifier exitNotifier) {
+		this.exitNotifier = exitNotifier;
 		sfg = new DirectedMultigraph<>(Eventable.class);
-		sfg.addVertex(initialState);
-		stateCounter.incrementAndGet();
-		this.initialState = initialState;
-		LOG.debug(""Initialized the stateflowgraph with an initial state"");
+		stateById = Maps.newConcurrentMap();
+		LOG.debug(""Initialized the stateflowgraph"");
 	}
 
 	/**
@@ -88,7 +95,7 @@
 	 * @param correctName
 	 *            if true the name of the state will be corrected according to the internal state
 	 *            counter.
-	 * @return the clone if one is detected null otherwise.
+	 * @return the clone if one is detected <code>null</code> otherwise.
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
 	@GuardedBy(""sfg"")
@@ -96,7 +103,9 @@
 		synchronized (sfg) {
 			boolean added = sfg.addVertex(stateVertix);
 			if (added) {
+				stateById.put(stateVertix.getId(), stateVertix);
 				int count = stateCounter.incrementAndGet();
+				exitNotifier.incrementNumberOfStates();
 				LOG.debug(""Number of states is now {}"", count);
 				if (correctName) {
 					correctStateName(stateVertix);
@@ -113,7 +122,7 @@
 	private void correctStateName(StateVertex stateVertix) {
 		// the -1 is for the ""index"" state.
 		int totalNumberOfStates = this.getAllStates().size() - 1;
-		String correctedName = makeStateName(totalNumberOfStates, stateVertix.isGuidedCrawling());
+		String correctedName = makeStateName(totalNumberOfStates);
 		if (!""index"".equals(stateVertix.getName())
 		        && !stateVertix.getName().equals(correctedName)) {
 			LOG.info(""Correcting state name from {}  to {}"", stateVertix.getName(), correctedName);
@@ -122,6 +131,19 @@
 	}
 
 	/**
+	 * @param id
+	 *            The ID of the state
+	 * @return The state if found or <code>null</code>.
+	 */
+	public StateVertex getById(int id) {
+		return stateById.get(id);
+	}
+
+	public StateVertex getInitialState() {
+		return stateById.get(StateVertex.INDEX_ID);
+	}
+
+	/**
 	 * Adds the specified edge to this graph, going from the source vertex to the target vertex.
 	 * More formally, adds the specified edge, e, to this graph if this graph contains no edge e2
 	 * such that e2.equals(e). If this graph already contains such an edge, the call leaves this
@@ -238,8 +260,8 @@
 	 *            the end state.
 	 * @return a list of shortest path of clickables from the state to the end
 	 */
-	public List<Eventable> getShortestPath(StateVertex start, StateVertex end) {
-		return DijkstraShortestPath.findPathBetween(sfg, start, end);
+	public ImmutableList<Eventable> getShortestPath(StateVertex start, StateVertex end) {
+		return ImmutableList.copyOf(DijkstraShortestPath.findPathBetween(sfg, start, end));
 	}
 
 	/**
@@ -371,11 +393,15 @@
 	 * 
 	 * @return State name the name of the state
 	 */
-	public String getNewStateName() {
-		String state = makeStateName(nextStateNameCounter.incrementAndGet(), false);
+	public String getNewStateName(int id) {
+		String state = makeStateName(id);
 		return state;
 	}
 
+	public int getNextStateId() {
+		return nextStateNameCounter.incrementAndGet();
+	}
+
 	/**
 	 * Make a new state name given its id. Separated to get a central point when changing the names
 	 * of states. The automatic state names start with ""state"" and guided ones with ""guide"".
@@ -384,23 +410,15 @@
 	 *            the id where this name needs to be for.
 	 * @return the String containing the new name.
 	 */
-	private String makeStateName(int id, boolean guided) {
-
-		if (guided) {
-			return ""guided"" + id;
-		}
-
+	private String makeStateName(int id) {
 		return ""state"" + id;
 	}
 
-	public boolean isInitialState(StateVertex state) {
-		return initialState.equals(state);
-	}
-
 	/**
 	 * @return The number of states, currently in the graph.
 	 */
 	public int getNumberOfStates() {
 		return stateCounter.get();
 	}
+
 }
"
bda6e186947f5dcf7894057ee2c6b12aa394b3b4,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index aef2647..5551a72 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -8,6 +8,7 @@
 import java.util.Arrays;
 import java.util.List;
 
+import javax.inject.Inject;
 import javax.xml.xpath.XPathExpressionException;
 
 import org.slf4j.Logger;
@@ -20,10 +21,11 @@
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.CandidateElement;
-import com.crawljax.core.configuration.InputSpecification;
+import com.crawljax.core.configuration.CrawlRules;
 import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.util.DomUtils;
 import com.crawljax.util.XPathHelper;
+import com.google.inject.assistedinject.Assisted;
 
 /**
  * Handles form values and fills in the form input elements with random values of the defined
@@ -39,7 +41,7 @@
 
 	private static final double HALF = 0.5;
 
-	private FormInputValueHelper formInputValueHelper;
+	private final FormInputValueHelper formInputValueHelper;
 
 	/**
 	 * Public constructor.
@@ -51,10 +53,12 @@
 	 * @param randomInput
 	 *            if random data should be generated on the input fields.
 	 */
-	public FormHandler(EmbeddedBrowser browser, InputSpecification inputSpecification,
-	        boolean randomInput) {
+	@Inject
+	public FormHandler(@Assisted EmbeddedBrowser browser, CrawlRules config) {
 		this.browser = browser;
-		this.formInputValueHelper = new FormInputValueHelper(inputSpecification, randomInput);
+		this.formInputValueHelper =
+		        new FormInputValueHelper(config.getInputSpecification(),
+		                config.isRandomInputInForms());
 	}
 
 	private static final String[] ALLOWED_INPUT_TYPES =
"
4ace3143ec259a40845371b8c8c2cdc8008a4791,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 399759d..9ab8886 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -541,9 +541,8 @@
 			String current = browser.getWindowHandle();
 			for (String handle : browser.getWindowHandles()) {
 				if (!handle.equals(browser.getWindowHandle())) {
-
 					browser.switchTo().window(handle);
-					LOGGER.info(""Closing other window with title \"""" + browser.getTitle() + ""\"""");
+					LOGGER.debug(""Closing other window with title \""{}\"""", browser.getTitle());
 					browser.close();
 					browser.switchTo().window(current);
 				}
"
4ace3143ec259a40845371b8c8c2cdc8008a4791,Alex Nederlof,Crawler.java,MODIFY,"follow -> [CrawlPath path] | [CrawlPath path, StateVertex targetState]","diff --git a/core/src/main/java/com/crawljax/core/Crawler.java b/core/src/main/java/com/crawljax/core/Crawler.java
index 7b9fcfc..a56d916 100644
--- a/core/src/main/java/com/crawljax/core/Crawler.java
+++ b/core/src/main/java/com/crawljax/core/Crawler.java
@@ -96,6 +96,7 @@
 		stateMachine =
 		        new StateMachine(sess.getStateFlowGraph(),
 		                crawlRules.getInvariants(), plugins, stateComparator);
+		context.setStateMachine(stateMachine);
 		crawlpath = new CrawlPath();
 		browser.goToUrl(url);
 		plugins.runOnUrlLoadPlugins(context);
@@ -110,8 +111,14 @@
 		LOG.debug(""Resetting the crawler and going to state {}"", crawlTask.getName());
 		reset();
 		ImmutableList<Eventable> eventables = shortestPathTo(crawlTask);
-		follow(CrawlPath.copyOf(eventables));
-		crawlThroughActions();
+		try {
+			follow(CrawlPath.copyOf(eventables), crawlTask);
+			crawlThroughActions();
+		} catch (StateUnreachableException ex) {
+			LOG.info(ex.getMessage());
+			LOG.debug(ex.getMessage(), ex);
+			candidateActionCache.purgeActionsForState(ex.getTarget());
+		}
 	}
 
 	private ImmutableList<Eventable> shortestPathTo(StateVertex crawlTask) {
@@ -129,37 +136,53 @@
 		candidateActionCache.addActions(extract, currentState);
 	}
 
-	private void follow(CrawlPath path) throws CrawljaxException {
+	private void follow(CrawlPath path, StateVertex targetState)
+	        throws StateUnreachableException,
+	        CrawljaxException {
 		StateVertex curState = context.getSession().getInitialState();
 
 		for (Eventable clickable : path) {
 
-			if (!candidateExtractor.checkCrawlCondition()) {
-				LOG.debug(""Crawl conditions not complete. Not following path"");
-				// TODO this is not correct probably.
-				return;
-			}
+			checkCrawlConditions(targetState);
 
 			LOG.debug(""Backtracking by executing {} on element: {}"", clickable.getEventType(),
 			        clickable);
 
-			stateMachine.changeState(clickable.getTargetStateVertex());
+			boolean switched = stateMachine.changeState(clickable.getTargetStateVertex());
+			if (!switched) {
+				throw new StateUnreachableException(targetState, ""Could not switch states"");
+			}
 			curState = clickable.getTargetStateVertex();
 			crawlpath.add(clickable);
 			handleInputElements(clickable);
 			if (fireEvent(clickable)) {
-
+				if (crawlerLeftDomain()) {
+					throw new StateUnreachableException(targetState,
+					        ""Domain left while following path"");
+				}
 				int depth = crawlDepth.incrementAndGet();
 				LOG.info(""Crawl depth is now {}"", depth);
-
 				plugins.runOnRevisitStatePlugins(context, curState);
+
+			} else {
+				throw new StateUnreachableException(targetState, ""couldn't fire eventable ""
+				        + clickable);
 			}
 
-			if (!candidateExtractor.checkCrawlCondition()) {
-				LOG.debug(""Crawl conditions not complete. Not following path"");
-				// TODO this is not correct probably.
-				return;
-			}
+			checkCrawlConditions(targetState);
+		}
+
+		if (!curState.equals(targetState)) {
+			throw new StateUnreachableException(targetState,
+			        ""The path didn't result in the desired state but in state ""
+			                + curState.getName());
+		}
+	}
+
+	private void checkCrawlConditions(StateVertex targetState) {
+		if (!candidateExtractor.checkCrawlCondition()) {
+			throw new StateUnreachableException(targetState,
+			        ""Crawl conditions not complete. Not following path"");
 		}
 	}
 
@@ -295,10 +318,16 @@
 				        ""Element {} not clicked because not all crawl conditions where satisfied"",
 				        element);
 			}
-
 			// We have to check if we are still in the same state.
 			action = candidateActionCache.pollActionOrNull(stateMachine.getCurrentState());
 			interrupted = Thread.interrupted();
+			if (!interrupted && crawlerLeftDomain()) {
+				/*
+				 * It's okay to have left the domain because the action didn't complete due to an
+				 * interruption.
+				 */
+				throw new CrawljaxException(""Somehow we left the domain"");
+			}
 		}
 		if (interrupted) {
 			LOG.info(""Interrupted while firing actions. Putting back the actions on the todo list"");
@@ -325,8 +354,8 @@
 	}
 
 	private void inspectNewDom(Eventable event, StateVertex newState) {
-		crawlpath.add(event);
 		LOG.debug(""The DOM has changed. Event added to the crawl path"");
+		crawlpath.add(event);
 		boolean isNewState =
 		        stateMachine.swithToStateAndCheckIfClone(event, newState, context);
 		if (isNewState) {
@@ -384,11 +413,11 @@
 
 	private void goBackOneState() {
 		LOG.debug(""Going back one state"");
-		CrawlPath currentPath = crawlpath.immutableCopyWithoutLast();
+		CrawlPath currentPath = crawlpath.immutableCopy();
 		crawlpath = null;
-
+		StateVertex current = stateMachine.getCurrentState();
 		reset();
-		follow(currentPath);
+		follow(currentPath, current);
 	}
 
 	/**
"
4ace3143ec259a40845371b8c8c2cdc8008a4791,Alex Nederlof,UnfiredCandidateActions.java,MODIFY,"addActions -> [Collection actions, StateVertex state] | [ImmutableList extract, StateVertex currentState]","diff --git a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
index 695be5c..a529f57 100644
--- a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
+++ b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
@@ -6,6 +6,7 @@
 import java.util.Map;
 import java.util.Queue;
 import java.util.concurrent.BlockingQueue;
+import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.locks.Lock;
 
 import javax.inject.Inject;
@@ -36,6 +37,8 @@
 	private final BlockingQueue<Integer> statesWithCandidates;
 	private final Striped<Lock> locks;
 	private final Provider<StateFlowGraph> sfg;
+	private final AtomicInteger crawlerLostCount = new AtomicInteger();
+	private final AtomicInteger actionsNotFiredCount = new AtomicInteger();
 
 	@Inject
 	UnfiredCandidateActions(BrowserConfiguration config, Provider<StateFlowGraph> sfg) {
@@ -140,4 +143,22 @@
 		return sfg.get().getById(id);
 	}
 
+	public void purgeActionsForState(StateVertex crawlTask) {
+		Lock lock = locks.get(crawlTask.getId());
+		try {
+			lock.lock();
+			LOG.debug(""Removing tasks for target state {}"", crawlTask.getName());
+			removeStateFromQueue(crawlTask.getId());
+			Queue<CandidateCrawlAction> removed = cache.remove(crawlTask.getId());
+			if (removed != null) {
+				actionsNotFiredCount.addAndGet(removed.size());
+			}
+		} finally {
+			lock.unlock();
+		}
+		crawlerLostCount.incrementAndGet();
+		LOG.info(""In total {} actions weren't fired because crawljax got lost {} times"",
+		        actionsNotFiredCount, crawlerLostCount);
+	}
+
 }
"
4ace3143ec259a40845371b8c8c2cdc8008a4791,Alex Nederlof,BrowserConfiguration.java,MODIFY,"remoteConfig -> [int numberOfBrowsers, boolean bootstrap, String remoteUrl] | [int numberOfBrowsers, String remoteUrl]","diff --git a/core/src/main/java/com/crawljax/core/configuration/BrowserConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/BrowserConfiguration.java
index eaaa74c..c7ba209 100644
--- a/core/src/main/java/com/crawljax/core/configuration/BrowserConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/BrowserConfiguration.java
@@ -42,7 +42,6 @@
 
 	private final BrowserType browsertype;
 	private final int numberOfBrowsers;
-	private final boolean bootstrap;
 	private final Provider<EmbeddedBrowser> browserBuilder;
 	private String remoteHubUrl;
 
@@ -55,10 +54,9 @@
 	 * @param remoteUrl
 	 *            the URL of the remote HUB
 	 */
-	public static BrowserConfiguration remoteConfig(int numberOfBrowsers, boolean bootstrap,
-	        String remoteUrl) {
+	public static BrowserConfiguration remoteConfig(int numberOfBrowsers, String remoteUrl) {
 		BrowserConfiguration config =
-		        new BrowserConfiguration(BrowserType.remote, numberOfBrowsers, bootstrap);
+		        new BrowserConfiguration(BrowserType.remote, numberOfBrowsers);
 		config.remoteHubUrl = remoteUrl;
 		return config;
 	}
@@ -81,7 +79,7 @@
 	 *            crawl starts.
 	 */
 	public BrowserConfiguration(BrowserType browsertype, int numberOfBrowsers) {
-		this(browsertype, numberOfBrowsers, true);
+		this(browsertype, numberOfBrowsers, DEFAULT_BROWSER_BUILDER);
 	}
 
 	/**
@@ -90,27 +88,10 @@
 	 * @param numberOfBrowsers
 	 *            The number of browsers you'd like to use. They will be started as soon as the
 	 *            crawl starts.
-	 * @param bootstrap
-	 *            if you want the browsers to start when the crawler starts. If <code>false</code>
-	 *            the browser will only be started when they are needed.
-	 */
-	public BrowserConfiguration(BrowserType browsertype, int numberOfBrowsers, boolean bootstrap) {
-		this(browsertype, numberOfBrowsers, bootstrap, DEFAULT_BROWSER_BUILDER);
-	}
-
-	/**
-	 * @param browsertype
-	 *            The browser you'd like to use.
-	 * @param numberOfBrowsers
-	 *            The number of browsers you'd like to use. They will be started as soon as the
-	 *            crawl starts.
-	 * @param bootstrap
-	 *            if you want the browsers to start when the crawler starts. If <code>false</code>
-	 *            the browser will only be started when they are needed.
 	 * @param builder
 	 *            a custom {@link WebDriverBrowserBuilder}.
 	 */
-	public BrowserConfiguration(BrowserType browsertype, int numberOfBrowsers, boolean bootstrap,
+	public BrowserConfiguration(BrowserType browsertype, int numberOfBrowsers,
 	        Provider<EmbeddedBrowser> builder) {
 		Preconditions.checkArgument(numberOfBrowsers > 0,
 		        ""Number of browsers should be 1 or more"");
@@ -119,7 +100,6 @@
 
 		this.browsertype = browsertype;
 		this.numberOfBrowsers = numberOfBrowsers;
-		this.bootstrap = bootstrap;
 		this.browserBuilder = builder;
 	}
 
@@ -131,10 +111,6 @@
 		return numberOfBrowsers;
 	}
 
-	public boolean isBootstrap() {
-		return bootstrap;
-	}
-
 	public Provider<EmbeddedBrowser> getBrowserBuilder() {
 		return browserBuilder;
 	}
@@ -152,7 +128,6 @@
 		return Objects.toStringHelper(this)
 		        .add(""browsertype"", browsertype)
 		        .add(""numberOfBrowsers"", numberOfBrowsers)
-		        .add(""bootstrap"", bootstrap)
 		        .add(""browserBuilder"", browserBuilder)
 		        .add(""remoteHubUrl"", remoteHubUrl)
 		        .toString();
@@ -160,7 +135,7 @@
 
 	@Override
 	public int hashCode() {
-		return Objects.hashCode(browsertype, numberOfBrowsers, bootstrap, browserBuilder,
+		return Objects.hashCode(browsertype, numberOfBrowsers, browserBuilder,
 		        remoteHubUrl);
 	}
 
@@ -170,7 +145,6 @@
 			BrowserConfiguration that = (BrowserConfiguration) object;
 			return Objects.equal(this.browsertype, that.browsertype)
 			        && Objects.equal(this.numberOfBrowsers, that.numberOfBrowsers)
-			        && Objects.equal(this.bootstrap, that.bootstrap)
 			        && Objects.equal(this.browserBuilder, that.browserBuilder)
 			        && Objects.equal(this.remoteHubUrl, that.remoteHubUrl);
 		}
"
4ace3143ec259a40845371b8c8c2cdc8008a4791,Alex Nederlof,Plugins.java,MODIFY,"runPostCrawlingPlugins -> [CrawlSession session] | [CrawlSession session, ExitStatus exitReason]","diff --git a/core/src/main/java/com/crawljax/core/plugin/Plugins.java b/core/src/main/java/com/crawljax/core/plugin/Plugins.java
index 9c674e0..0f8a302 100644
--- a/core/src/main/java/com/crawljax/core/plugin/Plugins.java
+++ b/core/src/main/java/com/crawljax/core/plugin/Plugins.java
@@ -13,6 +13,7 @@
 import com.crawljax.core.CandidateElement;
 import com.crawljax.core.CrawlSession;
 import com.crawljax.core.CrawlerContext;
+import com.crawljax.core.ExitNotifier.ExitStatus;
 import com.crawljax.core.configuration.ProxyConfiguration;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateVertex;
@@ -29,12 +30,12 @@
  */
 public class Plugins {
 
-	private static final Logger LOGGER = LoggerFactory.getLogger(Plugins.class.getName());
+	private static final Logger LOGGER = LoggerFactory.getLogger(Plugins.class
+	        .getName());
 
 	@SuppressWarnings(""unchecked"")
 	private static final ImmutableSet<Class<? extends Plugin>> KNOWN_PLUGINS = ImmutableSet
-	        .of(DomChangeNotifierPlugin.class,
-	                OnBrowserCreatedPlugin.class,
+	        .of(DomChangeNotifierPlugin.class, OnBrowserCreatedPlugin.class,
 	                OnFireEventFailedPlugin.class,
 	                OnInvariantViolationPlugin.class, OnNewStatePlugin.class,
 	                OnRevisitStatePlugin.class, OnUrlLoadPlugin.class,
@@ -53,7 +54,8 @@
 	public Plugins(List<? extends Plugin> plugins) {
 		Preconditions.checkNotNull(plugins);
 		ImmutableListMultimap.Builder<Class<? extends Plugin>, Plugin> builder =
-		        ImmutableListMultimap.builder();
+		        ImmutableListMultimap
+		                .builder();
 		if (plugins.isEmpty()) {
 			LOGGER.warn(""No plugins loaded. There will be no output"");
 		} else {
@@ -61,12 +63,15 @@
 		}
 		this.plugins = builder.build();
 
-		checkArgument(this.plugins.get(DomChangeNotifierPlugin.class).size() < 2,
-		        ""Only one or none "" + DomChangeNotifierPlugin.class.getSimpleName()
+		checkArgument(
+		        this.plugins.get(DomChangeNotifierPlugin.class).size() < 2,
+		        ""Only one or none ""
+		                + DomChangeNotifierPlugin.class.getSimpleName()
 		                + "" can be specified"");
 	}
 
-	private void addPlugins(List<? extends Plugin> plugins,
+	private void addPlugins(
+	        List<? extends Plugin> plugins,
 	        ImmutableListMultimap.Builder<Class<? extends Plugin>, Plugin> builder) {
 		ArrayList<Plugin> unusedPlugins = Lists.newArrayList(plugins);
 		for (Plugin plugin : plugins) {
@@ -75,7 +80,8 @@
 					@SuppressWarnings(""unchecked"")
 					Class<? extends Plugin> pluginclass = (Class<? extends Plugin>) clasz;
 					builder.put(pluginclass, plugin);
-					LOGGER.info(""Loaded {} as a {}"", plugin, clasz.getSimpleName());
+					LOGGER.info(""Loaded {} as a {}"", plugin,
+					        clasz.getSimpleName());
 					unusedPlugins.remove(plugin);
 				}
 
@@ -89,7 +95,8 @@
 	}
 
 	private void reportFailingPlugin(Plugin plugin, RuntimeException e) {
-		LOGGER.error(""Plugin {} errored while running. {}"", plugin, e.getMessage(), e);
+		LOGGER.error(""Plugin {} errored while running. {}"", plugin,
+		        e.getMessage(), e);
 	}
 
 	/**
@@ -131,7 +138,8 @@
 	 * @param newState
 	 *            The new state
 	 */
-	public void runOnNewStatePlugins(CrawlerContext context, StateVertex newState) {
+	public void runOnNewStatePlugins(CrawlerContext context,
+	        StateVertex newState) {
 		LOGGER.debug(""Running OnNewStatePlugins..."");
 		for (Plugin plugin : plugins.get(OnNewStatePlugin.class)) {
 			if (plugin instanceof OnNewStatePlugin) {
@@ -156,14 +164,15 @@
 	 * @param context
 	 *            the session to load in the plugin
 	 */
-	public void runOnInvriantViolationPlugins(Invariant invariant, CrawlerContext context) {
+	public void runOnInvriantViolationPlugins(Invariant invariant,
+	        CrawlerContext context) {
 		LOGGER.debug(""Running OnInvriantViolationPlugins..."");
 		for (Plugin plugin : plugins.get(OnInvariantViolationPlugin.class)) {
 			if (plugin instanceof OnInvariantViolationPlugin) {
 				try {
 					LOGGER.debug(""Calling plugin {}"", plugin);
-					((OnInvariantViolationPlugin) plugin)
-					        .onInvariantViolation(invariant, context);
+					((OnInvariantViolationPlugin) plugin).onInvariantViolation(
+					        invariant, context);
 				} catch (RuntimeException e) {
 					reportFailingPlugin(plugin, e);
 				}
@@ -176,16 +185,18 @@
 	 * finished Warning: changing the session can change the behavior of other post crawl plugins.
 	 * It is not a clone!
 	 * 
+	 * @param exitReason
 	 * @param context
 	 *            the session to load in the plugin
 	 */
-	public void runPostCrawlingPlugins(CrawlSession session) {
+	public void runPostCrawlingPlugins(CrawlSession session, ExitStatus exitReason) {
 		LOGGER.debug(""Running PostCrawlingPlugins..."");
 		for (Plugin plugin : plugins.get(PostCrawlingPlugin.class)) {
 			if (plugin instanceof PostCrawlingPlugin) {
 				try {
 					LOGGER.debug(""Calling plugin {}"", plugin);
-					((PostCrawlingPlugin) plugin).postCrawling(session);
+					((PostCrawlingPlugin) plugin).postCrawling(session,
+					        exitReason);
 				} catch (RuntimeException e) {
 					reportFailingPlugin(plugin, e);
 				}
@@ -203,13 +214,15 @@
 	 * @param currentState
 	 *            the state the 'back tracking' operation is currently in
 	 */
-	public void runOnRevisitStatePlugins(CrawlerContext context, StateVertex currentState) {
+	public void runOnRevisitStatePlugins(CrawlerContext context,
+	        StateVertex currentState) {
 		LOGGER.debug(""Running OnRevisitStatePlugins..."");
 		for (Plugin plugin : plugins.get(OnRevisitStatePlugin.class)) {
 			if (plugin instanceof OnRevisitStatePlugin) {
 				LOGGER.debug(""Calling plugin {}"", plugin);
 				try {
-					((OnRevisitStatePlugin) plugin).onRevisitState(context, currentState);
+					((OnRevisitStatePlugin) plugin).onRevisitState(context,
+					        currentState);
 				} catch (RuntimeException e) {
 					reportFailingPlugin(plugin, e);
 				}
@@ -237,8 +250,8 @@
 			if (plugin instanceof PreStateCrawlingPlugin) {
 				LOGGER.debug(""Calling plugin {}"", plugin);
 				try {
-					((PreStateCrawlingPlugin) plugin)
-					        .preStateCrawling(context, candidateElements, state);
+					((PreStateCrawlingPlugin) plugin).preStateCrawling(context,
+					        candidateElements, state);
 				} catch (RuntimeException e) {
 					reportFailingPlugin(plugin, e);
 				}
@@ -278,15 +291,15 @@
 	 * @param path
 	 *            the path TO this eventable.
 	 */
-	public void runOnFireEventFailedPlugins(CrawlerContext context, Eventable eventable,
-	        List<Eventable> path) {
+	public void runOnFireEventFailedPlugins(CrawlerContext context,
+	        Eventable eventable, List<Eventable> path) {
 		LOGGER.debug(""Running OnFireEventFailedPlugins..."");
 		for (Plugin plugin : plugins.get(OnFireEventFailedPlugin.class)) {
 			if (plugin instanceof OnFireEventFailedPlugin) {
 				LOGGER.debug(""Calling plugin {}"", plugin);
 				try {
-					((OnFireEventFailedPlugin) plugin)
-					        .onFireEventFailed(context, eventable, path);
+					((OnFireEventFailedPlugin) plugin).onFireEventFailed(
+					        context, eventable, path);
 				} catch (RuntimeException e) {
 					reportFailingPlugin(plugin, e);
 				}
@@ -309,7 +322,8 @@
 			if (plugin instanceof OnBrowserCreatedPlugin) {
 				LOGGER.debug(""Calling plugin {}"", plugin);
 				try {
-					((OnBrowserCreatedPlugin) plugin).onBrowserCreated(newBrowser);
+					((OnBrowserCreatedPlugin) plugin)
+					        .onBrowserCreated(newBrowser);
 				} catch (RuntimeException e) {
 					reportFailingPlugin(plugin, e);
 				}
@@ -321,19 +335,18 @@
 	 * Load and run the DomChangeNotifierPlugin.
 	 */
 	public boolean runDomChangeNotifierPlugins(final CrawlerContext context,
-	        final StateVertex stateBefore,
-	        final Eventable event,
+	        final StateVertex stateBefore, final Eventable event,
 	        final StateVertex stateAfter) {
 		if (plugins.get(DomChangeNotifierPlugin.class).isEmpty()) {
 			LOGGER.debug(""No DomChangeNotifierPlugin found. Performing default DOM comparison..."");
 			return defaultDomComparison(stateBefore, stateAfter);
 		} else {
-			DomChangeNotifierPlugin domChange =
-			        (DomChangeNotifierPlugin) plugins.get(DomChangeNotifierPlugin.class).get(0);
+			DomChangeNotifierPlugin domChange = (DomChangeNotifierPlugin) plugins
+			        .get(DomChangeNotifierPlugin.class).get(0);
 			LOGGER.debug(""Calling plugin {}"", domChange);
 			try {
-				return domChange.isDomChanged(context, stateBefore.getDom(), event,
-				        stateAfter.getDom());
+				return domChange.isDomChanged(context, stateBefore.getDom(),
+				        event, stateAfter.getDom());
 			} catch (RuntimeException ex) {
 				LOGGER.error(
 				        ""Could not run {} because of error {}. Now running default DOM comparison"",
@@ -373,16 +386,15 @@
 
 	@Override
 	public String toString() {
-		return Objects.toStringHelper(this)
-		        .add(""plugins"", plugins)
-		        .toString();
+		return Objects.toStringHelper(this).add(""plugins"", plugins).toString();
 	}
 
 	/**
 	 * @return A {@link ImmutableSet} of the {@link Plugin#toString()} that are installed.
 	 */
 	public ImmutableSet<String> pluginNames() {
-		ImmutableSortedSet.Builder<String> names = ImmutableSortedSet.naturalOrder();
+		ImmutableSortedSet.Builder<String> names = ImmutableSortedSet
+		        .naturalOrder();
 		for (Plugin plugin : plugins.values()) {
 			names.add(plugin.toString());
 		}
"
4ace3143ec259a40845371b8c8c2cdc8008a4791,Alex Nederlof,PostCrawlingPlugin.java,MODIFY,"postCrawling -> [CrawlSession session] | [CrawlSession session, ExitStatus exitReason]","diff --git a/core/src/main/java/com/crawljax/core/plugin/PostCrawlingPlugin.java b/core/src/main/java/com/crawljax/core/plugin/PostCrawlingPlugin.java
index 9cf2b77..1969a75 100644
--- a/core/src/main/java/com/crawljax/core/plugin/PostCrawlingPlugin.java
+++ b/core/src/main/java/com/crawljax/core/plugin/PostCrawlingPlugin.java
@@ -1,6 +1,7 @@
 package com.crawljax.core.plugin;
 
 import com.crawljax.core.CrawlSession;
+import com.crawljax.core.ExitNotifier.ExitStatus;
 
 /**
  * Plugin type that is called after the crawling phase is finished. Examples: report generation,
@@ -14,7 +15,9 @@
 	 * 
 	 * @param session
 	 *            the crawl session.
+	 * @param exitReason
+	 *            The {@link ExitStatus} Crawljax stopped.
 	 */
-	void postCrawling(CrawlSession session);
+	void postCrawling(CrawlSession session, ExitStatus exitReason);
 
 }
"
4ace3143ec259a40845371b8c8c2cdc8008a4791,Alex Nederlof,PostCrawlStateGraphChecker.java,MODIFY,"postCrawling -> [CrawlSession session] | [CrawlSession session, ExitStatus status]","diff --git a/core/src/test/java/com/crawljax/core/state/PostCrawlStateGraphChecker.java b/core/src/test/java/com/crawljax/core/state/PostCrawlStateGraphChecker.java
index c7c8e8e..e604c48 100644
--- a/core/src/test/java/com/crawljax/core/state/PostCrawlStateGraphChecker.java
+++ b/core/src/test/java/com/crawljax/core/state/PostCrawlStateGraphChecker.java
@@ -7,6 +7,7 @@
 import static org.junit.Assert.assertThat;
 
 import com.crawljax.core.CrawlSession;
+import com.crawljax.core.ExitNotifier.ExitStatus;
 import com.crawljax.core.plugin.PostCrawlingPlugin;
 
 /**
@@ -16,7 +17,7 @@
 public class PostCrawlStateGraphChecker implements PostCrawlingPlugin {
 
 	@Override
-	public void postCrawling(CrawlSession session) {
+	public void postCrawling(CrawlSession session, ExitStatus status) {
 		StateFlowGraph stateFlowGraph = session.getStateFlowGraph();
 
 		allStatesHaveOneOreMoreIncomingEdges(stateFlowGraph);
"
4ace3143ec259a40845371b8c8c2cdc8008a4791,Alex Nederlof,CrawlOverview.java,MODIFY,"postCrawling -> [CrawlSession session] | [CrawlSession session, ExitStatus exitStatus]","diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java
index df60b88..f0284f6 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/CrawlOverview.java
@@ -8,6 +8,7 @@
 import org.openqa.selenium.Point;
 import org.openqa.selenium.WebDriverException;
 import org.openqa.selenium.WebElement;
+import org.openqa.selenium.remote.ErrorHandler.UnknownServerException;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -16,9 +17,12 @@
 import com.crawljax.core.CrawlSession;
 import com.crawljax.core.CrawlerContext;
 import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.ExitNotifier.ExitStatus;
+import com.crawljax.core.plugin.OnFireEventFailedPlugin;
 import com.crawljax.core.plugin.OnNewStatePlugin;
 import com.crawljax.core.plugin.PostCrawlingPlugin;
 import com.crawljax.core.plugin.PreStateCrawlingPlugin;
+import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.Identification;
 import com.crawljax.core.state.Identification.How;
 import com.crawljax.core.state.StateFlowGraph;
@@ -32,25 +36,27 @@
 import com.google.common.collect.Maps;
 
 /**
- * The overview is a plug-in that generates a HTML report from the crawling session which can be
- * used to inspect what is crawled by Crawljax The report contains screenshots of the visited states
- * and the clicked elements are highlighted. The report also contains the state-flow graph in which
- * the visited states are linked together. WARNING: This plugin is still in alpha development!
+ * The overview is a plug-in that generates a HTML report from the crawling
+ * session which can be used to inspect what is crawled by Crawljax The report
+ * contains screenshots of the visited states and the clicked elements are
+ * highlighted. The report also contains the state-flow graph in which the
+ * visited states are linked together.
  **/
-public class CrawlOverview
-        implements OnNewStatePlugin, PreStateCrawlingPlugin, PostCrawlingPlugin {
+public class CrawlOverview implements OnNewStatePlugin, PreStateCrawlingPlugin,
+		PostCrawlingPlugin, OnFireEventFailedPlugin {
 
-	private static final Logger LOG = LoggerFactory.getLogger(CrawlOverview.class);
+	private static final Logger LOG = LoggerFactory
+			.getLogger(CrawlOverview.class);
 
 	private final OutputBuilder outputBuilder;
 	private final Map<String, StateVertex> visitedStates;
+	private final OutPutModelCache outModelCache;
 
 	private OutPutModel result;
 
-	private final OutPutModelCache outModelCache;
-
 	public CrawlOverview(File outputFolder) {
-		Preconditions.checkNotNull(outputFolder, ""Output folder cannot be null"");
+		Preconditions
+				.checkNotNull(outputFolder, ""Output folder cannot be null"");
 		outputBuilder = new OutputBuilder(outputFolder);
 		outModelCache = new OutPutModelCache();
 		visitedStates = Maps.newHashMap();
@@ -64,6 +70,11 @@
 	public void onNewState(CrawlerContext context, StateVertex vertex) {
 		LOG.debug(""onNewState"");
 		StateBuilder state = outModelCache.addStateIfAbsent(vertex);
+		synchronized (visitedStates) {
+			if (!visitedStates.containsKey(state.getName())) {
+				visitedStates.put(state.getName(), vertex);
+			}
+		}
 		saveScreenshot(context.getBrowser(), state.getName(), vertex);
 		outputBuilder.persistDom(state.getName(), vertex.getDom());
 		Point point = getOffSet(context.getBrowser());
@@ -74,58 +85,57 @@
 	private Point getOffSet(EmbeddedBrowser embeddedBrowser) {
 		if (bodyHasOffset(embeddedBrowser)) {
 			try {
-				Number top =
-				        (Number) embeddedBrowser
-				                .executeJavaScript(""return document.body.getBoundingClientRect().top;"");
-				Number left =
-				        (Number) embeddedBrowser
-				                .executeJavaScript(""return document.body.getBoundingClientRect().left;"");
+				Number top = (Number) embeddedBrowser
+						.executeJavaScript(""return document.body.getBoundingClientRect().top;"");
+				Number left = (Number) embeddedBrowser
+						.executeJavaScript(""return document.body.getBoundingClientRect().left;"");
 				Point offset = new Point(left.intValue(), top.intValue());
 				return offset;
 			} catch (CrawljaxException e) {
-				LOG.warn(""Could not locate relative size of body, now using (0,0) instead"", e);
+				LOG.warn(
+						""Could not locate relative size of body, now using (0,0) instead"",
+						e);
 			}
 		}
 		return new Point(0, 0);
 	}
 
 	private boolean bodyHasOffset(EmbeddedBrowser embeddedBrowser) {
-		WebElement body = embeddedBrowser.getWebElement(new Identification(How.tag, ""body""));
+		WebElement body = embeddedBrowser.getWebElement(new Identification(
+				How.tag, ""body""));
 		String position = body.getCssValue(""position"");
 		LOG.debug(""Body has CSS position: {}"", position);
 		return ""relative"".equals(position);
 	}
 
-	private void saveScreenshot(EmbeddedBrowser browser, String name, StateVertex vertex) {
-		LOG.trace(""Saving screenshot"");
-		synchronized (visitedStates) {
-			if (!visitedStates.containsKey(name)) {
-				visitedStates.put(name, vertex);
-			}
-		}
+	private void saveScreenshot(EmbeddedBrowser browser, String name,
+			StateVertex vertex) {
 		LOG.debug(""Saving screenshot for state {}"", name);
 		File jpg = outputBuilder.newScreenShotFile(name);
 		File thumb = outputBuilder.newThumbNail(name);
 		try {
 			byte[] screenshot = browser.getScreenShot();
 			ImageWriter.writeScreenShotAndThumbnail(screenshot, jpg, thumb);
-		} catch (CrawljaxException e) {
-			LOG.warn(""Screenshots are not supported for {}"", browser);
+		} catch (CrawljaxException | WebDriverException e) {
+			LOG.warn(
+					""Screenshots are not supported or not functioning for {}. Exception message: {}"",
+					browser, e.getMessage());
+			LOG.debug(""Screenshot not made because {}"", e.getMessage(), e);
 		}
 		LOG.trace(""Screenshot saved"");
 	}
 
 	/**
-	 * Logs all the canidate elements so that the plugin knows which elements were the candidate
-	 * elements.
+	 * Logs all the canidate elements so that the plugin knows which elements
+	 * were the candidate elements.
 	 */
 	@Override
 	public void preStateCrawling(CrawlerContext context,
-	        ImmutableList<CandidateElement> candidateElements, StateVertex state) {
+			ImmutableList<CandidateElement> candidateElements, StateVertex state) {
 		LOG.debug(""preStateCrawling"");
 		List<CandidateElementPosition> newElements = Lists.newLinkedList();
-		LOG.info(""Prestate found new state {} with {} candidates"", state.getName(),
-		        candidateElements.size());
+		LOG.info(""Prestate found new state {} with {} candidates"",
+				state.getName(), candidateElements.size());
 		for (CandidateElement element : candidateElements) {
 			WebElement webElement = getWebElement(context.getBrowser(), element);
 			if (webElement != null) {
@@ -138,25 +148,30 @@
 		LOG.trace(""preState finished, elements added to state"");
 	}
 
-	private WebElement getWebElement(EmbeddedBrowser browser, CandidateElement element) {
+	private WebElement getWebElement(EmbeddedBrowser browser,
+			CandidateElement element) {
 		try {
-			// TODO Check if element.getIdentification().getValue() is correct replacement for
+			// TODO Check if element.getIdentification().getValue() is correct
+			// replacement for
 			// element.getXpath()
 			return browser.getWebElement(element.getIdentification());
 		} catch (WebDriverException e) {
-			LOG.info(""Could not locate element for positioning {}"", element.getElement());
+			LOG.info(""Could not locate element for positioning {}"",
+					element.getElement());
 			return null;
 		}
 	}
 
-	private CandidateElementPosition findElement(WebElement webElement, CandidateElement element) {
+	private CandidateElementPosition findElement(WebElement webElement,
+			CandidateElement element) {
 		Point location = webElement.getLocation();
 		Dimension size = webElement.getSize();
 		CandidateElementPosition renderedCandidateElement =
-		        // TODO Check if element.getIdentification().getValue() is correct replacement for
-		        // element.getXpath()
-		        new CandidateElementPosition(element.getIdentification().getValue(), location,
-		                size);
+		// TODO Check if element.getIdentification().getValue() is correct
+		// replacement for
+		// element.getXpath()
+		new CandidateElementPosition(element.getIdentification().getValue(),
+				location, size);
 		return renderedCandidateElement;
 	}
 
@@ -164,13 +179,14 @@
 	 * Generated the report.
 	 */
 	@Override
-	public void postCrawling(CrawlSession session) {
+	public void postCrawling(CrawlSession session, ExitStatus exitStatus) {
 		LOG.debug(""postCrawling"");
 		StateFlowGraph sfg = session.getStateFlowGraph();
-		result = outModelCache.close(session);
-		outputBuilder.write(result);
+		result = outModelCache.close(session, exitStatus);
+		outputBuilder.write(result, session.getConfig());
 		synchronized (visitedStates) {
-			StateWriter writer = new StateWriter(outputBuilder, sfg, visitedStates);
+			StateWriter writer = new StateWriter(outputBuilder, sfg,
+					visitedStates);
 			for (State state : result.getStates().values()) {
 				writer.writeHtmlForState(state);
 			}
@@ -179,7 +195,8 @@
 	}
 
 	/**
-	 * @return the result of the Crawl or <code>null</code> if it hasn't finished yet.
+	 * @return the result of the Crawl or <code>null</code> if it hasn't
+	 *         finished yet.
 	 */
 	public OutPutModel getResult() {
 		return result;
@@ -189,4 +206,10 @@
 	public String toString() {
 		return ""Crawl overview plugin"";
 	}
+
+	@Override
+	public void onFireEventFailed(CrawlerContext context, Eventable eventable,
+			List<Eventable> pathToFailure) {
+		outModelCache.registerFailEvent(context.getCurrentState(), eventable);
+	}
 }
"
4ace3143ec259a40845371b8c8c2cdc8008a4791,Alex Nederlof,OutPutModelCache.java,MODIFY,"close -> [CrawlSession session] | [CrawlSession session, ExitStatus exitStatus]","diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutPutModelCache.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutPutModelCache.java
index 2fa0d20..befb783 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutPutModelCache.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutPutModelCache.java
@@ -5,6 +5,7 @@
 import java.util.Date;
 import java.util.Set;
 import java.util.concurrent.ConcurrentMap;
+import java.util.concurrent.atomic.AtomicInteger;
 
 import javax.annotation.concurrent.ThreadSafe;
 
@@ -12,6 +13,7 @@
 import org.slf4j.LoggerFactory;
 
 import com.crawljax.core.CrawlSession;
+import com.crawljax.core.ExitNotifier.ExitStatus;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.StateVertex;
 import com.crawljax.plugins.crawloverview.model.CandidateElementPosition;
@@ -31,8 +33,12 @@
  */
 class OutPutModelCache {
 
-	private static final Logger LOG = LoggerFactory.getLogger(OutPutModelCache.class);
-	private final ConcurrentMap<String, StateBuilder> states = Maps.newConcurrentMap();
+	private static final Logger LOG = LoggerFactory
+	        .getLogger(OutPutModelCache.class);
+	private final ConcurrentMap<String, StateBuilder> states = Maps
+	        .newConcurrentMap();
+
+	private final AtomicInteger failedEvents = new AtomicInteger();
 
 	private final Date startDate = new Date();
 
@@ -49,21 +55,23 @@
 	/**
 	 * @return Makes the final calculations and retuns the {@link OutPutModel}.
 	 */
-	OutPutModel close(CrawlSession session) {
-		ImmutableList<Edge> edgesCopy = asEdges(session.getStateFlowGraph().getAllEdges());
+	public OutPutModel close(CrawlSession session, ExitStatus exitStatus) {
+		ImmutableList<Edge> edgesCopy = asEdges(session.getStateFlowGraph()
+		        .getAllEdges());
 		checkEdgesAndCountFans(edgesCopy);
 		ImmutableMap<String, State> statesCopy = buildStates();
 
-		if (statesCopy.size() != session.getStateFlowGraph().getAllStates().size()) {
+		if (statesCopy.size() != session.getStateFlowGraph().getAllStates()
+		        .size()) {
 			LOG.error(""Not all states from the session are in the result. This means there's a bug somewhere"");
-			LOG.info(""Printing state difference. \nSession states: {} \nResult states: {}"",
+			LOG.info(
+			        ""Printing state difference. \nSession states: {} \nResult states: {}"",
 			        statesCopy, session.getStateFlowGraph().getAllStates());
 		}
 
 		StateStatistics stateStats = new StateStatistics(statesCopy.values());
-		return new OutPutModel(statesCopy, edgesCopy,
-		        new Statistics(session, stateStats, startDate),
-		        session.getConfig());
+		return new OutPutModel(statesCopy, edgesCopy, new Statistics(session,
+		        stateStats, startDate, failedEvents.get()), exitStatus);
 	}
 
 	private ImmutableList<Edge> asEdges(Set<Eventable> allEdges) {
@@ -93,4 +101,14 @@
 		return builder.build();
 	}
 
+	public void registerFailEvent(StateVertex currentState, Eventable eventable) {
+		failedEvents.incrementAndGet();
+		if (currentState != null) {
+			StateBuilder builder = states.get(currentState.getName());
+			if (builder != null) {
+				builder.eventFailed(eventable);
+			}
+		}
+	}
+
 }
"
4ace3143ec259a40845371b8c8c2cdc8008a4791,Alex Nederlof,OutputBuilder.java,MODIFY,"write -> [OutPutModel outModel] | [OutPutModel result, CrawljaxConfiguration config]","diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
index b54504e..0b04e79 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/OutputBuilder.java
@@ -27,7 +27,9 @@
 import org.slf4j.LoggerFactory;
 
 import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.crawljax.plugins.crawloverview.model.OutPutModel;
+import com.crawljax.plugins.crawloverview.model.Serializer;
 import com.google.common.base.Charsets;
 import com.google.common.base.Strings;
 import com.google.common.io.ByteStreams;
@@ -166,9 +168,10 @@
 		}
 	}
 
-	void write(OutPutModel outModel) {
+	public void write(OutPutModel result, CrawljaxConfiguration config) {
 		try {
-			writeIndexFile(outModel);
+			writeIndexFile(result, config);
+			writeJsonToOutDir(Serializer.toPrettyJson(config), ""config.json"");
 		} catch (Exception e) {
 			LOG.error(e.getMessage(), e);
 		}
@@ -176,15 +179,16 @@
 		LOG.info(""Overview report generated"");
 	}
 
-	private void writeIndexFile(OutPutModel model) {
+	private void writeIndexFile(OutPutModel model, CrawljaxConfiguration config) {
 		LOG.debug(""Writing index file"");
 		VelocityContext context = new VelocityContext();
-		writeJsonToOutDir(Serializer.toPrettyJson(model));
+		writeJsonToOutDir(Serializer.toPrettyJson(model), JSON_OUTPUT_NAME);
 		context.put(""states"", Serializer.toPrettyJson(model.getStates()));
 		context.put(""edges"", Serializer.toPrettyJson(model.getEdges()));
-		context.put(""config"", BeanToReadableMap.toMap(model.getConfiguration()));
-		context.put(""crawledUrl"", model.getConfiguration().getUrl());
+		context.put(""config"", BeanToReadableMap.toMap(config));
+		context.put(""crawledUrl"", config.getUrl());
 		context.put(""stats"", model.getStatistics());
+		context.put(""exitStatus"", model.getExitStatus());
 
 		LOG.debug(""Writing urls report"");
 		context.put(""urls"", model.getStatistics().getStateStats().getUrls());
@@ -192,9 +196,9 @@
 		writeFile(context, indexFile, ""index.html"");
 	}
 
-	private void writeJsonToOutDir(String outModelJson) {
+	private void writeJsonToOutDir(String outModelJson, String filename) {
 		try {
-			Files.write(outModelJson, new File(this.outputDir, JSON_OUTPUT_NAME), Charsets.UTF_8);
+			Files.write(outModelJson, new File(this.outputDir, filename), Charsets.UTF_8);
 		} catch (IOException e) {
 			LOG.warn(""Could not write JSON model to output dir. "" + e.getMessage());
 		}
"
9948d32b1df2fad253848c191db3d17512db7e65,Alex Nederlof,Serializer.java,MODIFY,read -> [String json] | [File file],"diff --git a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/model/Serializer.java b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/model/Serializer.java
index 88cf5d6..3ec5e45 100644
--- a/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/model/Serializer.java
+++ b/plugins/crawloverview-plugin/src/main/java/com/crawljax/plugins/crawloverview/model/Serializer.java
@@ -1,5 +1,6 @@
 package com.crawljax.plugins.crawloverview.model;
 
+import java.io.File;
 import java.io.IOException;
 import java.text.SimpleDateFormat;
 import java.util.Locale;
@@ -70,7 +71,7 @@
 		}
 	}
 
-	static <T> T deserialize(String value, TypeReference<T> clasz) throws IOException {
+	public static <T> T deserialize(String value, TypeReference<T> clasz) throws IOException {
 		return MAPPER.readValue(value, clasz);
 	}
 
@@ -81,4 +82,8 @@
 	        IOException {
 		return MAPPER.readValue(json, OutPutModel.class);
 	}
+
+	public static OutPutModel read(File file) throws IOException {
+		return MAPPER.readValue(file, OutPutModel.class);
+	}
 }
"
fb0b6bfec024389334b20c61d91315d58ca2fbbe,Alex Nederlof,UnfiredCandidateActions.java,MODIFY,"addActions -> [Collection actions, StateVertex state] | [ImmutableList extract, StateVertex currentState]","diff --git a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
index a529f57..19055a1 100644
--- a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
+++ b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
@@ -64,7 +64,7 @@
 				return null;
 			} else {
 				CandidateCrawlAction action = queue.poll();
-				if (action == null) {
+				if (queue.isEmpty()) {
 					LOG.debug(""All actions polled for state {}"", state.getName());
 					cache.remove(state.getId());
 					removeStateFromQueue(state.getId());
@@ -75,6 +75,7 @@
 		} finally {
 			lock.unlock();
 		}
+
 	}
 
 	private void removeStateFromQueue(int id) {
@@ -104,6 +105,10 @@
 	 *            The state name. This should be unique per state.
 	 */
 	void addActions(Collection<CandidateCrawlAction> actions, StateVertex state) {
+		if (actions.isEmpty()) {
+			LOG.debug(""Received empty actions list. Ignoring..."");
+			return;
+		}
 		Lock lock = locks.get(state.getId());
 		try {
 			lock.lock();
"
5af558824b2f3fd43e18a52b9c2e13ae5e9bd9de,Alex Nederlof,UnfiredCandidateActions.java,MODIFY,"addActions -> [Collection actions, StateVertex state] | [ImmutableList extract, StateVertex currentState]","diff --git a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
index a529f57..19055a1 100644
--- a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
+++ b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
@@ -64,7 +64,7 @@
 				return null;
 			} else {
 				CandidateCrawlAction action = queue.poll();
-				if (action == null) {
+				if (queue.isEmpty()) {
 					LOG.debug(""All actions polled for state {}"", state.getName());
 					cache.remove(state.getId());
 					removeStateFromQueue(state.getId());
@@ -75,6 +75,7 @@
 		} finally {
 			lock.unlock();
 		}
+
 	}
 
 	private void removeStateFromQueue(int id) {
@@ -104,6 +105,10 @@
 	 *            The state name. This should be unique per state.
 	 */
 	void addActions(Collection<CandidateCrawlAction> actions, StateVertex state) {
+		if (actions.isEmpty()) {
+			LOG.debug(""Received empty actions list. Ignoring..."");
+			return;
+		}
 		Lock lock = locks.get(state.getId());
 		try {
 			lock.lock();
"
ed6309f28cf862c3f93daad12e5e2ae9cec0a800,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 9ab8886..2e54c1c 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -26,6 +26,7 @@
 import org.openqa.selenium.io.FileHandler;
 import org.openqa.selenium.remote.Augmenter;
 import org.openqa.selenium.remote.DesiredCapabilities;
+import org.openqa.selenium.remote.ErrorHandler.UnknownServerException;
 import org.openqa.selenium.remote.HttpCommandExecutor;
 import org.openqa.selenium.remote.RemoteWebDriver;
 import org.openqa.selenium.support.ui.Select;
@@ -590,43 +591,50 @@
 		}
 
 		for (int i = 0; i < nodeList.size(); i++) {
-			String frameIdentification = """";
-
-			if (topFrame != null && !topFrame.equals("""")) {
-				frameIdentification += topFrame + ""."";
+			try {
+				locateFrameAndgetSource(document, topFrame, nodeList.get(i));
+			} catch (UnknownServerException e) {
+				LOGGER.warn(""Could not add frame contents for element {}"", nodeList.get(i));
+				LOGGER.debug(""Could not load frame because of {}"", e.getMessage(), e);
 			}
+		}
+	}
 
-			Element frameElement = nodeList.get(i);
+	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement) {
+		String frameIdentification = """";
 
-			String nameId = DomUtils.getFrameIdentification(frameElement);
+		if (topFrame != null && !topFrame.equals("""")) {
+			frameIdentification += topFrame + ""."";
+		}
 
-			if (nameId != null
-			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
-				frameIdentification += nameId;
+		String nameId = DomUtils.getFrameIdentification(frameElement);
 
-				String handle = browser.getWindowHandle();
+		if (nameId != null
+		        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
+			frameIdentification += nameId;
 
-				LOGGER.debug(""The current H: "" + handle);
+			String handle = browser.getWindowHandle();
 
-				switchToFrame(frameIdentification);
+			LOGGER.debug(""The current H: "" + handle);
 
-				String toAppend = browser.getPageSource();
+			switchToFrame(frameIdentification);
 
-				LOGGER.debug(""frame dom: "" + toAppend);
+			String toAppend = browser.getPageSource();
 
-				browser.switchTo().defaultContent();
+			LOGGER.debug(""frame dom: "" + toAppend);
 
-				try {
-					Element toAppendElement = DomUtils.asDocument(toAppend).getDocumentElement();
-					Element importedElement =
-					        (Element) document.importNode(toAppendElement, true);
-					frameElement.appendChild(importedElement);
+			browser.switchTo().defaultContent();
 
-					appendFrameContent(importedElement, document, frameIdentification);
-				} catch (DOMException | IOException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				}
+			try {
+				Element toAppendElement = DomUtils.asDocument(toAppend).getDocumentElement();
+				Element importedElement =
+				        (Element) document.importNode(toAppendElement, true);
+				frameElement.appendChild(importedElement);
+
+				appendFrameContent(importedElement, document, frameIdentification);
+			} catch (DOMException | IOException e) {
+				LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
+				        + "" continuing..."", e);
 			}
 		}
 	}
"
990395fb2ef44bf5b4f8ebc1cf706aefa0ac4f30,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 9ab8886..2e54c1c 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -26,6 +26,7 @@
 import org.openqa.selenium.io.FileHandler;
 import org.openqa.selenium.remote.Augmenter;
 import org.openqa.selenium.remote.DesiredCapabilities;
+import org.openqa.selenium.remote.ErrorHandler.UnknownServerException;
 import org.openqa.selenium.remote.HttpCommandExecutor;
 import org.openqa.selenium.remote.RemoteWebDriver;
 import org.openqa.selenium.support.ui.Select;
@@ -590,43 +591,50 @@
 		}
 
 		for (int i = 0; i < nodeList.size(); i++) {
-			String frameIdentification = """";
-
-			if (topFrame != null && !topFrame.equals("""")) {
-				frameIdentification += topFrame + ""."";
+			try {
+				locateFrameAndgetSource(document, topFrame, nodeList.get(i));
+			} catch (UnknownServerException e) {
+				LOGGER.warn(""Could not add frame contents for element {}"", nodeList.get(i));
+				LOGGER.debug(""Could not load frame because of {}"", e.getMessage(), e);
 			}
+		}
+	}
 
-			Element frameElement = nodeList.get(i);
+	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement) {
+		String frameIdentification = """";
 
-			String nameId = DomUtils.getFrameIdentification(frameElement);
+		if (topFrame != null && !topFrame.equals("""")) {
+			frameIdentification += topFrame + ""."";
+		}
 
-			if (nameId != null
-			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
-				frameIdentification += nameId;
+		String nameId = DomUtils.getFrameIdentification(frameElement);
 
-				String handle = browser.getWindowHandle();
+		if (nameId != null
+		        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
+			frameIdentification += nameId;
 
-				LOGGER.debug(""The current H: "" + handle);
+			String handle = browser.getWindowHandle();
 
-				switchToFrame(frameIdentification);
+			LOGGER.debug(""The current H: "" + handle);
 
-				String toAppend = browser.getPageSource();
+			switchToFrame(frameIdentification);
 
-				LOGGER.debug(""frame dom: "" + toAppend);
+			String toAppend = browser.getPageSource();
 
-				browser.switchTo().defaultContent();
+			LOGGER.debug(""frame dom: "" + toAppend);
 
-				try {
-					Element toAppendElement = DomUtils.asDocument(toAppend).getDocumentElement();
-					Element importedElement =
-					        (Element) document.importNode(toAppendElement, true);
-					frameElement.appendChild(importedElement);
+			browser.switchTo().defaultContent();
 
-					appendFrameContent(importedElement, document, frameIdentification);
-				} catch (DOMException | IOException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				}
+			try {
+				Element toAppendElement = DomUtils.asDocument(toAppend).getDocumentElement();
+				Element importedElement =
+				        (Element) document.importNode(toAppendElement, true);
+				frameElement.appendChild(importedElement);
+
+				appendFrameContent(importedElement, document, frameIdentification);
+			} catch (DOMException | IOException e) {
+				LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
+				        + "" continuing..."", e);
 			}
 		}
 	}
"
913b9721b6d40c684855c9ddb6bfc5f2745fb8f0,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index b680e39..2e54c1c 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -26,6 +26,7 @@
 import org.openqa.selenium.io.FileHandler;
 import org.openqa.selenium.remote.Augmenter;
 import org.openqa.selenium.remote.DesiredCapabilities;
+import org.openqa.selenium.remote.ErrorHandler.UnknownServerException;
 import org.openqa.selenium.remote.HttpCommandExecutor;
 import org.openqa.selenium.remote.RemoteWebDriver;
 import org.openqa.selenium.support.ui.Select;
@@ -269,7 +270,8 @@
 			throwIfConnectionException(e);
 			return;
 		} catch (InterruptedException e) {
-			LOGGER.error(""goToUrl got interrupted while waiting for the page to be loaded"", e);
+			LOGGER.debug(""goToUrl got interrupted while waiting for the page to be loaded"", e);
+			Thread.currentThread().interrupt();
 			return;
 		}
 	}
@@ -295,9 +297,11 @@
 	 * @param eventable
 	 *            The HTML event type (onclick, onmouseover, ...).
 	 * @return true if firing event is successful.
+	 * @throws InterruptedException
+	 *             when interrupted during the wait.
 	 */
-	protected boolean fireEventWait(WebElement webElement, Eventable eventable)
-	        throws ElementNotVisibleException {
+	private boolean fireEventWait(WebElement webElement, Eventable eventable)
+	        throws ElementNotVisibleException, InterruptedException {
 		switch (eventable.getEventType()) {
 			case click:
 				try {
@@ -317,12 +321,7 @@
 				return false;
 		}
 
-		try {
-			Thread.sleep(this.crawlWaitEvent);
-		} catch (InterruptedException e) {
-			LOGGER.error(""fireEventWait got interrupted during wait process"", e);
-			return false;
-		}
+		Thread.sleep(this.crawlWaitEvent);
 		return true;
 	}
 
@@ -333,8 +332,14 @@
 			// close browser and close every associated window.
 			browser.quit();
 		} catch (WebDriverException e) {
+			if (e.getCause() instanceof InterruptedException) {
+				LOGGER.info(""Interrupted while waiting for the browser to close. It might not close correctly"");
+				Thread.currentThread().interrupt();
+				return;
+			}
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
+		LOGGER.debug(""Browser closed..."");
 	}
 
 	@Override
@@ -430,10 +435,13 @@
 	 * @param eventable
 	 *            The eventable.
 	 * @return true if it is able to fire the event successfully on the element.
+	 * @throws InterruptedException
+	 *             when interrupted during the wait.
 	 */
 	@Override
-	public synchronized boolean fireEvent(Eventable eventable) throws ElementNotVisibleException,
-	        NoSuchElementException {
+	public synchronized boolean fireEventAndWait(Eventable eventable)
+	        throws ElementNotVisibleException,
+	        NoSuchElementException, InterruptedException {
 		try {
 
 			boolean handleChanged = false;
@@ -534,9 +542,8 @@
 			String current = browser.getWindowHandle();
 			for (String handle : browser.getWindowHandles()) {
 				if (!handle.equals(browser.getWindowHandle())) {
-
 					browser.switchTo().window(handle);
-					LOGGER.info(""Closing other window with title \"""" + browser.getTitle() + ""\"""");
+					LOGGER.debug(""Closing other window with title \""{}\"""", browser.getTitle());
 					browser.close();
 					browser.switchTo().window(current);
 				}
@@ -584,43 +591,50 @@
 		}
 
 		for (int i = 0; i < nodeList.size(); i++) {
-			String frameIdentification = """";
-
-			if (topFrame != null && !topFrame.equals("""")) {
-				frameIdentification += topFrame + ""."";
+			try {
+				locateFrameAndgetSource(document, topFrame, nodeList.get(i));
+			} catch (UnknownServerException e) {
+				LOGGER.warn(""Could not add frame contents for element {}"", nodeList.get(i));
+				LOGGER.debug(""Could not load frame because of {}"", e.getMessage(), e);
 			}
+		}
+	}
 
-			Element frameElement = nodeList.get(i);
+	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement) {
+		String frameIdentification = """";
 
-			String nameId = DomUtils.getFrameIdentification(frameElement);
+		if (topFrame != null && !topFrame.equals("""")) {
+			frameIdentification += topFrame + ""."";
+		}
 
-			if (nameId != null
-			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
-				frameIdentification += nameId;
+		String nameId = DomUtils.getFrameIdentification(frameElement);
 
-				String handle = browser.getWindowHandle();
+		if (nameId != null
+		        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
+			frameIdentification += nameId;
 
-				LOGGER.debug(""The current H: "" + handle);
+			String handle = browser.getWindowHandle();
 
-				switchToFrame(frameIdentification);
+			LOGGER.debug(""The current H: "" + handle);
 
-				String toAppend = browser.getPageSource();
+			switchToFrame(frameIdentification);
 
-				LOGGER.debug(""frame dom: "" + toAppend);
+			String toAppend = browser.getPageSource();
 
-				browser.switchTo().defaultContent();
+			LOGGER.debug(""frame dom: "" + toAppend);
 
-				try {
-					Element toAppendElement = DomUtils.asDocument(toAppend).getDocumentElement();
-					Element importedElement =
-					        (Element) document.importNode(toAppendElement, true);
-					frameElement.appendChild(importedElement);
+			browser.switchTo().defaultContent();
 
-					appendFrameContent(importedElement, document, frameIdentification);
-				} catch (DOMException | IOException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				}
+			try {
+				Element toAppendElement = DomUtils.asDocument(toAppend).getDocumentElement();
+				Element importedElement =
+				        (Element) document.importNode(toAppendElement, true);
+				frameElement.appendChild(importedElement);
+
+				appendFrameContent(importedElement, document, frameIdentification);
+			} catch (DOMException | IOException e) {
+				LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
+				        + "" continuing..."", e);
 			}
 		}
 	}
"
913b9721b6d40c684855c9ddb6bfc5f2745fb8f0,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index b40d407..bfd9ba1 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -7,19 +7,23 @@
 import java.util.concurrent.TimeUnit;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
+import com.crawljax.core.CrawlController;
 import com.crawljax.core.Crawler;
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.core.plugin.Plugins;
+import com.crawljax.di.CoreModule;
 import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
+import com.google.inject.Guice;
+import com.google.inject.Injector;
 
 /**
  * Configures the {@link Crawler}. Set it up using the {@link #builderFor(String)} function.
  */
-public final class CrawljaxConfiguration {
+public class CrawljaxConfiguration {
 
 	public static class CrawljaxConfigurationBuilder {
 
@@ -82,7 +86,7 @@
 		}
 
 		/**
-		 * Set the crawl depth to unlimited.
+		 * Set the crawl depth to unlimited. The default depth is <code>2</code>.
 		 */
 		public CrawljaxConfigurationBuilder setUnlimitedCrawlDepth() {
 			config.maximumDepth = 0;
@@ -139,6 +143,11 @@
 			return config;
 		}
 
+		public CrawlController buildControl() {
+			Injector injector = Guice.createInjector(new CoreModule(build()));
+			return injector.getInstance(CrawlController.class);
+		}
+
 	}
 
 	/**
"
913b9721b6d40c684855c9ddb6bfc5f2745fb8f0,Ali Mesbah,CrawlPath.java,MODIFY,immutableCopy -> [boolean removeLast] | [],"diff --git a/core/src/main/java/com/crawljax/core/state/CrawlPath.java b/core/src/main/java/com/crawljax/core/state/CrawlPath.java
index 8aaf8dd..af8ad19 100644
--- a/core/src/main/java/com/crawljax/core/state/CrawlPath.java
+++ b/core/src/main/java/com/crawljax/core/state/CrawlPath.java
@@ -13,6 +13,10 @@
 
 	private final List<Eventable> eventablePath;
 
+	public static CrawlPath copyOf(List<Eventable> eventable) {
+		return new CrawlPath(Lists.newLinkedList(eventable));
+	}
+
 	/**
 	 * Start a new empty CrawlPath.
 	 */
@@ -55,7 +59,15 @@
 	 *            should the last element be removed?
 	 * @return the CrawlPath based on an immutable list.
 	 */
-	public CrawlPath immutableCopy(boolean removeLast) {
+	public CrawlPath immutableCopy() {
+		return immutableCopy(false);
+	}
+
+	public CrawlPath immutableCopyWithoutLast() {
+		return immutableCopy(true);
+	}
+
+	private CrawlPath immutableCopy(boolean removeLast) {
 		if (isEmpty()) {
 			return new CrawlPath();
 		}
"
913b9721b6d40c684855c9ddb6bfc5f2745fb8f0,Ali Mesbah,StateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index a2291d7..1312ab2 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -5,8 +5,12 @@
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
+import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.atomic.AtomicInteger;
 
+import javax.inject.Inject;
+import javax.inject.Singleton;
+
 import net.jcip.annotations.GuardedBy;
 
 import org.apache.commons.math.stat.descriptive.moment.Mean;
@@ -18,14 +22,17 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.google.common.base.Preconditions;
+import com.crawljax.core.ExitNotifier;
+import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableSet;
 import com.google.common.collect.Lists;
+import com.google.common.collect.Maps;
 
 /**
  * The State-Flow Graph is a multi-edge directed graph with states (StateVetex) on the vertices and
  * clickables (Eventable) on the edges.
  */
+@Singleton
 @SuppressWarnings(""serial"")
 public class StateFlowGraph implements Serializable {
 
@@ -39,8 +46,9 @@
 	 */
 	private final AtomicInteger stateCounter = new AtomicInteger();
 	private final AtomicInteger nextStateNameCounter = new AtomicInteger();
+	private final ConcurrentMap<Integer, StateVertex> stateById;
 
-	private final StateVertex initialState;
+	private final ExitNotifier exitNotifier;
 
 	/**
 	 * The constructor.
@@ -48,13 +56,12 @@
 	 * @param initialState
 	 *            the state to start from.
 	 */
-	public StateFlowGraph(StateVertex initialState) {
-		Preconditions.checkNotNull(initialState);
+	@Inject
+	public StateFlowGraph(ExitNotifier exitNotifier) {
+		this.exitNotifier = exitNotifier;
 		sfg = new DirectedMultigraph<>(Eventable.class);
-		sfg.addVertex(initialState);
-		stateCounter.incrementAndGet();
-		this.initialState = initialState;
-		LOG.debug(""Initialized the stateflowgraph with an initial state"");
+		stateById = Maps.newConcurrentMap();
+		LOG.debug(""Initialized the stateflowgraph"");
 	}
 
 	/**
@@ -88,7 +95,7 @@
 	 * @param correctName
 	 *            if true the name of the state will be corrected according to the internal state
 	 *            counter.
-	 * @return the clone if one is detected null otherwise.
+	 * @return the clone if one is detected <code>null</code> otherwise.
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
 	@GuardedBy(""sfg"")
@@ -96,7 +103,9 @@
 		synchronized (sfg) {
 			boolean added = sfg.addVertex(stateVertix);
 			if (added) {
+				stateById.put(stateVertix.getId(), stateVertix);
 				int count = stateCounter.incrementAndGet();
+				exitNotifier.incrementNumberOfStates();
 				LOG.debug(""Number of states is now {}"", count);
 				if (correctName) {
 					correctStateName(stateVertix);
@@ -113,7 +122,7 @@
 	private void correctStateName(StateVertex stateVertix) {
 		// the -1 is for the ""index"" state.
 		int totalNumberOfStates = this.getAllStates().size() - 1;
-		String correctedName = makeStateName(totalNumberOfStates, stateVertix.isGuidedCrawling());
+		String correctedName = makeStateName(totalNumberOfStates);
 		if (!""index"".equals(stateVertix.getName())
 		        && !stateVertix.getName().equals(correctedName)) {
 			LOG.info(""Correcting state name from {}  to {}"", stateVertix.getName(), correctedName);
@@ -122,6 +131,19 @@
 	}
 
 	/**
+	 * @param id
+	 *            The ID of the state
+	 * @return The state if found or <code>null</code>.
+	 */
+	public StateVertex getById(int id) {
+		return stateById.get(id);
+	}
+
+	public StateVertex getInitialState() {
+		return stateById.get(StateVertex.INDEX_ID);
+	}
+
+	/**
 	 * Adds the specified edge to this graph, going from the source vertex to the target vertex.
 	 * More formally, adds the specified edge, e, to this graph if this graph contains no edge e2
 	 * such that e2.equals(e). If this graph already contains such an edge, the call leaves this
@@ -238,8 +260,8 @@
 	 *            the end state.
 	 * @return a list of shortest path of clickables from the state to the end
 	 */
-	public List<Eventable> getShortestPath(StateVertex start, StateVertex end) {
-		return DijkstraShortestPath.findPathBetween(sfg, start, end);
+	public ImmutableList<Eventable> getShortestPath(StateVertex start, StateVertex end) {
+		return ImmutableList.copyOf(DijkstraShortestPath.findPathBetween(sfg, start, end));
 	}
 
 	/**
@@ -371,11 +393,15 @@
 	 * 
 	 * @return State name the name of the state
 	 */
-	public String getNewStateName() {
-		String state = makeStateName(nextStateNameCounter.incrementAndGet(), false);
+	public String getNewStateName(int id) {
+		String state = makeStateName(id);
 		return state;
 	}
 
+	public int getNextStateId() {
+		return nextStateNameCounter.incrementAndGet();
+	}
+
 	/**
 	 * Make a new state name given its id. Separated to get a central point when changing the names
 	 * of states. The automatic state names start with ""state"" and guided ones with ""guide"".
@@ -384,23 +410,15 @@
 	 *            the id where this name needs to be for.
 	 * @return the String containing the new name.
 	 */
-	private String makeStateName(int id, boolean guided) {
-
-		if (guided) {
-			return ""guided"" + id;
-		}
-
+	private String makeStateName(int id) {
 		return ""state"" + id;
 	}
 
-	public boolean isInitialState(StateVertex state) {
-		return initialState.equals(state);
-	}
-
 	/**
 	 * @return The number of states, currently in the graph.
 	 */
 	public int getNumberOfStates() {
 		return stateCounter.get();
 	}
+
 }
"
913b9721b6d40c684855c9ddb6bfc5f2745fb8f0,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index aef2647..5551a72 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -8,6 +8,7 @@
 import java.util.Arrays;
 import java.util.List;
 
+import javax.inject.Inject;
 import javax.xml.xpath.XPathExpressionException;
 
 import org.slf4j.Logger;
@@ -20,10 +21,11 @@
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.CandidateElement;
-import com.crawljax.core.configuration.InputSpecification;
+import com.crawljax.core.configuration.CrawlRules;
 import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.util.DomUtils;
 import com.crawljax.util.XPathHelper;
+import com.google.inject.assistedinject.Assisted;
 
 /**
  * Handles form values and fills in the form input elements with random values of the defined
@@ -39,7 +41,7 @@
 
 	private static final double HALF = 0.5;
 
-	private FormInputValueHelper formInputValueHelper;
+	private final FormInputValueHelper formInputValueHelper;
 
 	/**
 	 * Public constructor.
@@ -51,10 +53,12 @@
 	 * @param randomInput
 	 *            if random data should be generated on the input fields.
 	 */
-	public FormHandler(EmbeddedBrowser browser, InputSpecification inputSpecification,
-	        boolean randomInput) {
+	@Inject
+	public FormHandler(@Assisted EmbeddedBrowser browser, CrawlRules config) {
 		this.browser = browser;
-		this.formInputValueHelper = new FormInputValueHelper(inputSpecification, randomInput);
+		this.formInputValueHelper =
+		        new FormInputValueHelper(config.getInputSpecification(),
+		                config.isRandomInputInForms());
 	}
 
 	private static final String[] ALLOWED_INPUT_TYPES =
"
1c6c6e1c7f7dabe8c5276fe113866ba6d6f01b34,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 2e54c1c..bb10305 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -51,12 +51,6 @@
 import com.crawljax.util.DomUtils;
 import com.google.common.collect.ImmutableSortedSet;
 
-/**
- * @author mesbah
- * @author Frank Groeneveld
- * @version $Id: WebDriverBackedEmbeddedBrowser.java 387 2010-07-13 13:55:49Z slenselink@google.com
- *          $
- */
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
 	private long crawlWaitEvent;
 	private static final Logger LOGGER = LoggerFactory
"
1c6c6e1c7f7dabe8c5276fe113866ba6d6f01b34,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index bfd9ba1..bf6584f 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -2,8 +2,10 @@
 
 import static com.google.common.base.Preconditions.checkArgument;
 
+import java.io.UnsupportedEncodingException;
 import java.net.MalformedURLException;
 import java.net.URL;
+import java.net.URLEncoder;
 import java.util.concurrent.TimeUnit;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
@@ -38,6 +40,33 @@
 		}
 
 		/**
+		 * If the website uses <a
+		 * href=""http://en.wikipedia.org/wiki/Basic_access_authentication"">Basic auth</a> you can
+		 * set the username and password here.
+		 * 
+		 * @param username
+		 *            The username for the website.
+		 * @param password
+		 *            The password for the website.
+		 * @return {@link CrawljaxConfigurationBuilder} for method chaining.
+		 */
+		public CrawljaxConfigurationBuilder setBasicAuth(String username, String password) {
+			try {
+				String encodedUsername = URLEncoder.encode(username, ""UTF-8"");
+				String encodedPassword = URLEncoder.encode(password, ""UTF-8"");
+				config.url =
+				        new URL(config.url.getProtocol()
+				                + ""://"" + encodedUsername
+				                + "":"" + encodedPassword + ""@"" + config.url.getAuthority()
+				                + config.url.getPath());
+				System.out.println(""URL "" + config.url);
+			} catch (UnsupportedEncodingException | MalformedURLException e) {
+				throw new CrawljaxException(""Could not parse the username/password to a URL"", e);
+			}
+			return this;
+		}
+
+		/**
 		 * @param states
 		 *            The maximum number of states the Crawler should crawl. The default is
 		 *            unlimited.
"
c38a2ca7ded747d1285bd9f8b5aad74bbe75bdf0,Alex Nederlof,RunWithWebServer.java,MODIFY,newConfigBuilder -> [String context] | [],"diff --git a/core/src/test/java/com/crawljax/test/RunWithWebServer.java b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
index d61980e..68ee936 100644
--- a/core/src/test/java/com/crawljax/test/RunWithWebServer.java
+++ b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
@@ -38,6 +38,11 @@
 		this.started = true;
 	}
 
+	/**
+	 * Override this method to configure custom server settings.
+	 * 
+	 * @return a {@link Server}.
+	 */
 	protected Server newWebServer() {
 		Server server = new Server(0);
 		ResourceHandler handler = new ResourceHandler();
"
4ce2c6d417714be64cf0c158a6d2335edc65d89e,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 2e54c1c..bb10305 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -51,12 +51,6 @@
 import com.crawljax.util.DomUtils;
 import com.google.common.collect.ImmutableSortedSet;
 
-/**
- * @author mesbah
- * @author Frank Groeneveld
- * @version $Id: WebDriverBackedEmbeddedBrowser.java 387 2010-07-13 13:55:49Z slenselink@google.com
- *          $
- */
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
 	private long crawlWaitEvent;
 	private static final Logger LOGGER = LoggerFactory
"
4ce2c6d417714be64cf0c158a6d2335edc65d89e,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index bfd9ba1..bf6584f 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -2,8 +2,10 @@
 
 import static com.google.common.base.Preconditions.checkArgument;
 
+import java.io.UnsupportedEncodingException;
 import java.net.MalformedURLException;
 import java.net.URL;
+import java.net.URLEncoder;
 import java.util.concurrent.TimeUnit;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
@@ -38,6 +40,33 @@
 		}
 
 		/**
+		 * If the website uses <a
+		 * href=""http://en.wikipedia.org/wiki/Basic_access_authentication"">Basic auth</a> you can
+		 * set the username and password here.
+		 * 
+		 * @param username
+		 *            The username for the website.
+		 * @param password
+		 *            The password for the website.
+		 * @return {@link CrawljaxConfigurationBuilder} for method chaining.
+		 */
+		public CrawljaxConfigurationBuilder setBasicAuth(String username, String password) {
+			try {
+				String encodedUsername = URLEncoder.encode(username, ""UTF-8"");
+				String encodedPassword = URLEncoder.encode(password, ""UTF-8"");
+				config.url =
+				        new URL(config.url.getProtocol()
+				                + ""://"" + encodedUsername
+				                + "":"" + encodedPassword + ""@"" + config.url.getAuthority()
+				                + config.url.getPath());
+				System.out.println(""URL "" + config.url);
+			} catch (UnsupportedEncodingException | MalformedURLException e) {
+				throw new CrawljaxException(""Could not parse the username/password to a URL"", e);
+			}
+			return this;
+		}
+
+		/**
 		 * @param states
 		 *            The maximum number of states the Crawler should crawl. The default is
 		 *            unlimited.
"
4ce2c6d417714be64cf0c158a6d2335edc65d89e,Ali Mesbah,RunWithWebServer.java,MODIFY,newConfigBuilder -> [String context] | [],"diff --git a/core/src/test/java/com/crawljax/test/RunWithWebServer.java b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
index f64d1f8..68ee936 100644
--- a/core/src/test/java/com/crawljax/test/RunWithWebServer.java
+++ b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
@@ -31,16 +31,26 @@
 
 	@Override
 	public void before() throws Exception {
-		server = new Server(0);
-		ResourceHandler handler = new ResourceHandler();
-		handler.setBaseResource(resource);
-		server.setHandler(handler);
+		server = newWebServer();
 		server.start();
 		this.port = ((ServerConnector) server.getConnectors()[0]).getLocalPort();
 		this.demoSite = new URL(""http"", ""localhost"", port, ""/"");
 		this.started = true;
 	}
 
+	/**
+	 * Override this method to configure custom server settings.
+	 * 
+	 * @return a {@link Server}.
+	 */
+	protected Server newWebServer() {
+		Server server = new Server(0);
+		ResourceHandler handler = new ResourceHandler();
+		handler.setBaseResource(resource);
+		server.setHandler(handler);
+		return server;
+	}
+
 	@Override
 	public void after() {
 		try {
"
304f75e944d6180cd5fbdc8545cbc83519fe380c,Alex Nederlof,StateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index 1312ab2..5b3c9fd 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -164,13 +164,10 @@
 	 */
 	@GuardedBy(""sfg"")
 	public boolean addEdge(StateVertex sourceVert, StateVertex targetVert, Eventable clickable) {
+		clickable.setSource(sourceVert);
+		clickable.setTarget(targetVert);
 		synchronized (sfg) {
-			if (sfg.containsEdge(sourceVert, targetVert)
-			        && sfg.getAllEdges(sourceVert, targetVert).contains(clickable)) {
-				return false;
-			} else {
-				return sfg.addEdge(sourceVert, targetVert, clickable);
-			}
+			return sfg.addEdge(sourceVert, targetVert, clickable);
 		}
 	}
 
"
304f75e944d6180cd5fbdc8545cbc83519fe380c,Alex Nederlof,StateVertex.java,MODIFY,equals -> [Object obj] | [Object object],"diff --git a/core/src/main/java/com/crawljax/core/state/StateVertex.java b/core/src/main/java/com/crawljax/core/state/StateVertex.java
index e6b6d5d..a936ac2 100644
--- a/core/src/main/java/com/crawljax/core/state/StateVertex.java
+++ b/core/src/main/java/com/crawljax/core/state/StateVertex.java
@@ -4,12 +4,10 @@
 import java.io.Serializable;
 import java.util.Collection;
 
-import org.apache.commons.lang.builder.EqualsBuilder;
-import org.apache.commons.lang.builder.HashCodeBuilder;
 import org.w3c.dom.Document;
 
 import com.crawljax.util.DomUtils;
-import com.google.common.base.Strings;
+import com.google.common.base.Objects;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Queues;
 
@@ -108,54 +106,26 @@
 		return url;
 	}
 
-	/**
-	 * Returns a hashcode. Uses reflection to determine the fields to test.
-	 * 
-	 * @return the hashCode of this StateVertex
-	 */
 	@Override
 	public int hashCode() {
-		HashCodeBuilder builder = new HashCodeBuilder();
-		if (Strings.isNullOrEmpty(strippedDom)) {
-			builder.append(dom);
-		} else {
-			builder.append(strippedDom);
-		}
-
-		return builder.toHashCode();
+		return Objects.hashCode(strippedDom);
 	}
 
-	/**
-	 * Compare this vertex to a other StateVertex.
-	 * 
-	 * @param obj
-	 *            the Object to compare this vertex
-	 * @return Return true if equal. Uses reflection.
-	 * @see java.lang.Object#equals(java.lang.Object)
-	 */
 	@Override
-	public boolean equals(Object obj) {
-		if (!(obj instanceof StateVertex)) {
-			return false;
+	public boolean equals(Object object) {
+		if (object instanceof StateVertex) {
+			StateVertex that = (StateVertex) object;
+			return Objects.equal(this.strippedDom, that.strippedDom);
 		}
-
-		if (this == obj) {
-			return true;
-		}
-		final StateVertex rhs = (StateVertex) obj;
-
-		return new EqualsBuilder().append(this.strippedDom, rhs.getStrippedDom())
-		        .isEquals();
+		return false;
 	}
 
-	/**
-	 * Returns the name of this state as string.
-	 * 
-	 * @return a string representation of the current StateVertex
-	 */
 	@Override
 	public String toString() {
-		return name;
+		return Objects.toStringHelper(this)
+		        .add(""id"", id)
+		        .add(""name"", name)
+		        .toString();
 	}
 
 	/**
"
601c80394b1f8f523efc19adeec7faee99295609,Alex Nederlof,StateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index 1312ab2..5b3c9fd 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -164,13 +164,10 @@
 	 */
 	@GuardedBy(""sfg"")
 	public boolean addEdge(StateVertex sourceVert, StateVertex targetVert, Eventable clickable) {
+		clickable.setSource(sourceVert);
+		clickable.setTarget(targetVert);
 		synchronized (sfg) {
-			if (sfg.containsEdge(sourceVert, targetVert)
-			        && sfg.getAllEdges(sourceVert, targetVert).contains(clickable)) {
-				return false;
-			} else {
-				return sfg.addEdge(sourceVert, targetVert, clickable);
-			}
+			return sfg.addEdge(sourceVert, targetVert, clickable);
 		}
 	}
 
"
c04ca499d9a99de5329cfe52817a1aa012509485,Alex Nederlof,InMemoryStateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
index 86206ac..2475515 100644
--- a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
@@ -3,6 +3,9 @@
 import java.io.Serializable;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.atomic.AtomicInteger;
+import java.util.concurrent.locks.Lock;
+import java.util.concurrent.locks.ReadWriteLock;
+import java.util.concurrent.locks.ReentrantReadWriteLock;
 
 import javax.inject.Inject;
 import javax.inject.Singleton;
@@ -31,6 +34,8 @@
 	        .getName());
 
 	private final DirectedGraph<StateVertex, Eventable> sfg;
+	private final Lock readLock;
+	private final Lock writeLock;
 
 	/**
 	 * Intermediate counter for the number of states, not relaying on getAllStates.size() because of
@@ -39,7 +44,6 @@
 	private final AtomicInteger stateCounter = new AtomicInteger();
 	private final AtomicInteger nextStateNameCounter = new AtomicInteger();
 	private final ConcurrentMap<Integer, StateVertex> stateById;
-
 	private final ExitNotifier exitNotifier;
 
 	/**
@@ -54,6 +58,9 @@
 		sfg = new DirectedMultigraph<>(Eventable.class);
 		stateById = Maps.newConcurrentMap();
 		LOG.debug(""Initialized the stateflowgraph"");
+		ReadWriteLock lock = new ReentrantReadWriteLock();
+		readLock = lock.readLock();
+		writeLock = lock.writeLock();
 	}
 
 	/**
@@ -91,7 +98,8 @@
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
 	public StateVertex putIfAbsent(StateVertex stateVertix, boolean correctName) {
-		synchronized (sfg) {
+		writeLock.lock();
+		try {
 			boolean added = sfg.addVertex(stateVertix);
 			if (added) {
 				stateById.put(stateVertix.getId(), stateVertix);
@@ -107,6 +115,8 @@
 				LOG.debug(""Graph already contained vertex {}"", stateVertix);
 				return this.getStateInGraph(stateVertix);
 			}
+		} finally {
+			writeLock.unlock();
 		}
 	}
 
@@ -151,73 +161,117 @@
 	 * @see org.jgrapht.Graph#addEdge(Object, Object, Object)
 	 */
 	public boolean addEdge(StateVertex sourceVert, StateVertex targetVert, Eventable clickable) {
-		synchronized (sfg) {
+		writeLock.lock();
+		try {
 			if (sfg.containsEdge(sourceVert, targetVert)
 			        && sfg.getAllEdges(sourceVert, targetVert).contains(clickable)) {
 				return false;
 			} else {
 				return sfg.addEdge(sourceVert, targetVert, clickable);
 			}
+		} finally {
+			writeLock.unlock();
 		}
 	}
 
 	@Override
 	public String toString() {
-		synchronized (sfg) {
+		readLock.lock();
+		try {
 			return sfg.toString();
+		} finally {
+			readLock.unlock();
 		}
 	}
 
 	@Override
 	public ImmutableSet<Eventable> getOutgoingClickables(StateVertex stateVertix) {
-		return ImmutableSet.copyOf(sfg.outgoingEdgesOf(stateVertix));
+		readLock.lock();
+		try {
+			return ImmutableSet.copyOf(sfg.outgoingEdgesOf(stateVertix));
+		} finally {
+			readLock.unlock();
+		}
 	}
 
 	@Override
 	public ImmutableSet<Eventable> getIncomingClickable(StateVertex stateVertix) {
-		return ImmutableSet.copyOf(sfg.incomingEdgesOf(stateVertix));
+		readLock.lock();
+		try {
+			return ImmutableSet.copyOf(sfg.incomingEdgesOf(stateVertix));
+		} finally {
+			readLock.unlock();
+		}
 	}
 
 	@Override
 	public boolean canGoTo(StateVertex source, StateVertex target) {
-		synchronized (sfg) {
+		readLock.lock();
+		try {
 			return sfg.containsEdge(source, target) || sfg.containsEdge(target, source);
+		} finally {
+			readLock.unlock();
 		}
 	}
 
 	@Override
 	public ImmutableList<Eventable> getShortestPath(StateVertex start, StateVertex end) {
-		return ImmutableList.copyOf(DijkstraShortestPath.findPathBetween(sfg, start, end));
+		readLock.lock();
+		try {
+			return ImmutableList.copyOf(DijkstraShortestPath.findPathBetween(sfg, start, end));
+		} finally {
+			readLock.unlock();
+		}
 	}
 
 	@Override
 	public ImmutableSet<StateVertex> getAllStates() {
-		return ImmutableSet.copyOf(sfg.vertexSet());
+		readLock.lock();
+		try {
+			return ImmutableSet.copyOf(sfg.vertexSet());
+		} finally {
+			readLock.unlock();
+		}
 	}
 
 	@Override
 	public ImmutableSet<Eventable> getAllEdges() {
-		return ImmutableSet.copyOf(sfg.edgeSet());
+		readLock.lock();
+		try {
+			return ImmutableSet.copyOf(sfg.edgeSet());
+		} finally {
+			readLock.unlock();
+		}
 	}
 
 	private StateVertex getStateInGraph(StateVertex state) {
-		for (StateVertex st : sfg.vertexSet()) {
-			if (state.equals(st)) {
-				return st;
+		readLock.lock();
+		try {
+			for (StateVertex st : sfg.vertexSet()) {
+				if (state.equals(st)) {
+					return st;
+				}
 			}
+			return null;
+		} finally {
+			readLock.unlock();
 		}
-		return null;
 	}
 
 	@Override
 	public int getMeanStateStringSize() {
-		final Mean mean = new Mean();
+		readLock.lock();
+		try {
+			final Mean mean = new Mean();
 
-		for (StateVertex state : sfg.vertexSet()) {
-			mean.increment(state.getDomSize());
+			for (StateVertex state : sfg.vertexSet()) {
+				mean.increment(state.getDomSize());
+			}
+
+			return (int) mean.getResult();
+		} finally {
+			readLock.unlock();
 		}
-
-		return (int) mean.getResult();
 	}
 
 	/**
"
d41f3674d178dacbc176514aea643a3b90c47564,Alex Nederlof,InMemoryStateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
index 2475515..0492b6f 100644
--- a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
@@ -81,6 +81,10 @@
 		return putIfAbsent(stateVertix, true);
 	}
 
+	public StateVertex putIndex(StateVertex index) {
+		return putIfAbsent(index, false);
+	}
+
 	/**
 	 * Adds a state (as a vertix) to the State-Flow Graph if not already present. More formally,
 	 * adds the specified vertex, v, to this graph if this graph contains no vertex u such that
@@ -97,7 +101,7 @@
 	 * @return the clone if one is detected <code>null</code> otherwise.
 	 * @see org.jgrapht.Graph#addVertex(Object)
 	 */
-	public StateVertex putIfAbsent(StateVertex stateVertix, boolean correctName) {
+	private StateVertex putIfAbsent(StateVertex stateVertix, boolean correctName) {
 		writeLock.lock();
 		try {
 			boolean added = sfg.addVertex(stateVertix);
@@ -106,12 +110,9 @@
 				int count = stateCounter.incrementAndGet();
 				exitNotifier.incrementNumberOfStates();
 				LOG.debug(""Number of states is now {}"", count);
-				if (correctName) {
-					correctStateName(stateVertix);
-				}
 				return null;
 			} else {
-				// Graph already contained the vertix
+				// Graph already contained the vertex
 				LOG.debug(""Graph already contained vertex {}"", stateVertix);
 				return this.getStateInGraph(stateVertix);
 			}
@@ -120,17 +121,6 @@
 		}
 	}
 
-	private void correctStateName(StateVertex stateVertix) {
-		// the -1 is for the ""index"" state.
-		int totalNumberOfStates = this.getAllStates().size() - 1;
-		String correctedName = getNewStateName(totalNumberOfStates);
-		if (!""index"".equals(stateVertix.getName())
-		        && !stateVertix.getName().equals(correctedName)) {
-			LOG.info(""Correcting state name from {}  to {}"", stateVertix.getName(), correctedName);
-			stateVertix.setName(correctedName);
-		}
-	}
-
 	@Override
 	public StateVertex getById(int id) {
 		return stateById.get(id);
@@ -265,7 +255,7 @@
 			final Mean mean = new Mean();
 
 			for (StateVertex state : sfg.vertexSet()) {
-				mean.increment(state.getDomSize());
+				mean.increment(state.getDom().getBytes().length);
 			}
 
 			return (int) mean.getResult();
@@ -274,22 +264,18 @@
 		}
 	}
 
-	/**
-	 * Return the name of the (new)State. By using the AtomicInteger the stateCounter is thread-safe
-	 * 
-	 * @return State name the name of the state
-	 */
-	String getNewStateName(int id) {
-		return ""state"" + id;
-	}
-
-	int getNextStateId() {
-		return nextStateNameCounter.incrementAndGet();
-	}
-
 	@Override
 	public int getNumberOfStates() {
 		return stateCounter.get();
 	}
 
+	StateVertex newStateFor(String url, String dom, String strippedDom) {
+		int id = nextStateNameCounter.incrementAndGet();
+		return new StateVertex(id, url, getNewStateName(id), dom, strippedDom);
+	}
+
+	private String getNewStateName(int id) {
+		return ""state"" + id;
+	}
+
 }
"
d41f3674d178dacbc176514aea643a3b90c47564,Alex Nederlof,StateVertex.java,MODIFY,equals -> [Object object] | [Object obj],"diff --git a/core/src/main/java/com/crawljax/core/state/StateVertex.java b/core/src/main/java/com/crawljax/core/state/StateVertex.java
index e6b6d5d..d21fa68 100644
--- a/core/src/main/java/com/crawljax/core/state/StateVertex.java
+++ b/core/src/main/java/com/crawljax/core/state/StateVertex.java
@@ -9,6 +9,7 @@
 import org.w3c.dom.Document;
 
 import com.crawljax.util.DomUtils;
+import com.google.common.annotations.VisibleForTesting;
 import com.google.common.base.Strings;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Queues;
@@ -28,20 +29,10 @@
 
 	private final Collection<Eventable> foundEventables;
 	private final int id;
-	private String name;
-	private String dom;
+	private final String dom;
 	private final String strippedDom;
 	private final String url;
-
-	/**
-	 * Default constructor to support saving instances of this class as an XML.
-	 */
-	public StateVertex(int id) {
-		this.id = id;
-		this.strippedDom = """";
-		this.url = """";
-		foundEventables = Queues.newConcurrentLinkedQueue();
-	}
+	private String name;
 
 	/**
 	 * Creates a current state without an url and the stripped dom equals the dom.
@@ -51,7 +42,8 @@
 	 * @param dom
 	 *            the current DOM tree of the browser
 	 */
-	public StateVertex(int id, String name, String dom) {
+	@VisibleForTesting
+	StateVertex(int id, String name, String dom) {
 		this(id, null, name, dom, dom);
 	}
 
@@ -159,15 +151,6 @@
 	}
 
 	/**
-	 * Return the size of the DOM in bytes.
-	 * 
-	 * @return the size of the dom
-	 */
-	public int getDomSize() {
-		return getDom().getBytes().length;
-	}
-
-	/**
 	 * @return the id. This is guaranteed to be unique per state.
 	 */
 	public int getId() {
@@ -175,22 +158,6 @@
 	}
 
 	/**
-	 * @param name
-	 *            the name to set
-	 */
-	public void setName(String name) {
-		this.name = name;
-	}
-
-	/**
-	 * @param dom
-	 *            the dom to set
-	 */
-	public void setDom(String dom) {
-		this.dom = dom;
-	}
-
-	/**
 	 * @return a Document instance of the dom string.
 	 * @throws IOException
 	 *             if an exception is thrown.
"
80d9914e4914d689d3fb7d9c98d501f7346434f4,Alex Nederlof,InMemoryStateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
index 0492b6f..a0e3287 100644
--- a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
@@ -150,7 +150,8 @@
 	 * @return true if this graph did not already contain the specified edge.
 	 * @see org.jgrapht.Graph#addEdge(Object, Object, Object)
 	 */
-	public boolean addEdge(StateVertex sourceVert, StateVertex targetVert, Eventable clickable) {
+	public boolean addEdge(StateVertex sourceVert, StateVertex targetVert,
+	        Eventable clickable) {
 		writeLock.lock();
 		try {
 			if (sfg.containsEdge(sourceVert, targetVert)
@@ -271,7 +272,7 @@
 
 	StateVertex newStateFor(String url, String dom, String strippedDom) {
 		int id = nextStateNameCounter.incrementAndGet();
-		return new StateVertex(id, url, getNewStateName(id), dom, strippedDom);
+		return new StateVertexImpl(id, url, getNewStateName(id), dom, strippedDom);
 	}
 
 	private String getNewStateName(int id) {
"
06902a0a909a8ab3107435a124c722a5770cb0ef,Alex Nederlof,StateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
index 1312ab2..5b3c9fd 100644
--- a/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/StateFlowGraph.java
@@ -164,13 +164,10 @@
 	 */
 	@GuardedBy(""sfg"")
 	public boolean addEdge(StateVertex sourceVert, StateVertex targetVert, Eventable clickable) {
+		clickable.setSource(sourceVert);
+		clickable.setTarget(targetVert);
 		synchronized (sfg) {
-			if (sfg.containsEdge(sourceVert, targetVert)
-			        && sfg.getAllEdges(sourceVert, targetVert).contains(clickable)) {
-				return false;
-			} else {
-				return sfg.addEdge(sourceVert, targetVert, clickable);
-			}
+			return sfg.addEdge(sourceVert, targetVert, clickable);
 		}
 	}
 
"
6dc3087b913421b1d53cb1eaab488332b9cd0a33,Alex Nederlof,InMemoryStateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
index a0e3287..51d7d4c 100644
--- a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
@@ -152,14 +152,11 @@
 	 */
 	public boolean addEdge(StateVertex sourceVert, StateVertex targetVert,
 	        Eventable clickable) {
+		clickable.setSource(sourceVert);
+		clickable.setTarget(targetVert);
 		writeLock.lock();
 		try {
-			if (sfg.containsEdge(sourceVert, targetVert)
-			        && sfg.getAllEdges(sourceVert, targetVert).contains(clickable)) {
-				return false;
-			} else {
-				return sfg.addEdge(sourceVert, targetVert, clickable);
-			}
+			return sfg.addEdge(sourceVert, targetVert, clickable);
 		} finally {
 			writeLock.unlock();
 		}
"
6dc3087b913421b1d53cb1eaab488332b9cd0a33,Alex Nederlof,StateVertexImpl.java,MODIFY,equals -> [Object obj] | [Object object],"diff --git a/core/src/main/java/com/crawljax/core/state/StateVertexImpl.java b/core/src/main/java/com/crawljax/core/state/StateVertexImpl.java
index a8c3a25..e8478b3 100644
--- a/core/src/main/java/com/crawljax/core/state/StateVertexImpl.java
+++ b/core/src/main/java/com/crawljax/core/state/StateVertexImpl.java
@@ -3,13 +3,11 @@
 import java.io.IOException;
 import java.util.Collection;
 
-import org.apache.commons.lang.builder.EqualsBuilder;
-import org.apache.commons.lang.builder.HashCodeBuilder;
 import org.w3c.dom.Document;
 
 import com.crawljax.util.DomUtils;
 import com.google.common.annotations.VisibleForTesting;
-import com.google.common.base.Strings;
+import com.google.common.base.Objects;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Queues;
 
@@ -83,42 +81,26 @@
 		return url;
 	}
 
-	/**
-	 * {@link #hashCode()} is done on the {@link #getStrippedDom()}.
-	 */
 	@Override
 	public int hashCode() {
-		HashCodeBuilder builder = new HashCodeBuilder();
-		if (Strings.isNullOrEmpty(strippedDom)) {
-			builder.append(dom);
-		} else {
-			builder.append(strippedDom);
-		}
-
-		return builder.toHashCode();
+		return Objects.hashCode(strippedDom);
 	}
 
-	/**
-	 * Equals is done on the {@link #getStrippedDom()}.
-	 */
 	@Override
-	public boolean equals(Object obj) {
-		if (!(obj instanceof StateVertex)) {
-			return false;
+	public boolean equals(Object object) {
+		if (object instanceof StateVertex) {
+			StateVertex that = (StateVertex) object;
+			return Objects.equal(this.strippedDom, that.getStrippedDom());
 		}
-
-		if (this == obj) {
-			return true;
-		}
-		final StateVertex rhs = (StateVertex) obj;
-
-		return new EqualsBuilder().append(this.strippedDom, rhs.getStrippedDom())
-		        .isEquals();
+		return false;
 	}
 
 	@Override
 	public String toString() {
-		return name;
+		return Objects.toStringHelper(this)
+		        .add(""id"", id)
+		        .add(""name"", name)
+		        .toString();
 	}
 
 	@Override
"
2f3d53977d4a30fc2aa939ff4c3d18b4e96c69bf,Alex Nederlof,InMemoryStateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
index 51d7d4c..ed77d35 100644
--- a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
@@ -1,6 +1,10 @@
 package com.crawljax.core.state;
 
 import java.io.Serializable;
+import java.util.ArrayList;
+import java.util.HashSet;
+import java.util.List;
+import java.util.Set;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.locks.Lock;
@@ -12,7 +16,9 @@
 
 import org.apache.commons.math.stat.descriptive.moment.Mean;
 import org.jgrapht.DirectedGraph;
+import org.jgrapht.GraphPath;
 import org.jgrapht.alg.DijkstraShortestPath;
+import org.jgrapht.alg.KShortestPaths;
 import org.jgrapht.graph.DirectedMultigraph;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -20,7 +26,9 @@
 import com.crawljax.core.ExitNotifier;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.ImmutableSet;
+import com.google.common.collect.Lists;
 import com.google.common.collect.Maps;
+import com.google.common.collect.Sets;
 
 /**
  * The State-Flow Graph is a multi-edge directed graph with states (StateVetex) on the vertices and
@@ -276,4 +284,76 @@
 		return ""state"" + id;
 	}
 
+	@Override
+	public List<List<GraphPath<StateVertex, Eventable>>> getAllPossiblePaths(StateVertex index) {
+		final List<List<GraphPath<StateVertex, Eventable>>> results = Lists.newArrayList();
+
+		final KShortestPaths<StateVertex, Eventable> kPaths =
+		        new KShortestPaths<>(this.sfg, index, Integer.MAX_VALUE);
+
+		for (StateVertex state : getDeepStates(index)) {
+			List<GraphPath<StateVertex, Eventable>> paths = kPaths.getPaths(state);
+			results.add(paths);
+		}
+
+		return results;
+	}
+
+	/**
+	 * @param state
+	 *            The starting state.
+	 * @return A list of the deepest states (states with no outgoing edges).
+	 */
+	private List<StateVertex> getDeepStates(StateVertex state) {
+		final List<StateVertex> deepStates = new ArrayList<StateVertex>();
+
+		traverse(Sets.<String> newHashSet(), deepStates, state);
+
+		return deepStates;
+	}
+
+	private void traverse(Set<String> visitedStates, List<StateVertex> deepStates,
+	        StateVertex state) {
+		visitedStates.add(state.getName());
+
+		Set<StateVertex> outgoingSet = getOutgoingStates(state);
+
+		if ((outgoingSet == null) || outgoingSet.isEmpty()) {
+			deepStates.add(state);
+		} else {
+			if (cyclic(visitedStates, outgoingSet)) {
+				deepStates.add(state);
+			} else {
+				for (StateVertex st : outgoingSet) {
+					if (!visitedStates.contains(st.getName())) {
+						traverse(visitedStates, deepStates, st);
+					}
+				}
+			}
+		}
+	}
+
+	private boolean cyclic(Set<String> visitedStates, Set<StateVertex> outgoingSet) {
+		int i = 0;
+
+		for (StateVertex state : outgoingSet) {
+			if (visitedStates.contains(state.getName())) {
+				i++;
+			}
+		}
+
+		return i == outgoingSet.size();
+	}
+
+	@Override
+	public ImmutableSet<StateVertex> getOutgoingStates(StateVertex stateVertix) {
+		final Set<StateVertex> result = new HashSet<>();
+
+		for (Eventable c : getOutgoingClickables(stateVertix)) {
+			result.add(sfg.getEdgeTarget(c));
+		}
+
+		return ImmutableSet.copyOf(result);
+	}
+
 }
"
12cd571f664bf64156bb057b1aa9936c9947a89a,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index b680e39..bb10305 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -26,6 +26,7 @@
 import org.openqa.selenium.io.FileHandler;
 import org.openqa.selenium.remote.Augmenter;
 import org.openqa.selenium.remote.DesiredCapabilities;
+import org.openqa.selenium.remote.ErrorHandler.UnknownServerException;
 import org.openqa.selenium.remote.HttpCommandExecutor;
 import org.openqa.selenium.remote.RemoteWebDriver;
 import org.openqa.selenium.support.ui.Select;
@@ -50,12 +51,6 @@
 import com.crawljax.util.DomUtils;
 import com.google.common.collect.ImmutableSortedSet;
 
-/**
- * @author mesbah
- * @author Frank Groeneveld
- * @version $Id: WebDriverBackedEmbeddedBrowser.java 387 2010-07-13 13:55:49Z slenselink@google.com
- *          $
- */
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
 	private long crawlWaitEvent;
 	private static final Logger LOGGER = LoggerFactory
@@ -269,7 +264,8 @@
 			throwIfConnectionException(e);
 			return;
 		} catch (InterruptedException e) {
-			LOGGER.error(""goToUrl got interrupted while waiting for the page to be loaded"", e);
+			LOGGER.debug(""goToUrl got interrupted while waiting for the page to be loaded"", e);
+			Thread.currentThread().interrupt();
 			return;
 		}
 	}
@@ -295,9 +291,11 @@
 	 * @param eventable
 	 *            The HTML event type (onclick, onmouseover, ...).
 	 * @return true if firing event is successful.
+	 * @throws InterruptedException
+	 *             when interrupted during the wait.
 	 */
-	protected boolean fireEventWait(WebElement webElement, Eventable eventable)
-	        throws ElementNotVisibleException {
+	private boolean fireEventWait(WebElement webElement, Eventable eventable)
+	        throws ElementNotVisibleException, InterruptedException {
 		switch (eventable.getEventType()) {
 			case click:
 				try {
@@ -317,12 +315,7 @@
 				return false;
 		}
 
-		try {
-			Thread.sleep(this.crawlWaitEvent);
-		} catch (InterruptedException e) {
-			LOGGER.error(""fireEventWait got interrupted during wait process"", e);
-			return false;
-		}
+		Thread.sleep(this.crawlWaitEvent);
 		return true;
 	}
 
@@ -333,8 +326,14 @@
 			// close browser and close every associated window.
 			browser.quit();
 		} catch (WebDriverException e) {
+			if (e.getCause() instanceof InterruptedException) {
+				LOGGER.info(""Interrupted while waiting for the browser to close. It might not close correctly"");
+				Thread.currentThread().interrupt();
+				return;
+			}
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
+		LOGGER.debug(""Browser closed..."");
 	}
 
 	@Override
@@ -430,10 +429,13 @@
 	 * @param eventable
 	 *            The eventable.
 	 * @return true if it is able to fire the event successfully on the element.
+	 * @throws InterruptedException
+	 *             when interrupted during the wait.
 	 */
 	@Override
-	public synchronized boolean fireEvent(Eventable eventable) throws ElementNotVisibleException,
-	        NoSuchElementException {
+	public synchronized boolean fireEventAndWait(Eventable eventable)
+	        throws ElementNotVisibleException,
+	        NoSuchElementException, InterruptedException {
 		try {
 
 			boolean handleChanged = false;
@@ -534,9 +536,8 @@
 			String current = browser.getWindowHandle();
 			for (String handle : browser.getWindowHandles()) {
 				if (!handle.equals(browser.getWindowHandle())) {
-
 					browser.switchTo().window(handle);
-					LOGGER.info(""Closing other window with title \"""" + browser.getTitle() + ""\"""");
+					LOGGER.debug(""Closing other window with title \""{}\"""", browser.getTitle());
 					browser.close();
 					browser.switchTo().window(current);
 				}
@@ -584,43 +585,50 @@
 		}
 
 		for (int i = 0; i < nodeList.size(); i++) {
-			String frameIdentification = """";
-
-			if (topFrame != null && !topFrame.equals("""")) {
-				frameIdentification += topFrame + ""."";
+			try {
+				locateFrameAndgetSource(document, topFrame, nodeList.get(i));
+			} catch (UnknownServerException e) {
+				LOGGER.warn(""Could not add frame contents for element {}"", nodeList.get(i));
+				LOGGER.debug(""Could not load frame because of {}"", e.getMessage(), e);
 			}
+		}
+	}
 
-			Element frameElement = nodeList.get(i);
+	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement) {
+		String frameIdentification = """";
 
-			String nameId = DomUtils.getFrameIdentification(frameElement);
+		if (topFrame != null && !topFrame.equals("""")) {
+			frameIdentification += topFrame + ""."";
+		}
 
-			if (nameId != null
-			        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
-				frameIdentification += nameId;
+		String nameId = DomUtils.getFrameIdentification(frameElement);
 
-				String handle = browser.getWindowHandle();
+		if (nameId != null
+		        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
+			frameIdentification += nameId;
 
-				LOGGER.debug(""The current H: "" + handle);
+			String handle = browser.getWindowHandle();
 
-				switchToFrame(frameIdentification);
+			LOGGER.debug(""The current H: "" + handle);
 
-				String toAppend = browser.getPageSource();
+			switchToFrame(frameIdentification);
 
-				LOGGER.debug(""frame dom: "" + toAppend);
+			String toAppend = browser.getPageSource();
 
-				browser.switchTo().defaultContent();
+			LOGGER.debug(""frame dom: "" + toAppend);
 
-				try {
-					Element toAppendElement = DomUtils.asDocument(toAppend).getDocumentElement();
-					Element importedElement =
-					        (Element) document.importNode(toAppendElement, true);
-					frameElement.appendChild(importedElement);
+			browser.switchTo().defaultContent();
 
-					appendFrameContent(importedElement, document, frameIdentification);
-				} catch (DOMException | IOException e) {
-					LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-					        + "" continuing..."", e);
-				}
+			try {
+				Element toAppendElement = DomUtils.asDocument(toAppend).getDocumentElement();
+				Element importedElement =
+				        (Element) document.importNode(toAppendElement, true);
+				frameElement.appendChild(importedElement);
+
+				appendFrameContent(importedElement, document, frameIdentification);
+			} catch (DOMException | IOException e) {
+				LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
+				        + "" continuing..."", e);
 			}
 		}
 	}
"
12cd571f664bf64156bb057b1aa9936c9947a89a,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index b40d407..bf6584f 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -2,24 +2,30 @@
 
 import static com.google.common.base.Preconditions.checkArgument;
 
+import java.io.UnsupportedEncodingException;
 import java.net.MalformedURLException;
 import java.net.URL;
+import java.net.URLEncoder;
 import java.util.concurrent.TimeUnit;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
+import com.crawljax.core.CrawlController;
 import com.crawljax.core.Crawler;
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.core.plugin.Plugins;
+import com.crawljax.di.CoreModule;
 import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
+import com.google.inject.Guice;
+import com.google.inject.Injector;
 
 /**
  * Configures the {@link Crawler}. Set it up using the {@link #builderFor(String)} function.
  */
-public final class CrawljaxConfiguration {
+public class CrawljaxConfiguration {
 
 	public static class CrawljaxConfigurationBuilder {
 
@@ -34,6 +40,33 @@
 		}
 
 		/**
+		 * If the website uses <a
+		 * href=""http://en.wikipedia.org/wiki/Basic_access_authentication"">Basic auth</a> you can
+		 * set the username and password here.
+		 * 
+		 * @param username
+		 *            The username for the website.
+		 * @param password
+		 *            The password for the website.
+		 * @return {@link CrawljaxConfigurationBuilder} for method chaining.
+		 */
+		public CrawljaxConfigurationBuilder setBasicAuth(String username, String password) {
+			try {
+				String encodedUsername = URLEncoder.encode(username, ""UTF-8"");
+				String encodedPassword = URLEncoder.encode(password, ""UTF-8"");
+				config.url =
+				        new URL(config.url.getProtocol()
+				                + ""://"" + encodedUsername
+				                + "":"" + encodedPassword + ""@"" + config.url.getAuthority()
+				                + config.url.getPath());
+				System.out.println(""URL "" + config.url);
+			} catch (UnsupportedEncodingException | MalformedURLException e) {
+				throw new CrawljaxException(""Could not parse the username/password to a URL"", e);
+			}
+			return this;
+		}
+
+		/**
 		 * @param states
 		 *            The maximum number of states the Crawler should crawl. The default is
 		 *            unlimited.
@@ -82,7 +115,7 @@
 		}
 
 		/**
-		 * Set the crawl depth to unlimited.
+		 * Set the crawl depth to unlimited. The default depth is <code>2</code>.
 		 */
 		public CrawljaxConfigurationBuilder setUnlimitedCrawlDepth() {
 			config.maximumDepth = 0;
@@ -139,6 +172,11 @@
 			return config;
 		}
 
+		public CrawlController buildControl() {
+			Injector injector = Guice.createInjector(new CoreModule(build()));
+			return injector.getInstance(CrawlController.class);
+		}
+
 	}
 
 	/**
"
12cd571f664bf64156bb057b1aa9936c9947a89a,Alex Nederlof,CrawlPath.java,MODIFY,immutableCopy -> [boolean removeLast] | [],"diff --git a/core/src/main/java/com/crawljax/core/state/CrawlPath.java b/core/src/main/java/com/crawljax/core/state/CrawlPath.java
index 8aaf8dd..af8ad19 100644
--- a/core/src/main/java/com/crawljax/core/state/CrawlPath.java
+++ b/core/src/main/java/com/crawljax/core/state/CrawlPath.java
@@ -13,6 +13,10 @@
 
 	private final List<Eventable> eventablePath;
 
+	public static CrawlPath copyOf(List<Eventable> eventable) {
+		return new CrawlPath(Lists.newLinkedList(eventable));
+	}
+
 	/**
 	 * Start a new empty CrawlPath.
 	 */
@@ -55,7 +59,15 @@
 	 *            should the last element be removed?
 	 * @return the CrawlPath based on an immutable list.
 	 */
-	public CrawlPath immutableCopy(boolean removeLast) {
+	public CrawlPath immutableCopy() {
+		return immutableCopy(false);
+	}
+
+	public CrawlPath immutableCopyWithoutLast() {
+		return immutableCopy(true);
+	}
+
+	private CrawlPath immutableCopy(boolean removeLast) {
 		if (isEmpty()) {
 			return new CrawlPath();
 		}
"
12cd571f664bf64156bb057b1aa9936c9947a89a,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index aef2647..5551a72 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -8,6 +8,7 @@
 import java.util.Arrays;
 import java.util.List;
 
+import javax.inject.Inject;
 import javax.xml.xpath.XPathExpressionException;
 
 import org.slf4j.Logger;
@@ -20,10 +21,11 @@
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.CandidateElement;
-import com.crawljax.core.configuration.InputSpecification;
+import com.crawljax.core.configuration.CrawlRules;
 import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.util.DomUtils;
 import com.crawljax.util.XPathHelper;
+import com.google.inject.assistedinject.Assisted;
 
 /**
  * Handles form values and fills in the form input elements with random values of the defined
@@ -39,7 +41,7 @@
 
 	private static final double HALF = 0.5;
 
-	private FormInputValueHelper formInputValueHelper;
+	private final FormInputValueHelper formInputValueHelper;
 
 	/**
 	 * Public constructor.
@@ -51,10 +53,12 @@
 	 * @param randomInput
 	 *            if random data should be generated on the input fields.
 	 */
-	public FormHandler(EmbeddedBrowser browser, InputSpecification inputSpecification,
-	        boolean randomInput) {
+	@Inject
+	public FormHandler(@Assisted EmbeddedBrowser browser, CrawlRules config) {
 		this.browser = browser;
-		this.formInputValueHelper = new FormInputValueHelper(inputSpecification, randomInput);
+		this.formInputValueHelper =
+		        new FormInputValueHelper(config.getInputSpecification(),
+		                config.isRandomInputInForms());
 	}
 
 	private static final String[] ALLOWED_INPUT_TYPES =
"
12cd571f664bf64156bb057b1aa9936c9947a89a,Alex Nederlof,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 0bc8d5f..bdb6a53 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -295,16 +295,18 @@
 		// make sure not before the node
 		int openElements = 1;
 		int i = 0;
-		int position = pos; 
+		int position = pos;
 		String dom_lower = dom.toLowerCase();
 		String element_lower = element.toLowerCase();
 		String openElement = ""<"" + element_lower;
 		String closeElement = ""</"" + element_lower;
 		while (i < MAX_SEARCH_LOOPS) {
-			if (dom_lower.indexOf(openElement, position) == -1 && dom_lower.indexOf(closeElement, position) == -1) {
+			if (dom_lower.indexOf(openElement, position) == -1
+			        && dom_lower.indexOf(closeElement, position) == -1) {
 				return -1;
 			}
-			if (dom_lower.indexOf(openElement, position) < dom_lower.indexOf(closeElement, position)
+			if (dom_lower.indexOf(openElement, position) < dom_lower.indexOf(closeElement,
+			        position)
 			        && dom_lower.indexOf(openElement, position) != -1) {
 				openElements++;
 				position = dom_lower.indexOf(openElement, position) + 1;
@@ -341,14 +343,18 @@
 	 *         text()
 	 */
 	public static String stripXPathToElement(String xpath) {
-		String xpathStripped = xpath; 
-		
+		String xpathStripped = xpath;
+
 		if (!Strings.isNullOrEmpty(xpathStripped)) {
 			if (xpathStripped.toLowerCase().contains(""/text()"")) {
-				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/text()""));
+				xpathStripped =
+				        xpathStripped
+				                .substring(0, xpathStripped.toLowerCase().indexOf(""/text()""));
 			}
 			if (xpathStripped.toLowerCase().contains(""/comment()"")) {
-				xpathStripped = xpathStripped.substring(0, xpathStripped.toLowerCase().indexOf(""/comment()""));
+				xpathStripped =
+				        xpathStripped.substring(0,
+				                xpathStripped.toLowerCase().indexOf(""/comment()""));
 			}
 			if (xpathStripped.contains(""@"")) {
 				xpathStripped = xpathStripped.substring(0, xpathStripped.indexOf(""@"") - 1);
"
12cd571f664bf64156bb057b1aa9936c9947a89a,Alex Nederlof,RunWithWebServer.java,MODIFY,newConfigBuilder -> [String context] | [],"diff --git a/core/src/test/java/com/crawljax/test/RunWithWebServer.java b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
index f64d1f8..68ee936 100644
--- a/core/src/test/java/com/crawljax/test/RunWithWebServer.java
+++ b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
@@ -31,16 +31,26 @@
 
 	@Override
 	public void before() throws Exception {
-		server = new Server(0);
-		ResourceHandler handler = new ResourceHandler();
-		handler.setBaseResource(resource);
-		server.setHandler(handler);
+		server = newWebServer();
 		server.start();
 		this.port = ((ServerConnector) server.getConnectors()[0]).getLocalPort();
 		this.demoSite = new URL(""http"", ""localhost"", port, ""/"");
 		this.started = true;
 	}
 
+	/**
+	 * Override this method to configure custom server settings.
+	 * 
+	 * @return a {@link Server}.
+	 */
+	protected Server newWebServer() {
+		Server server = new Server(0);
+		ResourceHandler handler = new ResourceHandler();
+		handler.setBaseResource(resource);
+		server.setHandler(handler);
+		return server;
+	}
+
 	@Override
 	public void after() {
 		try {
"
2772766df80c99a2e53008a5556a7ede2d73cbc7,Jeremy Hewett,Plugins.java,MODIFY,"getInstanceOf -> [Plugin plugin, IHostInterface hostInterface] | [Plugin plugin, HostInterface hostInterface]","diff --git a/web/src/main/java/com/crawljax/web/model/Plugins.java b/web/src/main/java/com/crawljax/web/model/Plugins.java
index 55f4b77..e718c9c 100644
--- a/web/src/main/java/com/crawljax/web/model/Plugins.java
+++ b/web/src/main/java/com/crawljax/web/model/Plugins.java
@@ -1,6 +1,6 @@
 package com.crawljax.web.model;
 
-import com.crawljax.core.plugin.IHostInterface;
+import com.crawljax.core.plugin.HostInterface;
 import com.crawljax.web.LogWebSocketServlet;
 import com.crawljax.web.fs.PluginManager;
 
@@ -62,12 +62,12 @@
 		return pluginList.get(id);
 	}
 
-	public com.crawljax.core.plugin.Plugin getInstanceOf(Plugin plugin, IHostInterface hostInterface) {
+	public com.crawljax.core.plugin.Plugin getInstanceOf(Plugin plugin, HostInterface hostInterface) {
 		com.crawljax.core.plugin.Plugin instance = null;
 		ClassLoader cl = new URLClassLoader(new URL[]{plugin.getUrl()});
 		try {
 			Class pluginClass = cl.loadClass(plugin.getImplementation());
-			Constructor constructor = pluginClass.getDeclaredConstructor(IHostInterface.class);
+			Constructor constructor = pluginClass.getDeclaredConstructor(HostInterface.class);
 			instance = (com.crawljax.core.plugin.Plugin)constructor.newInstance(hostInterface);
 		} catch (Throwable e) {
 			LogWebSocketServlet.sendToAll(""Could not create instance of plugin "" + plugin.getName());
"
e74a60ee419bfc9535f0b6f55a390bc162427270,Jeremy Hewett,Parameter.java,MODIFY,setId -> [String id] | [String value],"diff --git a/core/src/main/java/com/crawljax/core/plugin/jaxb/generated/Parameter.java b/core/src/main/java/com/crawljax/core/plugin/jaxb/generated/Parameter.java
index f1cf1b6..530b002 100644
--- a/core/src/main/java/com/crawljax/core/plugin/jaxb/generated/Parameter.java
+++ b/core/src/main/java/com/crawljax/core/plugin/jaxb/generated/Parameter.java
@@ -2,7 +2,7 @@
 // This file was generated by the JavaTM Architecture for XML Binding(JAXB) Reference Implementation, v2.2.4-2 
 // See <a href=""http://java.sun.com/xml/jaxb"">http://java.sun.com/xml/jaxb</a> 
 // Any modifications to this file will be lost upon recompilation of the source schema. 
-// Generated on: 2013.06.21 at 02:45:09 PM PDT 
+// Generated on: 2013.07.05 at 01:38:08 PM PDT 
 //
 
 
@@ -26,6 +26,16 @@
  *       &lt;sequence>
  *         &lt;element name=""id"" type=""{http://www.w3.org/2001/XMLSchema}string""/>
  *         &lt;element name=""display-name"" type=""{http://www.w3.org/2001/XMLSchema}string""/>
+ *         &lt;element name=""type"">
+ *           &lt;simpleType>
+ *             &lt;restriction base=""{http://www.w3.org/2001/XMLSchema}string"">
+ *               &lt;enumeration value=""textbox""/>
+ *               &lt;enumeration value=""checkbox""/>
+ *               &lt;enumeration value=""select""/>
+ *             &lt;/restriction>
+ *           &lt;/simpleType>
+ *         &lt;/element>
+ *         &lt;element name=""options"" type=""{}option-list"" minOccurs=""0""/>
  *       &lt;/sequence>
  *     &lt;/restriction>
  *   &lt;/complexContent>
@@ -37,7 +47,9 @@
 @XmlAccessorType(XmlAccessType.FIELD)
 @XmlType(name = ""parameter"", propOrder = {
     ""id"",
-    ""displayName""
+    ""displayName"",
+    ""type"",
+    ""options""
 })
 public class Parameter {
 
@@ -45,6 +57,9 @@
     protected String id;
     @XmlElement(name = ""display-name"", required = true)
     protected String displayName;
+    @XmlElement(required = true)
+    protected String type;
+    protected OptionList options;
 
     /**
      * Gets the value of the id property.
@@ -94,4 +109,52 @@
         this.displayName = value;
     }
 
+    /**
+     * Gets the value of the type property.
+     * 
+     * @return
+     *     possible object is
+     *     {@link String }
+     *     
+     */
+    public String getType() {
+        return type;
+    }
+
+    /**
+     * Sets the value of the type property.
+     * 
+     * @param value
+     *     allowed object is
+     *     {@link String }
+     *     
+     */
+    public void setType(String value) {
+        this.type = value;
+    }
+
+    /**
+     * Gets the value of the options property.
+     * 
+     * @return
+     *     possible object is
+     *     {@link OptionList }
+     *     
+     */
+    public OptionList getOptions() {
+        return options;
+    }
+
+    /**
+     * Sets the value of the options property.
+     * 
+     * @param value
+     *     allowed object is
+     *     {@link OptionList }
+     *     
+     */
+    public void setOptions(OptionList value) {
+        this.options = value;
+    }
+
 }
"
e74a60ee419bfc9535f0b6f55a390bc162427270,Jeremy Hewett,CrawlRecord.java,MODIFY,setPlugins -> [Map plugins] | [ConcurrentHashMap plugins],"diff --git a/web/src/main/java/com/crawljax/web/model/CrawlRecord.java b/web/src/main/java/com/crawljax/web/model/CrawlRecord.java
index 9c3a9ea..f508162 100644
--- a/web/src/main/java/com/crawljax/web/model/CrawlRecord.java
+++ b/web/src/main/java/com/crawljax/web/model/CrawlRecord.java
@@ -15,7 +15,7 @@
 	private long duration;
 	private String outputFolder;
 	private CrawlStatusType crawlStatus = CrawlStatusType.idle;
-	private Map<String, Plugin> plugins = new ConcurrentHashMap<String, Plugin>();
+	private ConcurrentHashMap<String, Plugin> plugins = new ConcurrentHashMap<String, Plugin>();
 
 	public enum CrawlStatusType {
 		idle, queued, initializing, running, success, failure
@@ -141,11 +141,11 @@
 		this.crawlStatus = crawlStatus;
 	}
 
-	public Map<String, Plugin> getPlugins() {
+	public ConcurrentHashMap<String, Plugin> getPlugins() {
 		return plugins;
 	}
 
-	public void setPlugins(Map<String, Plugin> plugins) {
+	public void setPlugins(ConcurrentHashMap<String, Plugin> plugins) {
 		this.plugins = plugins;
 	}
 
"
e74a60ee419bfc9535f0b6f55a390bc162427270,Jeremy Hewett,Parameter.java,MODIFY,setId -> [String value] | [String id],"diff --git a/web/src/main/java/com/crawljax/web/model/Parameter.java b/web/src/main/java/com/crawljax/web/model/Parameter.java
index fe76985..5125927 100644
--- a/web/src/main/java/com/crawljax/web/model/Parameter.java
+++ b/web/src/main/java/com/crawljax/web/model/Parameter.java
@@ -1,10 +1,33 @@
 package com.crawljax.web.model;
 
+import java.util.ArrayList;
+import java.util.List;
+
 public class Parameter {
+	public enum ParameterType {
+		textbox,
+		checkbox,
+		select
+	}
+
 	private String id;
 	private String displayName;
+	private ParameterType type;
+	private List<SelectOption> options = new ArrayList<>();
 	private String value;
 
+	public Parameter() {}
+
+	public Parameter(Parameter parameter) {
+		this.id = parameter.getId();
+		this.displayName = parameter.getDisplayName();
+		this.type = parameter.getType();
+		for(int i = 0; i < parameter.getOptions().size(); i++) {
+			this.options.add(new SelectOption(parameter.getOptions().get(i)));
+		}
+		this.value = parameter.getValue();
+	}
+
 	public String getId() {
 		return id;
 	}
@@ -21,6 +44,22 @@
 		this.displayName = displayName;
 	}
 
+	public ParameterType getType() {
+		return type;
+	}
+
+	public void setType(ParameterType type) {
+		this.type = type;
+	}
+
+	public List<SelectOption> getOptions() {
+		return options;
+	}
+
+	public void setOptions(List<SelectOption> options) {
+		this.options = options;
+	}
+
 	public String getValue() {
 		return value;
 	}
"
19770c7ff445da3cef9c9d5c33120d0d5f4d5635,Alex Nederlof,Parameter.java,MODIFY,setId -> [String id] | [String value],"diff --git a/core/src/main/java/com/crawljax/core/plugin/jaxb/generated/Parameter.java b/core/src/main/java/com/crawljax/core/plugin/jaxb/generated/Parameter.java
index f1cf1b6..530b002 100644
--- a/core/src/main/java/com/crawljax/core/plugin/jaxb/generated/Parameter.java
+++ b/core/src/main/java/com/crawljax/core/plugin/jaxb/generated/Parameter.java
@@ -2,7 +2,7 @@
 // This file was generated by the JavaTM Architecture for XML Binding(JAXB) Reference Implementation, v2.2.4-2 
 // See <a href=""http://java.sun.com/xml/jaxb"">http://java.sun.com/xml/jaxb</a> 
 // Any modifications to this file will be lost upon recompilation of the source schema. 
-// Generated on: 2013.06.21 at 02:45:09 PM PDT 
+// Generated on: 2013.07.05 at 01:38:08 PM PDT 
 //
 
 
@@ -26,6 +26,16 @@
  *       &lt;sequence>
  *         &lt;element name=""id"" type=""{http://www.w3.org/2001/XMLSchema}string""/>
  *         &lt;element name=""display-name"" type=""{http://www.w3.org/2001/XMLSchema}string""/>
+ *         &lt;element name=""type"">
+ *           &lt;simpleType>
+ *             &lt;restriction base=""{http://www.w3.org/2001/XMLSchema}string"">
+ *               &lt;enumeration value=""textbox""/>
+ *               &lt;enumeration value=""checkbox""/>
+ *               &lt;enumeration value=""select""/>
+ *             &lt;/restriction>
+ *           &lt;/simpleType>
+ *         &lt;/element>
+ *         &lt;element name=""options"" type=""{}option-list"" minOccurs=""0""/>
  *       &lt;/sequence>
  *     &lt;/restriction>
  *   &lt;/complexContent>
@@ -37,7 +47,9 @@
 @XmlAccessorType(XmlAccessType.FIELD)
 @XmlType(name = ""parameter"", propOrder = {
     ""id"",
-    ""displayName""
+    ""displayName"",
+    ""type"",
+    ""options""
 })
 public class Parameter {
 
@@ -45,6 +57,9 @@
     protected String id;
     @XmlElement(name = ""display-name"", required = true)
     protected String displayName;
+    @XmlElement(required = true)
+    protected String type;
+    protected OptionList options;
 
     /**
      * Gets the value of the id property.
@@ -94,4 +109,52 @@
         this.displayName = value;
     }
 
+    /**
+     * Gets the value of the type property.
+     * 
+     * @return
+     *     possible object is
+     *     {@link String }
+     *     
+     */
+    public String getType() {
+        return type;
+    }
+
+    /**
+     * Sets the value of the type property.
+     * 
+     * @param value
+     *     allowed object is
+     *     {@link String }
+     *     
+     */
+    public void setType(String value) {
+        this.type = value;
+    }
+
+    /**
+     * Gets the value of the options property.
+     * 
+     * @return
+     *     possible object is
+     *     {@link OptionList }
+     *     
+     */
+    public OptionList getOptions() {
+        return options;
+    }
+
+    /**
+     * Sets the value of the options property.
+     * 
+     * @param value
+     *     allowed object is
+     *     {@link OptionList }
+     *     
+     */
+    public void setOptions(OptionList value) {
+        this.options = value;
+    }
+
 }
"
19770c7ff445da3cef9c9d5c33120d0d5f4d5635,Alex Nederlof,Parameter.java,MODIFY,setId -> [String value] | [String id],"diff --git a/web/src/main/java/com/crawljax/web/model/Parameter.java b/web/src/main/java/com/crawljax/web/model/Parameter.java
index fe76985..5125927 100644
--- a/web/src/main/java/com/crawljax/web/model/Parameter.java
+++ b/web/src/main/java/com/crawljax/web/model/Parameter.java
@@ -1,10 +1,33 @@
 package com.crawljax.web.model;
 
+import java.util.ArrayList;
+import java.util.List;
+
 public class Parameter {
+	public enum ParameterType {
+		textbox,
+		checkbox,
+		select
+	}
+
 	private String id;
 	private String displayName;
+	private ParameterType type;
+	private List<SelectOption> options = new ArrayList<>();
 	private String value;
 
+	public Parameter() {}
+
+	public Parameter(Parameter parameter) {
+		this.id = parameter.getId();
+		this.displayName = parameter.getDisplayName();
+		this.type = parameter.getType();
+		for(int i = 0; i < parameter.getOptions().size(); i++) {
+			this.options.add(new SelectOption(parameter.getOptions().get(i)));
+		}
+		this.value = parameter.getValue();
+	}
+
 	public String getId() {
 		return id;
 	}
@@ -21,6 +44,22 @@
 		this.displayName = displayName;
 	}
 
+	public ParameterType getType() {
+		return type;
+	}
+
+	public void setType(ParameterType type) {
+		this.type = type;
+	}
+
+	public List<SelectOption> getOptions() {
+		return options;
+	}
+
+	public void setOptions(List<SelectOption> options) {
+		this.options = options;
+	}
+
 	public String getValue() {
 		return value;
 	}
"
62073fc375667ac6ef387e3aad7216dfcd1b2029,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index bb10305..1ce2ff0 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -39,7 +39,6 @@
 
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.AcceptAllFramesChecker;
-import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.crawljax.core.configuration.IgnoreFrameChecker;
 import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.core.state.Eventable;
@@ -52,66 +51,8 @@
 import com.google.common.collect.ImmutableSortedSet;
 
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
-	private long crawlWaitEvent;
 	private static final Logger LOGGER = LoggerFactory
 	        .getLogger(WebDriverBackedEmbeddedBrowser.class);
-	private final WebDriver browser;
-
-	private ImmutableSortedSet<String> filterAttributes;
-	private long crawlWaitReload;
-	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
-
-	/**
-	 * Constructor without configuration values, these must be updated using the
-	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
-		this.browser = driver;
-	}
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload, long crawlWaitEvent) {
-		this(driver);
-		this.filterAttributes = filterAttributes;
-		this.crawlWaitEvent = crawlWaitEvent;
-		this.crawlWaitReload = crawlWaitReload;
-	}
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload,
-	        long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
-		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
-		this.ignoreFrameChecker = ignoreFrameChecker;
-	}
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
@@ -239,6 +180,66 @@
 		return new RemoteWebDriver(executor, capabilities);
 	}
 
+	private final ImmutableSortedSet<String> filterAttributes;
+	private final WebDriver browser;
+
+	private long crawlWaitEvent;
+	private long crawlWaitReload;
+	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
+
+	/**
+	 * Constructor without configuration values, these must be updated using the
+	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
+		this.browser = driver;
+		filterAttributes = ImmutableSortedSet.of();
+	}
+
+	/**
+	 * Constructor.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload, long crawlWaitEvent) {
+		this.browser = driver;
+		this.filterAttributes = filterAttributes;
+		this.crawlWaitEvent = crawlWaitEvent;
+		this.crawlWaitReload = crawlWaitReload;
+	}
+
+	/**
+	 * Constructor.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload,
+	        long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
+		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
+		this.ignoreFrameChecker = ignoreFrameChecker;
+	}
+
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
 	 * 
@@ -337,7 +338,7 @@
 	}
 
 	@Override
-	public String getDom() {
+	public String getStrippedDom() {
 
 		try {
 			String dom = toUniformDOM(DomUtils.getDocumentToString(getDomTreeWithFrames()));
@@ -349,6 +350,11 @@
 		}
 	}
 
+	@Override
+	public String getUnStrippedDom() {
+		return browser.getPageSource();
+	}
+
 	/**
 	 * @param html
 	 *            The html string.
@@ -379,13 +385,11 @@
 	 */
 	private String filterAttributes(String html) {
 		String filteredHtml = html;
-		if (this.filterAttributes != null) {
-			for (String attribute : this.filterAttributes) {
-				String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
-				Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
-				Matcher m = p.matcher(html);
-				filteredHtml = m.replaceAll("""");
-			}
+		for (String attribute : this.filterAttributes) {
+			String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
+			Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
+			Matcher m = p.matcher(html);
+			filteredHtml = m.replaceAll("""");
 		}
 		return filteredHtml;
 	}
@@ -652,10 +656,10 @@
 
 	/**
 	 * @return the dom without the iframe contents.
-	 * @see com.crawljax.browser.EmbeddedBrowser#getDomWithoutIframeContent()
+	 * @see com.crawljax.browser.EmbeddedBrowser#getStrippedDomWithoutIframeContent()
 	 */
 	@Override
-	public String getDomWithoutIframeContent() {
+	public String getStrippedDomWithoutIframeContent() {
 		try {
 			String dom = browser.getPageSource();
 			String result = toUniformDOM(dom);
@@ -856,15 +860,6 @@
 		return browser;
 	}
 
-	@Override
-	public void updateConfiguration(CrawljaxConfiguration configuration) {
-		// Retrieve the config values used
-		this.filterAttributes =
-		        configuration.getCrawlRules().getPreCrawlConfig().getFilterAttributeNames();
-		this.crawlWaitReload = configuration.getCrawlRules().getWaitAfterReloadUrl();
-		this.crawlWaitEvent = configuration.getCrawlRules().getWaitAfterEvent();
-	}
-
 	private boolean exceptionIsConnectionException(WebDriverException exception) {
 		return exception != null && exception.getCause() != null
 		        && exception.getCause() instanceof IOException;
"
62073fc375667ac6ef387e3aad7216dfcd1b2029,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index 5551a72..97973c2 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -194,7 +194,7 @@
 		List<FormInput> formInputs = new ArrayList<FormInput>();
 		Document dom;
 		try {
-			dom = DomUtils.asDocument(browser.getDom());
+			dom = DomUtils.asDocument(browser.getStrippedDom());
 			List<Node> nodes = getInputElements(dom);
 			for (Node node : nodes) {
 				FormInput formInput =
@@ -227,7 +227,7 @@
 	 */
 	public void handleFormElements(List<FormInput> formInputs) {
 		try {
-			Document dom = DomUtils.asDocument(browser.getDomWithoutIframeContent());
+			Document dom = DomUtils.asDocument(browser.getStrippedDomWithoutIframeContent());
 			for (FormInput input : formInputs) {
 				LOGGER.debug(""Filling in: "" + input);
 				setInputElementValue(formInputValueHelper.getBelongingNode(input, dom), input);
"
62073fc375667ac6ef387e3aad7216dfcd1b2029,Alex Nederlof,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index 85af1cd..c1ebb1d 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -15,12 +15,10 @@
 import com.crawljax.core.state.Eventable;
 
 /**
- * class for finding and checking elements.
- * 
- * @author danny
+ * Finds and checks elements.
  */
 public class ElementResolver {
-	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class.getName());
+	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class);
 
 	private final EmbeddedBrowser browser;
 	private final Eventable eventable;
@@ -54,7 +52,7 @@
 	public String resolve(boolean logging) {
 		Document dom = null;
 		try {
-			dom = DomUtils.asDocument(browser.getDom());
+			dom = DomUtils.asDocument(browser.getStrippedDom());
 		} catch (IOException e) {
 			LOGGER.error(e.getMessage(), e);
 			return """";
"
c23198e3b516b776a4fabd04b639101dc6545791,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 1ce2ff0..9c4d8c9 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -338,6 +338,12 @@
 	}
 
 	@Override
+	@Deprecated
+	public String getDom() {
+		return getStrippedDom();
+	}
+
+	@Override
 	public String getStrippedDom() {
 
 		try {
"
326cd569ceb4c2750c928896c74de74250d8eaf0,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index bf6584f..a4638b3 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -158,7 +158,7 @@
 		/**
 		 * @param configuration
 		 *            a custom {@link BrowserConfiguration}. The default is a single
-		 *            {@link BrowserType#firefox} browser.
+		 *            {@link BrowserType#FIREFOX} browser.
 		 */
 		public CrawljaxConfigurationBuilder setBrowserConfig(BrowserConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -204,7 +204,7 @@
 
 	private URL url;
 
-	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.firefox);
+	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.FIREFOX);
 	private Plugins plugins;
 	private ProxyConfiguration proxyConfiguration = ProxyConfiguration.noProxy();
 
"
326cd569ceb4c2750c928896c74de74250d8eaf0,Alex Nederlof,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index d0d3edd..3e16f5b 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -529,11 +529,6 @@
 		transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
 		transformer.setOutputProperty(OutputKeys.METHOD, method);
 
-		if (indent > -1) {
-			transformer.setOutputProperty(
-			        org.apache.xml.serializer.OutputPropertiesFactory.S_KEY_INDENT_AMOUNT,
-			        Integer.toString(indent));
-		}
 		transformer.transform(new DOMSource(document), new StreamResult(new FileOutputStream(
 		        filePathname)));
 	}
"
6d849eb235cfdff5b2b0298b4f22af70baf868f0,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 9c4d8c9..d7cd498 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -597,14 +597,14 @@
 		for (int i = 0; i < nodeList.size(); i++) {
 			try {
 				locateFrameAndgetSource(document, topFrame, nodeList.get(i));
-			} catch (UnknownServerException e) {
+			} catch (UnknownServerException | NoSuchFrameException e) {
 				LOGGER.warn(""Could not add frame contents for element {}"", nodeList.get(i));
 				LOGGER.debug(""Could not load frame because of {}"", e.getMessage(), e);
 			}
 		}
 	}
 
-	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement) {
+	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement) throws NoSuchFrameException {
 		String frameIdentification = """";
 
 		if (topFrame != null && !topFrame.equals("""")) {
@@ -643,7 +643,7 @@
 		}
 	}
 
-	private void switchToFrame(String frameIdentification) {
+	private void switchToFrame(String frameIdentification) throws NoSuchFrameException {
 		LOGGER.debug(""frame identification: "" + frameIdentification);
 
 		if (frameIdentification.contains(""."")) {
"
e76f5357b63ad0e48c95ad1988b29b32253eb2a2,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index d7cd498..e645a17 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -48,6 +48,7 @@
 import com.crawljax.forms.InputValue;
 import com.crawljax.forms.RandomInputValueGenerator;
 import com.crawljax.util.DomUtils;
+import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableSortedSet;
 
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
@@ -214,7 +215,7 @@
 	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
 	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload, long crawlWaitEvent) {
 		this.browser = driver;
-		this.filterAttributes = filterAttributes;
+		this.filterAttributes = Preconditions.checkNotNull(filterAttributes);
 		this.crawlWaitEvent = crawlWaitEvent;
 		this.crawlWaitReload = crawlWaitReload;
 	}
"
fed42674c69a1ea3ec6275370a907a1c1f90108b,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index bb10305..e645a17 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -39,7 +39,6 @@
 
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.AcceptAllFramesChecker;
-import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.crawljax.core.configuration.IgnoreFrameChecker;
 import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.core.state.Eventable;
@@ -49,69 +48,12 @@
 import com.crawljax.forms.InputValue;
 import com.crawljax.forms.RandomInputValueGenerator;
 import com.crawljax.util.DomUtils;
+import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableSortedSet;
 
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
-	private long crawlWaitEvent;
 	private static final Logger LOGGER = LoggerFactory
 	        .getLogger(WebDriverBackedEmbeddedBrowser.class);
-	private final WebDriver browser;
-
-	private ImmutableSortedSet<String> filterAttributes;
-	private long crawlWaitReload;
-	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
-
-	/**
-	 * Constructor without configuration values, these must be updated using the
-	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
-		this.browser = driver;
-	}
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload, long crawlWaitEvent) {
-		this(driver);
-		this.filterAttributes = filterAttributes;
-		this.crawlWaitEvent = crawlWaitEvent;
-		this.crawlWaitReload = crawlWaitReload;
-	}
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload,
-	        long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
-		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
-		this.ignoreFrameChecker = ignoreFrameChecker;
-	}
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
@@ -239,6 +181,66 @@
 		return new RemoteWebDriver(executor, capabilities);
 	}
 
+	private final ImmutableSortedSet<String> filterAttributes;
+	private final WebDriver browser;
+
+	private long crawlWaitEvent;
+	private long crawlWaitReload;
+	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
+
+	/**
+	 * Constructor without configuration values, these must be updated using the
+	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
+		this.browser = driver;
+		filterAttributes = ImmutableSortedSet.of();
+	}
+
+	/**
+	 * Constructor.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload, long crawlWaitEvent) {
+		this.browser = driver;
+		this.filterAttributes = Preconditions.checkNotNull(filterAttributes);
+		this.crawlWaitEvent = crawlWaitEvent;
+		this.crawlWaitReload = crawlWaitReload;
+	}
+
+	/**
+	 * Constructor.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload,
+	        long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
+		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
+		this.ignoreFrameChecker = ignoreFrameChecker;
+	}
+
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
 	 * 
@@ -337,7 +339,13 @@
 	}
 
 	@Override
+	@Deprecated
 	public String getDom() {
+		return getStrippedDom();
+	}
+
+	@Override
+	public String getStrippedDom() {
 
 		try {
 			String dom = toUniformDOM(DomUtils.getDocumentToString(getDomTreeWithFrames()));
@@ -349,6 +357,11 @@
 		}
 	}
 
+	@Override
+	public String getUnStrippedDom() {
+		return browser.getPageSource();
+	}
+
 	/**
 	 * @param html
 	 *            The html string.
@@ -379,13 +392,11 @@
 	 */
 	private String filterAttributes(String html) {
 		String filteredHtml = html;
-		if (this.filterAttributes != null) {
-			for (String attribute : this.filterAttributes) {
-				String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
-				Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
-				Matcher m = p.matcher(html);
-				filteredHtml = m.replaceAll("""");
-			}
+		for (String attribute : this.filterAttributes) {
+			String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
+			Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
+			Matcher m = p.matcher(html);
+			filteredHtml = m.replaceAll("""");
 		}
 		return filteredHtml;
 	}
@@ -587,14 +598,14 @@
 		for (int i = 0; i < nodeList.size(); i++) {
 			try {
 				locateFrameAndgetSource(document, topFrame, nodeList.get(i));
-			} catch (UnknownServerException e) {
+			} catch (UnknownServerException | NoSuchFrameException e) {
 				LOGGER.warn(""Could not add frame contents for element {}"", nodeList.get(i));
 				LOGGER.debug(""Could not load frame because of {}"", e.getMessage(), e);
 			}
 		}
 	}
 
-	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement) {
+	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement) throws NoSuchFrameException {
 		String frameIdentification = """";
 
 		if (topFrame != null && !topFrame.equals("""")) {
@@ -633,7 +644,7 @@
 		}
 	}
 
-	private void switchToFrame(String frameIdentification) {
+	private void switchToFrame(String frameIdentification) throws NoSuchFrameException {
 		LOGGER.debug(""frame identification: "" + frameIdentification);
 
 		if (frameIdentification.contains(""."")) {
@@ -652,10 +663,10 @@
 
 	/**
 	 * @return the dom without the iframe contents.
-	 * @see com.crawljax.browser.EmbeddedBrowser#getDomWithoutIframeContent()
+	 * @see com.crawljax.browser.EmbeddedBrowser#getStrippedDomWithoutIframeContent()
 	 */
 	@Override
-	public String getDomWithoutIframeContent() {
+	public String getStrippedDomWithoutIframeContent() {
 		try {
 			String dom = browser.getPageSource();
 			String result = toUniformDOM(dom);
@@ -856,15 +867,6 @@
 		return browser;
 	}
 
-	@Override
-	public void updateConfiguration(CrawljaxConfiguration configuration) {
-		// Retrieve the config values used
-		this.filterAttributes =
-		        configuration.getCrawlRules().getPreCrawlConfig().getFilterAttributeNames();
-		this.crawlWaitReload = configuration.getCrawlRules().getWaitAfterReloadUrl();
-		this.crawlWaitEvent = configuration.getCrawlRules().getWaitAfterEvent();
-	}
-
 	private boolean exceptionIsConnectionException(WebDriverException exception) {
 		return exception != null && exception.getCause() != null
 		        && exception.getCause() instanceof IOException;
"
fed42674c69a1ea3ec6275370a907a1c1f90108b,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index 5551a72..97973c2 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -194,7 +194,7 @@
 		List<FormInput> formInputs = new ArrayList<FormInput>();
 		Document dom;
 		try {
-			dom = DomUtils.asDocument(browser.getDom());
+			dom = DomUtils.asDocument(browser.getStrippedDom());
 			List<Node> nodes = getInputElements(dom);
 			for (Node node : nodes) {
 				FormInput formInput =
@@ -227,7 +227,7 @@
 	 */
 	public void handleFormElements(List<FormInput> formInputs) {
 		try {
-			Document dom = DomUtils.asDocument(browser.getDomWithoutIframeContent());
+			Document dom = DomUtils.asDocument(browser.getStrippedDomWithoutIframeContent());
 			for (FormInput input : formInputs) {
 				LOGGER.debug(""Filling in: "" + input);
 				setInputElementValue(formInputValueHelper.getBelongingNode(input, dom), input);
"
fed42674c69a1ea3ec6275370a907a1c1f90108b,Alex Nederlof,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index 85af1cd..c1ebb1d 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -15,12 +15,10 @@
 import com.crawljax.core.state.Eventable;
 
 /**
- * class for finding and checking elements.
- * 
- * @author danny
+ * Finds and checks elements.
  */
 public class ElementResolver {
-	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class.getName());
+	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class);
 
 	private final EmbeddedBrowser browser;
 	private final Eventable eventable;
@@ -54,7 +52,7 @@
 	public String resolve(boolean logging) {
 		Document dom = null;
 		try {
-			dom = DomUtils.asDocument(browser.getDom());
+			dom = DomUtils.asDocument(browser.getStrippedDom());
 		} catch (IOException e) {
 			LOGGER.error(e.getMessage(), e);
 			return """";
"
82f711012c19a3c5e1d3222f7b721dc16fb4a897,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index a4638b3..a35319d 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -2,6 +2,7 @@
 
 import static com.google.common.base.Preconditions.checkArgument;
 
+import java.io.File;
 import java.io.UnsupportedEncodingException;
 import java.net.MalformedURLException;
 import java.net.URL;
@@ -166,6 +167,33 @@
 			return this;
 		}
 
+		/**
+		 * Set the output folder for any {@link Plugin} you might configure. Crawljax itself doesn't
+		 * need an output folder but many plug-ins do.
+		 * 
+		 * @param output
+		 *            The output folder. If it does not exist it will be created.
+		 * @throws IllegalStateException
+		 *             if the specified file is not writable or exists but isn't a folder.
+		 */
+		public CrawljaxConfigurationBuilder setOutputDirectory(File output) {
+			config.output = output;
+			checkOutputDirWritable();
+			return this;
+		}
+
+		private void checkOutputDirWritable() {
+			if (!config.output.exists()) {
+				Preconditions.checkState(config.output.mkdirs(),
+				        ""Could not create the output directory %s "", config.output);
+			} else {
+				Preconditions.checkArgument(config.output.isDirectory(),
+				        ""Output directory %s is not a folder"", config.output);
+				Preconditions.checkState(config.output.canWrite(),
+				        ""Output directory %s is not writable"", config.output);
+			}
+		}
+
 		public CrawljaxConfiguration build() {
 			config.plugins = new Plugins(pluginBuilder.build());
 			config.crawlRules = crawlRules.build();
@@ -213,6 +241,7 @@
 	private int maximumStates = 0;
 	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);;
 	private int maximumDepth = 2;
+	private File output = new File(""out"");
 
 	private CrawljaxConfiguration() {
 	}
@@ -249,6 +278,10 @@
 		return maximumDepth;
 	}
 
+	public File getOutputDir() {
+		return output;
+	}
+
 	@Override
 	public int hashCode() {
 		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
"
f784e2f4c82ad36ce2f4ca91adcc88ba06f7d2e7,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index bb10305..e645a17 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -39,7 +39,6 @@
 
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.AcceptAllFramesChecker;
-import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.crawljax.core.configuration.IgnoreFrameChecker;
 import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.core.state.Eventable;
@@ -49,69 +48,12 @@
 import com.crawljax.forms.InputValue;
 import com.crawljax.forms.RandomInputValueGenerator;
 import com.crawljax.util.DomUtils;
+import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableSortedSet;
 
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
-	private long crawlWaitEvent;
 	private static final Logger LOGGER = LoggerFactory
 	        .getLogger(WebDriverBackedEmbeddedBrowser.class);
-	private final WebDriver browser;
-
-	private ImmutableSortedSet<String> filterAttributes;
-	private long crawlWaitReload;
-	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
-
-	/**
-	 * Constructor without configuration values, these must be updated using the
-	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
-		this.browser = driver;
-	}
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload, long crawlWaitEvent) {
-		this(driver);
-		this.filterAttributes = filterAttributes;
-		this.crawlWaitEvent = crawlWaitEvent;
-		this.crawlWaitReload = crawlWaitReload;
-	}
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload,
-	        long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
-		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
-		this.ignoreFrameChecker = ignoreFrameChecker;
-	}
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
@@ -239,6 +181,66 @@
 		return new RemoteWebDriver(executor, capabilities);
 	}
 
+	private final ImmutableSortedSet<String> filterAttributes;
+	private final WebDriver browser;
+
+	private long crawlWaitEvent;
+	private long crawlWaitReload;
+	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
+
+	/**
+	 * Constructor without configuration values, these must be updated using the
+	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
+		this.browser = driver;
+		filterAttributes = ImmutableSortedSet.of();
+	}
+
+	/**
+	 * Constructor.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload, long crawlWaitEvent) {
+		this.browser = driver;
+		this.filterAttributes = Preconditions.checkNotNull(filterAttributes);
+		this.crawlWaitEvent = crawlWaitEvent;
+		this.crawlWaitReload = crawlWaitReload;
+	}
+
+	/**
+	 * Constructor.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload,
+	        long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
+		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
+		this.ignoreFrameChecker = ignoreFrameChecker;
+	}
+
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
 	 * 
@@ -337,7 +339,13 @@
 	}
 
 	@Override
+	@Deprecated
 	public String getDom() {
+		return getStrippedDom();
+	}
+
+	@Override
+	public String getStrippedDom() {
 
 		try {
 			String dom = toUniformDOM(DomUtils.getDocumentToString(getDomTreeWithFrames()));
@@ -349,6 +357,11 @@
 		}
 	}
 
+	@Override
+	public String getUnStrippedDom() {
+		return browser.getPageSource();
+	}
+
 	/**
 	 * @param html
 	 *            The html string.
@@ -379,13 +392,11 @@
 	 */
 	private String filterAttributes(String html) {
 		String filteredHtml = html;
-		if (this.filterAttributes != null) {
-			for (String attribute : this.filterAttributes) {
-				String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
-				Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
-				Matcher m = p.matcher(html);
-				filteredHtml = m.replaceAll("""");
-			}
+		for (String attribute : this.filterAttributes) {
+			String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
+			Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
+			Matcher m = p.matcher(html);
+			filteredHtml = m.replaceAll("""");
 		}
 		return filteredHtml;
 	}
@@ -587,14 +598,14 @@
 		for (int i = 0; i < nodeList.size(); i++) {
 			try {
 				locateFrameAndgetSource(document, topFrame, nodeList.get(i));
-			} catch (UnknownServerException e) {
+			} catch (UnknownServerException | NoSuchFrameException e) {
 				LOGGER.warn(""Could not add frame contents for element {}"", nodeList.get(i));
 				LOGGER.debug(""Could not load frame because of {}"", e.getMessage(), e);
 			}
 		}
 	}
 
-	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement) {
+	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement) throws NoSuchFrameException {
 		String frameIdentification = """";
 
 		if (topFrame != null && !topFrame.equals("""")) {
@@ -633,7 +644,7 @@
 		}
 	}
 
-	private void switchToFrame(String frameIdentification) {
+	private void switchToFrame(String frameIdentification) throws NoSuchFrameException {
 		LOGGER.debug(""frame identification: "" + frameIdentification);
 
 		if (frameIdentification.contains(""."")) {
@@ -652,10 +663,10 @@
 
 	/**
 	 * @return the dom without the iframe contents.
-	 * @see com.crawljax.browser.EmbeddedBrowser#getDomWithoutIframeContent()
+	 * @see com.crawljax.browser.EmbeddedBrowser#getStrippedDomWithoutIframeContent()
 	 */
 	@Override
-	public String getDomWithoutIframeContent() {
+	public String getStrippedDomWithoutIframeContent() {
 		try {
 			String dom = browser.getPageSource();
 			String result = toUniformDOM(dom);
@@ -856,15 +867,6 @@
 		return browser;
 	}
 
-	@Override
-	public void updateConfiguration(CrawljaxConfiguration configuration) {
-		// Retrieve the config values used
-		this.filterAttributes =
-		        configuration.getCrawlRules().getPreCrawlConfig().getFilterAttributeNames();
-		this.crawlWaitReload = configuration.getCrawlRules().getWaitAfterReloadUrl();
-		this.crawlWaitEvent = configuration.getCrawlRules().getWaitAfterEvent();
-	}
-
 	private boolean exceptionIsConnectionException(WebDriverException exception) {
 		return exception != null && exception.getCause() != null
 		        && exception.getCause() instanceof IOException;
"
f784e2f4c82ad36ce2f4ca91adcc88ba06f7d2e7,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index bf6584f..a4638b3 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -158,7 +158,7 @@
 		/**
 		 * @param configuration
 		 *            a custom {@link BrowserConfiguration}. The default is a single
-		 *            {@link BrowserType#firefox} browser.
+		 *            {@link BrowserType#FIREFOX} browser.
 		 */
 		public CrawljaxConfigurationBuilder setBrowserConfig(BrowserConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -204,7 +204,7 @@
 
 	private URL url;
 
-	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.firefox);
+	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.FIREFOX);
 	private Plugins plugins;
 	private ProxyConfiguration proxyConfiguration = ProxyConfiguration.noProxy();
 
"
f784e2f4c82ad36ce2f4ca91adcc88ba06f7d2e7,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index 5551a72..97973c2 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -194,7 +194,7 @@
 		List<FormInput> formInputs = new ArrayList<FormInput>();
 		Document dom;
 		try {
-			dom = DomUtils.asDocument(browser.getDom());
+			dom = DomUtils.asDocument(browser.getStrippedDom());
 			List<Node> nodes = getInputElements(dom);
 			for (Node node : nodes) {
 				FormInput formInput =
@@ -227,7 +227,7 @@
 	 */
 	public void handleFormElements(List<FormInput> formInputs) {
 		try {
-			Document dom = DomUtils.asDocument(browser.getDomWithoutIframeContent());
+			Document dom = DomUtils.asDocument(browser.getStrippedDomWithoutIframeContent());
 			for (FormInput input : formInputs) {
 				LOGGER.debug(""Filling in: "" + input);
 				setInputElementValue(formInputValueHelper.getBelongingNode(input, dom), input);
"
f784e2f4c82ad36ce2f4ca91adcc88ba06f7d2e7,Ali Mesbah,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index d0d3edd..3e16f5b 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -529,11 +529,6 @@
 		transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
 		transformer.setOutputProperty(OutputKeys.METHOD, method);
 
-		if (indent > -1) {
-			transformer.setOutputProperty(
-			        org.apache.xml.serializer.OutputPropertiesFactory.S_KEY_INDENT_AMOUNT,
-			        Integer.toString(indent));
-		}
 		transformer.transform(new DOMSource(document), new StreamResult(new FileOutputStream(
 		        filePathname)));
 	}
"
f784e2f4c82ad36ce2f4ca91adcc88ba06f7d2e7,Ali Mesbah,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index 85af1cd..c1ebb1d 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -15,12 +15,10 @@
 import com.crawljax.core.state.Eventable;
 
 /**
- * class for finding and checking elements.
- * 
- * @author danny
+ * Finds and checks elements.
  */
 public class ElementResolver {
-	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class.getName());
+	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class);
 
 	private final EmbeddedBrowser browser;
 	private final Eventable eventable;
@@ -54,7 +52,7 @@
 	public String resolve(boolean logging) {
 		Document dom = null;
 		try {
-			dom = DomUtils.asDocument(browser.getDom());
+			dom = DomUtils.asDocument(browser.getStrippedDom());
 		} catch (IOException e) {
 			LOGGER.error(e.getMessage(), e);
 			return """";
"
c64f7c489f205f20ccd7f2786a6431594d886d66,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index a4638b3..a35319d 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -2,6 +2,7 @@
 
 import static com.google.common.base.Preconditions.checkArgument;
 
+import java.io.File;
 import java.io.UnsupportedEncodingException;
 import java.net.MalformedURLException;
 import java.net.URL;
@@ -166,6 +167,33 @@
 			return this;
 		}
 
+		/**
+		 * Set the output folder for any {@link Plugin} you might configure. Crawljax itself doesn't
+		 * need an output folder but many plug-ins do.
+		 * 
+		 * @param output
+		 *            The output folder. If it does not exist it will be created.
+		 * @throws IllegalStateException
+		 *             if the specified file is not writable or exists but isn't a folder.
+		 */
+		public CrawljaxConfigurationBuilder setOutputDirectory(File output) {
+			config.output = output;
+			checkOutputDirWritable();
+			return this;
+		}
+
+		private void checkOutputDirWritable() {
+			if (!config.output.exists()) {
+				Preconditions.checkState(config.output.mkdirs(),
+				        ""Could not create the output directory %s "", config.output);
+			} else {
+				Preconditions.checkArgument(config.output.isDirectory(),
+				        ""Output directory %s is not a folder"", config.output);
+				Preconditions.checkState(config.output.canWrite(),
+				        ""Output directory %s is not writable"", config.output);
+			}
+		}
+
 		public CrawljaxConfiguration build() {
 			config.plugins = new Plugins(pluginBuilder.build());
 			config.crawlRules = crawlRules.build();
@@ -213,6 +241,7 @@
 	private int maximumStates = 0;
 	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);;
 	private int maximumDepth = 2;
+	private File output = new File(""out"");
 
 	private CrawljaxConfiguration() {
 	}
@@ -249,6 +278,10 @@
 		return maximumDepth;
 	}
 
+	public File getOutputDir() {
+		return output;
+	}
+
 	@Override
 	public int hashCode() {
 		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
"
085ce701a22e987bbf131756bfd5a523b8fe25c0,Alex Nederlof,UnfiredCandidateActions.java,MODIFY,"addActions -> [Collection actions, StateVertex state] | [ImmutableList extract, StateVertex currentState]","diff --git a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
index 19055a1..4e1beb3 100644
--- a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
+++ b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
@@ -6,7 +6,6 @@
 import java.util.Map;
 import java.util.Queue;
 import java.util.concurrent.BlockingQueue;
-import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.locks.Lock;
 
 import javax.inject.Inject;
@@ -16,10 +15,13 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import com.codahale.metrics.Counter;
+import com.codahale.metrics.MetricRegistry;
 import com.crawljax.core.configuration.BrowserConfiguration;
 import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.core.state.StateFlowGraph;
 import com.crawljax.core.state.StateVertex;
+import com.crawljax.metrics.MetricsModule;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Queues;
@@ -37,16 +39,22 @@
 	private final BlockingQueue<Integer> statesWithCandidates;
 	private final Striped<Lock> locks;
 	private final Provider<StateFlowGraph> sfg;
-	private final AtomicInteger crawlerLostCount = new AtomicInteger();
-	private final AtomicInteger actionsNotFiredCount = new AtomicInteger();
+	private final Counter crawlerLostCount;
+	private final Counter unfiredActionsCount;
 
 	@Inject
-	UnfiredCandidateActions(BrowserConfiguration config, Provider<StateFlowGraph> sfg) {
+	UnfiredCandidateActions(BrowserConfiguration config, Provider<StateFlowGraph> sfg,
+	        MetricRegistry registry) {
 		this.sfg = sfg;
 		cache = Maps.newHashMap();
 		statesWithCandidates = Queues.newLinkedBlockingQueue();
 		// Every browser gets a lock.
 		locks = Striped.lock(config.getNumberOfBrowsers());
+
+		crawlerLostCount =
+		        registry.register(MetricsModule.EVENTS_PREFIX + ""crawler_lost"", new Counter());
+		unfiredActionsCount =
+		        registry.register(MetricsModule.EVENTS_PREFIX + ""unfired_actions"", new Counter());
 	}
 
 	/**
@@ -156,14 +164,11 @@
 			removeStateFromQueue(crawlTask.getId());
 			Queue<CandidateCrawlAction> removed = cache.remove(crawlTask.getId());
 			if (removed != null) {
-				actionsNotFiredCount.addAndGet(removed.size());
+				unfiredActionsCount.inc(removed.size());
 			}
 		} finally {
 			lock.unlock();
+			crawlerLostCount.inc();
 		}
-		crawlerLostCount.incrementAndGet();
-		LOG.info(""In total {} actions weren't fired because crawljax got lost {} times"",
-		        actionsNotFiredCount, crawlerLostCount);
 	}
-
 }
"
085ce701a22e987bbf131756bfd5a523b8fe25c0,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index a35319d..486e854 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -15,7 +15,6 @@
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
-import com.crawljax.core.plugin.Plugins;
 import com.crawljax.di.CoreModule;
 import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
@@ -195,7 +194,7 @@
 		}
 
 		public CrawljaxConfiguration build() {
-			config.plugins = new Plugins(pluginBuilder.build());
+			config.plugins = pluginBuilder.build();
 			config.crawlRules = crawlRules.build();
 			return config;
 		}
@@ -233,7 +232,7 @@
 	private URL url;
 
 	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.FIREFOX);
-	private Plugins plugins;
+	private ImmutableList<Plugin> plugins;
 	private ProxyConfiguration proxyConfiguration = ProxyConfiguration.noProxy();
 
 	private CrawlRules crawlRules;
@@ -254,7 +253,7 @@
 		return browserConfig;
 	}
 
-	public Plugins getPlugins() {
+	public ImmutableList<Plugin> getPlugins() {
 		return plugins;
 	}
 
"
123ef76f0453a69e02f65c13c230cbda344ccc08,Jeremy Hewett,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index bb10305..e645a17 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -39,7 +39,6 @@
 
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.AcceptAllFramesChecker;
-import com.crawljax.core.configuration.CrawljaxConfiguration;
 import com.crawljax.core.configuration.IgnoreFrameChecker;
 import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.core.state.Eventable;
@@ -49,69 +48,12 @@
 import com.crawljax.forms.InputValue;
 import com.crawljax.forms.RandomInputValueGenerator;
 import com.crawljax.util.DomUtils;
+import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableSortedSet;
 
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
-	private long crawlWaitEvent;
 	private static final Logger LOGGER = LoggerFactory
 	        .getLogger(WebDriverBackedEmbeddedBrowser.class);
-	private final WebDriver browser;
-
-	private ImmutableSortedSet<String> filterAttributes;
-	private long crawlWaitReload;
-	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
-
-	/**
-	 * Constructor without configuration values, these must be updated using the
-	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
-		this.browser = driver;
-	}
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload, long crawlWaitEvent) {
-		this(driver);
-		this.filterAttributes = filterAttributes;
-		this.crawlWaitEvent = crawlWaitEvent;
-		this.crawlWaitReload = crawlWaitReload;
-	}
-
-	/**
-	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
-	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload,
-	        long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
-		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
-		this.ignoreFrameChecker = ignoreFrameChecker;
-	}
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
@@ -239,6 +181,66 @@
 		return new RemoteWebDriver(executor, capabilities);
 	}
 
+	private final ImmutableSortedSet<String> filterAttributes;
+	private final WebDriver browser;
+
+	private long crawlWaitEvent;
+	private long crawlWaitReload;
+	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
+
+	/**
+	 * Constructor without configuration values, these must be updated using the
+	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
+		this.browser = driver;
+		filterAttributes = ImmutableSortedSet.of();
+	}
+
+	/**
+	 * Constructor.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload, long crawlWaitEvent) {
+		this.browser = driver;
+		this.filterAttributes = Preconditions.checkNotNull(filterAttributes);
+		this.crawlWaitEvent = crawlWaitEvent;
+		this.crawlWaitReload = crawlWaitReload;
+	}
+
+	/**
+	 * Constructor.
+	 * 
+	 * @param driver
+	 *            The WebDriver to use.
+	 * @param filterAttributes
+	 *            the attributes to be filtered from DOM.
+	 * @param crawlWaitReload
+	 *            the period to wait after a reload.
+	 * @param crawlWaitEvent
+	 *            the period to wait after an event is fired.
+	 * @param ignoreFrameChecker
+	 *            the checker used to determine if a certain frame must be ignored.
+	 */
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
+	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload,
+	        long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
+		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
+		this.ignoreFrameChecker = ignoreFrameChecker;
+	}
+
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
 	 * 
@@ -337,7 +339,13 @@
 	}
 
 	@Override
+	@Deprecated
 	public String getDom() {
+		return getStrippedDom();
+	}
+
+	@Override
+	public String getStrippedDom() {
 
 		try {
 			String dom = toUniformDOM(DomUtils.getDocumentToString(getDomTreeWithFrames()));
@@ -349,6 +357,11 @@
 		}
 	}
 
+	@Override
+	public String getUnStrippedDom() {
+		return browser.getPageSource();
+	}
+
 	/**
 	 * @param html
 	 *            The html string.
@@ -379,13 +392,11 @@
 	 */
 	private String filterAttributes(String html) {
 		String filteredHtml = html;
-		if (this.filterAttributes != null) {
-			for (String attribute : this.filterAttributes) {
-				String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
-				Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
-				Matcher m = p.matcher(html);
-				filteredHtml = m.replaceAll("""");
-			}
+		for (String attribute : this.filterAttributes) {
+			String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
+			Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
+			Matcher m = p.matcher(html);
+			filteredHtml = m.replaceAll("""");
 		}
 		return filteredHtml;
 	}
@@ -587,14 +598,14 @@
 		for (int i = 0; i < nodeList.size(); i++) {
 			try {
 				locateFrameAndgetSource(document, topFrame, nodeList.get(i));
-			} catch (UnknownServerException e) {
+			} catch (UnknownServerException | NoSuchFrameException e) {
 				LOGGER.warn(""Could not add frame contents for element {}"", nodeList.get(i));
 				LOGGER.debug(""Could not load frame because of {}"", e.getMessage(), e);
 			}
 		}
 	}
 
-	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement) {
+	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement) throws NoSuchFrameException {
 		String frameIdentification = """";
 
 		if (topFrame != null && !topFrame.equals("""")) {
@@ -633,7 +644,7 @@
 		}
 	}
 
-	private void switchToFrame(String frameIdentification) {
+	private void switchToFrame(String frameIdentification) throws NoSuchFrameException {
 		LOGGER.debug(""frame identification: "" + frameIdentification);
 
 		if (frameIdentification.contains(""."")) {
@@ -652,10 +663,10 @@
 
 	/**
 	 * @return the dom without the iframe contents.
-	 * @see com.crawljax.browser.EmbeddedBrowser#getDomWithoutIframeContent()
+	 * @see com.crawljax.browser.EmbeddedBrowser#getStrippedDomWithoutIframeContent()
 	 */
 	@Override
-	public String getDomWithoutIframeContent() {
+	public String getStrippedDomWithoutIframeContent() {
 		try {
 			String dom = browser.getPageSource();
 			String result = toUniformDOM(dom);
@@ -856,15 +867,6 @@
 		return browser;
 	}
 
-	@Override
-	public void updateConfiguration(CrawljaxConfiguration configuration) {
-		// Retrieve the config values used
-		this.filterAttributes =
-		        configuration.getCrawlRules().getPreCrawlConfig().getFilterAttributeNames();
-		this.crawlWaitReload = configuration.getCrawlRules().getWaitAfterReloadUrl();
-		this.crawlWaitEvent = configuration.getCrawlRules().getWaitAfterEvent();
-	}
-
 	private boolean exceptionIsConnectionException(WebDriverException exception) {
 		return exception != null && exception.getCause() != null
 		        && exception.getCause() instanceof IOException;
"
123ef76f0453a69e02f65c13c230cbda344ccc08,Jeremy Hewett,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index bf6584f..a35319d 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -2,6 +2,7 @@
 
 import static com.google.common.base.Preconditions.checkArgument;
 
+import java.io.File;
 import java.io.UnsupportedEncodingException;
 import java.net.MalformedURLException;
 import java.net.URL;
@@ -158,7 +159,7 @@
 		/**
 		 * @param configuration
 		 *            a custom {@link BrowserConfiguration}. The default is a single
-		 *            {@link BrowserType#firefox} browser.
+		 *            {@link BrowserType#FIREFOX} browser.
 		 */
 		public CrawljaxConfigurationBuilder setBrowserConfig(BrowserConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -166,6 +167,33 @@
 			return this;
 		}
 
+		/**
+		 * Set the output folder for any {@link Plugin} you might configure. Crawljax itself doesn't
+		 * need an output folder but many plug-ins do.
+		 * 
+		 * @param output
+		 *            The output folder. If it does not exist it will be created.
+		 * @throws IllegalStateException
+		 *             if the specified file is not writable or exists but isn't a folder.
+		 */
+		public CrawljaxConfigurationBuilder setOutputDirectory(File output) {
+			config.output = output;
+			checkOutputDirWritable();
+			return this;
+		}
+
+		private void checkOutputDirWritable() {
+			if (!config.output.exists()) {
+				Preconditions.checkState(config.output.mkdirs(),
+				        ""Could not create the output directory %s "", config.output);
+			} else {
+				Preconditions.checkArgument(config.output.isDirectory(),
+				        ""Output directory %s is not a folder"", config.output);
+				Preconditions.checkState(config.output.canWrite(),
+				        ""Output directory %s is not writable"", config.output);
+			}
+		}
+
 		public CrawljaxConfiguration build() {
 			config.plugins = new Plugins(pluginBuilder.build());
 			config.crawlRules = crawlRules.build();
@@ -204,7 +232,7 @@
 
 	private URL url;
 
-	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.firefox);
+	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.FIREFOX);
 	private Plugins plugins;
 	private ProxyConfiguration proxyConfiguration = ProxyConfiguration.noProxy();
 
@@ -213,6 +241,7 @@
 	private int maximumStates = 0;
 	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);;
 	private int maximumDepth = 2;
+	private File output = new File(""out"");
 
 	private CrawljaxConfiguration() {
 	}
@@ -249,6 +278,10 @@
 		return maximumDepth;
 	}
 
+	public File getOutputDir() {
+		return output;
+	}
+
 	@Override
 	public int hashCode() {
 		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
"
123ef76f0453a69e02f65c13c230cbda344ccc08,Jeremy Hewett,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index 5551a72..97973c2 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -194,7 +194,7 @@
 		List<FormInput> formInputs = new ArrayList<FormInput>();
 		Document dom;
 		try {
-			dom = DomUtils.asDocument(browser.getDom());
+			dom = DomUtils.asDocument(browser.getStrippedDom());
 			List<Node> nodes = getInputElements(dom);
 			for (Node node : nodes) {
 				FormInput formInput =
@@ -227,7 +227,7 @@
 	 */
 	public void handleFormElements(List<FormInput> formInputs) {
 		try {
-			Document dom = DomUtils.asDocument(browser.getDomWithoutIframeContent());
+			Document dom = DomUtils.asDocument(browser.getStrippedDomWithoutIframeContent());
 			for (FormInput input : formInputs) {
 				LOGGER.debug(""Filling in: "" + input);
 				setInputElementValue(formInputValueHelper.getBelongingNode(input, dom), input);
"
123ef76f0453a69e02f65c13c230cbda344ccc08,Jeremy Hewett,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index d0d3edd..3e16f5b 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -529,11 +529,6 @@
 		transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
 		transformer.setOutputProperty(OutputKeys.METHOD, method);
 
-		if (indent > -1) {
-			transformer.setOutputProperty(
-			        org.apache.xml.serializer.OutputPropertiesFactory.S_KEY_INDENT_AMOUNT,
-			        Integer.toString(indent));
-		}
 		transformer.transform(new DOMSource(document), new StreamResult(new FileOutputStream(
 		        filePathname)));
 	}
"
123ef76f0453a69e02f65c13c230cbda344ccc08,Jeremy Hewett,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index 85af1cd..c1ebb1d 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -15,12 +15,10 @@
 import com.crawljax.core.state.Eventable;
 
 /**
- * class for finding and checking elements.
- * 
- * @author danny
+ * Finds and checks elements.
  */
 public class ElementResolver {
-	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class.getName());
+	private static final Logger LOGGER = LoggerFactory.getLogger(ElementResolver.class);
 
 	private final EmbeddedBrowser browser;
 	private final Eventable eventable;
@@ -54,7 +52,7 @@
 	public String resolve(boolean logging) {
 		Document dom = null;
 		try {
-			dom = DomUtils.asDocument(browser.getDom());
+			dom = DomUtils.asDocument(browser.getStrippedDom());
 		} catch (IOException e) {
 			LOGGER.error(e.getMessage(), e);
 			return """";
"
635cb62b7335ac2830a28207cd4268217f9d0ad6,Alex Nederlof,CrawlActionsBuilder.java,MODIFY,click -> [String tagNames] | [String tagName],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
index c6b5a4e..9dea6fe 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
@@ -11,12 +11,6 @@
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Lists;
 
-/**
- * Specifies the actions for CrawlElements NOTE: In general CrawlActions is not designed to be
- * instantiated directly. CrawlActions should be used via {@link CrawlSpecification} To add
- * conditions to check whether a tag should (not) be clicked one can use {@link #when(Condition...)}
- * . See also {@link Condition}
- */
 public class CrawlActionsBuilder {
 
 	private static final Logger LOG = LoggerFactory.getLogger(CrawlActionsBuilder.class);
@@ -92,9 +86,8 @@
 	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}. If
 	 * no clicks are specified, {@link #clickDefaultElements()} is enabled.
 	 * 
-	 * @param tagName
+	 * @param tagNames
 	 *            the tag name of the elements to be included
-	 * @return this CrawlElement
 	 */
 	public void click(String... tagNames) {
 		for (String tagName : tagNames) {
"
635cb62b7335ac2830a28207cd4268217f9d0ad6,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 486e854..aa1a044 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -104,7 +104,7 @@
 		}
 
 		/**
-		 * @param time
+		 * @param depth
 		 *            The maximum depth the crawler can reach. The default is <code>2</code>.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumDepth(int depth) {
@@ -148,8 +148,7 @@
 		}
 
 		/**
-		 * @return The {@link CrawlRulesBuilder} to define crawling rules. If no specified, Crawljax
-		 *         will do {@link CrawlRulesBuilder#}
+		 * @return The {@link CrawlRulesBuilder} to define crawling rules.
 		 */
 		public CrawlRulesBuilder crawlRules() {
 			return crawlRules;
"
635cb62b7335ac2830a28207cd4268217f9d0ad6,Alex Nederlof,CrawlPath.java,MODIFY,immutableCopy -> [boolean removeLast] | [],"diff --git a/core/src/main/java/com/crawljax/core/state/CrawlPath.java b/core/src/main/java/com/crawljax/core/state/CrawlPath.java
index af8ad19..82d1feb 100644
--- a/core/src/main/java/com/crawljax/core/state/CrawlPath.java
+++ b/core/src/main/java/com/crawljax/core/state/CrawlPath.java
@@ -55,8 +55,6 @@
 	 * Create an immutableCopy of the current CrawlPath, used for backtracking for giving them to
 	 * plugins.
 	 * 
-	 * @param removeLast
-	 *            should the last element be removed?
 	 * @return the CrawlPath based on an immutable list.
 	 */
 	public CrawlPath immutableCopy() {
"
635cb62b7335ac2830a28207cd4268217f9d0ad6,Alex Nederlof,InMemoryStateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
index ed77d35..b6abd4c 100644
--- a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
@@ -57,8 +57,8 @@
 	/**
 	 * The constructor.
 	 * 
-	 * @param initialState
-	 *            the state to start from.
+	 * @param exitNotifier
+	 *            used for triggering an exit.
 	 */
 	@Inject
 	public InMemoryStateFlowGraph(ExitNotifier exitNotifier) {
"
635cb62b7335ac2830a28207cd4268217f9d0ad6,Alex Nederlof,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index 97973c2..ea780e2 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -1,6 +1,3 @@
-/**
- * Created Aug 13, 2008
- */
 package com.crawljax.forms;
 
 import java.io.IOException;
@@ -43,16 +40,6 @@
 
 	private final FormInputValueHelper formInputValueHelper;
 
-	/**
-	 * Public constructor.
-	 * 
-	 * @param browser
-	 *            the embedded browser.
-	 * @param inputSpecification
-	 *            the input specification.
-	 * @param randomInput
-	 *            if random data should be generated on the input fields.
-	 */
 	@Inject
 	public FormHandler(@Assisted EmbeddedBrowser browser, CrawlRules config) {
 		this.browser = browser;
"
635cb62b7335ac2830a28207cd4268217f9d0ad6,Alex Nederlof,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index bdb6a53..285207e 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -126,7 +126,6 @@
 	 *            the Document to search in
 	 * @param xpathExpr
 	 *            the xpath query
-	 * @author cor-paul
 	 * @return the list of nodes which match the query
 	 * @throws XPathExpressionException
 	 *             On error.
@@ -233,7 +232,6 @@
 	 *            the Document to search in
 	 * @param xpath
 	 *            the xpath query
-	 * @author Danny
 	 * @return position of xpath element, if fails returns -1
 	 **/
 	public static int getXPathLocation(String dom, String xpath) {
"
9af35109c9f735e28319fa72250457153a6ad4ae,Alex Nederlof,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index 285207e..f535be4 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -70,9 +70,7 @@
 			Node el = mySiblings.get(i);
 
 			if (el.equals(node)) {
-				buffer.append(""["");
-				buffer.append(Integer.toString(i + 1));
-				buffer.append(""]"");
+				buffer.append('[').append(Integer.toString(i + 1)).append(']');
 				// Found so break;
 				break;
 			}
@@ -243,7 +241,7 @@
 		int number;
 		for (String element : elements) {
 			if (!element.isEmpty() && !element.startsWith(""@"") && !element.contains(""()"")) {
-				if (element.indexOf(""["") != -1) {
+				if (element.contains(""["")) {
 					try {
 						number =
 						        Integer.parseInt(element.substring(element.indexOf(""["") + 1,
"
fd7a06f045312b80d2234088935178db74d622a8,daisy1754,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/core/src/main/java/com/crawljax/core/CrawlQueue.java b/core/src/main/java/com/crawljax/core/CrawlQueue.java
index 0d76156..bb9e752 100644
--- a/core/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/core/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -1,6 +1,3 @@
-/**
- * 
- */
 package com.crawljax.core;
 
 import java.util.Collection;
"
fb2a637aa74990d07fc4cbbca08e28919d7d55ba,Alex Nederlof,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/core/src/main/java/com/crawljax/core/CrawlQueue.java b/core/src/main/java/com/crawljax/core/CrawlQueue.java
index 0d76156..bb9e752 100644
--- a/core/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/core/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -1,6 +1,3 @@
-/**
- * 
- */
 package com.crawljax.core;
 
 import java.util.Collection;
"
5fbb48d91747a471400f49d8e4e88945c0ea03d8,Jeremy Hewett,Configuration.java,MODIFY,setFormInputValues -> [List formInputValues] | [Map formInputValues],"diff --git a/web/src/main/java/com/crawljax/web/model/Configuration.java b/web/src/main/java/com/crawljax/web/model/Configuration.java
index 8c34492..5bdf03d 100644
--- a/web/src/main/java/com/crawljax/web/model/Configuration.java
+++ b/web/src/main/java/com/crawljax/web/model/Configuration.java
@@ -1,8 +1,6 @@
 package com.crawljax.web.model;
 
-import java.util.ArrayList;
-import java.util.Date;
-import java.util.List;
+import java.util.*;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 
@@ -25,7 +23,7 @@
 	private List<Condition> pageConditions = new ArrayList<>();
 	private List<Condition> invariants = new ArrayList<>();
 	private List<Comparator> comparators = new ArrayList<>();
-	private List<NameValuePair> formInputValues = new ArrayList<>();
+	private Map<String, String> formInputValues = new HashMap<>();
 	private Date lastCrawl = null;
 	private long lastDuration;
 	private Date lastModified = null;
@@ -305,7 +303,7 @@
 	/**
 	 * @return the formInputValues
 	 */
-	public List<NameValuePair> getFormInputValues() {
+	public Map<String, String> getFormInputValues() {
 		return formInputValues;
 	}
 
@@ -313,7 +311,7 @@
 	 * @param formInputValues
 	 *            the formInputValues to set
 	 */
-	public void setFormInputValues(List<NameValuePair> formInputValues) {
+	public void setFormInputValues(Map<String, String> formInputValues) {
 		this.formInputValues = formInputValues;
 	}
 
"
beed38da36e88a8b122af32021d61903162c3690,Jeremy Hewett,Configuration.java,MODIFY,setFormInputValues -> [Map formInputValues] | [List formInputValues],"diff --git a/web/src/main/java/com/crawljax/web/model/Configuration.java b/web/src/main/java/com/crawljax/web/model/Configuration.java
index 5bdf03d..2abdbfa 100644
--- a/web/src/main/java/com/crawljax/web/model/Configuration.java
+++ b/web/src/main/java/com/crawljax/web/model/Configuration.java
@@ -1,9 +1,11 @@
 package com.crawljax.web.model;
 
-import java.util.*;
-
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
 
+import java.util.ArrayList;
+import java.util.Date;
+import java.util.List;
+
 public class Configuration {
 	private String id;
 	private String name;
@@ -23,7 +25,7 @@
 	private List<Condition> pageConditions = new ArrayList<>();
 	private List<Condition> invariants = new ArrayList<>();
 	private List<Comparator> comparators = new ArrayList<>();
-	private Map<String, String> formInputValues = new HashMap<>();
+	private List<NameValuePair> formInputValues = new ArrayList<>();
 	private Date lastCrawl = null;
 	private long lastDuration;
 	private Date lastModified = null;
@@ -303,7 +305,7 @@
 	/**
 	 * @return the formInputValues
 	 */
-	public Map<String, String> getFormInputValues() {
+	public List<NameValuePair> getFormInputValues() {
 		return formInputValues;
 	}
 
@@ -311,7 +313,7 @@
 	 * @param formInputValues
 	 *            the formInputValues to set
 	 */
-	public void setFormInputValues(Map<String, String> formInputValues) {
+	public void setFormInputValues(List<NameValuePair> formInputValues) {
 		this.formInputValues = formInputValues;
 	}
 
"
c3b14830f1c3296c03da7f0ab67d19ec0181d81d,Jeremy Hewett,PluginsResource.java,MODIFY,"addPlugin -> [String name, String file] | [String name, String file, String url]","diff --git a/web/src/main/java/com/crawljax/web/jaxrs/PluginsResource.java b/web/src/main/java/com/crawljax/web/jaxrs/PluginsResource.java
index cfe2d07..5570743 100644
--- a/web/src/main/java/com/crawljax/web/jaxrs/PluginsResource.java
+++ b/web/src/main/java/com/crawljax/web/jaxrs/PluginsResource.java
@@ -1,6 +1,8 @@
 package com.crawljax.web.jaxrs;
 
 import java.io.IOException;
+import java.net.MalformedURLException;
+import java.net.URL;
 
 import javax.ws.rs.Consumes;
 import javax.ws.rs.DELETE;
@@ -61,19 +63,32 @@
 	@POST
 	@Consumes(MediaType.MULTIPART_FORM_DATA)
 	public Response addPlugin(@FormDataParam(""name"") String name,
-	        @FormDataParam(""file"") String file) {
-		String content = file.substring(file.indexOf(',') + 1);
-		BASE64Decoder decoder = new BASE64Decoder();
+	        @FormDataParam(""file"") String file,
+			@FormDataParam(""url"") String url) {
 		Plugin plugin = null;
-		try {
-			byte[] decodedBytes = decoder.decodeBuffer(content);
+
+		if(file != null) {
+			String content = file.substring(file.indexOf(',') + 1);
+			BASE64Decoder decoder = new BASE64Decoder();
 			try {
-				plugin = plugins.add(name, decodedBytes);
+				byte[] decodedBytes = decoder.decodeBuffer(content);
+				try {
+					plugin = plugins.add(name, decodedBytes);
+				} catch (CrawljaxWebException e) {
+					LogWebSocketServlet.sendToAll(""message-error-"" + e.getMessage());
+				}
+			} catch (IOException e) {
+				e.printStackTrace();
+			}
+		} else if(url != null) {
+			try {
+				URL urlObject = new URL(url);
+				plugin = plugins.add(name, urlObject);
+			} catch (MalformedURLException e) {
+				LogWebSocketServlet.sendToAll(""message-error-Invalid URL"");
 			} catch (CrawljaxWebException e) {
 				LogWebSocketServlet.sendToAll(""message-error-"" + e.getMessage());
 			}
-		} catch (IOException e) {
-			e.printStackTrace();
 		}
 		return Response.ok(plugin).build();
 	}
@@ -81,7 +96,11 @@
 	@DELETE
 	@Path(""{id}"")
 	public Response removePlugin(Plugin plugin) {
-		plugin = plugins.remove(plugin);
+		try {
+			plugin = plugins.remove(plugin);
+		} catch (CrawljaxWebException e) {
+			LogWebSocketServlet.sendToAll(""message-error-"" + e.getMessage());
+		}
 		return Response.ok(plugin).build();
 	}
 }
"
c3b14830f1c3296c03da7f0ab67d19ec0181d81d,Jeremy Hewett,Plugins.java,MODIFY,"add -> [String fileName, byte[] data] | [String name, URL url]","diff --git a/web/src/main/java/com/crawljax/web/model/Plugins.java b/web/src/main/java/com/crawljax/web/model/Plugins.java
index 3048be2..d88246e 100644
--- a/web/src/main/java/com/crawljax/web/model/Plugins.java
+++ b/web/src/main/java/com/crawljax/web/model/Plugins.java
@@ -46,7 +46,24 @@
 		if (extensionIndex < 0) {
 			throw new CrawljaxWebException(""Expected .jar file"");
 		}
-		String id = fileName.substring(0, extensionIndex);
+		String id = adaptToId(fileName.substring(0, extensionIndex));
+		Plugin plugin = pluginManager.save(id, data);
+		if(plugin != null) {
+			pluginList.put(plugin.getId(), plugin);
+		}
+		return plugin;
+	}
+
+	public Plugin add(String name, URL url) throws CrawljaxWebException {
+		String id = adaptToId(name);
+		Plugin plugin = pluginManager.save(id, url);
+		if(plugin != null) {
+			pluginList.put(plugin.getId(), plugin);
+		}
+		return plugin;
+	}
+
+	private String adaptToId(String id) {
 		id = id.toLowerCase().replaceAll(""[^a-z0-9]+"", ""-"");
 		if (pluginList.containsKey(id)) {
 			int i = 1;
@@ -55,16 +72,14 @@
 			}
 			id += Integer.toString(i);
 		}
-		Plugin plugin = pluginManager.save(id, data);
-		if(plugin != null) {
-			pluginList.put(plugin.getId(), plugin);
-		}
-		return plugin;
+		return id;
 	}
 
-	public Plugin remove(Plugin plugin) {
+	public Plugin remove(Plugin plugin) throws CrawljaxWebException {
 		if(pluginManager.delete(plugin)) {
 			pluginList.remove(plugin.getId());
+		} else {
+			throw new CrawljaxWebException(""Failed to delete plugin file"");
 		}
 		return plugin;
 	}
"
1222cfdd92ee9d55905e23dba1ec476a2414d0f0,Jeremy Hewett,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/core/src/main/java/com/crawljax/core/CrawlQueue.java b/core/src/main/java/com/crawljax/core/CrawlQueue.java
index 0d76156..bb9e752 100644
--- a/core/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/core/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -1,6 +1,3 @@
-/**
- * 
- */
 package com.crawljax.core;
 
 import java.util.Collection;
"
1222cfdd92ee9d55905e23dba1ec476a2414d0f0,Jeremy Hewett,UnfiredCandidateActions.java,MODIFY,"addActions -> [Collection actions, StateVertex state] | [ImmutableList extract, StateVertex currentState]","diff --git a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
index 19055a1..4e1beb3 100644
--- a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
+++ b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
@@ -6,7 +6,6 @@
 import java.util.Map;
 import java.util.Queue;
 import java.util.concurrent.BlockingQueue;
-import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.locks.Lock;
 
 import javax.inject.Inject;
@@ -16,10 +15,13 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import com.codahale.metrics.Counter;
+import com.codahale.metrics.MetricRegistry;
 import com.crawljax.core.configuration.BrowserConfiguration;
 import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.core.state.StateFlowGraph;
 import com.crawljax.core.state.StateVertex;
+import com.crawljax.metrics.MetricsModule;
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Maps;
 import com.google.common.collect.Queues;
@@ -37,16 +39,22 @@
 	private final BlockingQueue<Integer> statesWithCandidates;
 	private final Striped<Lock> locks;
 	private final Provider<StateFlowGraph> sfg;
-	private final AtomicInteger crawlerLostCount = new AtomicInteger();
-	private final AtomicInteger actionsNotFiredCount = new AtomicInteger();
+	private final Counter crawlerLostCount;
+	private final Counter unfiredActionsCount;
 
 	@Inject
-	UnfiredCandidateActions(BrowserConfiguration config, Provider<StateFlowGraph> sfg) {
+	UnfiredCandidateActions(BrowserConfiguration config, Provider<StateFlowGraph> sfg,
+	        MetricRegistry registry) {
 		this.sfg = sfg;
 		cache = Maps.newHashMap();
 		statesWithCandidates = Queues.newLinkedBlockingQueue();
 		// Every browser gets a lock.
 		locks = Striped.lock(config.getNumberOfBrowsers());
+
+		crawlerLostCount =
+		        registry.register(MetricsModule.EVENTS_PREFIX + ""crawler_lost"", new Counter());
+		unfiredActionsCount =
+		        registry.register(MetricsModule.EVENTS_PREFIX + ""unfired_actions"", new Counter());
 	}
 
 	/**
@@ -156,14 +164,11 @@
 			removeStateFromQueue(crawlTask.getId());
 			Queue<CandidateCrawlAction> removed = cache.remove(crawlTask.getId());
 			if (removed != null) {
-				actionsNotFiredCount.addAndGet(removed.size());
+				unfiredActionsCount.inc(removed.size());
 			}
 		} finally {
 			lock.unlock();
+			crawlerLostCount.inc();
 		}
-		crawlerLostCount.incrementAndGet();
-		LOG.info(""In total {} actions weren't fired because crawljax got lost {} times"",
-		        actionsNotFiredCount, crawlerLostCount);
 	}
-
 }
"
1222cfdd92ee9d55905e23dba1ec476a2414d0f0,Jeremy Hewett,CrawlActionsBuilder.java,MODIFY,click -> [String tagNames] | [String tagName],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
index c6b5a4e..9dea6fe 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
@@ -11,12 +11,6 @@
 import com.google.common.collect.ImmutableList;
 import com.google.common.collect.Lists;
 
-/**
- * Specifies the actions for CrawlElements NOTE: In general CrawlActions is not designed to be
- * instantiated directly. CrawlActions should be used via {@link CrawlSpecification} To add
- * conditions to check whether a tag should (not) be clicked one can use {@link #when(Condition...)}
- * . See also {@link Condition}
- */
 public class CrawlActionsBuilder {
 
 	private static final Logger LOG = LoggerFactory.getLogger(CrawlActionsBuilder.class);
@@ -92,9 +86,8 @@
 	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}. If
 	 * no clicks are specified, {@link #clickDefaultElements()} is enabled.
 	 * 
-	 * @param tagName
+	 * @param tagNames
 	 *            the tag name of the elements to be included
-	 * @return this CrawlElement
 	 */
 	public void click(String... tagNames) {
 		for (String tagName : tagNames) {
"
1222cfdd92ee9d55905e23dba1ec476a2414d0f0,Jeremy Hewett,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index a35319d..aa1a044 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -15,7 +15,6 @@
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
-import com.crawljax.core.plugin.Plugins;
 import com.crawljax.di.CoreModule;
 import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
@@ -105,7 +104,7 @@
 		}
 
 		/**
-		 * @param time
+		 * @param depth
 		 *            The maximum depth the crawler can reach. The default is <code>2</code>.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumDepth(int depth) {
@@ -149,8 +148,7 @@
 		}
 
 		/**
-		 * @return The {@link CrawlRulesBuilder} to define crawling rules. If no specified, Crawljax
-		 *         will do {@link CrawlRulesBuilder#}
+		 * @return The {@link CrawlRulesBuilder} to define crawling rules.
 		 */
 		public CrawlRulesBuilder crawlRules() {
 			return crawlRules;
@@ -195,7 +193,7 @@
 		}
 
 		public CrawljaxConfiguration build() {
-			config.plugins = new Plugins(pluginBuilder.build());
+			config.plugins = pluginBuilder.build();
 			config.crawlRules = crawlRules.build();
 			return config;
 		}
@@ -233,7 +231,7 @@
 	private URL url;
 
 	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.FIREFOX);
-	private Plugins plugins;
+	private ImmutableList<Plugin> plugins;
 	private ProxyConfiguration proxyConfiguration = ProxyConfiguration.noProxy();
 
 	private CrawlRules crawlRules;
@@ -254,7 +252,7 @@
 		return browserConfig;
 	}
 
-	public Plugins getPlugins() {
+	public ImmutableList<Plugin> getPlugins() {
 		return plugins;
 	}
 
"
1222cfdd92ee9d55905e23dba1ec476a2414d0f0,Jeremy Hewett,CrawlPath.java,MODIFY,immutableCopy -> [boolean removeLast] | [],"diff --git a/core/src/main/java/com/crawljax/core/state/CrawlPath.java b/core/src/main/java/com/crawljax/core/state/CrawlPath.java
index af8ad19..82d1feb 100644
--- a/core/src/main/java/com/crawljax/core/state/CrawlPath.java
+++ b/core/src/main/java/com/crawljax/core/state/CrawlPath.java
@@ -55,8 +55,6 @@
 	 * Create an immutableCopy of the current CrawlPath, used for backtracking for giving them to
 	 * plugins.
 	 * 
-	 * @param removeLast
-	 *            should the last element be removed?
 	 * @return the CrawlPath based on an immutable list.
 	 */
 	public CrawlPath immutableCopy() {
"
1222cfdd92ee9d55905e23dba1ec476a2414d0f0,Jeremy Hewett,InMemoryStateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
index ed77d35..b6abd4c 100644
--- a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
@@ -57,8 +57,8 @@
 	/**
 	 * The constructor.
 	 * 
-	 * @param initialState
-	 *            the state to start from.
+	 * @param exitNotifier
+	 *            used for triggering an exit.
 	 */
 	@Inject
 	public InMemoryStateFlowGraph(ExitNotifier exitNotifier) {
"
1222cfdd92ee9d55905e23dba1ec476a2414d0f0,Jeremy Hewett,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index 97973c2..ea780e2 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -1,6 +1,3 @@
-/**
- * Created Aug 13, 2008
- */
 package com.crawljax.forms;
 
 import java.io.IOException;
@@ -43,16 +40,6 @@
 
 	private final FormInputValueHelper formInputValueHelper;
 
-	/**
-	 * Public constructor.
-	 * 
-	 * @param browser
-	 *            the embedded browser.
-	 * @param inputSpecification
-	 *            the input specification.
-	 * @param randomInput
-	 *            if random data should be generated on the input fields.
-	 */
 	@Inject
 	public FormHandler(@Assisted EmbeddedBrowser browser, CrawlRules config) {
 		this.browser = browser;
"
1222cfdd92ee9d55905e23dba1ec476a2414d0f0,Jeremy Hewett,XPathHelper.java,MODIFY,"evaluateXpathExpression -> [Document dom, String xpathExpr] | [String domStr, String xpathExpr]","diff --git a/core/src/main/java/com/crawljax/util/XPathHelper.java b/core/src/main/java/com/crawljax/util/XPathHelper.java
index bdb6a53..f535be4 100644
--- a/core/src/main/java/com/crawljax/util/XPathHelper.java
+++ b/core/src/main/java/com/crawljax/util/XPathHelper.java
@@ -70,9 +70,7 @@
 			Node el = mySiblings.get(i);
 
 			if (el.equals(node)) {
-				buffer.append(""["");
-				buffer.append(Integer.toString(i + 1));
-				buffer.append(""]"");
+				buffer.append('[').append(Integer.toString(i + 1)).append(']');
 				// Found so break;
 				break;
 			}
@@ -126,7 +124,6 @@
 	 *            the Document to search in
 	 * @param xpathExpr
 	 *            the xpath query
-	 * @author cor-paul
 	 * @return the list of nodes which match the query
 	 * @throws XPathExpressionException
 	 *             On error.
@@ -233,7 +230,6 @@
 	 *            the Document to search in
 	 * @param xpath
 	 *            the xpath query
-	 * @author Danny
 	 * @return position of xpath element, if fails returns -1
 	 **/
 	public static int getXPathLocation(String dom, String xpath) {
@@ -245,7 +241,7 @@
 		int number;
 		for (String element : elements) {
 			if (!element.isEmpty() && !element.startsWith(""@"") && !element.contains(""()"")) {
-				if (element.indexOf(""["") != -1) {
+				if (element.contains(""["")) {
 					try {
 						number =
 						        Integer.parseInt(element.substring(element.indexOf(""["") + 1,
"
254cbc08ba211a7db9289230dc0d3d285df45c08,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index e645a17..6a5e7ed 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -23,7 +23,6 @@
 import org.openqa.selenium.WebDriverException;
 import org.openqa.selenium.WebElement;
 import org.openqa.selenium.internal.WrapsDriver;
-import org.openqa.selenium.io.FileHandler;
 import org.openqa.selenium.remote.Augmenter;
 import org.openqa.selenium.remote.DesiredCapabilities;
 import org.openqa.selenium.remote.ErrorHandler.UnknownServerException;
@@ -50,6 +49,7 @@
 import com.crawljax.util.DomUtils;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableSortedSet;
+import com.google.common.io.Files;
 
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
 	private static final Logger LOGGER = LoggerFactory
@@ -605,7 +605,8 @@
 		}
 	}
 
-	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement) throws NoSuchFrameException {
+	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement)
+	        throws NoSuchFrameException {
 		String frameIdentification = """";
 
 		if (topFrame != null && !topFrame.equals("""")) {
@@ -812,7 +813,7 @@
 		try {
 			File tmpfile = takeScreenShotOnBrowser(browser, OutputType.FILE);
 			try {
-				FileHandler.copy(tmpfile, file);
+				Files.copy(tmpfile, file);
 			} catch (IOException e) {
 				throw new CrawljaxException(e);
 			}
"
16b249cf03cc9f25e87983643f3e45155760393e,Alex Nederlof,CandidateElementExtractor.java,MODIFY,"extractElements -> [Document dom, Builder results, String relatedFrame] | [Document dom, List results, String relatedFrame]","diff --git a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
index c36d311..1273615 100644
--- a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
+++ b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
@@ -3,12 +3,12 @@
 import java.io.IOException;
 import java.util.ArrayList;
 import java.util.Collections;
+import java.util.LinkedList;
 import java.util.List;
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
 import javax.inject.Inject;
-import javax.xml.bind.annotation.adapters.CollapsedStringAdapter;
 import javax.xml.xpath.XPathExpressionException;
 
 import org.slf4j.Logger;
@@ -35,7 +35,6 @@
 import com.google.common.collect.ImmutableList.Builder;
 import com.google.common.collect.ImmutableMultimap;
 import com.google.common.collect.ImmutableSortedSet;
-import com.google.common.collect.Lists;
 import com.google.inject.assistedinject.Assisted;
 
 /**
@@ -55,7 +54,7 @@
 	private final ImmutableList<CrawlElement> includedCrawlElements;
 
 	private final boolean clickOnce;
-	private final boolean randomize;
+	private final boolean randomizeElementsOrder;
 
 	private final ImmutableSortedSet<String> ignoredFrameIdentifiers;
 
@@ -81,16 +80,13 @@
 		CrawlRules rules = config.getCrawlRules();
 		PreCrawlConfiguration preCrawlConfig = rules.getPreCrawlConfig();
 		this.excludeCrawlElements = asMultiMap(preCrawlConfig.getExcludedElements());
-		this.includedCrawlElements =
-		        ImmutableList
-		                .<CrawlElement> builder()
-		                .addAll(preCrawlConfig.getIncludedElements())
-		                .addAll(rules.getInputSpecification().getCrawlElements())
-		                .build();
-
+		this.includedCrawlElements = ImmutableList.<CrawlElement> builder()
+		        .addAll(preCrawlConfig.getIncludedElements())
+		        .addAll(rules.getInputSpecification().getCrawlElements())
+		        .build();
 		crawlFrames = rules.shouldCrawlFrames();
 		clickOnce = rules.isClickOnce();
-		randomize = rules.isRandomized();
+		randomizeElementsOrder = rules.isRandomizeCandidateElements();
 		ignoredFrameIdentifiers = rules.getIgnoredFrameIdentifiers();
 	}
 
@@ -115,11 +111,11 @@
 	 */
 	public ImmutableList<CandidateElement> extract(StateVertex currentState)
 	        throws CrawljaxException {
-		Builder<CandidateElement> results = ImmutableList.builder();
+		LinkedList<CandidateElement> results = new LinkedList<>();
 
 		if (!checkedElements.checkCrawlCondition(browser)) {
 			LOG.info(""State {} did not satisfy the CrawlConditions."", currentState.getName());
-			return results.build();
+			return ImmutableList.of();
 		}
 		LOG.debug(""Looking in state: {} for candidate elements"", currentState.getName());
 
@@ -130,19 +126,15 @@
 			LOG.error(e.getMessage(), e);
 			throw new CrawljaxException(e);
 		}
-		ImmutableList<CandidateElement> found = results.build();
-		
-		if(randomize){
-			ArrayList<CandidateElement> shuffleCandidateElements = Lists.newArrayList(found);
-			Collections.shuffle(shuffleCandidateElements);
-			found = ImmutableList.copyOf(shuffleCandidateElements);
+		if (randomizeElementsOrder) {
+			Collections.shuffle(results);
 		}
-		
-		LOG.debug(""Found {} new candidate elements to analyze!"", found.size());
-		return found;
+
+		LOG.debug(""Found {} new candidate elements to analyze!"", results.size());
+		return ImmutableList.copyOf(results);
 	}
 
-	private void extractElements(Document dom, Builder<CandidateElement> results,
+	private void extractElements(Document dom, List<CandidateElement> results,
 	        String relatedFrame) {
 		LOG.debug(""Extracting elements for related frame '{}'"", relatedFrame);
 		for (CrawlElement tag : includedCrawlElements) {
@@ -158,7 +150,7 @@
 		}
 	}
 
-	private void addFramesCandidates(Document dom, Builder<CandidateElement> results,
+	private void addFramesCandidates(Document dom, List<CandidateElement> results,
 	        String relatedFrame, NodeList frameNodes) {
 
 		if (frameNodes == null) {
@@ -216,7 +208,7 @@
 	}
 
 	private void evaluateElements(Document dom, CrawlElement crawl,
-	        Builder<CandidateElement> results, String relatedFrame) {
+	        List<CandidateElement> results, String relatedFrame) {
 		try {
 			List<Element> nodeListForCrawlElement =
 			        getNodeListForTagElement(dom, crawl,
@@ -337,7 +329,7 @@
 		return false;
 	}
 
-	private void evaluateElement(Builder<CandidateElement> results, String relatedFrame,
+	private void evaluateElement(List<CandidateElement> results, String relatedFrame,
 	        CrawlElement crawl, Element sourceElement) {
 		EventableCondition eventableCondition =
 		        checkedElements.getEventableConditionChecker().getEventableCondition(
"
67a60742804904945c40514b4c1e2590bc1ba791,Alex Nederlof,CrawlRules.java,MODIFY,builder -> [] | [CrawljaxConfigurationBuilder builder],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlRules.java b/core/src/main/java/com/crawljax/core/configuration/CrawlRules.java
index 702a47f..8437379 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlRules.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlRules.java
@@ -9,6 +9,7 @@
 import com.crawljax.condition.crawlcondition.CrawlCondition;
 import com.crawljax.condition.invariant.Invariant;
 import com.crawljax.core.configuration.CrawlActionsBuilder.ExcludeByParentBuilder;
+import com.crawljax.core.configuration.CrawljaxConfiguration.CrawljaxConfigurationBuilder;
 import com.crawljax.core.configuration.PreCrawlConfiguration.PreCrawlConfigurationBuilder;
 import com.crawljax.core.state.Eventable.EventType;
 import com.crawljax.oraclecomparator.OracleComparator;
@@ -33,8 +34,10 @@
 		private final PreCrawlConfigurationBuilder preCrawlConfig;
 		private final ImmutableSortedSet.Builder<String> ignoredFrameIdentifiers =
 		        ImmutableSortedSet.naturalOrder();
+		private final CrawljaxConfigurationBuilder crawljaxBuilder;
 
-		private CrawlRulesBuilder() {
+		private CrawlRulesBuilder(CrawljaxConfigurationBuilder crawljaxBuilder) {
+			this.crawljaxBuilder = crawljaxBuilder;
 			crawlRules = new CrawlRules();
 			crawlActionsBuilder = new CrawlActionsBuilder();
 			preCrawlConfig = PreCrawlConfiguration.builder();
@@ -219,17 +222,21 @@
 
 		/**
 		 * @param tagNames
+		 * @return
 		 * @see com.crawljax.core.configuration.CrawlActionsBuilder#click(java.lang.String[])
 		 */
-		public void click(String... tagNames) {
+		public CrawlRulesBuilder click(String... tagNames) {
 			crawlActionsBuilder.click(tagNames);
+			return this;
 		}
 
 		/**
+		 * @return
 		 * @see com.crawljax.core.configuration.CrawlActionsBuilder#clickDefaultElements()
 		 */
-		public void clickDefaultElements() {
+		public CrawlRulesBuilder clickDefaultElements() {
 			crawlActionsBuilder.clickDefaultElements();
+			return this;
 		}
 
 		/**
@@ -247,6 +254,39 @@
 			return crawlActionsBuilder.dontClickChildrenOf(tagname);
 		}
 
+		/**
+		 * Follow links in anchor tags that have an <code>href</code> element that points to an URL
+		 * outside of this website. This does not prevent JavaScript from opening an external URL.
+		 * <p>
+		 * Once the browser reaches an external URL it will <em>not</em> accept that URL as a new
+		 * state. Crawljax is not meant to crawl outside a website. This option exists so that you
+		 * can check all URLs for <code>404</code> errors.
+		 * 
+		 * @param follow
+		 *            Set to true to follow exteranl urls. Default is <code>false</code>.
+		 */
+		public CrawlRulesBuilder followExternalLinks(boolean follow) {
+			crawlRules.followExternalLinks = follow;
+			return this;
+		}
+
+		/**
+		 * Helper method for method chaining. Now you can do
+		 * 
+		 * <pre>
+		 * CrawljaxConfiguration.builderFor(&quot;http://example.com&quot;)
+		 *         .crawlRules()
+		 *         .followExternalLinks(true)
+		 *         .endRules()
+		 *         .build();
+		 * </pre>
+		 * 
+		 * @return The {@link CrawljaxConfigurationBuilder} to make method chaining easier.
+		 */
+		public CrawljaxConfigurationBuilder endRules() {
+			return crawljaxBuilder;
+		}
+
 		CrawlRules build() {
 			crawlRules.crawlEvents = crawlEvents.build();
 			if (crawlRules.crawlEvents.isEmpty()) {
@@ -281,8 +321,8 @@
 	 */
 	public static final long DEFAULT_WAIT_AFTER_EVENT = 500;
 
-	public static CrawlRulesBuilder builder() {
-		return new CrawlRulesBuilder();
+	public static CrawlRulesBuilder builder(CrawljaxConfigurationBuilder builder) {
+		return new CrawlRulesBuilder(builder);
 	}
 
 	private ImmutableSortedSet<EventType> crawlEvents;
@@ -302,6 +342,7 @@
 	private boolean crawlHiddenAnchors = false;
 	private long waitAfterReloadUrl = DEFAULT_WAIT_AFTER_RELOAD;
 	private long waitAfterEvent = DEFAULT_WAIT_AFTER_EVENT;
+	private boolean followExternalLinks = false;
 
 	private CrawlRules() {
 	}
@@ -381,12 +422,16 @@
 
 	}
 
+	public boolean followExternalLinks() {
+		return followExternalLinks;
+	}
+
 	@Override
 	public int hashCode() {
 		return Objects.hashCode(crawlEvents, invariants, oracleComparators,
 		        ignoredFrameIdentifiers, preCrawlConfig, randomInputInForms, inputSpecification,
 		        testInvariantsWhileCrawling, clickOnce, crawlFrames, crawlHiddenAnchors,
-		        waitAfterReloadUrl, waitAfterEvent);
+		        waitAfterReloadUrl, waitAfterEvent, followExternalLinks);
 	}
 
 	@Override
@@ -408,7 +453,8 @@
 			        && Objects.equal(this.crawlFrames, that.crawlFrames)
 			        && Objects.equal(this.crawlHiddenAnchors, that.crawlHiddenAnchors)
 			        && Objects.equal(this.waitAfterReloadUrl, that.waitAfterReloadUrl)
-			        && Objects.equal(this.waitAfterEvent, that.waitAfterEvent);
+			        && Objects.equal(this.waitAfterEvent, that.waitAfterEvent)
+			        && Objects.equal(this.followExternalLinks, that.followExternalLinks);
 		}
 		return false;
 	}
@@ -432,6 +478,7 @@
 		        .add(""crawlHiddenAnchors"", crawlHiddenAnchors)
 		        .add(""waitAfterReloadUrl"", waitAfterReloadUrl)
 		        .add(""waitAfterEvent"", waitAfterEvent)
+		        .add(""followExternalLinks"", followExternalLinks)
 		        .toString();
 	}
 
"
67a60742804904945c40514b4c1e2590bc1ba791,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index aa1a044..ba576bb 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -10,17 +10,13 @@
 import java.util.concurrent.TimeUnit;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
-import com.crawljax.core.CrawlController;
 import com.crawljax.core.Crawler;
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
-import com.crawljax.di.CoreModule;
 import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
-import com.google.inject.Guice;
-import com.google.inject.Injector;
 
 /**
  * Configures the {@link Crawler}. Set it up using the {@link #builderFor(String)} function.
@@ -31,12 +27,13 @@
 
 		private final ImmutableList.Builder<Plugin> pluginBuilder = ImmutableList.builder();
 		private final CrawljaxConfiguration config;
-		private final CrawlRulesBuilder crawlRules = CrawlRules.builder();
+		private final CrawlRulesBuilder crawlRules;
 
 		private CrawljaxConfigurationBuilder(URL url) {
 			Preconditions.checkNotNull(url);
 			config = new CrawljaxConfiguration();
 			config.url = url;
+			crawlRules = CrawlRules.builder(this);
 		}
 
 		/**
@@ -198,11 +195,6 @@
 			return config;
 		}
 
-		public CrawlController buildControl() {
-			Injector injector = Guice.createInjector(new CoreModule(build()));
-			return injector.getInstance(CrawlController.class);
-		}
-
 	}
 
 	/**
"
df7b49120099ca50b3394293333cacd50ee973b0,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index aa1a044..ba576bb 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -10,17 +10,13 @@
 import java.util.concurrent.TimeUnit;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
-import com.crawljax.core.CrawlController;
 import com.crawljax.core.Crawler;
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
-import com.crawljax.di.CoreModule;
 import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
-import com.google.inject.Guice;
-import com.google.inject.Injector;
 
 /**
  * Configures the {@link Crawler}. Set it up using the {@link #builderFor(String)} function.
@@ -31,12 +27,13 @@
 
 		private final ImmutableList.Builder<Plugin> pluginBuilder = ImmutableList.builder();
 		private final CrawljaxConfiguration config;
-		private final CrawlRulesBuilder crawlRules = CrawlRules.builder();
+		private final CrawlRulesBuilder crawlRules;
 
 		private CrawljaxConfigurationBuilder(URL url) {
 			Preconditions.checkNotNull(url);
 			config = new CrawljaxConfiguration();
 			config.url = url;
+			crawlRules = CrawlRules.builder(this);
 		}
 
 		/**
@@ -198,11 +195,6 @@
 			return config;
 		}
 
-		public CrawlController buildControl() {
-			Injector injector = Guice.createInjector(new CoreModule(build()));
-			return injector.getInstance(CrawlController.class);
-		}
-
 	}
 
 	/**
"
2c71373d21a3f587f2f445865cf3a69f72d52415,Jeremy Hewett,PluginManager.java,MODIFY,"save -> [String id, URL url] | [String id, byte[] data]","diff --git a/web/src/main/java/com/crawljax/web/fs/PluginManager.java b/web/src/main/java/com/crawljax/web/fs/PluginManager.java
index 8f66343..f516899 100644
--- a/web/src/main/java/com/crawljax/web/fs/PluginManager.java
+++ b/web/src/main/java/com/crawljax/web/fs/PluginManager.java
@@ -19,6 +19,8 @@
 import java.io.Reader;
 import java.net.MalformedURLException;
 import java.net.URL;
+import java.nio.channels.Channels;
+import java.nio.channels.ReadableByteChannel;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.zip.ZipEntry;
 import java.util.zip.ZipFile;
@@ -105,20 +107,18 @@
 	private File download(URL source, File destinationDir, String name) {
 		destinationDir.mkdirs();
 		File result = new File(destinationDir, name);
-		try(InputStream inputStream = source.openStream()){
-			if(result.exists()) {
-				result.delete();
-			}
+		if(result.exists()) {
+			result.delete();
+		}
+		try {
 			result.createNewFile();
-			try(FileOutputStream fos = new FileOutputStream(result)) {
-				int c = inputStream.read();
-				while(c != -1) {
-					fos.write(c);
-					c = inputStream.read();
+			try(ReadableByteChannel rbc = Channels.newChannel(source.openStream())) {
+				try(FileOutputStream fos = new FileOutputStream(result)) {
+					fos.getChannel().transferFrom(rbc, 0, Long.MAX_VALUE);
+					fos.flush();
 				}
-				fos.flush();
 			}
-		} catch (IOException e) {
+		} catch (Exception e) {
 			LOG.error(e.toString());
 			LOG.debug(e.toString());
 		}
"
f9da9dc6ce7a415eb21ce4f3fc20cf047288c332,Jeremy Hewett,PluginManager.java,MODIFY,"download -> [URL source, File destinationDir, String name] | [URL source, File destination]","diff --git a/web/src/main/java/com/crawljax/web/fs/PluginManager.java b/web/src/main/java/com/crawljax/web/fs/PluginManager.java
index f516899..30eb72a 100644
--- a/web/src/main/java/com/crawljax/web/fs/PluginManager.java
+++ b/web/src/main/java/com/crawljax/web/fs/PluginManager.java
@@ -21,6 +21,8 @@
 import java.net.URL;
 import java.nio.channels.Channels;
 import java.nio.channels.ReadableByteChannel;
+import java.util.ArrayList;
+import java.util.List;
 import java.util.concurrent.ConcurrentHashMap;
 import java.util.zip.ZipEntry;
 import java.util.zip.ZipFile;
@@ -41,36 +43,36 @@
 
 	public ConcurrentHashMap<String, Plugin> loadAll() {
 		ConcurrentHashMap<String, Plugin> plugins = new ConcurrentHashMap<>();
-		File[] pluginJars = pluginsFolder.listFiles(new FilenameFilter() {
-			public boolean accept(File dir, String name) {
-				return name.endsWith("".jar"");
-			}
-		});
-		for (File f : pluginJars) {
-			Plugin p = load(f);
-			if(p != null) {
-				plugins.put(p.getId(), p);
-			}
-		}
+		List<String> pluginIds = new ArrayList<>();
+
 		File[] locators = pluginsFolder.listFiles(new FilenameFilter() {
 			public boolean accept(File dir, String name) {
 				return name.endsWith("".locator"");
 			}
 		});
-		for (File f : locators) {
-			URL url = null;
-			try {
-				url = new URL(readFile(f).trim());
-			} catch (MalformedURLException e) {
-				LOG.error(e.toString());
-				LOG.debug(e.toString());
+		for(File locator : locators) {
+			pluginIds.add(locator.getName().substring(0, locator.getName().indexOf("".locator"")));
+		}
+
+		File[] jars = pluginsFolder.listFiles(new FilenameFilter() {
+			public boolean accept(File dir, String name) {
+				return name.endsWith("".jar"");
 			}
-			File jar = download(url, pluginsFolder, f.getName().replace("".locator"", "".jar""));
-			Plugin p = load(jar);
+		});
+		for(File jar : jars) {
+			String id = jar.getName().substring(0, jar.getName().indexOf("".jar""));
+			if(!pluginIds.contains(id)) {
+				pluginIds.add(id);
+			}
+		}
+
+		for (String id : pluginIds) {
+			Plugin p = load(id);
 			if(p != null) {
 				plugins.put(p.getId(), p);
 			}
 		}
+
 		return plugins;
 	}
 
@@ -104,16 +106,14 @@
 		return result;
 	}
 
-	private File download(URL source, File destinationDir, String name) {
-		destinationDir.mkdirs();
-		File result = new File(destinationDir, name);
-		if(result.exists()) {
-			result.delete();
+	private File download(URL source, File destination) {
+		if(destination.exists()) {
+			destination.delete();
 		}
 		try {
-			result.createNewFile();
+			destination.createNewFile();
 			try(ReadableByteChannel rbc = Channels.newChannel(source.openStream())) {
-				try(FileOutputStream fos = new FileOutputStream(result)) {
+				try(FileOutputStream fos = new FileOutputStream(destination)) {
 					fos.getChannel().transferFrom(rbc, 0, Long.MAX_VALUE);
 					fos.flush();
 				}
@@ -122,31 +122,47 @@
 			LOG.error(e.toString());
 			LOG.debug(e.toString());
 		}
-		return result;
+		return destination;
 	}
 
-	private Plugin load(File jarFile) {
+	public Plugin load(String pluginId) {
+		File jar = loadPluginJar(pluginId);
 		Plugin plugin = null;
 		try {
-			PluginDescriptor descriptor = loadPluginDescriptorFromJar(jarFile);
+			PluginDescriptor descriptor = loadPluginDescriptorFromJar(jar);
 			if(descriptor == null) {
 				throw new Exception(""Failed to load plugin descriptor"");
 			}
 			plugin = new Plugin();
-			plugin.setId(jarFile.getName().substring(0, jarFile.getName().indexOf("".jar"")));
-			plugin.setUrl(jarFile.toURI().toURL());
+			plugin.setId(pluginId);
+			plugin.setJarFile(jar);
 			plugin.setName(descriptor.getName());
 			plugin.setDescription(descriptor.getDescription());
 			plugin.setImplementation(descriptor.getImplementation());
 			plugin.setParameters(descriptor.getParameters());
 			plugin.setCrawljaxVersions(descriptor.getCrawljaxVersions());
 		} catch (Exception e) {
-			LOG.error(""Could not load plugin {}"", jarFile.getName());
-			LOG.debug(""Could not load plugin {}. \n{}"", jarFile.getName(), e.getStackTrace());
+			LOG.error(""Could not load plugin {}"", jar.getName());
+			LOG.debug(""Could not load plugin {}. \n{}"", jar.getName(), e.getStackTrace());
 		}
 		return plugin;
 	}
 
+	private File loadPluginJar(String pluginId) {
+		File locator = new File(pluginsFolder, pluginId + "".locator"");
+		File jar = new File(pluginsFolder, pluginId + "".jar"");
+		if(locator.exists()) {
+			try {
+				URL url = new URL(readFile(locator).trim());
+				jar = download(url, jar);
+			} catch (MalformedURLException e) {
+				LOG.error(e.toString());
+				LOG.debug(e.toString());
+			}
+		}
+		return jar;
+	}
+
 	private PluginDescriptor loadPluginDescriptorFromJar(File jarFile) {
 		PluginDescriptor pluginDescriptor = null;
 		try {
@@ -183,9 +199,9 @@
 			throw new CrawljaxWebException(""Could not save plugin file"");
 		}
 
-		Plugin plugin = load(pluginJar);
+		Plugin plugin = load(id);
 		if(plugin == null) {
-			pluginJar.delete();
+			delete(id);
 			throw new CrawljaxWebException(""Could not read plugin descriptor"");
 		}
 
@@ -193,34 +209,32 @@
 	}
 
 	public Plugin save(String id, URL url) throws CrawljaxWebException {
-		File jar = download(url, pluginsFolder, id + "".jar"");
-		Plugin plugin = load(jar);
-		if(plugin == null) {
-			jar.delete();
-			throw new CrawljaxWebException(""Could not read plugin descriptor"");
-		} else {
-			File urlFile = new File(pluginsFolder, id + "".locator"");
-			try {
-				if (urlFile.exists()) {
-					urlFile.delete();
-				}
-				urlFile.createNewFile();
-				try(FileOutputStream fos = new FileOutputStream(urlFile)) {
-					fos.write(url.toExternalForm().getBytes());
-					fos.flush();
-				}
-			} catch (IOException e) {
-				jar.delete();
-				LOG.error(e.toString());
-				LOG.debug(e.toString());
-				throw new CrawljaxWebException(""Could not save plugin file"");
+		File urlFile = new File(pluginsFolder, id + "".locator"");
+		try {
+			if (urlFile.exists()) {
+				urlFile.delete();
 			}
+			urlFile.createNewFile();
+			try(FileOutputStream fos = new FileOutputStream(urlFile)) {
+				fos.write(url.toExternalForm().getBytes());
+				fos.flush();
+			}
+		} catch (IOException e) {
+			urlFile.delete();
+			LOG.error(e.toString());
+			LOG.debug(e.toString());
+			throw new CrawljaxWebException(""Could not save plugin file"");
+		}
+		Plugin plugin = load(id);
+		if(plugin == null) {
+			delete(id);
+			throw new CrawljaxWebException(""Could not read plugin descriptor"");
 		}
 		return plugin;
 	}
 
-	public boolean delete(Plugin plugin) {
-		File pluginLocator = new File(pluginsFolder, plugin.getId() + "".locator"");
+	public boolean delete(String id) {
+		File pluginLocator = new File(pluginsFolder, id + "".locator"");
 		boolean removedPL = true;
 		if(pluginLocator.exists()) {
 			removedPL = pluginLocator.delete();
@@ -229,7 +243,7 @@
 				LOG.debug(""Failed to delete plugin file: "" + pluginLocator);
 			}
 		}
-		File pluginJar = new File(pluginsFolder, plugin.getId() + "".jar"");
+		File pluginJar = new File(pluginsFolder, id + "".jar"");
 		boolean removedJar = pluginJar.delete();
 		if(!removedJar) {
 			LOG.error(""Failed to delete plugin file: "" + pluginJar);
"
f9da9dc6ce7a415eb21ce4f3fc20cf047288c332,Jeremy Hewett,Plugins.java,MODIFY,"add -> [String name, URL url] | [String fileName, byte[] data]","diff --git a/web/src/main/java/com/crawljax/web/model/Plugins.java b/web/src/main/java/com/crawljax/web/model/Plugins.java
index 6678064..34a1f41 100644
--- a/web/src/main/java/com/crawljax/web/model/Plugins.java
+++ b/web/src/main/java/com/crawljax/web/model/Plugins.java
@@ -39,12 +39,6 @@
 		return pluginList.values();
 	}
 
-	public Collection<Plugin> reloadFromDisk() {
-		pluginList.clear();
-		pluginList.putAll(pluginManager.loadAll());
-		return pluginList.values();
-	}
-
 	public Plugin add(String fileName, byte[] data) throws CrawljaxWebException {
 		int extensionIndex = fileName.indexOf("".jar"");
 		if (extensionIndex < 0) {
@@ -80,7 +74,7 @@
 	}
 
 	public Plugin remove(Plugin plugin) throws CrawljaxWebException {
-		if(pluginManager.delete(plugin)) {
+		if(pluginManager.delete(plugin.getId())) {
 			pluginList.remove(plugin.getId());
 		} else {
 			throw new CrawljaxWebException(""Failed to delete plugin file"");
@@ -94,17 +88,11 @@
 
 	public com.crawljax.core.plugin.Plugin getInstanceOf(Plugin plugin, File resourceDir,
 	        HostInterface hostInterface) {
-		File source = null;
+		File source;
 		File dest = new File(resourceDir, plugin.getId() + "".jar"");
-		try {
-			source = new File(plugin.getUrl().toURI());
-			copyFile(source, dest);
-		} catch (Exception e) {
-			LOG.error(""Could not create instance of plugin {}"", plugin.getName());
-			LOG.debug(""Could not create instance of plugin {}. {}"", plugin.getName(), e.getStackTrace());
-			return null;
-		}
-		URL instanceURL = null;
+		source = reload(plugin.getId()).getJarFile();
+		copyFile(source, dest);
+		URL instanceURL;
 		try {
 			instanceURL = (new File(resourceDir.getAbsolutePath() + File.separatorChar + source.getName())).toURI().toURL();
 		} catch (MalformedURLException e) {
@@ -129,6 +117,17 @@
 		return instance;
 	}
 
+	public Plugin reload(String pluginId) {
+		pluginList.put(pluginId, pluginManager.load(pluginId));
+		return pluginList.get(pluginId);
+	}
+
+	public Collection<Plugin> reloadAll() {
+		pluginList.clear();
+		pluginList.putAll(pluginManager.loadAll());
+		return pluginList.values();
+	}
+
 	private void copyFile(File source, File dest) {
 		try (InputStream in = new FileInputStream(source)) {
 			try(FileOutputStream out = new FileOutputStream(dest)) {
"
165b9f41f6fbf8079cb3b86050d926d3c42f7c35,Jeremy Hewett,PluginManager.java,MODIFY,"save -> [String id, URL url] | [String id, byte[] data]","diff --git a/web/src/main/java/com/crawljax/web/fs/PluginManager.java b/web/src/main/java/com/crawljax/web/fs/PluginManager.java
index 30eb72a..13a9b3d 100644
--- a/web/src/main/java/com/crawljax/web/fs/PluginManager.java
+++ b/web/src/main/java/com/crawljax/web/fs/PluginManager.java
@@ -138,7 +138,6 @@
 			plugin.setJarFile(jar);
 			plugin.setName(descriptor.getName());
 			plugin.setDescription(descriptor.getDescription());
-			plugin.setImplementation(descriptor.getImplementation());
 			plugin.setParameters(descriptor.getParameters());
 			plugin.setCrawljaxVersions(descriptor.getCrawljaxVersions());
 		} catch (Exception e) {
"
165b9f41f6fbf8079cb3b86050d926d3c42f7c35,Jeremy Hewett,Plugins.java,MODIFY,"add -> [String name, URL url] | [String fileName, byte[] data]","diff --git a/web/src/main/java/com/crawljax/web/model/Plugins.java b/web/src/main/java/com/crawljax/web/model/Plugins.java
index 34a1f41..7db18aa 100644
--- a/web/src/main/java/com/crawljax/web/model/Plugins.java
+++ b/web/src/main/java/com/crawljax/web/model/Plugins.java
@@ -1,24 +1,30 @@
 package com.crawljax.web.model;
 
-import java.io.*;
-import java.lang.reflect.Constructor;
-import java.net.MalformedURLException;
-import java.net.URISyntaxException;
-import java.net.URL;
-import java.net.URLClassLoader;
-import java.util.Collection;
-import java.util.Map;
-
-import javax.inject.Inject;
-import javax.inject.Singleton;
-
 import com.crawljax.core.plugin.HostInterface;
 import com.crawljax.web.exception.CrawljaxWebException;
 import com.crawljax.web.fs.PluginManager;
 import com.google.common.io.ByteStreams;
+import org.reflections.Reflections;
+import org.reflections.util.ClasspathHelper;
+import org.reflections.util.ConfigurationBuilder;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
+import javax.inject.Inject;
+import javax.inject.Singleton;
+import java.io.File;
+import java.io.FileInputStream;
+import java.io.FileOutputStream;
+import java.io.IOException;
+import java.io.InputStream;
+import java.lang.reflect.Constructor;
+import java.net.MalformedURLException;
+import java.net.URL;
+import java.net.URLClassLoader;
+import java.util.Collection;
+import java.util.Map;
+import java.util.Set;
+
 @Singleton
 public class Plugins {
 	private static final Logger LOG = LoggerFactory.getLogger(Plugins.class);
@@ -26,10 +32,15 @@
 	private final Map<String, Plugin> pluginList;
 	private final PluginManager pluginManager;
 
+	Set<Class<? extends com.crawljax.core.plugin.Plugin>> basePluginClasses;
+
 	@Inject
 	public Plugins(PluginManager pluginManager) {
 		this.pluginManager = pluginManager;
 		pluginList = pluginManager.loadAll();
+
+		Reflections reflections = new Reflections(""com.crawljax.core.plugin"");
+		basePluginClasses = reflections.getSubTypesOf(com.crawljax.core.plugin.Plugin.class);
 	}
 
 	/**
@@ -88,32 +99,42 @@
 
 	public com.crawljax.core.plugin.Plugin getInstanceOf(Plugin plugin, File resourceDir,
 	        HostInterface hostInterface) {
-		File source;
-		File dest = new File(resourceDir, plugin.getId() + "".jar"");
-		source = reload(plugin.getId()).getJarFile();
-		copyFile(source, dest);
+		File source = reload(plugin.getId()).getJarFile();
+		File dest = new File(resourceDir, plugin.getJarFile().getName());
+		copyFileContents(source, dest);
 		URL instanceURL;
 		try {
-			instanceURL = (new File(resourceDir.getAbsolutePath() + File.separatorChar + source.getName())).toURI().toURL();
+			instanceURL = dest.toURI().toURL();
 		} catch (MalformedURLException e) {
 			LOG.error(""Could not create instance of plugin {}"", plugin.getName());
 			LOG.debug(""Could not create instance of plugin {}. {}"", plugin.getName(), e.getStackTrace());
 			return null;
 		}
+
+		ClassLoader newClassLoader = new URLClassLoader(new URL[]{instanceURL}, Thread.currentThread().getContextClassLoader());
+		Thread.currentThread().setContextClassLoader(newClassLoader);
+
+		Reflections reflections = new Reflections(new ConfigurationBuilder()
+					.addUrls(instanceURL, ClasspathHelper.forClass(com.crawljax.core.plugin.Plugin.class))
+					.addClassLoader(newClassLoader));
+
+		Set<Class<? extends com.crawljax.core.plugin.Plugin>> pluginClasses = reflections.getSubTypesOf(com.crawljax.core.plugin.Plugin.class);
+		pluginClasses.removeAll(basePluginClasses);
+
 		com.crawljax.core.plugin.Plugin instance = null;
-		ClassLoader originalClassLoader = Thread.currentThread().getContextClassLoader();
-		ClassLoader newClassLoader = new URLClassLoader(new URL[]{instanceURL}, originalClassLoader);
-		try {
-			Thread.currentThread().setContextClassLoader(newClassLoader);
-			Class pluginClass = newClassLoader.loadClass(plugin.getImplementation());
-			Constructor constructor = pluginClass.getDeclaredConstructor(HostInterface.class);
-			instance = (com.crawljax.core.plugin.Plugin) constructor.newInstance(hostInterface);
-		} catch (Throwable e) {
+		for(Class<? extends com.crawljax.core.plugin.Plugin> pluginClass : pluginClasses) {
+			try {
+				Constructor constructor = pluginClass.getDeclaredConstructor(HostInterface.class);
+				instance = (com.crawljax.core.plugin.Plugin) constructor.newInstance(hostInterface);
+				break;
+			} catch (Exception e) { }
+		}
+
+		if(instance == null) {
 			LOG.error(""Could not create instance of plugin "" + plugin.getName());
 			LOG.debug(""Could not create instance of plugin "" + plugin.getName());
-		} finally {
-			//Thread.currentThread().setContextClassLoader(originalClassLoader); //Currently commented out so plugins can get their resources from the classloader
 		}
+
 		return instance;
 	}
 
@@ -128,7 +149,7 @@
 		return pluginList.values();
 	}
 
-	private void copyFile(File source, File dest) {
+	private void copyFileContents(File source, File dest) {
 		try (InputStream in = new FileInputStream(source)) {
 			try(FileOutputStream out = new FileOutputStream(dest)) {
 				ByteStreams.copy(in, out);
"
ee21fdeafc908cfd87f853f66b3b8cdddd7d69ff,Jeremy Hewett,CrawljaxServer.java,MODIFY,"setupWebContext -> [File outputFolder] | [File outputFolder, File pluginsFolder]","diff --git a/web/src/main/java/com/crawljax/web/CrawljaxServer.java b/web/src/main/java/com/crawljax/web/CrawljaxServer.java
index d5ef5f3..b0a1d4f 100644
--- a/web/src/main/java/com/crawljax/web/CrawljaxServer.java
+++ b/web/src/main/java/com/crawljax/web/CrawljaxServer.java
@@ -1,8 +1,11 @@
 package com.crawljax.web;
 
-import java.io.File;
-import java.io.IOException;
-import java.util.concurrent.*;
+import ch.qos.logback.classic.LoggerContext;
+import com.crawljax.web.di.CrawljaxWebModule;
+import com.google.inject.Guice;
+import com.google.inject.Injector;
+import com.google.inject.servlet.GuiceFilter;
+import com.google.inject.servlet.GuiceServletContextListener;
 import org.eclipse.jetty.server.Server;
 import org.eclipse.jetty.server.ServerConnector;
 import org.eclipse.jetty.server.handler.HandlerList;
@@ -12,11 +15,11 @@
 import org.slf4j.LoggerFactory;
 import org.slf4j.bridge.SLF4JBridgeHandler;
 
-import com.crawljax.web.di.CrawljaxWebModule;
-import com.google.inject.Guice;
-import com.google.inject.Injector;
-import com.google.inject.servlet.GuiceFilter;
-import com.google.inject.servlet.GuiceServletContextListener;
+import java.io.File;
+import java.io.IOException;
+import java.util.concurrent.Callable;
+import java.util.concurrent.CountDownLatch;
+import java.util.concurrent.TimeUnit;
 
 public class CrawljaxServer implements Callable<Void> {
 
@@ -26,20 +29,14 @@
 	private final CountDownLatch isRunningLatch = new CountDownLatch(1);
 	private String url = null;
 
-	public CrawljaxServer(int port, File outputDir) {
-		configureServer(port, outputDir);
-	}
-
-	public CrawljaxServer(int port) {
-		configureServer(port, new File(""out""));
-	}
-
-	private void configureServer(int port, File outputDir) {
+	public CrawljaxServer(CrawljaxServerConfigurationBuilder configurationBuilder) {
+		LoggerContext loggerContext = (LoggerContext) LoggerFactory.getILoggerFactory();
+		loggerContext.putProperty(""output_folder"", configurationBuilder.getOutputDir().getAbsolutePath());
 		setupJulToSlf4();
-		server = new Server(port);
+		server = new Server(configurationBuilder.getPort());
 		HandlerList handlerList = new HandlerList();
-		handlerList.addHandler(setupOutputContext(outputDir));
-		handlerList.addHandler(setupWebContext(outputDir));
+		handlerList.addHandler(setupOutputContext(configurationBuilder.getOutputDir()));
+		handlerList.addHandler(setupWebContext(configurationBuilder.getOutputDir(), configurationBuilder.getPluginDir()));
 		server.setHandler(handlerList);
 	}
 
@@ -55,7 +52,6 @@
 	 * @see Thread#join()
 	 */
 	public void start(boolean join) {
-
 		LOG.info(""Starting the server"");
 		try {
 			server.start();
@@ -110,7 +106,7 @@
 		SLF4JBridgeHandler.install();
 	}
 
-	private WebAppContext setupWebContext(final File outputFolder) {
+	private WebAppContext setupWebContext(final File outputFolder, final File pluginsFolder) {
 		WebAppContext webAppContext = new WebAppContext();
 		webAppContext.setContextPath(""/"");
 		webAppContext.setBaseResource(Resource.newClassPathResource(""web""));
@@ -119,7 +115,7 @@
 
 			@Override
 			protected Injector getInjector() {
-				return Guice.createInjector(new CrawljaxWebModule(outputFolder));
+				return Guice.createInjector(new CrawljaxWebModule(outputFolder, pluginsFolder));
 			}
 
 		});
@@ -128,7 +124,7 @@
 		return webAppContext;
 	}
 
-	private WebAppContext setupOutputContext(File outputFolder) {
+	private WebAppContext setupOutputContext(final File outputFolder) {
 		WebAppContext webAppContext = new WebAppContext();
 		webAppContext.setContextPath(""/output"");
 		try {
"
bbe417a4b28d3de52a154f5a59fbc5783df3cbaf,Jeremy Hewett,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index e645a17..6a5e7ed 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -23,7 +23,6 @@
 import org.openqa.selenium.WebDriverException;
 import org.openqa.selenium.WebElement;
 import org.openqa.selenium.internal.WrapsDriver;
-import org.openqa.selenium.io.FileHandler;
 import org.openqa.selenium.remote.Augmenter;
 import org.openqa.selenium.remote.DesiredCapabilities;
 import org.openqa.selenium.remote.ErrorHandler.UnknownServerException;
@@ -50,6 +49,7 @@
 import com.crawljax.util.DomUtils;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableSortedSet;
+import com.google.common.io.Files;
 
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
 	private static final Logger LOGGER = LoggerFactory
@@ -605,7 +605,8 @@
 		}
 	}
 
-	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement) throws NoSuchFrameException {
+	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement)
+	        throws NoSuchFrameException {
 		String frameIdentification = """";
 
 		if (topFrame != null && !topFrame.equals("""")) {
@@ -812,7 +813,7 @@
 		try {
 			File tmpfile = takeScreenShotOnBrowser(browser, OutputType.FILE);
 			try {
-				FileHandler.copy(tmpfile, file);
+				Files.copy(tmpfile, file);
 			} catch (IOException e) {
 				throw new CrawljaxException(e);
 			}
"
bbe417a4b28d3de52a154f5a59fbc5783df3cbaf,Jeremy Hewett,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URL url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index aa1a044..ba576bb 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -10,17 +10,13 @@
 import java.util.concurrent.TimeUnit;
 
 import com.crawljax.browser.EmbeddedBrowser.BrowserType;
-import com.crawljax.core.CrawlController;
 import com.crawljax.core.Crawler;
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
-import com.crawljax.di.CoreModule;
 import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
-import com.google.inject.Guice;
-import com.google.inject.Injector;
 
 /**
  * Configures the {@link Crawler}. Set it up using the {@link #builderFor(String)} function.
@@ -31,12 +27,13 @@
 
 		private final ImmutableList.Builder<Plugin> pluginBuilder = ImmutableList.builder();
 		private final CrawljaxConfiguration config;
-		private final CrawlRulesBuilder crawlRules = CrawlRules.builder();
+		private final CrawlRulesBuilder crawlRules;
 
 		private CrawljaxConfigurationBuilder(URL url) {
 			Preconditions.checkNotNull(url);
 			config = new CrawljaxConfiguration();
 			config.url = url;
+			crawlRules = CrawlRules.builder(this);
 		}
 
 		/**
@@ -198,11 +195,6 @@
 			return config;
 		}
 
-		public CrawlController buildControl() {
-			Injector injector = Guice.createInjector(new CoreModule(build()));
-			return injector.getInstance(CrawlController.class);
-		}
-
 	}
 
 	/**
"
117b68c5a159df414215faf4765b3411d31b5ba5,Jeremy Hewett,WorkDirManager.java,MODIFY,loadConfiguration -> [File configFile] | [String id],"diff --git a/web/src/main/java/com/crawljax/web/fs/WorkDirManager.java b/web/src/main/java/com/crawljax/web/fs/WorkDirManager.java
index 264f3b2..1f935b0 100644
--- a/web/src/main/java/com/crawljax/web/fs/WorkDirManager.java
+++ b/web/src/main/java/com/crawljax/web/fs/WorkDirManager.java
@@ -49,18 +49,20 @@
 		File[] configFiles = configFolder.listFiles(new FilenameFilter() {
 			@Override
 			public boolean accept(File dir, String name) {
-				return name.endsWith(""json"");
+				return name.endsWith("".json"");
 			}
 		});
 		for (File f : configFiles) {
-			Configuration c = loadConfiguration(f);
+			String id = f.getName().substring(0, f.getName().indexOf("".json""));
+			Configuration c = loadConfiguration(id);
 			configs.put(c.getId(), c);
 		}
 		return configs;
 	}
 
-	private Configuration loadConfiguration(File configFile) {
+	public Configuration loadConfiguration(String id) {
 		Configuration config = null;
+		File configFile = new File(configFolder, id + "".json"");
 		try {
 			config = mapper.readValue(configFile, Configuration.class);
 		} catch (IOException e) {
"
117b68c5a159df414215faf4765b3411d31b5ba5,Jeremy Hewett,ConfigurationsResource.java,MODIFY,getNewConfiguration -> [] | [String id],"diff --git a/web/src/main/java/com/crawljax/web/jaxrs/ConfigurationsResource.java b/web/src/main/java/com/crawljax/web/jaxrs/ConfigurationsResource.java
index 2c98740..c5a8774 100644
--- a/web/src/main/java/com/crawljax/web/jaxrs/ConfigurationsResource.java
+++ b/web/src/main/java/com/crawljax/web/jaxrs/ConfigurationsResource.java
@@ -45,6 +45,16 @@
 	}
 
 	@GET
+	@Path(""/new/{id}"")
+	public Response getNewConfiguration(@PathParam(""id"") String id) {
+		Configuration config = new Configuration();
+		if(id != null && !id.isEmpty()) {
+			config = configurations.getCopyOf(id);
+		}
+		return Response.ok(config).build();
+	}
+
+	@GET
 	@Path(""/new"")
 	public Response getNewConfiguration() {
 		Configuration config = new Configuration();
"
6325e7e075a86d6b64314c3474e6d4d0f3f41553,Jeremy Hewett,Plugins.java,MODIFY,"add -> [String name, URL url] | [String fileName, byte[] data]","diff --git a/web/src/main/java/com/crawljax/web/model/Plugins.java b/web/src/main/java/com/crawljax/web/model/Plugins.java
index 7db18aa..9dc6737 100644
--- a/web/src/main/java/com/crawljax/web/model/Plugins.java
+++ b/web/src/main/java/com/crawljax/web/model/Plugins.java
@@ -63,8 +63,12 @@
 		return plugin;
 	}
 
-	public Plugin add(String name, URL url) throws CrawljaxWebException {
-		String id = adaptToId(name);
+	public Plugin add(String fileName, URL url) throws CrawljaxWebException {
+		int extensionIndex = fileName.indexOf("".jar"");
+		if (extensionIndex > 0) {
+			fileName = fileName.substring(0, extensionIndex);
+		}
+		String id = adaptToId(fileName);
 		Plugin plugin = pluginManager.save(id, url);
 		if(plugin != null) {
 			pluginList.put(plugin.getId(), plugin);
"
630d1790a0660a48de1b208d0880335c2d4c3001,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 6a5e7ed..cd3c477 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -11,6 +11,20 @@
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
+import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.configuration.AcceptAllFramesChecker;
+import com.crawljax.core.configuration.IgnoreFrameChecker;
+import com.crawljax.core.exception.BrowserConnectionException;
+import com.crawljax.core.state.Eventable;
+import com.crawljax.core.state.Identification;
+import com.crawljax.forms.FormHandler;
+import com.crawljax.forms.FormInput;
+import com.crawljax.forms.InputValue;
+import com.crawljax.forms.RandomInputValueGenerator;
+import com.crawljax.util.DomUtils;
+import com.google.common.base.Preconditions;
+import com.google.common.collect.ImmutableSortedSet;
+import com.google.common.io.Files;
 import org.openqa.selenium.ElementNotVisibleException;
 import org.openqa.selenium.JavascriptExecutor;
 import org.openqa.selenium.NoSuchElementException;
@@ -28,6 +42,7 @@
 import org.openqa.selenium.remote.ErrorHandler.UnknownServerException;
 import org.openqa.selenium.remote.HttpCommandExecutor;
 import org.openqa.selenium.remote.RemoteWebDriver;
+import org.openqa.selenium.remote.UnreachableBrowserException;
 import org.openqa.selenium.support.ui.Select;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -36,21 +51,6 @@
 import org.w3c.dom.Element;
 import org.w3c.dom.NodeList;
 
-import com.crawljax.core.CrawljaxException;
-import com.crawljax.core.configuration.AcceptAllFramesChecker;
-import com.crawljax.core.configuration.IgnoreFrameChecker;
-import com.crawljax.core.exception.BrowserConnectionException;
-import com.crawljax.core.state.Eventable;
-import com.crawljax.core.state.Identification;
-import com.crawljax.forms.FormHandler;
-import com.crawljax.forms.FormInput;
-import com.crawljax.forms.InputValue;
-import com.crawljax.forms.RandomInputValueGenerator;
-import com.crawljax.util.DomUtils;
-import com.google.common.base.Preconditions;
-import com.google.common.collect.ImmutableSortedSet;
-import com.google.common.io.Files;
-
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
 	private static final Logger LOGGER = LoggerFactory
 	        .getLogger(WebDriverBackedEmbeddedBrowser.class);
@@ -328,7 +328,7 @@
 			// close browser and close every associated window.
 			browser.quit();
 		} catch (WebDriverException e) {
-			if (e.getCause() instanceof InterruptedException) {
+			if (e.getCause() instanceof InterruptedException || e.getCause().getCause() instanceof InterruptedException) {
 				LOGGER.info(""Interrupted while waiting for the browser to close. It might not close correctly"");
 				Thread.currentThread().interrupt();
 				return;
"
d18a2e35180f1dc388ff97e6f02d938db6991fe6,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 6a5e7ed..cd3c477 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -11,6 +11,20 @@
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
+import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.configuration.AcceptAllFramesChecker;
+import com.crawljax.core.configuration.IgnoreFrameChecker;
+import com.crawljax.core.exception.BrowserConnectionException;
+import com.crawljax.core.state.Eventable;
+import com.crawljax.core.state.Identification;
+import com.crawljax.forms.FormHandler;
+import com.crawljax.forms.FormInput;
+import com.crawljax.forms.InputValue;
+import com.crawljax.forms.RandomInputValueGenerator;
+import com.crawljax.util.DomUtils;
+import com.google.common.base.Preconditions;
+import com.google.common.collect.ImmutableSortedSet;
+import com.google.common.io.Files;
 import org.openqa.selenium.ElementNotVisibleException;
 import org.openqa.selenium.JavascriptExecutor;
 import org.openqa.selenium.NoSuchElementException;
@@ -28,6 +42,7 @@
 import org.openqa.selenium.remote.ErrorHandler.UnknownServerException;
 import org.openqa.selenium.remote.HttpCommandExecutor;
 import org.openqa.selenium.remote.RemoteWebDriver;
+import org.openqa.selenium.remote.UnreachableBrowserException;
 import org.openqa.selenium.support.ui.Select;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -36,21 +51,6 @@
 import org.w3c.dom.Element;
 import org.w3c.dom.NodeList;
 
-import com.crawljax.core.CrawljaxException;
-import com.crawljax.core.configuration.AcceptAllFramesChecker;
-import com.crawljax.core.configuration.IgnoreFrameChecker;
-import com.crawljax.core.exception.BrowserConnectionException;
-import com.crawljax.core.state.Eventable;
-import com.crawljax.core.state.Identification;
-import com.crawljax.forms.FormHandler;
-import com.crawljax.forms.FormInput;
-import com.crawljax.forms.InputValue;
-import com.crawljax.forms.RandomInputValueGenerator;
-import com.crawljax.util.DomUtils;
-import com.google.common.base.Preconditions;
-import com.google.common.collect.ImmutableSortedSet;
-import com.google.common.io.Files;
-
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
 	private static final Logger LOGGER = LoggerFactory
 	        .getLogger(WebDriverBackedEmbeddedBrowser.class);
@@ -328,7 +328,7 @@
 			// close browser and close every associated window.
 			browser.quit();
 		} catch (WebDriverException e) {
-			if (e.getCause() instanceof InterruptedException) {
+			if (e.getCause() instanceof InterruptedException || e.getCause().getCause() instanceof InterruptedException) {
 				LOGGER.info(""Interrupted while waiting for the browser to close. It might not close correctly"");
 				Thread.currentThread().interrupt();
 				return;
"
e4f0984cf18e79dcea60b24681e4f02a30b461cc,Keheliya Gallaba,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 6a5e7ed..cd3c477 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -11,6 +11,20 @@
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
+import com.crawljax.core.CrawljaxException;
+import com.crawljax.core.configuration.AcceptAllFramesChecker;
+import com.crawljax.core.configuration.IgnoreFrameChecker;
+import com.crawljax.core.exception.BrowserConnectionException;
+import com.crawljax.core.state.Eventable;
+import com.crawljax.core.state.Identification;
+import com.crawljax.forms.FormHandler;
+import com.crawljax.forms.FormInput;
+import com.crawljax.forms.InputValue;
+import com.crawljax.forms.RandomInputValueGenerator;
+import com.crawljax.util.DomUtils;
+import com.google.common.base.Preconditions;
+import com.google.common.collect.ImmutableSortedSet;
+import com.google.common.io.Files;
 import org.openqa.selenium.ElementNotVisibleException;
 import org.openqa.selenium.JavascriptExecutor;
 import org.openqa.selenium.NoSuchElementException;
@@ -28,6 +42,7 @@
 import org.openqa.selenium.remote.ErrorHandler.UnknownServerException;
 import org.openqa.selenium.remote.HttpCommandExecutor;
 import org.openqa.selenium.remote.RemoteWebDriver;
+import org.openqa.selenium.remote.UnreachableBrowserException;
 import org.openqa.selenium.support.ui.Select;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -36,21 +51,6 @@
 import org.w3c.dom.Element;
 import org.w3c.dom.NodeList;
 
-import com.crawljax.core.CrawljaxException;
-import com.crawljax.core.configuration.AcceptAllFramesChecker;
-import com.crawljax.core.configuration.IgnoreFrameChecker;
-import com.crawljax.core.exception.BrowserConnectionException;
-import com.crawljax.core.state.Eventable;
-import com.crawljax.core.state.Identification;
-import com.crawljax.forms.FormHandler;
-import com.crawljax.forms.FormInput;
-import com.crawljax.forms.InputValue;
-import com.crawljax.forms.RandomInputValueGenerator;
-import com.crawljax.util.DomUtils;
-import com.google.common.base.Preconditions;
-import com.google.common.collect.ImmutableSortedSet;
-import com.google.common.io.Files;
-
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
 	private static final Logger LOGGER = LoggerFactory
 	        .getLogger(WebDriverBackedEmbeddedBrowser.class);
@@ -328,7 +328,7 @@
 			// close browser and close every associated window.
 			browser.quit();
 		} catch (WebDriverException e) {
-			if (e.getCause() instanceof InterruptedException) {
+			if (e.getCause() instanceof InterruptedException || e.getCause().getCause() instanceof InterruptedException) {
 				LOGGER.info(""Interrupted while waiting for the browser to close. It might not close correctly"");
 				Thread.currentThread().interrupt();
 				return;
"
cce001509797b8b23ea287014e94227e570ae40a,Alex Nederlof,EmbeddedBrowser.java,MODIFY,goToUrl -> [URL url] | [URI url],"diff --git a/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
index 6ef668d..d8ba38f 100644
--- a/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/EmbeddedBrowser.java
@@ -1,17 +1,16 @@
 package com.crawljax.browser;
 
 import java.io.File;
-import java.net.URL;
-
-import org.openqa.selenium.ElementNotVisibleException;
-import org.openqa.selenium.WebDriver;
-import org.openqa.selenium.WebElement;
+import java.net.URI;
 
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.PreCrawlConfiguration;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.Identification;
 import com.crawljax.forms.FormInput;
+import org.openqa.selenium.ElementNotVisibleException;
+import org.openqa.selenium.WebDriver;
+import org.openqa.selenium.WebElement;
 
 /**
  * Browser interface used by Crawjax.
@@ -31,7 +30,7 @@
 	 * @param url
 	 *            the URL.
 	 */
-	void goToUrl(URL url);
+	void goToUrl(URI url);
 
 	/**
 	 * fires the event.
"
cce001509797b8b23ea287014e94227e570ae40a,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index cd3c477..41cd3de 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -3,6 +3,7 @@
 import java.io.File;
 import java.io.IOException;
 import java.net.MalformedURLException;
+import java.net.URI;
 import java.net.URL;
 import java.util.ArrayList;
 import java.util.HashSet;
@@ -42,7 +43,6 @@
 import org.openqa.selenium.remote.ErrorHandler.UnknownServerException;
 import org.openqa.selenium.remote.HttpCommandExecutor;
 import org.openqa.selenium.remote.RemoteWebDriver;
-import org.openqa.selenium.remote.UnreachableBrowserException;
 import org.openqa.selenium.support.ui.Select;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -189,8 +189,7 @@
 	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
 
 	/**
-	 * Constructor without configuration values, these must be updated using the
-	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
+	 * Constructor without configuration values.
 	 * 
 	 * @param driver
 	 *            The WebDriver to use.
@@ -257,9 +256,9 @@
 	 *            The URL.
 	 */
 	@Override
-	public void goToUrl(URL url) {
+	public void goToUrl(URI url) {
 		try {
-			browser.navigate().to(url);
+			browser.navigate().to(url.toString());
 			Thread.sleep(this.crawlWaitReload);
 			handlePopups();
 		} catch (WebDriverException e) {
"
cce001509797b8b23ea287014e94227e570ae40a,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URI url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index ba576bb..fb86e06 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -4,8 +4,7 @@
 
 import java.io.File;
 import java.io.UnsupportedEncodingException;
-import java.net.MalformedURLException;
-import java.net.URL;
+import java.net.URI;
 import java.net.URLEncoder;
 import java.util.concurrent.TimeUnit;
 
@@ -29,7 +28,7 @@
 		private final CrawljaxConfiguration config;
 		private final CrawlRulesBuilder crawlRules;
 
-		private CrawljaxConfigurationBuilder(URL url) {
+		private CrawljaxConfigurationBuilder(URI url) {
 			Preconditions.checkNotNull(url);
 			config = new CrawljaxConfiguration();
 			config.url = url;
@@ -40,36 +39,32 @@
 		 * If the website uses <a
 		 * href=""http://en.wikipedia.org/wiki/Basic_access_authentication"">Basic auth</a> you can
 		 * set the username and password here.
-		 * 
-		 * @param username
-		 *            The username for the website.
-		 * @param password
-		 *            The password for the website.
+		 *
+		 * @param username The username for the website.
+		 * @param password The password for the website.
 		 * @return {@link CrawljaxConfigurationBuilder} for method chaining.
 		 */
 		public CrawljaxConfigurationBuilder setBasicAuth(String username, String password) {
 			try {
 				String encodedUsername = URLEncoder.encode(username, ""UTF-8"");
 				String encodedPassword = URLEncoder.encode(password, ""UTF-8"");
-				config.url =
-				        new URL(config.url.getProtocol()
-				                + ""://"" + encodedUsername
-				                + "":"" + encodedPassword + ""@"" + config.url.getAuthority()
-				                + config.url.getPath());
-				System.out.println(""URL "" + config.url);
-			} catch (UnsupportedEncodingException | MalformedURLException e) {
+				config.url = URI.create(config.url.getScheme()
+				  + ""://"" + encodedUsername
+				  + "":"" + encodedPassword + ""@"" + config.url.getAuthority()
+				  + config.url.getPath());
+			}
+			catch (UnsupportedEncodingException e) {
 				throw new CrawljaxException(""Could not parse the username/password to a URL"", e);
 			}
 			return this;
 		}
 
 		/**
-		 * @param states
-		 *            The maximum number of states the Crawler should crawl. The default is
-		 *            unlimited.
+		 * @param states The maximum number of states the Crawler should crawl. The default is
+		 *               unlimited.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumStates(int states) {
-			checkArgument(states > 1, ""Number of maximum states should be largen than 1"");
+			checkArgument(states > 1, ""Number of maximum states should be larger than 1"");
 			config.maximumStates = states;
 			return this;
 		}
@@ -83,8 +78,7 @@
 		}
 
 		/**
-		 * @param time
-		 *            The maximum time the crawler should run. Default is one hour.
+		 * @param time The maximum time the crawler should run. Default is one hour.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumRunTime(long time, TimeUnit unit) {
 			checkArgument(time >= 0, ""Time should be larger than 0, or 0 for infinate."");
@@ -101,12 +95,11 @@
 		}
 
 		/**
-		 * @param depth
-		 *            The maximum depth the crawler can reach. The default is <code>2</code>.
+		 * @param depth The maximum depth the crawler can reach. The default is <code>2</code>.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumDepth(int depth) {
 			Preconditions.checkArgument(depth >= 0,
-			        ""Depth should be 0 for infinite, or larger for a certain depth."");
+			  ""Depth should be 0 for infinite, or larger for a certain depth."");
 			config.maximumDepth = depth;
 			return this;
 		}
@@ -125,9 +118,8 @@
 		 * <p>
 		 * You can call this method several times to add multiple plugins
 		 * </p>
-		 * 
-		 * @param plugins
-		 *            the plugins you would like to enable.
+		 *
+		 * @param plugins the plugins you would like to enable.
 		 */
 		public CrawljaxConfigurationBuilder addPlugin(Plugin... plugins) {
 			pluginBuilder.add(plugins);
@@ -135,8 +127,7 @@
 		}
 
 		/**
-		 * @param configuration
-		 *            The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
+		 * @param configuration The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
 		 */
 		public CrawljaxConfigurationBuilder setProxyConfig(ProxyConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -152,9 +143,8 @@
 		}
 
 		/**
-		 * @param configuration
-		 *            a custom {@link BrowserConfiguration}. The default is a single
-		 *            {@link BrowserType#FIREFOX} browser.
+		 * @param configuration a custom {@link BrowserConfiguration}. The default is a single
+		 *                      {@link BrowserType#FIREFOX} browser.
 		 */
 		public CrawljaxConfigurationBuilder setBrowserConfig(BrowserConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -165,11 +155,9 @@
 		/**
 		 * Set the output folder for any {@link Plugin} you might configure. Crawljax itself doesn't
 		 * need an output folder but many plug-ins do.
-		 * 
-		 * @param output
-		 *            The output folder. If it does not exist it will be created.
-		 * @throws IllegalStateException
-		 *             if the specified file is not writable or exists but isn't a folder.
+		 *
+		 * @param output The output folder. If it does not exist it will be created.
+		 * @throws IllegalStateException if the specified file is not writable or exists but isn't a folder.
 		 */
 		public CrawljaxConfigurationBuilder setOutputDirectory(File output) {
 			config.output = output;
@@ -180,12 +168,13 @@
 		private void checkOutputDirWritable() {
 			if (!config.output.exists()) {
 				Preconditions.checkState(config.output.mkdirs(),
-				        ""Could not create the output directory %s "", config.output);
-			} else {
+				  ""Could not create the output directory %s "", config.output);
+			}
+			else {
 				Preconditions.checkArgument(config.output.isDirectory(),
-				        ""Output directory %s is not a folder"", config.output);
+				  ""Output directory %s is not a folder"", config.output);
 				Preconditions.checkState(config.output.canWrite(),
-				        ""Output directory %s is not writable"", config.output);
+				  ""Output directory %s is not writable"", config.output);
 			}
 		}
 
@@ -198,29 +187,23 @@
 	}
 
 	/**
-	 * @param url
-	 *            The url you want to setup a configuration for
+	 * @param url The url you want to setup a configuration for
 	 * @return The builder to configure the crawler.
 	 */
-	public static CrawljaxConfigurationBuilder builderFor(URL url) {
+	public static CrawljaxConfigurationBuilder builderFor(URI url) {
 		Preconditions.checkNotNull(url, ""URL was null"");
 		return new CrawljaxConfigurationBuilder(url);
 	}
 
 	/**
-	 * @param url
-	 *            The url you want to setup a configuration for
+	 * @param url The url you want to setup a configuration for
 	 * @return The builder to configure the crawler.
 	 */
 	public static CrawljaxConfigurationBuilder builderFor(String url) {
-		try {
-			return new CrawljaxConfigurationBuilder(new URL(url));
-		} catch (MalformedURLException e) {
-			throw new CrawljaxException(""Could not read that URL"", e);
-		}
+		return new CrawljaxConfigurationBuilder(URI.create(url));
 	}
 
-	private URL url;
+	private URI url;
 
 	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.FIREFOX);
 	private ImmutableList<Plugin> plugins;
@@ -229,14 +212,15 @@
 	private CrawlRules crawlRules;
 
 	private int maximumStates = 0;
-	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);;
+	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);
+	;
 	private int maximumDepth = 2;
 	private File output = new File(""out"");
 
 	private CrawljaxConfiguration() {
 	}
 
-	public URL getUrl() {
+	public URI getUrl() {
 		return url;
 	}
 
@@ -275,7 +259,7 @@
 	@Override
 	public int hashCode() {
 		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
-		        maximumStates, maximumRuntime, maximumDepth);
+		  maximumStates, maximumRuntime, maximumDepth);
 	}
 
 	@Override
@@ -283,13 +267,13 @@
 		if (object instanceof CrawljaxConfiguration) {
 			CrawljaxConfiguration that = (CrawljaxConfiguration) object;
 			return Objects.equal(this.url, that.url)
-			        && Objects.equal(this.browserConfig, that.browserConfig)
-			        && Objects.equal(this.plugins, that.plugins)
-			        && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
-			        && Objects.equal(this.crawlRules, that.crawlRules)
-			        && Objects.equal(this.maximumStates, that.maximumStates)
-			        && Objects.equal(this.maximumRuntime, that.maximumRuntime)
-			        && Objects.equal(this.maximumDepth, that.maximumDepth);
+			  && Objects.equal(this.browserConfig, that.browserConfig)
+			  && Objects.equal(this.plugins, that.plugins)
+			  && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
+			  && Objects.equal(this.crawlRules, that.crawlRules)
+			  && Objects.equal(this.maximumStates, that.maximumStates)
+			  && Objects.equal(this.maximumRuntime, that.maximumRuntime)
+			  && Objects.equal(this.maximumDepth, that.maximumDepth);
 		}
 		return false;
 	}
@@ -297,15 +281,15 @@
 	@Override
 	public String toString() {
 		return Objects.toStringHelper(this)
-		        .add(""url"", url)
-		        .add(""browserConfig"", browserConfig)
-		        .add(""plugins"", plugins)
-		        .add(""proxyConfiguration"", proxyConfiguration)
-		        .add(""crawlRules"", crawlRules)
-		        .add(""maximumStates"", maximumStates)
-		        .add(""maximumRuntime"", maximumRuntime)
-		        .add(""maximumDepth"", maximumDepth)
-		        .toString();
+					  .add(""url"", url)
+					  .add(""browserConfig"", browserConfig)
+					  .add(""plugins"", plugins)
+					  .add(""proxyConfiguration"", proxyConfiguration)
+					  .add(""crawlRules"", crawlRules)
+					  .add(""maximumStates"", maximumStates)
+					  .add(""maximumRuntime"", maximumRuntime)
+					  .add(""maximumDepth"", maximumDepth)
+					  .toString();
 	}
 
 }
\ No newline at end of file
"
cce001509797b8b23ea287014e94227e570ae40a,Alex Nederlof,UrlUtils.java,MODIFY,"isSameDomain -> [String currentUrl, URL url] | [String currentUrl, URI url]","diff --git a/core/src/main/java/com/crawljax/util/UrlUtils.java b/core/src/main/java/com/crawljax/util/UrlUtils.java
index 048c7ab..459ddef 100644
--- a/core/src/main/java/com/crawljax/util/UrlUtils.java
+++ b/core/src/main/java/com/crawljax/util/UrlUtils.java
@@ -1,11 +1,6 @@
 package com.crawljax.util;
 
-import java.net.MalformedURLException;
 import java.net.URI;
-import java.net.URISyntaxException;
-import java.net.URL;
-import java.util.regex.PatternSyntaxException;
-
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -14,19 +9,23 @@
 	private static final Logger LOG = LoggerFactory.getLogger(UrlUtils.class);
 
 	/**
-	 * @param currentUrl
-	 *            The current url
-	 * @param href
-	 *            The target URL, relative or not
+	 * @param currentUrl The current url
+	 * @param href       The target URL, relative or not
 	 * @return The new URL.
 	 */
-	public static URL extractNewUrl(String currentUrl, String href) throws MalformedURLException {
+	public static URI extractNewUrl(String currentUrl, String href) {
 		if (href == null || isJavascript(href) || href.startsWith(""mailto:"")) {
-			throw new MalformedURLException(href + "" is not a HTTP url"");
-		} else if (href.contains(""://"")) {
-			return new URL(href);
-		} else {
-			return new URL(new URL(currentUrl), href);
+			throw new IllegalArgumentException(href + "" is not a HTTP url"");
+		}
+		else if (href.contains(""://"")) {
+			return URI.create(href);
+		}
+		else {
+			URI current = URI.create(currentUrl);
+			if (current.getPath().isEmpty() && !href.startsWith(""/"")) {
+				return URI.create(currentUrl).resolve(""/"" + href);
+			}
+			return URI.create(currentUrl).resolve(href);
 		}
 	}
 
@@ -35,27 +34,7 @@
 	}
 
 	/**
-	 * Internal used function to strip the basePath from a given url.
-	 * 
-	 * @param url
-	 *            the url to examine
-	 * @return the base path with file stipped
-	 */
-	static String getBasePath(URL url) {
-		String file = url.getFile().replaceAll(""\\*"", """");
-
-		try {
-			return url.getPath().replaceAll(file, """");
-		} catch (PatternSyntaxException pe) {
-			LOG.error(pe.getMessage());
-			return """";
-		}
-
-	}
-
-	/**
-	 * @param url
-	 *            the URL string.
+	 * @param url the URL string.
 	 * @return the base part of the URL.
 	 */
 	public static String getBaseUrl(String url) {
@@ -67,11 +46,9 @@
 	/**
 	 * Retrieve the var value for varName from a HTTP query string (format is
 	 * ""var1=val1&var2=val2"").
-	 * 
-	 * @param varName
-	 *            the name.
-	 * @param haystack
-	 *            the haystack.
+	 *
+	 * @param varName  the name.
+	 * @param haystack the haystack.
 	 * @return variable value for varName
 	 */
 	public static String getVarFromQueryString(String varName, String haystack) {
@@ -96,23 +73,17 @@
 	}
 
 	/**
-	 * Checks if the given URL is part of the domain, or a subdomain of the given {@link URL}.
-	 * 
-	 * @param currentUrl
-	 *            The url you want to check.
-	 * @param url
-	 *            The URL acting as the base.
+	 * Checks if the given URL is part of the domain, or a subdomain of the given {@link java.net.URI}.
+	 *
+	 * @param currentUrl The url you want to check.
+	 * @param url        The URL acting as the base.
 	 * @return If the URL is part of the domain.
 	 */
-	public static boolean isSameDomain(String currentUrl, URL url) {
-		try {
-			String current = URI.create(currentUrl).getHost().toLowerCase();
-			String original = url.toURI().getHost().toLowerCase();
-			return current.endsWith(original);
-		} catch (URISyntaxException e) {
-			LOG.warn(""Could not parse URI {}"", currentUrl);
-			return false;
-		}
+	public static boolean isSameDomain(String currentUrl, URI url) {
+		String current = URI.create(currentUrl).getHost().toLowerCase();
+		String original = url.getHost().toLowerCase();
+		return current.endsWith(original);
+
 	}
 
 	private UrlUtils() {
"
cce001509797b8b23ea287014e94227e570ae40a,Alex Nederlof,RunWithWebServer.java,MODIFY,newConfigBuilder -> [String context] | [],"diff --git a/core/src/test/java/com/crawljax/test/RunWithWebServer.java b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
index 68ee936..6229ff1 100644
--- a/core/src/test/java/com/crawljax/test/RunWithWebServer.java
+++ b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
@@ -1,6 +1,6 @@
 package com.crawljax.test;
 
-import java.net.URL;
+import java.net.URI;
 
 import org.eclipse.jetty.server.Server;
 import org.eclipse.jetty.server.ServerConnector;
@@ -17,7 +17,7 @@
 	private final Resource resource;
 
 	private int port;
-	private URL demoSite;
+	private URI demoSite;
 	private Server server;
 	private boolean started;
 
@@ -34,7 +34,7 @@
 		server = newWebServer();
 		server.start();
 		this.port = ((ServerConnector) server.getConnectors()[0]).getLocalPort();
-		this.demoSite = new URL(""http"", ""localhost"", port, ""/"");
+		this.demoSite = URI.create(""http://localhost:"" + port + ""/"");
 		this.started = true;
 	}
 
@@ -62,7 +62,7 @@
 		}
 	}
 
-	public URL getSiteUrl() {
+	public URI getSiteUrl() {
 		checkServerStarted();
 		return demoSite;
 	}
"
de56e2261c8b1d4dd7225da0d6575c8bf91f3a12,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index cd3c477..41cd3de 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -3,6 +3,7 @@
 import java.io.File;
 import java.io.IOException;
 import java.net.MalformedURLException;
+import java.net.URI;
 import java.net.URL;
 import java.util.ArrayList;
 import java.util.HashSet;
@@ -42,7 +43,6 @@
 import org.openqa.selenium.remote.ErrorHandler.UnknownServerException;
 import org.openqa.selenium.remote.HttpCommandExecutor;
 import org.openqa.selenium.remote.RemoteWebDriver;
-import org.openqa.selenium.remote.UnreachableBrowserException;
 import org.openqa.selenium.support.ui.Select;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -189,8 +189,7 @@
 	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
 
 	/**
-	 * Constructor without configuration values, these must be updated using the
-	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
+	 * Constructor without configuration values.
 	 * 
 	 * @param driver
 	 *            The WebDriver to use.
@@ -257,9 +256,9 @@
 	 *            The URL.
 	 */
 	@Override
-	public void goToUrl(URL url) {
+	public void goToUrl(URI url) {
 		try {
-			browser.navigate().to(url);
+			browser.navigate().to(url.toString());
 			Thread.sleep(this.crawlWaitReload);
 			handlePopups();
 		} catch (WebDriverException e) {
"
de56e2261c8b1d4dd7225da0d6575c8bf91f3a12,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URI url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index ba576bb..fb86e06 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -4,8 +4,7 @@
 
 import java.io.File;
 import java.io.UnsupportedEncodingException;
-import java.net.MalformedURLException;
-import java.net.URL;
+import java.net.URI;
 import java.net.URLEncoder;
 import java.util.concurrent.TimeUnit;
 
@@ -29,7 +28,7 @@
 		private final CrawljaxConfiguration config;
 		private final CrawlRulesBuilder crawlRules;
 
-		private CrawljaxConfigurationBuilder(URL url) {
+		private CrawljaxConfigurationBuilder(URI url) {
 			Preconditions.checkNotNull(url);
 			config = new CrawljaxConfiguration();
 			config.url = url;
@@ -40,36 +39,32 @@
 		 * If the website uses <a
 		 * href=""http://en.wikipedia.org/wiki/Basic_access_authentication"">Basic auth</a> you can
 		 * set the username and password here.
-		 * 
-		 * @param username
-		 *            The username for the website.
-		 * @param password
-		 *            The password for the website.
+		 *
+		 * @param username The username for the website.
+		 * @param password The password for the website.
 		 * @return {@link CrawljaxConfigurationBuilder} for method chaining.
 		 */
 		public CrawljaxConfigurationBuilder setBasicAuth(String username, String password) {
 			try {
 				String encodedUsername = URLEncoder.encode(username, ""UTF-8"");
 				String encodedPassword = URLEncoder.encode(password, ""UTF-8"");
-				config.url =
-				        new URL(config.url.getProtocol()
-				                + ""://"" + encodedUsername
-				                + "":"" + encodedPassword + ""@"" + config.url.getAuthority()
-				                + config.url.getPath());
-				System.out.println(""URL "" + config.url);
-			} catch (UnsupportedEncodingException | MalformedURLException e) {
+				config.url = URI.create(config.url.getScheme()
+				  + ""://"" + encodedUsername
+				  + "":"" + encodedPassword + ""@"" + config.url.getAuthority()
+				  + config.url.getPath());
+			}
+			catch (UnsupportedEncodingException e) {
 				throw new CrawljaxException(""Could not parse the username/password to a URL"", e);
 			}
 			return this;
 		}
 
 		/**
-		 * @param states
-		 *            The maximum number of states the Crawler should crawl. The default is
-		 *            unlimited.
+		 * @param states The maximum number of states the Crawler should crawl. The default is
+		 *               unlimited.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumStates(int states) {
-			checkArgument(states > 1, ""Number of maximum states should be largen than 1"");
+			checkArgument(states > 1, ""Number of maximum states should be larger than 1"");
 			config.maximumStates = states;
 			return this;
 		}
@@ -83,8 +78,7 @@
 		}
 
 		/**
-		 * @param time
-		 *            The maximum time the crawler should run. Default is one hour.
+		 * @param time The maximum time the crawler should run. Default is one hour.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumRunTime(long time, TimeUnit unit) {
 			checkArgument(time >= 0, ""Time should be larger than 0, or 0 for infinate."");
@@ -101,12 +95,11 @@
 		}
 
 		/**
-		 * @param depth
-		 *            The maximum depth the crawler can reach. The default is <code>2</code>.
+		 * @param depth The maximum depth the crawler can reach. The default is <code>2</code>.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumDepth(int depth) {
 			Preconditions.checkArgument(depth >= 0,
-			        ""Depth should be 0 for infinite, or larger for a certain depth."");
+			  ""Depth should be 0 for infinite, or larger for a certain depth."");
 			config.maximumDepth = depth;
 			return this;
 		}
@@ -125,9 +118,8 @@
 		 * <p>
 		 * You can call this method several times to add multiple plugins
 		 * </p>
-		 * 
-		 * @param plugins
-		 *            the plugins you would like to enable.
+		 *
+		 * @param plugins the plugins you would like to enable.
 		 */
 		public CrawljaxConfigurationBuilder addPlugin(Plugin... plugins) {
 			pluginBuilder.add(plugins);
@@ -135,8 +127,7 @@
 		}
 
 		/**
-		 * @param configuration
-		 *            The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
+		 * @param configuration The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
 		 */
 		public CrawljaxConfigurationBuilder setProxyConfig(ProxyConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -152,9 +143,8 @@
 		}
 
 		/**
-		 * @param configuration
-		 *            a custom {@link BrowserConfiguration}. The default is a single
-		 *            {@link BrowserType#FIREFOX} browser.
+		 * @param configuration a custom {@link BrowserConfiguration}. The default is a single
+		 *                      {@link BrowserType#FIREFOX} browser.
 		 */
 		public CrawljaxConfigurationBuilder setBrowserConfig(BrowserConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -165,11 +155,9 @@
 		/**
 		 * Set the output folder for any {@link Plugin} you might configure. Crawljax itself doesn't
 		 * need an output folder but many plug-ins do.
-		 * 
-		 * @param output
-		 *            The output folder. If it does not exist it will be created.
-		 * @throws IllegalStateException
-		 *             if the specified file is not writable or exists but isn't a folder.
+		 *
+		 * @param output The output folder. If it does not exist it will be created.
+		 * @throws IllegalStateException if the specified file is not writable or exists but isn't a folder.
 		 */
 		public CrawljaxConfigurationBuilder setOutputDirectory(File output) {
 			config.output = output;
@@ -180,12 +168,13 @@
 		private void checkOutputDirWritable() {
 			if (!config.output.exists()) {
 				Preconditions.checkState(config.output.mkdirs(),
-				        ""Could not create the output directory %s "", config.output);
-			} else {
+				  ""Could not create the output directory %s "", config.output);
+			}
+			else {
 				Preconditions.checkArgument(config.output.isDirectory(),
-				        ""Output directory %s is not a folder"", config.output);
+				  ""Output directory %s is not a folder"", config.output);
 				Preconditions.checkState(config.output.canWrite(),
-				        ""Output directory %s is not writable"", config.output);
+				  ""Output directory %s is not writable"", config.output);
 			}
 		}
 
@@ -198,29 +187,23 @@
 	}
 
 	/**
-	 * @param url
-	 *            The url you want to setup a configuration for
+	 * @param url The url you want to setup a configuration for
 	 * @return The builder to configure the crawler.
 	 */
-	public static CrawljaxConfigurationBuilder builderFor(URL url) {
+	public static CrawljaxConfigurationBuilder builderFor(URI url) {
 		Preconditions.checkNotNull(url, ""URL was null"");
 		return new CrawljaxConfigurationBuilder(url);
 	}
 
 	/**
-	 * @param url
-	 *            The url you want to setup a configuration for
+	 * @param url The url you want to setup a configuration for
 	 * @return The builder to configure the crawler.
 	 */
 	public static CrawljaxConfigurationBuilder builderFor(String url) {
-		try {
-			return new CrawljaxConfigurationBuilder(new URL(url));
-		} catch (MalformedURLException e) {
-			throw new CrawljaxException(""Could not read that URL"", e);
-		}
+		return new CrawljaxConfigurationBuilder(URI.create(url));
 	}
 
-	private URL url;
+	private URI url;
 
 	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.FIREFOX);
 	private ImmutableList<Plugin> plugins;
@@ -229,14 +212,15 @@
 	private CrawlRules crawlRules;
 
 	private int maximumStates = 0;
-	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);;
+	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);
+	;
 	private int maximumDepth = 2;
 	private File output = new File(""out"");
 
 	private CrawljaxConfiguration() {
 	}
 
-	public URL getUrl() {
+	public URI getUrl() {
 		return url;
 	}
 
@@ -275,7 +259,7 @@
 	@Override
 	public int hashCode() {
 		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
-		        maximumStates, maximumRuntime, maximumDepth);
+		  maximumStates, maximumRuntime, maximumDepth);
 	}
 
 	@Override
@@ -283,13 +267,13 @@
 		if (object instanceof CrawljaxConfiguration) {
 			CrawljaxConfiguration that = (CrawljaxConfiguration) object;
 			return Objects.equal(this.url, that.url)
-			        && Objects.equal(this.browserConfig, that.browserConfig)
-			        && Objects.equal(this.plugins, that.plugins)
-			        && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
-			        && Objects.equal(this.crawlRules, that.crawlRules)
-			        && Objects.equal(this.maximumStates, that.maximumStates)
-			        && Objects.equal(this.maximumRuntime, that.maximumRuntime)
-			        && Objects.equal(this.maximumDepth, that.maximumDepth);
+			  && Objects.equal(this.browserConfig, that.browserConfig)
+			  && Objects.equal(this.plugins, that.plugins)
+			  && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
+			  && Objects.equal(this.crawlRules, that.crawlRules)
+			  && Objects.equal(this.maximumStates, that.maximumStates)
+			  && Objects.equal(this.maximumRuntime, that.maximumRuntime)
+			  && Objects.equal(this.maximumDepth, that.maximumDepth);
 		}
 		return false;
 	}
@@ -297,15 +281,15 @@
 	@Override
 	public String toString() {
 		return Objects.toStringHelper(this)
-		        .add(""url"", url)
-		        .add(""browserConfig"", browserConfig)
-		        .add(""plugins"", plugins)
-		        .add(""proxyConfiguration"", proxyConfiguration)
-		        .add(""crawlRules"", crawlRules)
-		        .add(""maximumStates"", maximumStates)
-		        .add(""maximumRuntime"", maximumRuntime)
-		        .add(""maximumDepth"", maximumDepth)
-		        .toString();
+					  .add(""url"", url)
+					  .add(""browserConfig"", browserConfig)
+					  .add(""plugins"", plugins)
+					  .add(""proxyConfiguration"", proxyConfiguration)
+					  .add(""crawlRules"", crawlRules)
+					  .add(""maximumStates"", maximumStates)
+					  .add(""maximumRuntime"", maximumRuntime)
+					  .add(""maximumDepth"", maximumDepth)
+					  .toString();
 	}
 
 }
\ No newline at end of file
"
de56e2261c8b1d4dd7225da0d6575c8bf91f3a12,Alex Nederlof,RunWithWebServer.java,MODIFY,newConfigBuilder -> [String context] | [],"diff --git a/core/src/test/java/com/crawljax/test/RunWithWebServer.java b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
index 68ee936..6229ff1 100644
--- a/core/src/test/java/com/crawljax/test/RunWithWebServer.java
+++ b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
@@ -1,6 +1,6 @@
 package com.crawljax.test;
 
-import java.net.URL;
+import java.net.URI;
 
 import org.eclipse.jetty.server.Server;
 import org.eclipse.jetty.server.ServerConnector;
@@ -17,7 +17,7 @@
 	private final Resource resource;
 
 	private int port;
-	private URL demoSite;
+	private URI demoSite;
 	private Server server;
 	private boolean started;
 
@@ -34,7 +34,7 @@
 		server = newWebServer();
 		server.start();
 		this.port = ((ServerConnector) server.getConnectors()[0]).getLocalPort();
-		this.demoSite = new URL(""http"", ""localhost"", port, ""/"");
+		this.demoSite = URI.create(""http://localhost:"" + port + ""/"");
 		this.started = true;
 	}
 
@@ -62,7 +62,7 @@
 		}
 	}
 
-	public URL getSiteUrl() {
+	public URI getSiteUrl() {
 		checkServerStarted();
 		return demoSite;
 	}
"
577704ce9dc8e65fe978f19900cd6a67ad07c3ba,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URI url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index fb86e06..869887c 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -13,6 +13,7 @@
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
+import com.crawljax.core.state.StateVertexFactory;
 import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
@@ -153,6 +154,22 @@
 		}
 
 		/**
+		 * Set a custom {@link com.crawljax.core.state.StateVertexFactory} to be able to use your own
+		 * {@link com.crawljax.core.state.StateVertex} objects. This is useful when you want to have a custom
+		 * comparator
+		 * in the stateflowgraph which relies on the {@link Object#hashCode()} or {@link Object#equals(Object)} of the
+		 * {@link com.crawljax.core.state.StateVertex}.
+		 *
+		 * @param vertexFactory The factory you want to use.
+		 * @return The builder for method chaining.
+		 */
+		public CrawljaxConfigurationBuilder setStateVertexFactory(StateVertexFactory vertexFactory) {
+			Preconditions.checkNotNull(vertexFactory);
+			config.stateVertexFactory = vertexFactory;
+			return this;
+		}
+
+		/**
 		 * Set the output folder for any {@link Plugin} you might configure. Crawljax itself doesn't
 		 * need an output folder but many plug-ins do.
 		 *
@@ -217,6 +234,8 @@
 	private int maximumDepth = 2;
 	private File output = new File(""out"");
 
+	private StateVertexFactory stateVertexFactory;
+
 	private CrawljaxConfiguration() {
 	}
 
@@ -256,6 +275,11 @@
 		return output;
 	}
 
+
+	public StateVertexFactory getStateVertexFactory() {
+		return stateVertexFactory;
+	}
+
 	@Override
 	public int hashCode() {
 		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
"
577704ce9dc8e65fe978f19900cd6a67ad07c3ba,Alex Nederlof,InMemoryStateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
index b6abd4c..b71c424 100644
--- a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
@@ -1,5 +1,8 @@
 package com.crawljax.core.state;
 
+import javax.inject.Inject;
+import javax.inject.Singleton;
+
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashSet;
@@ -11,9 +14,12 @@
 import java.util.concurrent.locks.ReadWriteLock;
 import java.util.concurrent.locks.ReentrantReadWriteLock;
 
-import javax.inject.Inject;
-import javax.inject.Singleton;
-
+import com.crawljax.core.ExitNotifier;
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableSet;
+import com.google.common.collect.Lists;
+import com.google.common.collect.Maps;
+import com.google.common.collect.Sets;
 import org.apache.commons.math.stat.descriptive.moment.Mean;
 import org.jgrapht.DirectedGraph;
 import org.jgrapht.GraphPath;
@@ -23,13 +29,6 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.crawljax.core.ExitNotifier;
-import com.google.common.collect.ImmutableList;
-import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Lists;
-import com.google.common.collect.Maps;
-import com.google.common.collect.Sets;
-
 /**
  * The State-Flow Graph is a multi-edge directed graph with states (StateVetex) on the vertices and
  * clickables (Eventable) on the edges.
@@ -53,6 +52,7 @@
 	private final AtomicInteger nextStateNameCounter = new AtomicInteger();
 	private final ConcurrentMap<Integer, StateVertex> stateById;
 	private final ExitNotifier exitNotifier;
+	private final StateVertexFactory vertexFactory;
 
 	/**
 	 * The constructor.
@@ -61,8 +61,9 @@
 	 *            used for triggering an exit.
 	 */
 	@Inject
-	public InMemoryStateFlowGraph(ExitNotifier exitNotifier) {
+	public InMemoryStateFlowGraph(ExitNotifier exitNotifier, StateVertexFactory vertexFactory) {
 		this.exitNotifier = exitNotifier;
+		this.vertexFactory = vertexFactory;
 		sfg = new DirectedMultigraph<>(Eventable.class);
 		stateById = Maps.newConcurrentMap();
 		LOG.debug(""Initialized the stateflowgraph"");
@@ -277,7 +278,7 @@
 
 	StateVertex newStateFor(String url, String dom, String strippedDom) {
 		int id = nextStateNameCounter.incrementAndGet();
-		return new StateVertexImpl(id, url, getNewStateName(id), dom, strippedDom);
+		return vertexFactory.newStateVertex(id, url, getNewStateName(id), dom, strippedDom);
 	}
 
 	private String getNewStateName(int id) {
"
c30de97b07bc58b1385915b96c83ee603525c1d8,Keheliya Gallaba,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index cd3c477..41cd3de 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -3,6 +3,7 @@
 import java.io.File;
 import java.io.IOException;
 import java.net.MalformedURLException;
+import java.net.URI;
 import java.net.URL;
 import java.util.ArrayList;
 import java.util.HashSet;
@@ -42,7 +43,6 @@
 import org.openqa.selenium.remote.ErrorHandler.UnknownServerException;
 import org.openqa.selenium.remote.HttpCommandExecutor;
 import org.openqa.selenium.remote.RemoteWebDriver;
-import org.openqa.selenium.remote.UnreachableBrowserException;
 import org.openqa.selenium.support.ui.Select;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -189,8 +189,7 @@
 	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
 
 	/**
-	 * Constructor without configuration values, these must be updated using the
-	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
+	 * Constructor without configuration values.
 	 * 
 	 * @param driver
 	 *            The WebDriver to use.
@@ -257,9 +256,9 @@
 	 *            The URL.
 	 */
 	@Override
-	public void goToUrl(URL url) {
+	public void goToUrl(URI url) {
 		try {
-			browser.navigate().to(url);
+			browser.navigate().to(url.toString());
 			Thread.sleep(this.crawlWaitReload);
 			handlePopups();
 		} catch (WebDriverException e) {
"
c30de97b07bc58b1385915b96c83ee603525c1d8,Keheliya Gallaba,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URI url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index ba576bb..fb86e06 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -4,8 +4,7 @@
 
 import java.io.File;
 import java.io.UnsupportedEncodingException;
-import java.net.MalformedURLException;
-import java.net.URL;
+import java.net.URI;
 import java.net.URLEncoder;
 import java.util.concurrent.TimeUnit;
 
@@ -29,7 +28,7 @@
 		private final CrawljaxConfiguration config;
 		private final CrawlRulesBuilder crawlRules;
 
-		private CrawljaxConfigurationBuilder(URL url) {
+		private CrawljaxConfigurationBuilder(URI url) {
 			Preconditions.checkNotNull(url);
 			config = new CrawljaxConfiguration();
 			config.url = url;
@@ -40,36 +39,32 @@
 		 * If the website uses <a
 		 * href=""http://en.wikipedia.org/wiki/Basic_access_authentication"">Basic auth</a> you can
 		 * set the username and password here.
-		 * 
-		 * @param username
-		 *            The username for the website.
-		 * @param password
-		 *            The password for the website.
+		 *
+		 * @param username The username for the website.
+		 * @param password The password for the website.
 		 * @return {@link CrawljaxConfigurationBuilder} for method chaining.
 		 */
 		public CrawljaxConfigurationBuilder setBasicAuth(String username, String password) {
 			try {
 				String encodedUsername = URLEncoder.encode(username, ""UTF-8"");
 				String encodedPassword = URLEncoder.encode(password, ""UTF-8"");
-				config.url =
-				        new URL(config.url.getProtocol()
-				                + ""://"" + encodedUsername
-				                + "":"" + encodedPassword + ""@"" + config.url.getAuthority()
-				                + config.url.getPath());
-				System.out.println(""URL "" + config.url);
-			} catch (UnsupportedEncodingException | MalformedURLException e) {
+				config.url = URI.create(config.url.getScheme()
+				  + ""://"" + encodedUsername
+				  + "":"" + encodedPassword + ""@"" + config.url.getAuthority()
+				  + config.url.getPath());
+			}
+			catch (UnsupportedEncodingException e) {
 				throw new CrawljaxException(""Could not parse the username/password to a URL"", e);
 			}
 			return this;
 		}
 
 		/**
-		 * @param states
-		 *            The maximum number of states the Crawler should crawl. The default is
-		 *            unlimited.
+		 * @param states The maximum number of states the Crawler should crawl. The default is
+		 *               unlimited.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumStates(int states) {
-			checkArgument(states > 1, ""Number of maximum states should be largen than 1"");
+			checkArgument(states > 1, ""Number of maximum states should be larger than 1"");
 			config.maximumStates = states;
 			return this;
 		}
@@ -83,8 +78,7 @@
 		}
 
 		/**
-		 * @param time
-		 *            The maximum time the crawler should run. Default is one hour.
+		 * @param time The maximum time the crawler should run. Default is one hour.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumRunTime(long time, TimeUnit unit) {
 			checkArgument(time >= 0, ""Time should be larger than 0, or 0 for infinate."");
@@ -101,12 +95,11 @@
 		}
 
 		/**
-		 * @param depth
-		 *            The maximum depth the crawler can reach. The default is <code>2</code>.
+		 * @param depth The maximum depth the crawler can reach. The default is <code>2</code>.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumDepth(int depth) {
 			Preconditions.checkArgument(depth >= 0,
-			        ""Depth should be 0 for infinite, or larger for a certain depth."");
+			  ""Depth should be 0 for infinite, or larger for a certain depth."");
 			config.maximumDepth = depth;
 			return this;
 		}
@@ -125,9 +118,8 @@
 		 * <p>
 		 * You can call this method several times to add multiple plugins
 		 * </p>
-		 * 
-		 * @param plugins
-		 *            the plugins you would like to enable.
+		 *
+		 * @param plugins the plugins you would like to enable.
 		 */
 		public CrawljaxConfigurationBuilder addPlugin(Plugin... plugins) {
 			pluginBuilder.add(plugins);
@@ -135,8 +127,7 @@
 		}
 
 		/**
-		 * @param configuration
-		 *            The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
+		 * @param configuration The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
 		 */
 		public CrawljaxConfigurationBuilder setProxyConfig(ProxyConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -152,9 +143,8 @@
 		}
 
 		/**
-		 * @param configuration
-		 *            a custom {@link BrowserConfiguration}. The default is a single
-		 *            {@link BrowserType#FIREFOX} browser.
+		 * @param configuration a custom {@link BrowserConfiguration}. The default is a single
+		 *                      {@link BrowserType#FIREFOX} browser.
 		 */
 		public CrawljaxConfigurationBuilder setBrowserConfig(BrowserConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -165,11 +155,9 @@
 		/**
 		 * Set the output folder for any {@link Plugin} you might configure. Crawljax itself doesn't
 		 * need an output folder but many plug-ins do.
-		 * 
-		 * @param output
-		 *            The output folder. If it does not exist it will be created.
-		 * @throws IllegalStateException
-		 *             if the specified file is not writable or exists but isn't a folder.
+		 *
+		 * @param output The output folder. If it does not exist it will be created.
+		 * @throws IllegalStateException if the specified file is not writable or exists but isn't a folder.
 		 */
 		public CrawljaxConfigurationBuilder setOutputDirectory(File output) {
 			config.output = output;
@@ -180,12 +168,13 @@
 		private void checkOutputDirWritable() {
 			if (!config.output.exists()) {
 				Preconditions.checkState(config.output.mkdirs(),
-				        ""Could not create the output directory %s "", config.output);
-			} else {
+				  ""Could not create the output directory %s "", config.output);
+			}
+			else {
 				Preconditions.checkArgument(config.output.isDirectory(),
-				        ""Output directory %s is not a folder"", config.output);
+				  ""Output directory %s is not a folder"", config.output);
 				Preconditions.checkState(config.output.canWrite(),
-				        ""Output directory %s is not writable"", config.output);
+				  ""Output directory %s is not writable"", config.output);
 			}
 		}
 
@@ -198,29 +187,23 @@
 	}
 
 	/**
-	 * @param url
-	 *            The url you want to setup a configuration for
+	 * @param url The url you want to setup a configuration for
 	 * @return The builder to configure the crawler.
 	 */
-	public static CrawljaxConfigurationBuilder builderFor(URL url) {
+	public static CrawljaxConfigurationBuilder builderFor(URI url) {
 		Preconditions.checkNotNull(url, ""URL was null"");
 		return new CrawljaxConfigurationBuilder(url);
 	}
 
 	/**
-	 * @param url
-	 *            The url you want to setup a configuration for
+	 * @param url The url you want to setup a configuration for
 	 * @return The builder to configure the crawler.
 	 */
 	public static CrawljaxConfigurationBuilder builderFor(String url) {
-		try {
-			return new CrawljaxConfigurationBuilder(new URL(url));
-		} catch (MalformedURLException e) {
-			throw new CrawljaxException(""Could not read that URL"", e);
-		}
+		return new CrawljaxConfigurationBuilder(URI.create(url));
 	}
 
-	private URL url;
+	private URI url;
 
 	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.FIREFOX);
 	private ImmutableList<Plugin> plugins;
@@ -229,14 +212,15 @@
 	private CrawlRules crawlRules;
 
 	private int maximumStates = 0;
-	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);;
+	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);
+	;
 	private int maximumDepth = 2;
 	private File output = new File(""out"");
 
 	private CrawljaxConfiguration() {
 	}
 
-	public URL getUrl() {
+	public URI getUrl() {
 		return url;
 	}
 
@@ -275,7 +259,7 @@
 	@Override
 	public int hashCode() {
 		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
-		        maximumStates, maximumRuntime, maximumDepth);
+		  maximumStates, maximumRuntime, maximumDepth);
 	}
 
 	@Override
@@ -283,13 +267,13 @@
 		if (object instanceof CrawljaxConfiguration) {
 			CrawljaxConfiguration that = (CrawljaxConfiguration) object;
 			return Objects.equal(this.url, that.url)
-			        && Objects.equal(this.browserConfig, that.browserConfig)
-			        && Objects.equal(this.plugins, that.plugins)
-			        && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
-			        && Objects.equal(this.crawlRules, that.crawlRules)
-			        && Objects.equal(this.maximumStates, that.maximumStates)
-			        && Objects.equal(this.maximumRuntime, that.maximumRuntime)
-			        && Objects.equal(this.maximumDepth, that.maximumDepth);
+			  && Objects.equal(this.browserConfig, that.browserConfig)
+			  && Objects.equal(this.plugins, that.plugins)
+			  && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
+			  && Objects.equal(this.crawlRules, that.crawlRules)
+			  && Objects.equal(this.maximumStates, that.maximumStates)
+			  && Objects.equal(this.maximumRuntime, that.maximumRuntime)
+			  && Objects.equal(this.maximumDepth, that.maximumDepth);
 		}
 		return false;
 	}
@@ -297,15 +281,15 @@
 	@Override
 	public String toString() {
 		return Objects.toStringHelper(this)
-		        .add(""url"", url)
-		        .add(""browserConfig"", browserConfig)
-		        .add(""plugins"", plugins)
-		        .add(""proxyConfiguration"", proxyConfiguration)
-		        .add(""crawlRules"", crawlRules)
-		        .add(""maximumStates"", maximumStates)
-		        .add(""maximumRuntime"", maximumRuntime)
-		        .add(""maximumDepth"", maximumDepth)
-		        .toString();
+					  .add(""url"", url)
+					  .add(""browserConfig"", browserConfig)
+					  .add(""plugins"", plugins)
+					  .add(""proxyConfiguration"", proxyConfiguration)
+					  .add(""crawlRules"", crawlRules)
+					  .add(""maximumStates"", maximumStates)
+					  .add(""maximumRuntime"", maximumRuntime)
+					  .add(""maximumDepth"", maximumDepth)
+					  .toString();
 	}
 
 }
\ No newline at end of file
"
c30de97b07bc58b1385915b96c83ee603525c1d8,Keheliya Gallaba,RunWithWebServer.java,MODIFY,newConfigBuilder -> [String context] | [],"diff --git a/core/src/test/java/com/crawljax/test/RunWithWebServer.java b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
index 68ee936..6229ff1 100644
--- a/core/src/test/java/com/crawljax/test/RunWithWebServer.java
+++ b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
@@ -1,6 +1,6 @@
 package com.crawljax.test;
 
-import java.net.URL;
+import java.net.URI;
 
 import org.eclipse.jetty.server.Server;
 import org.eclipse.jetty.server.ServerConnector;
@@ -17,7 +17,7 @@
 	private final Resource resource;
 
 	private int port;
-	private URL demoSite;
+	private URI demoSite;
 	private Server server;
 	private boolean started;
 
@@ -34,7 +34,7 @@
 		server = newWebServer();
 		server.start();
 		this.port = ((ServerConnector) server.getConnectors()[0]).getLocalPort();
-		this.demoSite = new URL(""http"", ""localhost"", port, ""/"");
+		this.demoSite = URI.create(""http://localhost:"" + port + ""/"");
 		this.started = true;
 	}
 
@@ -62,7 +62,7 @@
 		}
 	}
 
-	public URL getSiteUrl() {
+	public URI getSiteUrl() {
 		checkServerStarted();
 		return demoSite;
 	}
"
566edfc9cea1c1166c6b77543d23171660d61b44,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URI url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index fb86e06..869887c 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -13,6 +13,7 @@
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
+import com.crawljax.core.state.StateVertexFactory;
 import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
@@ -153,6 +154,22 @@
 		}
 
 		/**
+		 * Set a custom {@link com.crawljax.core.state.StateVertexFactory} to be able to use your own
+		 * {@link com.crawljax.core.state.StateVertex} objects. This is useful when you want to have a custom
+		 * comparator
+		 * in the stateflowgraph which relies on the {@link Object#hashCode()} or {@link Object#equals(Object)} of the
+		 * {@link com.crawljax.core.state.StateVertex}.
+		 *
+		 * @param vertexFactory The factory you want to use.
+		 * @return The builder for method chaining.
+		 */
+		public CrawljaxConfigurationBuilder setStateVertexFactory(StateVertexFactory vertexFactory) {
+			Preconditions.checkNotNull(vertexFactory);
+			config.stateVertexFactory = vertexFactory;
+			return this;
+		}
+
+		/**
 		 * Set the output folder for any {@link Plugin} you might configure. Crawljax itself doesn't
 		 * need an output folder but many plug-ins do.
 		 *
@@ -217,6 +234,8 @@
 	private int maximumDepth = 2;
 	private File output = new File(""out"");
 
+	private StateVertexFactory stateVertexFactory;
+
 	private CrawljaxConfiguration() {
 	}
 
@@ -256,6 +275,11 @@
 		return output;
 	}
 
+
+	public StateVertexFactory getStateVertexFactory() {
+		return stateVertexFactory;
+	}
+
 	@Override
 	public int hashCode() {
 		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
"
566edfc9cea1c1166c6b77543d23171660d61b44,Alex Nederlof,InMemoryStateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
index b6abd4c..b71c424 100644
--- a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
@@ -1,5 +1,8 @@
 package com.crawljax.core.state;
 
+import javax.inject.Inject;
+import javax.inject.Singleton;
+
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashSet;
@@ -11,9 +14,12 @@
 import java.util.concurrent.locks.ReadWriteLock;
 import java.util.concurrent.locks.ReentrantReadWriteLock;
 
-import javax.inject.Inject;
-import javax.inject.Singleton;
-
+import com.crawljax.core.ExitNotifier;
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableSet;
+import com.google.common.collect.Lists;
+import com.google.common.collect.Maps;
+import com.google.common.collect.Sets;
 import org.apache.commons.math.stat.descriptive.moment.Mean;
 import org.jgrapht.DirectedGraph;
 import org.jgrapht.GraphPath;
@@ -23,13 +29,6 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.crawljax.core.ExitNotifier;
-import com.google.common.collect.ImmutableList;
-import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Lists;
-import com.google.common.collect.Maps;
-import com.google.common.collect.Sets;
-
 /**
  * The State-Flow Graph is a multi-edge directed graph with states (StateVetex) on the vertices and
  * clickables (Eventable) on the edges.
@@ -53,6 +52,7 @@
 	private final AtomicInteger nextStateNameCounter = new AtomicInteger();
 	private final ConcurrentMap<Integer, StateVertex> stateById;
 	private final ExitNotifier exitNotifier;
+	private final StateVertexFactory vertexFactory;
 
 	/**
 	 * The constructor.
@@ -61,8 +61,9 @@
 	 *            used for triggering an exit.
 	 */
 	@Inject
-	public InMemoryStateFlowGraph(ExitNotifier exitNotifier) {
+	public InMemoryStateFlowGraph(ExitNotifier exitNotifier, StateVertexFactory vertexFactory) {
 		this.exitNotifier = exitNotifier;
+		this.vertexFactory = vertexFactory;
 		sfg = new DirectedMultigraph<>(Eventable.class);
 		stateById = Maps.newConcurrentMap();
 		LOG.debug(""Initialized the stateflowgraph"");
@@ -277,7 +278,7 @@
 
 	StateVertex newStateFor(String url, String dom, String strippedDom) {
 		int id = nextStateNameCounter.incrementAndGet();
-		return new StateVertexImpl(id, url, getNewStateName(id), dom, strippedDom);
+		return vertexFactory.newStateVertex(id, url, getNewStateName(id), dom, strippedDom);
 	}
 
 	private String getNewStateName(int id) {
"
50b90be8aab43b01678fb4c9dace33517416c65f,Alex Nederlof,RunWithWebServer.java,MODIFY,newConfigBuilder -> [String context] | [],"diff --git a/core/src/test/java/com/crawljax/test/RunWithWebServer.java b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
index 6229ff1..9f3cc2f 100644
--- a/core/src/test/java/com/crawljax/test/RunWithWebServer.java
+++ b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
@@ -2,16 +2,17 @@
 
 import java.net.URI;
 
+import com.crawljax.browser.BrowserProvider;
+import com.crawljax.core.configuration.BrowserConfiguration;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
+import com.crawljax.core.configuration.CrawljaxConfiguration.CrawljaxConfigurationBuilder;
+import com.google.common.base.Preconditions;
 import org.eclipse.jetty.server.Server;
 import org.eclipse.jetty.server.ServerConnector;
 import org.eclipse.jetty.server.handler.ResourceHandler;
 import org.eclipse.jetty.util.resource.Resource;
 import org.junit.rules.ExternalResource;
 
-import com.crawljax.core.configuration.CrawljaxConfiguration;
-import com.crawljax.core.configuration.CrawljaxConfiguration.CrawljaxConfigurationBuilder;
-import com.google.common.base.Preconditions;
-
 public class RunWithWebServer extends ExternalResource {
 
 	private final Resource resource;
@@ -22,8 +23,7 @@
 	private boolean started;
 
 	/**
-	 * @param classPathResource
-	 *            The name of the resource. This resource must be on the test or regular classpath.
+	 * @param classPathResource The name of the resource. This resource must be on the test or regular classpath.
 	 */
 	public RunWithWebServer(String classPathResource) {
 		resource = Resource.newClassPathResource(classPathResource);
@@ -40,7 +40,7 @@
 
 	/**
 	 * Override this method to configure custom server settings.
-	 * 
+	 *
 	 * @return a {@link Server}.
 	 */
 	protected Server newWebServer() {
@@ -57,7 +57,8 @@
 			if (server != null) {
 				server.stop();
 			}
-		} catch (Exception e) {
+		}
+		catch (Exception e) {
 			throw new RuntimeException(""Could not stop the server"", e);
 		}
 	}
@@ -73,11 +74,13 @@
 	}
 
 	public CrawljaxConfigurationBuilder newConfigBuilder() {
-		return CrawljaxConfiguration.builderFor(getSiteUrl());
+		return CrawljaxConfiguration.builderFor(getSiteUrl())
+		                            .setBrowserConfig(new BrowserConfiguration(BrowserProvider.getBrowserType()));
 	}
 
 	public CrawljaxConfigurationBuilder newConfigBuilder(String context) {
-		return CrawljaxConfiguration.builderFor(getSiteUrl() + context);
+		return CrawljaxConfiguration.builderFor(getSiteUrl() + context)
+		                            .setBrowserConfig(new BrowserConfiguration(BrowserProvider.getBrowserType()));
 	}
 
 	public void stop() throws Exception {
"
5c94a402d167523c0633550f7c0462d46bc23bce,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index cd3c477..41cd3de 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -3,6 +3,7 @@
 import java.io.File;
 import java.io.IOException;
 import java.net.MalformedURLException;
+import java.net.URI;
 import java.net.URL;
 import java.util.ArrayList;
 import java.util.HashSet;
@@ -42,7 +43,6 @@
 import org.openqa.selenium.remote.ErrorHandler.UnknownServerException;
 import org.openqa.selenium.remote.HttpCommandExecutor;
 import org.openqa.selenium.remote.RemoteWebDriver;
-import org.openqa.selenium.remote.UnreachableBrowserException;
 import org.openqa.selenium.support.ui.Select;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
@@ -189,8 +189,7 @@
 	private IgnoreFrameChecker ignoreFrameChecker = new AcceptAllFramesChecker();
 
 	/**
-	 * Constructor without configuration values, these must be updated using the
-	 * {@link #updateConfiguration(CrawljaxConfigurationReader)}.
+	 * Constructor without configuration values.
 	 * 
 	 * @param driver
 	 *            The WebDriver to use.
@@ -257,9 +256,9 @@
 	 *            The URL.
 	 */
 	@Override
-	public void goToUrl(URL url) {
+	public void goToUrl(URI url) {
 		try {
-			browser.navigate().to(url);
+			browser.navigate().to(url.toString());
 			Thread.sleep(this.crawlWaitReload);
 			handlePopups();
 		} catch (WebDriverException e) {
"
5c94a402d167523c0633550f7c0462d46bc23bce,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URI url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index ba576bb..869887c 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -4,8 +4,7 @@
 
 import java.io.File;
 import java.io.UnsupportedEncodingException;
-import java.net.MalformedURLException;
-import java.net.URL;
+import java.net.URI;
 import java.net.URLEncoder;
 import java.util.concurrent.TimeUnit;
 
@@ -14,6 +13,7 @@
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
+import com.crawljax.core.state.StateVertexFactory;
 import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
@@ -29,7 +29,7 @@
 		private final CrawljaxConfiguration config;
 		private final CrawlRulesBuilder crawlRules;
 
-		private CrawljaxConfigurationBuilder(URL url) {
+		private CrawljaxConfigurationBuilder(URI url) {
 			Preconditions.checkNotNull(url);
 			config = new CrawljaxConfiguration();
 			config.url = url;
@@ -40,36 +40,32 @@
 		 * If the website uses <a
 		 * href=""http://en.wikipedia.org/wiki/Basic_access_authentication"">Basic auth</a> you can
 		 * set the username and password here.
-		 * 
-		 * @param username
-		 *            The username for the website.
-		 * @param password
-		 *            The password for the website.
+		 *
+		 * @param username The username for the website.
+		 * @param password The password for the website.
 		 * @return {@link CrawljaxConfigurationBuilder} for method chaining.
 		 */
 		public CrawljaxConfigurationBuilder setBasicAuth(String username, String password) {
 			try {
 				String encodedUsername = URLEncoder.encode(username, ""UTF-8"");
 				String encodedPassword = URLEncoder.encode(password, ""UTF-8"");
-				config.url =
-				        new URL(config.url.getProtocol()
-				                + ""://"" + encodedUsername
-				                + "":"" + encodedPassword + ""@"" + config.url.getAuthority()
-				                + config.url.getPath());
-				System.out.println(""URL "" + config.url);
-			} catch (UnsupportedEncodingException | MalformedURLException e) {
+				config.url = URI.create(config.url.getScheme()
+				  + ""://"" + encodedUsername
+				  + "":"" + encodedPassword + ""@"" + config.url.getAuthority()
+				  + config.url.getPath());
+			}
+			catch (UnsupportedEncodingException e) {
 				throw new CrawljaxException(""Could not parse the username/password to a URL"", e);
 			}
 			return this;
 		}
 
 		/**
-		 * @param states
-		 *            The maximum number of states the Crawler should crawl. The default is
-		 *            unlimited.
+		 * @param states The maximum number of states the Crawler should crawl. The default is
+		 *               unlimited.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumStates(int states) {
-			checkArgument(states > 1, ""Number of maximum states should be largen than 1"");
+			checkArgument(states > 1, ""Number of maximum states should be larger than 1"");
 			config.maximumStates = states;
 			return this;
 		}
@@ -83,8 +79,7 @@
 		}
 
 		/**
-		 * @param time
-		 *            The maximum time the crawler should run. Default is one hour.
+		 * @param time The maximum time the crawler should run. Default is one hour.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumRunTime(long time, TimeUnit unit) {
 			checkArgument(time >= 0, ""Time should be larger than 0, or 0 for infinate."");
@@ -101,12 +96,11 @@
 		}
 
 		/**
-		 * @param depth
-		 *            The maximum depth the crawler can reach. The default is <code>2</code>.
+		 * @param depth The maximum depth the crawler can reach. The default is <code>2</code>.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumDepth(int depth) {
 			Preconditions.checkArgument(depth >= 0,
-			        ""Depth should be 0 for infinite, or larger for a certain depth."");
+			  ""Depth should be 0 for infinite, or larger for a certain depth."");
 			config.maximumDepth = depth;
 			return this;
 		}
@@ -125,9 +119,8 @@
 		 * <p>
 		 * You can call this method several times to add multiple plugins
 		 * </p>
-		 * 
-		 * @param plugins
-		 *            the plugins you would like to enable.
+		 *
+		 * @param plugins the plugins you would like to enable.
 		 */
 		public CrawljaxConfigurationBuilder addPlugin(Plugin... plugins) {
 			pluginBuilder.add(plugins);
@@ -135,8 +128,7 @@
 		}
 
 		/**
-		 * @param configuration
-		 *            The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
+		 * @param configuration The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
 		 */
 		public CrawljaxConfigurationBuilder setProxyConfig(ProxyConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -152,9 +144,8 @@
 		}
 
 		/**
-		 * @param configuration
-		 *            a custom {@link BrowserConfiguration}. The default is a single
-		 *            {@link BrowserType#FIREFOX} browser.
+		 * @param configuration a custom {@link BrowserConfiguration}. The default is a single
+		 *                      {@link BrowserType#FIREFOX} browser.
 		 */
 		public CrawljaxConfigurationBuilder setBrowserConfig(BrowserConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -163,13 +154,27 @@
 		}
 
 		/**
+		 * Set a custom {@link com.crawljax.core.state.StateVertexFactory} to be able to use your own
+		 * {@link com.crawljax.core.state.StateVertex} objects. This is useful when you want to have a custom
+		 * comparator
+		 * in the stateflowgraph which relies on the {@link Object#hashCode()} or {@link Object#equals(Object)} of the
+		 * {@link com.crawljax.core.state.StateVertex}.
+		 *
+		 * @param vertexFactory The factory you want to use.
+		 * @return The builder for method chaining.
+		 */
+		public CrawljaxConfigurationBuilder setStateVertexFactory(StateVertexFactory vertexFactory) {
+			Preconditions.checkNotNull(vertexFactory);
+			config.stateVertexFactory = vertexFactory;
+			return this;
+		}
+
+		/**
 		 * Set the output folder for any {@link Plugin} you might configure. Crawljax itself doesn't
 		 * need an output folder but many plug-ins do.
-		 * 
-		 * @param output
-		 *            The output folder. If it does not exist it will be created.
-		 * @throws IllegalStateException
-		 *             if the specified file is not writable or exists but isn't a folder.
+		 *
+		 * @param output The output folder. If it does not exist it will be created.
+		 * @throws IllegalStateException if the specified file is not writable or exists but isn't a folder.
 		 */
 		public CrawljaxConfigurationBuilder setOutputDirectory(File output) {
 			config.output = output;
@@ -180,12 +185,13 @@
 		private void checkOutputDirWritable() {
 			if (!config.output.exists()) {
 				Preconditions.checkState(config.output.mkdirs(),
-				        ""Could not create the output directory %s "", config.output);
-			} else {
+				  ""Could not create the output directory %s "", config.output);
+			}
+			else {
 				Preconditions.checkArgument(config.output.isDirectory(),
-				        ""Output directory %s is not a folder"", config.output);
+				  ""Output directory %s is not a folder"", config.output);
 				Preconditions.checkState(config.output.canWrite(),
-				        ""Output directory %s is not writable"", config.output);
+				  ""Output directory %s is not writable"", config.output);
 			}
 		}
 
@@ -198,29 +204,23 @@
 	}
 
 	/**
-	 * @param url
-	 *            The url you want to setup a configuration for
+	 * @param url The url you want to setup a configuration for
 	 * @return The builder to configure the crawler.
 	 */
-	public static CrawljaxConfigurationBuilder builderFor(URL url) {
+	public static CrawljaxConfigurationBuilder builderFor(URI url) {
 		Preconditions.checkNotNull(url, ""URL was null"");
 		return new CrawljaxConfigurationBuilder(url);
 	}
 
 	/**
-	 * @param url
-	 *            The url you want to setup a configuration for
+	 * @param url The url you want to setup a configuration for
 	 * @return The builder to configure the crawler.
 	 */
 	public static CrawljaxConfigurationBuilder builderFor(String url) {
-		try {
-			return new CrawljaxConfigurationBuilder(new URL(url));
-		} catch (MalformedURLException e) {
-			throw new CrawljaxException(""Could not read that URL"", e);
-		}
+		return new CrawljaxConfigurationBuilder(URI.create(url));
 	}
 
-	private URL url;
+	private URI url;
 
 	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.FIREFOX);
 	private ImmutableList<Plugin> plugins;
@@ -229,14 +229,17 @@
 	private CrawlRules crawlRules;
 
 	private int maximumStates = 0;
-	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);;
+	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);
+	;
 	private int maximumDepth = 2;
 	private File output = new File(""out"");
 
+	private StateVertexFactory stateVertexFactory;
+
 	private CrawljaxConfiguration() {
 	}
 
-	public URL getUrl() {
+	public URI getUrl() {
 		return url;
 	}
 
@@ -272,10 +275,15 @@
 		return output;
 	}
 
+
+	public StateVertexFactory getStateVertexFactory() {
+		return stateVertexFactory;
+	}
+
 	@Override
 	public int hashCode() {
 		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
-		        maximumStates, maximumRuntime, maximumDepth);
+		  maximumStates, maximumRuntime, maximumDepth);
 	}
 
 	@Override
@@ -283,13 +291,13 @@
 		if (object instanceof CrawljaxConfiguration) {
 			CrawljaxConfiguration that = (CrawljaxConfiguration) object;
 			return Objects.equal(this.url, that.url)
-			        && Objects.equal(this.browserConfig, that.browserConfig)
-			        && Objects.equal(this.plugins, that.plugins)
-			        && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
-			        && Objects.equal(this.crawlRules, that.crawlRules)
-			        && Objects.equal(this.maximumStates, that.maximumStates)
-			        && Objects.equal(this.maximumRuntime, that.maximumRuntime)
-			        && Objects.equal(this.maximumDepth, that.maximumDepth);
+			  && Objects.equal(this.browserConfig, that.browserConfig)
+			  && Objects.equal(this.plugins, that.plugins)
+			  && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
+			  && Objects.equal(this.crawlRules, that.crawlRules)
+			  && Objects.equal(this.maximumStates, that.maximumStates)
+			  && Objects.equal(this.maximumRuntime, that.maximumRuntime)
+			  && Objects.equal(this.maximumDepth, that.maximumDepth);
 		}
 		return false;
 	}
@@ -297,15 +305,15 @@
 	@Override
 	public String toString() {
 		return Objects.toStringHelper(this)
-		        .add(""url"", url)
-		        .add(""browserConfig"", browserConfig)
-		        .add(""plugins"", plugins)
-		        .add(""proxyConfiguration"", proxyConfiguration)
-		        .add(""crawlRules"", crawlRules)
-		        .add(""maximumStates"", maximumStates)
-		        .add(""maximumRuntime"", maximumRuntime)
-		        .add(""maximumDepth"", maximumDepth)
-		        .toString();
+					  .add(""url"", url)
+					  .add(""browserConfig"", browserConfig)
+					  .add(""plugins"", plugins)
+					  .add(""proxyConfiguration"", proxyConfiguration)
+					  .add(""crawlRules"", crawlRules)
+					  .add(""maximumStates"", maximumStates)
+					  .add(""maximumRuntime"", maximumRuntime)
+					  .add(""maximumDepth"", maximumDepth)
+					  .toString();
 	}
 
 }
\ No newline at end of file
"
5c94a402d167523c0633550f7c0462d46bc23bce,Alex Nederlof,InMemoryStateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
index b6abd4c..b71c424 100644
--- a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
@@ -1,5 +1,8 @@
 package com.crawljax.core.state;
 
+import javax.inject.Inject;
+import javax.inject.Singleton;
+
 import java.io.Serializable;
 import java.util.ArrayList;
 import java.util.HashSet;
@@ -11,9 +14,12 @@
 import java.util.concurrent.locks.ReadWriteLock;
 import java.util.concurrent.locks.ReentrantReadWriteLock;
 
-import javax.inject.Inject;
-import javax.inject.Singleton;
-
+import com.crawljax.core.ExitNotifier;
+import com.google.common.collect.ImmutableList;
+import com.google.common.collect.ImmutableSet;
+import com.google.common.collect.Lists;
+import com.google.common.collect.Maps;
+import com.google.common.collect.Sets;
 import org.apache.commons.math.stat.descriptive.moment.Mean;
 import org.jgrapht.DirectedGraph;
 import org.jgrapht.GraphPath;
@@ -23,13 +29,6 @@
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
-import com.crawljax.core.ExitNotifier;
-import com.google.common.collect.ImmutableList;
-import com.google.common.collect.ImmutableSet;
-import com.google.common.collect.Lists;
-import com.google.common.collect.Maps;
-import com.google.common.collect.Sets;
-
 /**
  * The State-Flow Graph is a multi-edge directed graph with states (StateVetex) on the vertices and
  * clickables (Eventable) on the edges.
@@ -53,6 +52,7 @@
 	private final AtomicInteger nextStateNameCounter = new AtomicInteger();
 	private final ConcurrentMap<Integer, StateVertex> stateById;
 	private final ExitNotifier exitNotifier;
+	private final StateVertexFactory vertexFactory;
 
 	/**
 	 * The constructor.
@@ -61,8 +61,9 @@
 	 *            used for triggering an exit.
 	 */
 	@Inject
-	public InMemoryStateFlowGraph(ExitNotifier exitNotifier) {
+	public InMemoryStateFlowGraph(ExitNotifier exitNotifier, StateVertexFactory vertexFactory) {
 		this.exitNotifier = exitNotifier;
+		this.vertexFactory = vertexFactory;
 		sfg = new DirectedMultigraph<>(Eventable.class);
 		stateById = Maps.newConcurrentMap();
 		LOG.debug(""Initialized the stateflowgraph"");
@@ -277,7 +278,7 @@
 
 	StateVertex newStateFor(String url, String dom, String strippedDom) {
 		int id = nextStateNameCounter.incrementAndGet();
-		return new StateVertexImpl(id, url, getNewStateName(id), dom, strippedDom);
+		return vertexFactory.newStateVertex(id, url, getNewStateName(id), dom, strippedDom);
 	}
 
 	private String getNewStateName(int id) {
"
5c94a402d167523c0633550f7c0462d46bc23bce,Alex Nederlof,RunWithWebServer.java,MODIFY,newConfigBuilder -> [String context] | [],"diff --git a/core/src/test/java/com/crawljax/test/RunWithWebServer.java b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
index 68ee936..6229ff1 100644
--- a/core/src/test/java/com/crawljax/test/RunWithWebServer.java
+++ b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
@@ -1,6 +1,6 @@
 package com.crawljax.test;
 
-import java.net.URL;
+import java.net.URI;
 
 import org.eclipse.jetty.server.Server;
 import org.eclipse.jetty.server.ServerConnector;
@@ -17,7 +17,7 @@
 	private final Resource resource;
 
 	private int port;
-	private URL demoSite;
+	private URI demoSite;
 	private Server server;
 	private boolean started;
 
@@ -34,7 +34,7 @@
 		server = newWebServer();
 		server.start();
 		this.port = ((ServerConnector) server.getConnectors()[0]).getLocalPort();
-		this.demoSite = new URL(""http"", ""localhost"", port, ""/"");
+		this.demoSite = URI.create(""http://localhost:"" + port + ""/"");
 		this.started = true;
 	}
 
@@ -62,7 +62,7 @@
 		}
 	}
 
-	public URL getSiteUrl() {
+	public URI getSiteUrl() {
 		checkServerStarted();
 		return demoSite;
 	}
"
ee1fb1b32b948f8f287f94b6d073a1528e1248ee,Ali Mesbah,RunWithWebServer.java,MODIFY,newConfigBuilder -> [String context] | [],"diff --git a/core/src/test/java/com/crawljax/test/RunWithWebServer.java b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
index 6229ff1..9f3cc2f 100644
--- a/core/src/test/java/com/crawljax/test/RunWithWebServer.java
+++ b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
@@ -2,16 +2,17 @@
 
 import java.net.URI;
 
+import com.crawljax.browser.BrowserProvider;
+import com.crawljax.core.configuration.BrowserConfiguration;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
+import com.crawljax.core.configuration.CrawljaxConfiguration.CrawljaxConfigurationBuilder;
+import com.google.common.base.Preconditions;
 import org.eclipse.jetty.server.Server;
 import org.eclipse.jetty.server.ServerConnector;
 import org.eclipse.jetty.server.handler.ResourceHandler;
 import org.eclipse.jetty.util.resource.Resource;
 import org.junit.rules.ExternalResource;
 
-import com.crawljax.core.configuration.CrawljaxConfiguration;
-import com.crawljax.core.configuration.CrawljaxConfiguration.CrawljaxConfigurationBuilder;
-import com.google.common.base.Preconditions;
-
 public class RunWithWebServer extends ExternalResource {
 
 	private final Resource resource;
@@ -22,8 +23,7 @@
 	private boolean started;
 
 	/**
-	 * @param classPathResource
-	 *            The name of the resource. This resource must be on the test or regular classpath.
+	 * @param classPathResource The name of the resource. This resource must be on the test or regular classpath.
 	 */
 	public RunWithWebServer(String classPathResource) {
 		resource = Resource.newClassPathResource(classPathResource);
@@ -40,7 +40,7 @@
 
 	/**
 	 * Override this method to configure custom server settings.
-	 * 
+	 *
 	 * @return a {@link Server}.
 	 */
 	protected Server newWebServer() {
@@ -57,7 +57,8 @@
 			if (server != null) {
 				server.stop();
 			}
-		} catch (Exception e) {
+		}
+		catch (Exception e) {
 			throw new RuntimeException(""Could not stop the server"", e);
 		}
 	}
@@ -73,11 +74,13 @@
 	}
 
 	public CrawljaxConfigurationBuilder newConfigBuilder() {
-		return CrawljaxConfiguration.builderFor(getSiteUrl());
+		return CrawljaxConfiguration.builderFor(getSiteUrl())
+		                            .setBrowserConfig(new BrowserConfiguration(BrowserProvider.getBrowserType()));
 	}
 
 	public CrawljaxConfigurationBuilder newConfigBuilder(String context) {
-		return CrawljaxConfiguration.builderFor(getSiteUrl() + context);
+		return CrawljaxConfiguration.builderFor(getSiteUrl() + context)
+		                            .setBrowserConfig(new BrowserConfiguration(BrowserProvider.getBrowserType()));
 	}
 
 	public void stop() throws Exception {
"
8e56215e27d746df2b4f3af79f9d49d321dd1b2d,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URI url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 869887c..f8ec514 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -49,10 +49,8 @@
 			try {
 				String encodedUsername = URLEncoder.encode(username, ""UTF-8"");
 				String encodedPassword = URLEncoder.encode(password, ""UTF-8"");
-				config.url = URI.create(config.url.getScheme()
-				  + ""://"" + encodedUsername
-				  + "":"" + encodedPassword + ""@"" + config.url.getAuthority()
-				  + config.url.getPath());
+				String hostPrefix = encodedUsername + "":"" + encodedPassword + ""@"";
+				config.url = URI.create(config.url.toString().replaceFirst(""://"", ""://"" + hostPrefix));
 			}
 			catch (UnsupportedEncodingException e) {
 				throw new CrawljaxException(""Could not parse the username/password to a URL"", e);
"
3cad03a51b6919721315249ea914a199c18842e4,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URI url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 869887c..f8ec514 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -49,10 +49,8 @@
 			try {
 				String encodedUsername = URLEncoder.encode(username, ""UTF-8"");
 				String encodedPassword = URLEncoder.encode(password, ""UTF-8"");
-				config.url = URI.create(config.url.getScheme()
-				  + ""://"" + encodedUsername
-				  + "":"" + encodedPassword + ""@"" + config.url.getAuthority()
-				  + config.url.getPath());
+				String hostPrefix = encodedUsername + "":"" + encodedPassword + ""@"";
+				config.url = URI.create(config.url.toString().replaceFirst(""://"", ""://"" + hostPrefix));
 			}
 			catch (UnsupportedEncodingException e) {
 				throw new CrawljaxException(""Could not parse the username/password to a URL"", e);
"
18d68715377bbcaeb00cdfbe5349ac8f9a38bac9,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 41cd3de..bb40117 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -375,7 +375,7 @@
 		String htmlFormatted = m.replaceAll("""");
 
 		p = Pattern.compile(""<\\?xml:(.*?)>"");
-		m = p.matcher(html);
+		m = p.matcher(htmlFormatted);
 		htmlFormatted = m.replaceAll("""");
 
 		htmlFormatted = filterAttributes(htmlFormatted);
"
9134acc953462e9ccb4d928f6b3f3b572b0f603e,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index bb40117..7028901 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -338,12 +338,6 @@
 	}
 
 	@Override
-	@Deprecated
-	public String getDom() {
-		return getStrippedDom();
-	}
-
-	@Override
 	public String getStrippedDom() {
 
 		try {
"
bbea747e326ab1cccabc9614cf3b9811c9db825c,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index bb40117..7028901 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -338,12 +338,6 @@
 	}
 
 	@Override
-	@Deprecated
-	public String getDom() {
-		return getStrippedDom();
-	}
-
-	@Override
 	public String getStrippedDom() {
 
 		try {
"
1e85ddb5c224e1bd50d035357d3bd3a825b573c7,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URI url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index f8ec514..c08a6df 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -14,6 +14,10 @@
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.core.state.StateVertexFactory;
+import com.crawljax.domcomparators.DomTextContentStripper;
+import com.crawljax.domcomparators.AttributesStripper;
+import com.crawljax.domcomparators.DomStripper;
+import com.crawljax.domcomparators.ValidDomStripper;
 import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
@@ -26,6 +30,8 @@
 	public static class CrawljaxConfigurationBuilder {
 
 		private final ImmutableList.Builder<Plugin> pluginBuilder = ImmutableList.builder();
+		private final ImmutableList.Builder<ValidDomStripper> validStrippers = ImmutableList.builder();
+		private final ImmutableList.Builder<DomStripper> strippers = ImmutableList.builder();
 		private final CrawljaxConfiguration config;
 		private final CrawlRulesBuilder crawlRules;
 
@@ -37,8 +43,8 @@
 		}
 
 		/**
-		 * If the website uses <a
-		 * href=""http://en.wikipedia.org/wiki/Basic_access_authentication"">Basic auth</a> you can
+		 * If the website uses <a href=""http://en.wikipedia.org/wiki/Basic_access_authentication"">Basic auth</a> you
+		 * can
 		 * set the username and password here.
 		 *
 		 * @param username The username for the website.
@@ -59,8 +65,7 @@
 		}
 
 		/**
-		 * @param states The maximum number of states the Crawler should crawl. The default is
-		 *               unlimited.
+		 * @param states The maximum number of states the Crawler should crawl. The default is unlimited.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumStates(int states) {
 			checkArgument(states > 1, ""Number of maximum states should be larger than 1"");
@@ -98,7 +103,7 @@
 		 */
 		public CrawljaxConfigurationBuilder setMaximumDepth(int depth) {
 			Preconditions.checkArgument(depth >= 0,
-			  ""Depth should be 0 for infinite, or larger for a certain depth."");
+					""Depth should be 0 for infinite, or larger for a certain depth."");
 			config.maximumDepth = depth;
 			return this;
 		}
@@ -112,11 +117,8 @@
 		}
 
 		/**
-		 * Add plugins to Crawljax. Note that without plugins, Crawljax won't give any ouput. For
-		 * basic output at least enable the CrawlOverviewPlugin.
-		 * <p>
-		 * You can call this method several times to add multiple plugins
-		 * </p>
+		 * Add plugins to Crawljax. Note that without plugins, Crawljax won't give any ouput. For basic output at least
+		 * enable the CrawlOverviewPlugin. <p> You can call this method several times to add multiple plugins </p>
 		 *
 		 * @param plugins the plugins you would like to enable.
 		 */
@@ -142,8 +144,8 @@
 		}
 
 		/**
-		 * @param configuration a custom {@link BrowserConfiguration}. The default is a single
-		 *                      {@link BrowserType#FIREFOX} browser.
+		 * @param configuration a custom {@link BrowserConfiguration}. The default is a single {@link
+		 *                      BrowserType#FIREFOX} browser.
 		 */
 		public CrawljaxConfigurationBuilder setBrowserConfig(BrowserConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -152,11 +154,11 @@
 		}
 
 		/**
-		 * Set a custom {@link com.crawljax.core.state.StateVertexFactory} to be able to use your own
-		 * {@link com.crawljax.core.state.StateVertex} objects. This is useful when you want to have a custom
-		 * comparator
-		 * in the stateflowgraph which relies on the {@link Object#hashCode()} or {@link Object#equals(Object)} of the
-		 * {@link com.crawljax.core.state.StateVertex}.
+		 * Set a custom {@link com.crawljax.core.state.StateVertexFactory} to be able to use your own {@link
+		 * com.crawljax.core.state.StateVertex} objects. This is useful when you want to have a custom comparator in
+		 * the
+		 * stateflowgraph which relies on the {@link Object#hashCode()} or {@link Object#equals(Object)} of the {@link
+		 * com.crawljax.core.state.StateVertex}.
 		 *
 		 * @param vertexFactory The factory you want to use.
 		 * @return The builder for method chaining.
@@ -168,8 +170,8 @@
 		}
 
 		/**
-		 * Set the output folder for any {@link Plugin} you might configure. Crawljax itself doesn't
-		 * need an output folder but many plug-ins do.
+		 * Set the output folder for any {@link Plugin} you might configure. Crawljax itself doesn't need an output
+		 * folder but many plug-ins do.
 		 *
 		 * @param output The output folder. If it does not exist it will be created.
 		 * @throws IllegalStateException if the specified file is not writable or exists but isn't a folder.
@@ -180,22 +182,86 @@
 			return this;
 		}
 
+		/**
+		 * Add a {@link com.crawljax.domcomparators.DomStripper}.
+		 *
+		 * <p>
+		 * If no {@link com.crawljax.domcomparators.DomStripper} or
+		 * {@link com.crawljax.domcomparators.ValidDomStripper} is added,
+		 * Crawljax uses the build-in {@link com.crawljax.domcomparators.DomStructureStripper}
+		 *  and {@link com.crawljax.domcomparators.AttributesStripper}</p>
+		 *
+		 * <p>
+		 * Out-of-the-box available strippers are:
+		 * <ul>
+		 * <li>{@link com.crawljax.domcomparators.DomTextContentStripper}</li>
+		 * <li>{@link com.crawljax.domcomparators.DomStructureStripper}</li>
+		 * <li>{@link com.crawljax.domcomparators.DomTextContentStripper}</li>
+		 * <li>{@link com.crawljax.domcomparators.WhiteSpaceStripper}</li>
+		 * </ul>
+		 * </p>
+		 * <p/>
+		 * @param stripper The stripper you want to add. Order matters. Duplicates are allowed.
+		 * @return the builder for method chaining.
+		 */
+		public CrawljaxConfigurationBuilder addDomStripper(DomStripper stripper) {
+			strippers.add(stripper);
+			return this;
+		}
+
+		/**
+		 * Add a {@link com.crawljax.domcomparators.ValidDomStripper}.
+		 *
+		 * <p>If no {@link com.crawljax.domcomparators.DomStripper} or {@link com.crawljax.domcomparators
+		 * .ValidDomStripper} is added, Crawljax uses the build-in
+		 * {@link com.crawljax.domcomparators.DomTextContentStripper}
+		 * and {@link com.crawljax.domcomparators.AttributesStripper}</p>
+		 *
+		 * <p>
+		 * Out-of-the-box available strippers are:
+		 * <ul>
+		 * <li>{@link com.crawljax.domcomparators.DomTextContentStripper}</li>
+		 * <li>{@link com.crawljax.domcomparators.DomStructureStripper}</li>
+		 * <li>{@link com.crawljax.domcomparators.ByCssSelectorStripper}</li>
+		 * <li>{@link com.crawljax.domcomparators.WhiteSpaceStripper}</li>
+		 * <li>{@link com.crawljax.domcomparators.AttributesStripper}</li>
+		 * </ul>
+		 * </p>
+		 * <p/>
+		 *
+		 * @param stripper The stripper you want to add. Order matters. Duplicates are allowed.
+		 * @return the builder for method chaining.
+		 */
+		public CrawljaxConfigurationBuilder addValidDomStripper(ValidDomStripper stripper) {
+			validStrippers.add(stripper);
+			return this;
+		}
+
 		private void checkOutputDirWritable() {
 			if (!config.output.exists()) {
 				Preconditions.checkState(config.output.mkdirs(),
-				  ""Could not create the output directory %s "", config.output);
+						""Could not create the output directory %s "", config.output);
 			}
 			else {
 				Preconditions.checkArgument(config.output.isDirectory(),
-				  ""Output directory %s is not a folder"", config.output);
+						""Output directory %s is not a folder"", config.output);
 				Preconditions.checkState(config.output.canWrite(),
-				  ""Output directory %s is not writable"", config.output);
+						""Output directory %s is not writable"", config.output);
 			}
 		}
 
 		public CrawljaxConfiguration build() {
 			config.plugins = pluginBuilder.build();
 			config.crawlRules = crawlRules.build();
+			config.strippers = strippers.build();
+			config.validStrippers = validStrippers.build();
+
+			if (config.strippers.isEmpty() && config.validStrippers.isEmpty()) {
+				config.strippers = ImmutableList.of(
+						new DomTextContentStripper(),
+						new AttributesStripper()
+				);
+			}
 			return config;
 		}
 
@@ -222,6 +288,8 @@
 
 	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.FIREFOX);
 	private ImmutableList<Plugin> plugins;
+	private ImmutableList<DomStripper> strippers;
+	private ImmutableList<ValidDomStripper> validStrippers;
 	private ProxyConfiguration proxyConfiguration = ProxyConfiguration.noProxy();
 
 	private CrawlRules crawlRules;
@@ -273,6 +341,9 @@
 		return output;
 	}
 
+	public ImmutableList<DomStripper> getStrippers() {
+		return strippers;
+	}
 
 	public StateVertexFactory getStateVertexFactory() {
 		return stateVertexFactory;
@@ -281,7 +352,7 @@
 	@Override
 	public int hashCode() {
 		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
-		  maximumStates, maximumRuntime, maximumDepth);
+				maximumStates, maximumRuntime, maximumDepth, strippers, validStrippers);
 	}
 
 	@Override
@@ -289,13 +360,15 @@
 		if (object instanceof CrawljaxConfiguration) {
 			CrawljaxConfiguration that = (CrawljaxConfiguration) object;
 			return Objects.equal(this.url, that.url)
-			  && Objects.equal(this.browserConfig, that.browserConfig)
-			  && Objects.equal(this.plugins, that.plugins)
-			  && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
-			  && Objects.equal(this.crawlRules, that.crawlRules)
-			  && Objects.equal(this.maximumStates, that.maximumStates)
-			  && Objects.equal(this.maximumRuntime, that.maximumRuntime)
-			  && Objects.equal(this.maximumDepth, that.maximumDepth);
+					&& Objects.equal(this.browserConfig, that.browserConfig)
+					&& Objects.equal(this.plugins, that.plugins)
+					&& Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
+					&& Objects.equal(this.crawlRules, that.crawlRules)
+					&& Objects.equal(this.maximumStates, that.maximumStates)
+					&& Objects.equal(this.maximumRuntime, that.maximumRuntime)
+					&& Objects.equal(this.maximumDepth, that.maximumDepth)
+					&& Objects.equal(this.strippers, that.strippers)
+					&& Objects.equal(this.validStrippers, that.validStrippers);
 		}
 		return false;
 	}
@@ -303,15 +376,15 @@
 	@Override
 	public String toString() {
 		return Objects.toStringHelper(this)
-					  .add(""url"", url)
-					  .add(""browserConfig"", browserConfig)
-					  .add(""plugins"", plugins)
-					  .add(""proxyConfiguration"", proxyConfiguration)
-					  .add(""crawlRules"", crawlRules)
-					  .add(""maximumStates"", maximumStates)
-					  .add(""maximumRuntime"", maximumRuntime)
-					  .add(""maximumDepth"", maximumDepth)
-					  .toString();
+				.add(""url"", url)
+				.add(""browserConfig"", browserConfig)
+				.add(""plugins"", plugins)
+				.add(""proxyConfiguration"", proxyConfiguration)
+				.add(""crawlRules"", crawlRules)
+				.add(""maximumStates"", maximumStates)
+				.add(""maximumRuntime"", maximumRuntime)
+				.add(""maximumDepth"", maximumDepth)
+				.toString();
 	}
 
 }
\ No newline at end of file
"
69c96c2b064a9ba5d23ad13d5bfc5d4eb4bf5e29,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 7028901..c42807a 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -9,8 +9,6 @@
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
 
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.AcceptAllFramesChecker;
@@ -23,8 +21,6 @@
 import com.crawljax.forms.InputValue;
 import com.crawljax.forms.RandomInputValueGenerator;
 import com.crawljax.util.DomUtils;
-import com.google.common.base.Preconditions;
-import com.google.common.collect.ImmutableSortedSet;
 import com.google.common.io.Files;
 import org.openqa.selenium.ElementNotVisibleException;
 import org.openqa.selenium.JavascriptExecutor;
@@ -53,95 +49,69 @@
 
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
 	private static final Logger LOGGER = LoggerFactory
-	        .getLogger(WebDriverBackedEmbeddedBrowser.class);
+			.getLogger(WebDriverBackedEmbeddedBrowser.class);
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param hubUrl
-	 *            Url of the server.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
+	 *
+	 * @param hubUrl           Url of the server.
+	 * @param crawlWaitReload  the period to wait after a reload.
+	 * @param crawlWaitEvent   the period to wait after an event is fired.
 	 * @return The EmbeddedBrowser.
 	 */
-	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl, long crawlWaitEvent,
+			long crawlWaitReload) {
 		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
-		        filterAttributes, crawlWaitEvent, crawlWaitReload);
+				crawlWaitEvent, crawlWaitReload);
 	}
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param hubUrl
-	 *            Url of the server.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
+	 *
+	 * @param hubUrl             Url of the server.
+	 * @param crawlWaitReload    the period to wait after a reload.
+	 * @param crawlWaitEvent     the period to wait after an event is fired.
+	 * @param ignoreFrameChecker the checker used to determine if a certain frame must be ignored.
 	 * @return The EmbeddedBrowser.
 	 */
-	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent,
-	        long crawlWaitReload, IgnoreFrameChecker ignoreFrameChecker) {
+	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl, long crawlWaitEvent,
+			long crawlWaitReload, IgnoreFrameChecker ignoreFrameChecker) {
 		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
-		        filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
+				crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
 	}
 
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
+	 *
+	 * @param driver          The WebDriver to use.
+	 * @param crawlWaitReload the period to wait after a reload.
+	 * @param crawlWaitEvent  the period to wait after an event is fired.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
-		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
-		        crawlWaitReload);
+			long crawlWaitEvent, long crawlWaitReload) {
+		return new WebDriverBackedEmbeddedBrowser(driver, crawlWaitEvent,
+				crawlWaitReload);
 	}
 
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
+	 *
+	 * @param driver             The WebDriver to use.
+	 * @param crawlWaitReload    the period to wait after a reload.
+	 * @param crawlWaitEvent     the period to wait after an event is fired.
+	 * @param ignoreFrameChecker the checker used to determine if a certain frame must be ignored.
 	 * @return The EmbeddedBrowser.
 	 */
-	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent,
-	        long crawlWaitReload, IgnoreFrameChecker ignoreFrameChecker) {
-		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
-		        crawlWaitReload, ignoreFrameChecker);
+	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver, long crawlWaitEvent,
+			long crawlWaitReload, IgnoreFrameChecker ignoreFrameChecker) {
+		return new WebDriverBackedEmbeddedBrowser(driver, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
 	}
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param hubUrl
-	 *            Url of the server.
+	 *
+	 * @param hubUrl Url of the server.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl) {
@@ -151,9 +121,8 @@
 	/**
 	 * Private used static method for creation of a RemoteWebDriver. Taking care of the default
 	 * Capabilities and using the HttpCommandExecutor.
-	 * 
-	 * @param hubUrl
-	 *            the url of the hub to use.
+	 *
+	 * @param hubUrl the url of the hub to use.
 	 * @return the RemoteWebDriver instance.
 	 */
 	private static RemoteWebDriver buildRemoteWebDriver(String hubUrl) {
@@ -162,26 +131,27 @@
 		URL url;
 		try {
 			url = new URL(hubUrl);
-		} catch (MalformedURLException e) {
+		}
+		catch (MalformedURLException e) {
 			LOGGER.error(""The given hub url of the remote server is malformed can not continue!"",
-			        e);
+					e);
 			return null;
 		}
 		HttpCommandExecutor executor = null;
 		try {
 			executor = new HttpCommandExecutor(url);
-		} catch (Exception e) {
+		}
+		catch (Exception e) {
 			// TODO Stefan; refactor this catch, this will definitely result in
 			// NullPointers, why
 			// not throw RuntimeExcption direct?
 			LOGGER.error(""Received unknown exception while creating the ""
-			        + ""HttpCommandExecutor, can not continue!"", e);
+					+ ""HttpCommandExecutor, can not continue!"", e);
 			return null;
 		}
 		return new RemoteWebDriver(executor, capabilities);
 	}
 
-	private final ImmutableSortedSet<String> filterAttributes;
 	private final WebDriver browser;
 
 	private long crawlWaitEvent;
@@ -190,61 +160,44 @@
 
 	/**
 	 * Constructor without configuration values.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
+	 *
+	 * @param driver The WebDriver to use.
 	 */
 	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
 		this.browser = driver;
-		filterAttributes = ImmutableSortedSet.of();
 	}
 
 	/**
 	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
+	 *
+	 * @param driver          The WebDriver to use.
+	 * @param crawlWaitReload the period to wait after a reload.
+	 * @param crawlWaitEvent  the period to wait after an event is fired.
 	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload, long crawlWaitEvent) {
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver, long crawlWaitReload, long crawlWaitEvent) {
 		this.browser = driver;
-		this.filterAttributes = Preconditions.checkNotNull(filterAttributes);
 		this.crawlWaitEvent = crawlWaitEvent;
 		this.crawlWaitReload = crawlWaitReload;
 	}
 
 	/**
 	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
+	 *
+	 * @param driver             The WebDriver to use.
+	 * @param crawlWaitReload    the period to wait after a reload.
+	 * @param crawlWaitEvent     the period to wait after an event is fired.
+	 * @param ignoreFrameChecker the checker used to determine if a certain frame must be ignored.
 	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload,
-	        long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
-		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver, long crawlWaitReload,
+			long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
+		this(driver, crawlWaitReload, crawlWaitEvent);
 		this.ignoreFrameChecker = ignoreFrameChecker;
 	}
 
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
+	 *
+	 * @param driver The WebDriver to use.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver) {
@@ -252,8 +205,7 @@
 	}
 
 	/**
-	 * @param url
-	 *            The URL.
+	 * @param url The URL.
 	 */
 	@Override
 	public void goToUrl(URI url) {
@@ -261,10 +213,12 @@
 			browser.navigate().to(url.toString());
 			Thread.sleep(this.crawlWaitReload);
 			handlePopups();
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return;
-		} catch (InterruptedException e) {
+		}
+		catch (InterruptedException e) {
 			LOGGER.debug(""goToUrl got interrupted while waiting for the page to be loaded"", e);
 			Thread.currentThread().interrupt();
 			return;
@@ -277,33 +231,33 @@
 	private void handlePopups() {
 		try {
 			executeJavaScript(""window.alert = function(msg){return true;};""
-			        + ""window.confirm = function(msg){return true;};""
-			        + ""window.prompt = function(msg){return true;};"");
-		} catch (CrawljaxException e) {
+					+ ""window.confirm = function(msg){return true;};""
+					+ ""window.prompt = function(msg){return true;};"");
+		}
+		catch (CrawljaxException e) {
 			LOGGER.error(""Handling of PopUp windows failed"", e);
 		}
 	}
 
 	/**
 	 * Fires the event and waits for a specified time.
-	 * 
-	 * @param webElement
-	 *            the element to fire event on.
-	 * @param eventable
-	 *            The HTML event type (onclick, onmouseover, ...).
+	 *
+	 * @param webElement the element to fire event on.
+	 * @param eventable  The HTML event type (onclick, onmouseover, ...).
 	 * @return true if firing event is successful.
-	 * @throws InterruptedException
-	 *             when interrupted during the wait.
+	 * @throws InterruptedException when interrupted during the wait.
 	 */
 	private boolean fireEventWait(WebElement webElement, Eventable eventable)
-	        throws ElementNotVisibleException, InterruptedException {
+			throws ElementNotVisibleException, InterruptedException {
 		switch (eventable.getEventType()) {
 			case click:
 				try {
 					webElement.click();
-				} catch (ElementNotVisibleException e) {
+				}
+				catch (ElementNotVisibleException e) {
 					throw e;
-				} catch (WebDriverException e) {
+				}
+				catch (WebDriverException e) {
 					throwIfConnectionException(e);
 					return false;
 				}
@@ -326,8 +280,10 @@
 		try {
 			// close browser and close every associated window.
 			browser.quit();
-		} catch (WebDriverException e) {
-			if (e.getCause() instanceof InterruptedException || e.getCause().getCause() instanceof InterruptedException) {
+		}
+		catch (WebDriverException e) {
+			if (e.getCause() instanceof InterruptedException || e.getCause()
+					.getCause() instanceof InterruptedException) {
 				LOGGER.info(""Interrupted while waiting for the browser to close. It might not close correctly"");
 				Thread.currentThread().interrupt();
 				return;
@@ -338,76 +294,35 @@
 	}
 
 	@Override
-	public String getStrippedDom() {
-
-		try {
-			String dom = toUniformDOM(DomUtils.getDocumentToString(getDomTreeWithFrames()));
-			LOGGER.trace(dom);
-			return dom;
-		} catch (WebDriverException | CrawljaxException e) {
-			LOGGER.warn(""Could not get the dom"", e);
-			return """";
-		}
-	}
-
-	@Override
-	public String getUnStrippedDom() {
+	public String getDom() {
 		return browser.getPageSource();
 	}
 
-	/**
-	 * @param html
-	 *            The html string.
-	 * @return uniform version of dom with predefined attributes stripped
-	 */
-	private String toUniformDOM(String html) {
-
-		Pattern p =
-		        Pattern.compile(""<SCRIPT(.*?)</SCRIPT>"", Pattern.DOTALL
-		                | Pattern.CASE_INSENSITIVE);
-		Matcher m = p.matcher(html);
-		String htmlFormatted = m.replaceAll("""");
-
-		p = Pattern.compile(""<\\?xml:(.*?)>"");
-		m = p.matcher(htmlFormatted);
-		htmlFormatted = m.replaceAll("""");
-
-		htmlFormatted = filterAttributes(htmlFormatted);
-		return htmlFormatted;
-	}
-
-	/**
-	 * Filters attributes from the HTML string.
-	 * 
-	 * @param html
-	 *            The HTML to filter.
-	 * @return The filtered HTML string.
-	 */
-	private String filterAttributes(String html) {
-		String filteredHtml = html;
-		for (String attribute : this.filterAttributes) {
-			String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
-			Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
-			Matcher m = p.matcher(html);
-			filteredHtml = m.replaceAll("""");
+	@Override
+	public String getDomWithIFrameContents() {
+		try {
+			String dom = DomUtils.getDocumentToString(getDomTreeWithFrames());
+			LOGGER.trace(dom);
+			return dom;
+		} catch (WebDriverException | CrawljaxException e) {
+			LOGGER.warn(""Could not get the dom. Return original page source"", e);
+			return getDom();
 		}
-		return filteredHtml;
 	}
 
 	@Override
 	public void goBack() {
 		try {
 			browser.navigate().back();
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
 	}
 
 	/**
-	 * @param identification
-	 *            The identification object.
-	 * @param text
-	 *            The input.
+	 * @param identification The identification object.
+	 * @param text           The input.
 	 * @return true if succeeds.
 	 */
 	@Override
@@ -421,7 +336,8 @@
 				return true;
 			}
 			return false;
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return false;
 		}
@@ -429,17 +345,15 @@
 
 	/**
 	 * Fires an event on an element using its identification.
-	 * 
-	 * @param eventable
-	 *            The eventable.
+	 *
+	 * @param eventable The eventable.
 	 * @return true if it is able to fire the event successfully on the element.
-	 * @throws InterruptedException
-	 *             when interrupted during the wait.
+	 * @throws InterruptedException when interrupted during the wait.
 	 */
 	@Override
 	public synchronized boolean fireEventAndWait(Eventable eventable)
-	        throws ElementNotVisibleException,
-	        NoSuchElementException, InterruptedException {
+			throws ElementNotVisibleException,
+			NoSuchElementException, InterruptedException {
 		try {
 
 			boolean handleChanged = false;
@@ -450,7 +364,8 @@
 				try {
 
 					switchToFrame(eventable.getRelatedFrame());
-				} catch (NoSuchFrameException e) {
+				}
+				catch (NoSuchFrameException e) {
 					LOGGER.debug(""Frame not found, possibily while back-tracking.."", e);
 					// TODO Stefan, This exception is catched to prevent stopping
 					// from working
@@ -462,7 +377,7 @@
 			}
 
 			WebElement webElement =
-			        browser.findElement(eventable.getIdentification().getWebDriverBy());
+					browser.findElement(eventable.getIdentification().getWebDriverBy());
 
 			if (webElement != null) {
 				result = fireEventWait(webElement, eventable);
@@ -472,9 +387,11 @@
 				browser.switchTo().defaultContent();
 			}
 			return result;
-		} catch (ElementNotVisibleException | NoSuchElementException e) {
+		}
+		catch (ElementNotVisibleException | NoSuchElementException e) {
 			throw e;
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return false;
 		}
@@ -482,19 +399,18 @@
 
 	/**
 	 * Execute JavaScript in the browser.
-	 * 
-	 * @param code
-	 *            The code to execute.
+	 *
+	 * @param code The code to execute.
 	 * @return The return value of the JavaScript.
-	 * @throws CrawljaxException
-	 *             when javascript execution failed.
+	 * @throws CrawljaxException when javascript execution failed.
 	 */
 	@Override
 	public Object executeJavaScript(String code) throws CrawljaxException {
 		try {
 			JavascriptExecutor js = (JavascriptExecutor) browser;
 			return js.executeScript(code);
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			throw new CrawljaxException(e);
 		}
@@ -502,9 +418,8 @@
 
 	/**
 	 * Determines whether the corresponding element is visible.
-	 * 
-	 * @param identification
-	 *            The element to search for.
+	 *
+	 * @param identification The element to search for.
 	 * @return true if the element is visible
 	 */
 	@Override
@@ -516,7 +431,8 @@
 			}
 
 			return false;
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return false;
 		}
@@ -529,7 +445,8 @@
 	public String getCurrentUrl() {
 		try {
 			return browser.getCurrentUrl();
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
 	}
@@ -546,17 +463,18 @@
 					browser.switchTo().window(current);
 				}
 			}
-		} catch (UnhandledAlertException e) {
+		}
+		catch (UnhandledAlertException e) {
 			LOGGER.warn(""While closing the window, an alert got ignored: {}"", e.getMessage());
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
 	}
 
 	/**
 	 * @return a Document object containing the contents of iframes as well.
-	 * @throws CrawljaxException
-	 *             if an exception is thrown.
+	 * @throws CrawljaxException if an exception is thrown.
 	 */
 	private Document getDomTreeWithFrames() throws CrawljaxException {
 
@@ -564,7 +482,8 @@
 			Document document = DomUtils.asDocument(browser.getPageSource());
 			appendFrameContent(document.getDocumentElement(), document, """");
 			return document;
-		} catch (IOException e) {
+		}
+		catch (IOException e) {
 			throw new CrawljaxException(e.getMessage(), e);
 		}
 
@@ -591,7 +510,8 @@
 		for (int i = 0; i < nodeList.size(); i++) {
 			try {
 				locateFrameAndgetSource(document, topFrame, nodeList.get(i));
-			} catch (UnknownServerException | NoSuchFrameException e) {
+			}
+			catch (UnknownServerException | NoSuchFrameException e) {
 				LOGGER.warn(""Could not add frame contents for element {}"", nodeList.get(i));
 				LOGGER.debug(""Could not load frame because of {}"", e.getMessage(), e);
 			}
@@ -599,7 +519,7 @@
 	}
 
 	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement)
-	        throws NoSuchFrameException {
+			throws NoSuchFrameException {
 		String frameIdentification = """";
 
 		if (topFrame != null && !topFrame.equals("""")) {
@@ -609,7 +529,7 @@
 		String nameId = DomUtils.getFrameIdentification(frameElement);
 
 		if (nameId != null
-		        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
+				&& !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
 			frameIdentification += nameId;
 
 			String handle = browser.getWindowHandle();
@@ -627,13 +547,14 @@
 			try {
 				Element toAppendElement = DomUtils.asDocument(toAppend).getDocumentElement();
 				Element importedElement =
-				        (Element) document.importNode(toAppendElement, true);
+						(Element) document.importNode(toAppendElement, true);
 				frameElement.appendChild(importedElement);
 
 				appendFrameContent(importedElement, document, frameIdentification);
-			} catch (DOMException | IOException e) {
+			}
+			catch (DOMException | IOException e) {
 				LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-				        + "" continuing..."", e);
+						+ "" continuing..."", e);
 			}
 		}
 	}
@@ -649,33 +570,17 @@
 				browser.switchTo().frame(frameId);
 			}
 
-		} else {
+		}
+		else {
 			browser.switchTo().frame(frameIdentification);
 		}
 
 	}
 
 	/**
-	 * @return the dom without the iframe contents.
-	 * @see com.crawljax.browser.EmbeddedBrowser#getStrippedDomWithoutIframeContent()
-	 */
-	@Override
-	public String getStrippedDomWithoutIframeContent() {
-		try {
-			String dom = browser.getPageSource();
-			String result = toUniformDOM(dom);
-			return result;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return """";
-		}
-	}
-
-	/**
-	 * @param input
-	 *            the input to be filled.
+	 * @param input the input to be filled.
 	 * @return FormInput with random value assigned if possible. If no values were set it returns
-	 *         <code>null</code>
+	 * <code>null</code>
 	 */
 	@Override
 	public FormInput getInputWithRandomValue(FormInput input) {
@@ -686,7 +591,8 @@
 			if (!webElement.isDisplayed()) {
 				return null;
 			}
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return null;
 		}
@@ -694,7 +600,8 @@
 		Set<InputValue> values = new HashSet<>();
 		try {
 			setRandomValues(input, webElement, values);
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return null;
 		}
@@ -710,19 +617,22 @@
 		String inputString = input.getType().toLowerCase();
 		if (inputString.startsWith(""text"")) {
 			values.add(new InputValue(new RandomInputValueGenerator()
-			        .getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
-		} else if (inputString.equals(""checkbox"") || inputString.equals(""radio"")
-		        && !webElement.isSelected()) {
+					.getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
+		}
+		else if (inputString.equals(""checkbox"") || inputString.equals(""radio"")
+				&& !webElement.isSelected()) {
 			if (new RandomInputValueGenerator().getCheck()) {
 				values.add(new InputValue(""1"", true));
-			} else {
+			}
+			else {
 				values.add(new InputValue(""0"", false));
 			}
-		} else if (inputString.equals(""select"")) {
+		}
+		else if (inputString.equals(""select"")) {
 			Select select = new Select(webElement);
 			if (!select.getOptions().isEmpty()) {
 				WebElement option =
-				        new RandomInputValueGenerator().getRandomItem(select.getOptions());
+						new RandomInputValueGenerator().getRandomItem(select.getOptions());
 				values.add(new InputValue(option.getText(), true));
 			}
 
@@ -741,15 +651,15 @@
 			browser.switchTo().defaultContent();
 
 			return frameDom;
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return """";
 		}
 	}
 
 	/**
-	 * @param identification
-	 *            the identification of the element.
+	 * @param identification the identification of the element.
 	 * @return true if the element can be found in the DOM tree.
 	 */
 	@Override
@@ -760,73 +670,58 @@
 			// NoSuchElementExcpetion will be
 			// thrown, catched below.
 			return el != null;
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return false;
 		}
 	}
 
 	/**
-	 * @param identification
-	 *            the identification of the element.
+	 * @param identification the identification of the element.
 	 * @return the found element.
 	 */
 	@Override
 	public WebElement getWebElement(Identification identification) {
 		try {
 			return browser.findElement(identification.getWebDriverBy());
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
 	}
 
-	/**
-	 * @return the period to wait after an event.
-	 */
-	protected long getCrawlWaitEvent() {
-		return crawlWaitEvent;
-	}
-
-	/**
-	 * @return the list of attributes to be filtered from DOM.
-	 */
-	protected ImmutableSortedSet<String> getFilterAttributes() {
-		return filterAttributes;
-	}
-
-	/**
-	 * @return the period to waint after a reload.
-	 */
-	protected long getCrawlWaitReload() {
-		return crawlWaitReload;
-	}
-
 	@Override
 	public void saveScreenShot(File file) throws CrawljaxException {
 		try {
 			File tmpfile = takeScreenShotOnBrowser(browser, OutputType.FILE);
 			try {
 				Files.copy(tmpfile, file);
-			} catch (IOException e) {
+			}
+			catch (IOException e) {
 				throw new CrawljaxException(e);
 			}
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
 	}
 
 	private <T> T takeScreenShotOnBrowser(WebDriver driver, OutputType<T> outType)
-	        throws CrawljaxException {
+			throws CrawljaxException {
 		if (driver instanceof TakesScreenshot) {
 			T screenshot = ((TakesScreenshot) driver).getScreenshotAs(outType);
 			removeCanvasGeneratedByFirefoxDriverForScreenshots();
 			return screenshot;
-		} else if (driver instanceof RemoteWebDriver) {
+		}
+		else if (driver instanceof RemoteWebDriver) {
 			WebDriver augmentedWebdriver = new Augmenter().augment(driver);
 			return takeScreenShotOnBrowser(augmentedWebdriver, outType);
-		} else if (driver instanceof WrapsDriver) {
+		}
+		else if (driver instanceof WrapsDriver) {
 			return takeScreenShotOnBrowser(((WrapsDriver) driver).getWrappedDriver(), outType);
-		} else {
+		}
+		else {
 			throw new CrawljaxException(""Your current WebDriver doesn't support screenshots."");
 		}
 	}
@@ -835,7 +730,8 @@
 	public byte[] getScreenShot() throws CrawljaxException {
 		try {
 			return takeScreenShotOnBrowser(browser, OutputType.BYTES);
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
 	}
@@ -848,9 +744,10 @@
 		js += ""}"";
 		try {
 			executeJavaScript(js);
-		} catch (CrawljaxException e) {
+		}
+		catch (CrawljaxException e) {
 			LOGGER.error(""Removing of Canvas Generated By FirefoxDriver failed,""
-			        + "" most likely leaving it in the browser"", e);
+					+ "" most likely leaving it in the browser"", e);
 		}
 	}
 
@@ -863,11 +760,11 @@
 
 	private boolean exceptionIsConnectionException(WebDriverException exception) {
 		return exception != null && exception.getCause() != null
-		        && exception.getCause() instanceof IOException;
+				&& exception.getCause() instanceof IOException;
 	}
 
 	private RuntimeException wrapWebDriverExceptionIfConnectionException(
-	        WebDriverException exception) {
+			WebDriverException exception) {
 		if (exceptionIsConnectionException(exception)) {
 			return new BrowserConnectionException(exception);
 		}
@@ -879,4 +776,7 @@
 			throw wrapWebDriverExceptionIfConnectionException(exception);
 		}
 	}
+
+
+
 }
"
69c96c2b064a9ba5d23ad13d5bfc5d4eb4bf5e29,Alex Nederlof,WebDriverBrowserBuilder.java,MODIFY,"newFireFoxBrowser -> [ImmutableSortedSet filterAttributes, long crawlWaitReload, long crawlWaitEvent] | [long crawlWaitReload, long crawlWaitEvent]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java b/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java
index 18aa122..d9ed220 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java
@@ -8,7 +8,6 @@
 import com.crawljax.core.configuration.ProxyConfiguration.ProxyType;
 import com.crawljax.core.plugin.Plugins;
 import com.google.common.base.Strings;
-import com.google.common.collect.ImmutableSortedSet;
 import org.openqa.selenium.chrome.ChromeDriver;
 import org.openqa.selenium.chrome.ChromeOptions;
 import org.openqa.selenium.firefox.FirefoxDriver;
@@ -44,8 +43,6 @@
 	public EmbeddedBrowser get() {
 		LOGGER.debug(""Setting up a Browser"");
 		// Retrieve the config values used
-		ImmutableSortedSet<String> filterAttributes =
-		        configuration.getCrawlRules().getPreCrawlConfig().getFilterAttributeNames();
 		long crawlWaitReload = configuration.getCrawlRules().getWaitAfterReloadUrl();
 		long crawlWaitEvent = configuration.getCrawlRules().getWaitAfterEvent();
 
@@ -53,25 +50,24 @@
 		EmbeddedBrowser browser = null;
 		switch (configuration.getBrowserConfig().getBrowsertype()) {
 			case FIREFOX:
-				browser = newFireFoxBrowser(filterAttributes, crawlWaitReload, crawlWaitEvent);
+				browser = newFireFoxBrowser(crawlWaitReload, crawlWaitEvent);
 				break;
 			case INTERNET_EXPLORER:
 				browser =
 				        WebDriverBackedEmbeddedBrowser.withDriver(new InternetExplorerDriver(),
-				                filterAttributes, crawlWaitEvent, crawlWaitReload);
+				                crawlWaitEvent, crawlWaitReload);
 				break;
 			case CHROME:
-				browser = newChromeBrowser(filterAttributes, crawlWaitReload, crawlWaitEvent);
+				browser = newChromeBrowser(crawlWaitReload, crawlWaitEvent);
 				break;
 
 			case REMOTE:
 				browser =
 				        WebDriverBackedEmbeddedBrowser.withRemoteDriver(configuration
-				                .getBrowserConfig().getRemoteHubUrl(), filterAttributes,
-				                crawlWaitEvent, crawlWaitReload);
+				                .getBrowserConfig().getRemoteHubUrl(), crawlWaitEvent, crawlWaitReload);
 				break;
 			case PHANTOMJS:
-				browser = newPhantomJSDriver(filterAttributes, crawlWaitReload, crawlWaitEvent);
+				browser = newPhantomJSDriver(crawlWaitReload, crawlWaitEvent);
 
 				break;
 			default:
@@ -82,8 +78,7 @@
 		return browser;
 	}
 
-	private EmbeddedBrowser newFireFoxBrowser(ImmutableSortedSet<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent) {
+	private EmbeddedBrowser newFireFoxBrowser(long crawlWaitReload, long crawlWaitEvent) {
 		if (configuration.getProxyConfiguration() != null) {
 			FirefoxProfile profile = new FirefoxProfile();
 			String lang = configuration.getBrowserConfig().getLangOrNull();
@@ -100,16 +95,13 @@
 			/* use proxy for everything, including localhost */
 			profile.setPreference(""network.proxy.no_proxies_on"", """");
 
-			return WebDriverBackedEmbeddedBrowser.withDriver(new FirefoxDriver(profile),
-			        filterAttributes, crawlWaitReload, crawlWaitEvent);
+			return WebDriverBackedEmbeddedBrowser.withDriver(new FirefoxDriver(profile), crawlWaitReload, crawlWaitEvent);
 		}
 
-		return WebDriverBackedEmbeddedBrowser.withDriver(new FirefoxDriver(), filterAttributes,
-		        crawlWaitEvent, crawlWaitReload);
+		return WebDriverBackedEmbeddedBrowser.withDriver(new FirefoxDriver(), crawlWaitEvent, crawlWaitReload);
 	}
 
-	private EmbeddedBrowser newChromeBrowser(ImmutableSortedSet<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent) {
+	private EmbeddedBrowser newChromeBrowser(long crawlWaitReload, long crawlWaitEvent) {
 		ChromeDriver driverChrome;
 		if (configuration.getProxyConfiguration() != null
 		        && configuration.getProxyConfiguration().getType() != ProxyType.NOTHING) {
@@ -126,12 +118,10 @@
 			driverChrome = new ChromeDriver();
 		}
 
-		return WebDriverBackedEmbeddedBrowser.withDriver(driverChrome, filterAttributes,
-		        crawlWaitEvent, crawlWaitReload);
+		return WebDriverBackedEmbeddedBrowser.withDriver(driverChrome, crawlWaitEvent, crawlWaitReload);
 	}
 
-	private EmbeddedBrowser newPhantomJSDriver(ImmutableSortedSet<String> filterAttributes,
-	        long crawlWaitReload, long crawlWaitEvent) {
+	private EmbeddedBrowser newPhantomJSDriver(long crawlWaitReload, long crawlWaitEvent) {
 
 		DesiredCapabilities caps = new DesiredCapabilities();
 		caps.setCapability(""takesScreenshot"", true);
@@ -148,8 +138,7 @@
 		
 		PhantomJSDriver phantomJsDriver = new PhantomJSDriver(caps);
 
-		return WebDriverBackedEmbeddedBrowser.withDriver(phantomJsDriver, filterAttributes,
-		        crawlWaitEvent, crawlWaitReload);
+		return WebDriverBackedEmbeddedBrowser.withDriver(phantomJsDriver, crawlWaitEvent, crawlWaitReload);
 	}
 
 }
"
69c96c2b064a9ba5d23ad13d5bfc5d4eb4bf5e29,Alex Nederlof,CandidateElementExtractor.java,MODIFY,"addFramesCandidates -> [Document dom, List results, String relatedFrame, NodeList frameNodes] | [List results, String relatedFrame, NodeList frameNodes]","diff --git a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
index f0e36d4..3c22850 100644
--- a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
+++ b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
@@ -1,5 +1,8 @@
 package com.crawljax.core;
 
+import javax.inject.Inject;
+import javax.xml.xpath.XPathExpressionException;
+
 import java.io.IOException;
 import java.net.URI;
 import java.util.ArrayList;
@@ -9,16 +12,6 @@
 import java.util.regex.Matcher;
 import java.util.regex.Pattern;
 
-import javax.inject.Inject;
-import javax.xml.xpath.XPathExpressionException;
-
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-import org.w3c.dom.Document;
-import org.w3c.dom.Element;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.condition.eventablecondition.EventableConditionChecker;
@@ -37,6 +30,12 @@
 import com.google.common.collect.ImmutableMultimap;
 import com.google.common.collect.ImmutableSortedSet;
 import com.google.inject.assistedinject.Assisted;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.w3c.dom.Document;
+import org.w3c.dom.Element;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
 
 /**
  * This class extracts candidate elements from the DOM tree, based on the tags provided by the user.
@@ -127,7 +126,7 @@
 		LOG.debug(""Looking in state: {} for candidate elements"", currentState.getName());
 
 		try {
-			Document dom = DomUtils.asDocument(browser.getStrippedDomWithoutIframeContent());
+			Document dom = DomUtils.asDocument(browser.getDom());
 			extractElements(dom, results, """");
 		} catch (IOException e) {
 			LOG.error(e.getMessage(), e);
@@ -147,17 +146,18 @@
 		for (CrawlElement tag : includedCrawlElements) {
 			LOG.debug(""Extracting TAG: {}"", tag);
 
-			NodeList frameNodes = dom.getElementsByTagName(""FRAME"");
-			addFramesCandidates(dom, results, relatedFrame, frameNodes);
+			if (crawlFrames) {
+				NodeList frameNodes = dom.getElementsByTagName(""FRAME"");
+				addFramesCandidates(results, relatedFrame, frameNodes);
 
-			NodeList iFrameNodes = dom.getElementsByTagName(""IFRAME"");
-			addFramesCandidates(dom, results, relatedFrame, iFrameNodes);
-
+				NodeList iFrameNodes = dom.getElementsByTagName(""IFRAME"");
+				addFramesCandidates(results, relatedFrame, iFrameNodes);
+			}
 			evaluateElements(dom, tag, results, relatedFrame);
 		}
 	}
 
-	private void addFramesCandidates(Document dom, List<CandidateElement> results,
+	private void addFramesCandidates(List<CandidateElement> results,
 	        String relatedFrame, NodeList frameNodes) {
 
 		if (frameNodes == null) {
@@ -196,22 +196,18 @@
 	}
 
 	private boolean isFrameIgnored(String string) {
-		if (crawlFrames) {
-			for (String ignorePattern : ignoredFrameIdentifiers) {
-				if (ignorePattern.contains(""%"")) {
-					// replace with a useful wildcard for regex
-					String pattern = ignorePattern.replace(""%"", "".*"");
-					if (string.matches(pattern)) {
-						return true;
-					}
-				} else if (ignorePattern.equals(string)) {
+		for (String ignorePattern : ignoredFrameIdentifiers) {
+			if (ignorePattern.contains(""%"")) {
+				// replace with a useful wildcard for regex
+				String pattern = ignorePattern.replace(""%"", "".*"");
+				if (string.matches(pattern)) {
 					return true;
 				}
+			} else if (ignorePattern.equals(string)) {
+				return true;
 			}
-			return false;
-		} else {
-			return true;
 		}
+		return false;
 	}
 
 	private void evaluateElements(Document dom, CrawlElement crawl,
"
69c96c2b064a9ba5d23ad13d5bfc5d4eb4bf5e29,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URI url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index c08a6df..1ef6231 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -345,6 +345,10 @@
 		return strippers;
 	}
 
+	public ImmutableList<ValidDomStripper> getValidStrippers() {
+		return validStrippers;
+	}
+
 	public StateVertexFactory getStateVertexFactory() {
 		return stateVertexFactory;
 	}
"
69c96c2b064a9ba5d23ad13d5bfc5d4eb4bf5e29,Alex Nederlof,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index c1ebb1d..c0390da 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -1,19 +1,18 @@
 package com.crawljax.util;
 
-import java.io.IOException;
-
 import javax.xml.xpath.XPathExpressionException;
 
+import java.io.IOException;
+
+import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.core.state.Element;
+import com.crawljax.core.state.Eventable;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.w3c.dom.Document;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
 
-import com.crawljax.browser.EmbeddedBrowser;
-import com.crawljax.core.state.Element;
-import com.crawljax.core.state.Eventable;
-
 /**
  * Finds and checks elements.
  */
@@ -52,7 +51,7 @@
 	public String resolve(boolean logging) {
 		Document dom = null;
 		try {
-			dom = DomUtils.asDocument(browser.getStrippedDom());
+			dom = DomUtils.asDocument(browser.getDom());
 		} catch (IOException e) {
 			LOGGER.error(e.getMessage(), e);
 			return """";
"
855bd9bae493962c658964aadaa061f014869ae5,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 7028901..c42807a 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -9,8 +9,6 @@
 import java.util.HashSet;
 import java.util.List;
 import java.util.Set;
-import java.util.regex.Matcher;
-import java.util.regex.Pattern;
 
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.AcceptAllFramesChecker;
@@ -23,8 +21,6 @@
 import com.crawljax.forms.InputValue;
 import com.crawljax.forms.RandomInputValueGenerator;
 import com.crawljax.util.DomUtils;
-import com.google.common.base.Preconditions;
-import com.google.common.collect.ImmutableSortedSet;
 import com.google.common.io.Files;
 import org.openqa.selenium.ElementNotVisibleException;
 import org.openqa.selenium.JavascriptExecutor;
@@ -53,95 +49,69 @@
 
 public final class WebDriverBackedEmbeddedBrowser implements EmbeddedBrowser {
 	private static final Logger LOGGER = LoggerFactory
-	        .getLogger(WebDriverBackedEmbeddedBrowser.class);
+			.getLogger(WebDriverBackedEmbeddedBrowser.class);
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param hubUrl
-	 *            Url of the server.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
+	 *
+	 * @param hubUrl           Url of the server.
+	 * @param crawlWaitReload  the period to wait after a reload.
+	 * @param crawlWaitEvent   the period to wait after an event is fired.
 	 * @return The EmbeddedBrowser.
 	 */
-	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
+	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl, long crawlWaitEvent,
+			long crawlWaitReload) {
 		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
-		        filterAttributes, crawlWaitEvent, crawlWaitReload);
+				crawlWaitEvent, crawlWaitReload);
 	}
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param hubUrl
-	 *            Url of the server.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
+	 *
+	 * @param hubUrl             Url of the server.
+	 * @param crawlWaitReload    the period to wait after a reload.
+	 * @param crawlWaitEvent     the period to wait after an event is fired.
+	 * @param ignoreFrameChecker the checker used to determine if a certain frame must be ignored.
 	 * @return The EmbeddedBrowser.
 	 */
-	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent,
-	        long crawlWaitReload, IgnoreFrameChecker ignoreFrameChecker) {
+	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl, long crawlWaitEvent,
+			long crawlWaitReload, IgnoreFrameChecker ignoreFrameChecker) {
 		return WebDriverBackedEmbeddedBrowser.withDriver(buildRemoteWebDriver(hubUrl),
-		        filterAttributes, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
+				crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
 	}
 
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
+	 *
+	 * @param driver          The WebDriver to use.
+	 * @param crawlWaitReload the period to wait after a reload.
+	 * @param crawlWaitEvent  the period to wait after an event is fired.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent, long crawlWaitReload) {
-		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
-		        crawlWaitReload);
+			long crawlWaitEvent, long crawlWaitReload) {
+		return new WebDriverBackedEmbeddedBrowser(driver, crawlWaitEvent,
+				crawlWaitReload);
 	}
 
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
+	 *
+	 * @param driver             The WebDriver to use.
+	 * @param crawlWaitReload    the period to wait after a reload.
+	 * @param crawlWaitEvent     the period to wait after an event is fired.
+	 * @param ignoreFrameChecker the checker used to determine if a certain frame must be ignored.
 	 * @return The EmbeddedBrowser.
 	 */
-	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitEvent,
-	        long crawlWaitReload, IgnoreFrameChecker ignoreFrameChecker) {
-		return new WebDriverBackedEmbeddedBrowser(driver, filterAttributes, crawlWaitEvent,
-		        crawlWaitReload, ignoreFrameChecker);
+	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver, long crawlWaitEvent,
+			long crawlWaitReload, IgnoreFrameChecker ignoreFrameChecker) {
+		return new WebDriverBackedEmbeddedBrowser(driver, crawlWaitEvent, crawlWaitReload, ignoreFrameChecker);
 	}
 
 	/**
 	 * Create a RemoteWebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param hubUrl
-	 *            Url of the server.
+	 *
+	 * @param hubUrl Url of the server.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withRemoteDriver(String hubUrl) {
@@ -151,9 +121,8 @@
 	/**
 	 * Private used static method for creation of a RemoteWebDriver. Taking care of the default
 	 * Capabilities and using the HttpCommandExecutor.
-	 * 
-	 * @param hubUrl
-	 *            the url of the hub to use.
+	 *
+	 * @param hubUrl the url of the hub to use.
 	 * @return the RemoteWebDriver instance.
 	 */
 	private static RemoteWebDriver buildRemoteWebDriver(String hubUrl) {
@@ -162,26 +131,27 @@
 		URL url;
 		try {
 			url = new URL(hubUrl);
-		} catch (MalformedURLException e) {
+		}
+		catch (MalformedURLException e) {
 			LOGGER.error(""The given hub url of the remote server is malformed can not continue!"",
-			        e);
+					e);
 			return null;
 		}
 		HttpCommandExecutor executor = null;
 		try {
 			executor = new HttpCommandExecutor(url);
-		} catch (Exception e) {
+		}
+		catch (Exception e) {
 			// TODO Stefan; refactor this catch, this will definitely result in
 			// NullPointers, why
 			// not throw RuntimeExcption direct?
 			LOGGER.error(""Received unknown exception while creating the ""
-			        + ""HttpCommandExecutor, can not continue!"", e);
+					+ ""HttpCommandExecutor, can not continue!"", e);
 			return null;
 		}
 		return new RemoteWebDriver(executor, capabilities);
 	}
 
-	private final ImmutableSortedSet<String> filterAttributes;
 	private final WebDriver browser;
 
 	private long crawlWaitEvent;
@@ -190,61 +160,44 @@
 
 	/**
 	 * Constructor without configuration values.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
+	 *
+	 * @param driver The WebDriver to use.
 	 */
 	private WebDriverBackedEmbeddedBrowser(WebDriver driver) {
 		this.browser = driver;
-		filterAttributes = ImmutableSortedSet.of();
 	}
 
 	/**
 	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
+	 *
+	 * @param driver          The WebDriver to use.
+	 * @param crawlWaitReload the period to wait after a reload.
+	 * @param crawlWaitEvent  the period to wait after an event is fired.
 	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload, long crawlWaitEvent) {
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver, long crawlWaitReload, long crawlWaitEvent) {
 		this.browser = driver;
-		this.filterAttributes = Preconditions.checkNotNull(filterAttributes);
 		this.crawlWaitEvent = crawlWaitEvent;
 		this.crawlWaitReload = crawlWaitReload;
 	}
 
 	/**
 	 * Constructor.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
-	 * @param filterAttributes
-	 *            the attributes to be filtered from DOM.
-	 * @param crawlWaitReload
-	 *            the period to wait after a reload.
-	 * @param crawlWaitEvent
-	 *            the period to wait after an event is fired.
-	 * @param ignoreFrameChecker
-	 *            the checker used to determine if a certain frame must be ignored.
+	 *
+	 * @param driver             The WebDriver to use.
+	 * @param crawlWaitReload    the period to wait after a reload.
+	 * @param crawlWaitEvent     the period to wait after an event is fired.
+	 * @param ignoreFrameChecker the checker used to determine if a certain frame must be ignored.
 	 */
-	private WebDriverBackedEmbeddedBrowser(WebDriver driver,
-	        ImmutableSortedSet<String> filterAttributes, long crawlWaitReload,
-	        long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
-		this(driver, filterAttributes, crawlWaitReload, crawlWaitEvent);
+	private WebDriverBackedEmbeddedBrowser(WebDriver driver, long crawlWaitReload,
+			long crawlWaitEvent, IgnoreFrameChecker ignoreFrameChecker) {
+		this(driver, crawlWaitReload, crawlWaitEvent);
 		this.ignoreFrameChecker = ignoreFrameChecker;
 	}
 
 	/**
 	 * Create a WebDriver backed EmbeddedBrowser.
-	 * 
-	 * @param driver
-	 *            The WebDriver to use.
+	 *
+	 * @param driver The WebDriver to use.
 	 * @return The EmbeddedBrowser.
 	 */
 	public static WebDriverBackedEmbeddedBrowser withDriver(WebDriver driver) {
@@ -252,8 +205,7 @@
 	}
 
 	/**
-	 * @param url
-	 *            The URL.
+	 * @param url The URL.
 	 */
 	@Override
 	public void goToUrl(URI url) {
@@ -261,10 +213,12 @@
 			browser.navigate().to(url.toString());
 			Thread.sleep(this.crawlWaitReload);
 			handlePopups();
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return;
-		} catch (InterruptedException e) {
+		}
+		catch (InterruptedException e) {
 			LOGGER.debug(""goToUrl got interrupted while waiting for the page to be loaded"", e);
 			Thread.currentThread().interrupt();
 			return;
@@ -277,33 +231,33 @@
 	private void handlePopups() {
 		try {
 			executeJavaScript(""window.alert = function(msg){return true;};""
-			        + ""window.confirm = function(msg){return true;};""
-			        + ""window.prompt = function(msg){return true;};"");
-		} catch (CrawljaxException e) {
+					+ ""window.confirm = function(msg){return true;};""
+					+ ""window.prompt = function(msg){return true;};"");
+		}
+		catch (CrawljaxException e) {
 			LOGGER.error(""Handling of PopUp windows failed"", e);
 		}
 	}
 
 	/**
 	 * Fires the event and waits for a specified time.
-	 * 
-	 * @param webElement
-	 *            the element to fire event on.
-	 * @param eventable
-	 *            The HTML event type (onclick, onmouseover, ...).
+	 *
+	 * @param webElement the element to fire event on.
+	 * @param eventable  The HTML event type (onclick, onmouseover, ...).
 	 * @return true if firing event is successful.
-	 * @throws InterruptedException
-	 *             when interrupted during the wait.
+	 * @throws InterruptedException when interrupted during the wait.
 	 */
 	private boolean fireEventWait(WebElement webElement, Eventable eventable)
-	        throws ElementNotVisibleException, InterruptedException {
+			throws ElementNotVisibleException, InterruptedException {
 		switch (eventable.getEventType()) {
 			case click:
 				try {
 					webElement.click();
-				} catch (ElementNotVisibleException e) {
+				}
+				catch (ElementNotVisibleException e) {
 					throw e;
-				} catch (WebDriverException e) {
+				}
+				catch (WebDriverException e) {
 					throwIfConnectionException(e);
 					return false;
 				}
@@ -326,8 +280,10 @@
 		try {
 			// close browser and close every associated window.
 			browser.quit();
-		} catch (WebDriverException e) {
-			if (e.getCause() instanceof InterruptedException || e.getCause().getCause() instanceof InterruptedException) {
+		}
+		catch (WebDriverException e) {
+			if (e.getCause() instanceof InterruptedException || e.getCause()
+					.getCause() instanceof InterruptedException) {
 				LOGGER.info(""Interrupted while waiting for the browser to close. It might not close correctly"");
 				Thread.currentThread().interrupt();
 				return;
@@ -338,76 +294,35 @@
 	}
 
 	@Override
-	public String getStrippedDom() {
-
-		try {
-			String dom = toUniformDOM(DomUtils.getDocumentToString(getDomTreeWithFrames()));
-			LOGGER.trace(dom);
-			return dom;
-		} catch (WebDriverException | CrawljaxException e) {
-			LOGGER.warn(""Could not get the dom"", e);
-			return """";
-		}
-	}
-
-	@Override
-	public String getUnStrippedDom() {
+	public String getDom() {
 		return browser.getPageSource();
 	}
 
-	/**
-	 * @param html
-	 *            The html string.
-	 * @return uniform version of dom with predefined attributes stripped
-	 */
-	private String toUniformDOM(String html) {
-
-		Pattern p =
-		        Pattern.compile(""<SCRIPT(.*?)</SCRIPT>"", Pattern.DOTALL
-		                | Pattern.CASE_INSENSITIVE);
-		Matcher m = p.matcher(html);
-		String htmlFormatted = m.replaceAll("""");
-
-		p = Pattern.compile(""<\\?xml:(.*?)>"");
-		m = p.matcher(htmlFormatted);
-		htmlFormatted = m.replaceAll("""");
-
-		htmlFormatted = filterAttributes(htmlFormatted);
-		return htmlFormatted;
-	}
-
-	/**
-	 * Filters attributes from the HTML string.
-	 * 
-	 * @param html
-	 *            The HTML to filter.
-	 * @return The filtered HTML string.
-	 */
-	private String filterAttributes(String html) {
-		String filteredHtml = html;
-		for (String attribute : this.filterAttributes) {
-			String regex = ""\\s"" + attribute + ""=\""[^\""]*\"""";
-			Pattern p = Pattern.compile(regex, Pattern.CASE_INSENSITIVE);
-			Matcher m = p.matcher(html);
-			filteredHtml = m.replaceAll("""");
+	@Override
+	public String getDomWithIFrameContents() {
+		try {
+			String dom = DomUtils.getDocumentToString(getDomTreeWithFrames());
+			LOGGER.trace(dom);
+			return dom;
+		} catch (WebDriverException | CrawljaxException e) {
+			LOGGER.warn(""Could not get the dom. Return original page source"", e);
+			return getDom();
 		}
-		return filteredHtml;
 	}
 
 	@Override
 	public void goBack() {
 		try {
 			browser.navigate().back();
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
 	}
 
 	/**
-	 * @param identification
-	 *            The identification object.
-	 * @param text
-	 *            The input.
+	 * @param identification The identification object.
+	 * @param text           The input.
 	 * @return true if succeeds.
 	 */
 	@Override
@@ -421,7 +336,8 @@
 				return true;
 			}
 			return false;
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return false;
 		}
@@ -429,17 +345,15 @@
 
 	/**
 	 * Fires an event on an element using its identification.
-	 * 
-	 * @param eventable
-	 *            The eventable.
+	 *
+	 * @param eventable The eventable.
 	 * @return true if it is able to fire the event successfully on the element.
-	 * @throws InterruptedException
-	 *             when interrupted during the wait.
+	 * @throws InterruptedException when interrupted during the wait.
 	 */
 	@Override
 	public synchronized boolean fireEventAndWait(Eventable eventable)
-	        throws ElementNotVisibleException,
-	        NoSuchElementException, InterruptedException {
+			throws ElementNotVisibleException,
+			NoSuchElementException, InterruptedException {
 		try {
 
 			boolean handleChanged = false;
@@ -450,7 +364,8 @@
 				try {
 
 					switchToFrame(eventable.getRelatedFrame());
-				} catch (NoSuchFrameException e) {
+				}
+				catch (NoSuchFrameException e) {
 					LOGGER.debug(""Frame not found, possibily while back-tracking.."", e);
 					// TODO Stefan, This exception is catched to prevent stopping
 					// from working
@@ -462,7 +377,7 @@
 			}
 
 			WebElement webElement =
-			        browser.findElement(eventable.getIdentification().getWebDriverBy());
+					browser.findElement(eventable.getIdentification().getWebDriverBy());
 
 			if (webElement != null) {
 				result = fireEventWait(webElement, eventable);
@@ -472,9 +387,11 @@
 				browser.switchTo().defaultContent();
 			}
 			return result;
-		} catch (ElementNotVisibleException | NoSuchElementException e) {
+		}
+		catch (ElementNotVisibleException | NoSuchElementException e) {
 			throw e;
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return false;
 		}
@@ -482,19 +399,18 @@
 
 	/**
 	 * Execute JavaScript in the browser.
-	 * 
-	 * @param code
-	 *            The code to execute.
+	 *
+	 * @param code The code to execute.
 	 * @return The return value of the JavaScript.
-	 * @throws CrawljaxException
-	 *             when javascript execution failed.
+	 * @throws CrawljaxException when javascript execution failed.
 	 */
 	@Override
 	public Object executeJavaScript(String code) throws CrawljaxException {
 		try {
 			JavascriptExecutor js = (JavascriptExecutor) browser;
 			return js.executeScript(code);
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			throw new CrawljaxException(e);
 		}
@@ -502,9 +418,8 @@
 
 	/**
 	 * Determines whether the corresponding element is visible.
-	 * 
-	 * @param identification
-	 *            The element to search for.
+	 *
+	 * @param identification The element to search for.
 	 * @return true if the element is visible
 	 */
 	@Override
@@ -516,7 +431,8 @@
 			}
 
 			return false;
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return false;
 		}
@@ -529,7 +445,8 @@
 	public String getCurrentUrl() {
 		try {
 			return browser.getCurrentUrl();
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
 	}
@@ -546,17 +463,18 @@
 					browser.switchTo().window(current);
 				}
 			}
-		} catch (UnhandledAlertException e) {
+		}
+		catch (UnhandledAlertException e) {
 			LOGGER.warn(""While closing the window, an alert got ignored: {}"", e.getMessage());
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
 	}
 
 	/**
 	 * @return a Document object containing the contents of iframes as well.
-	 * @throws CrawljaxException
-	 *             if an exception is thrown.
+	 * @throws CrawljaxException if an exception is thrown.
 	 */
 	private Document getDomTreeWithFrames() throws CrawljaxException {
 
@@ -564,7 +482,8 @@
 			Document document = DomUtils.asDocument(browser.getPageSource());
 			appendFrameContent(document.getDocumentElement(), document, """");
 			return document;
-		} catch (IOException e) {
+		}
+		catch (IOException e) {
 			throw new CrawljaxException(e.getMessage(), e);
 		}
 
@@ -591,7 +510,8 @@
 		for (int i = 0; i < nodeList.size(); i++) {
 			try {
 				locateFrameAndgetSource(document, topFrame, nodeList.get(i));
-			} catch (UnknownServerException | NoSuchFrameException e) {
+			}
+			catch (UnknownServerException | NoSuchFrameException e) {
 				LOGGER.warn(""Could not add frame contents for element {}"", nodeList.get(i));
 				LOGGER.debug(""Could not load frame because of {}"", e.getMessage(), e);
 			}
@@ -599,7 +519,7 @@
 	}
 
 	private void locateFrameAndgetSource(Document document, String topFrame, Element frameElement)
-	        throws NoSuchFrameException {
+			throws NoSuchFrameException {
 		String frameIdentification = """";
 
 		if (topFrame != null && !topFrame.equals("""")) {
@@ -609,7 +529,7 @@
 		String nameId = DomUtils.getFrameIdentification(frameElement);
 
 		if (nameId != null
-		        && !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
+				&& !ignoreFrameChecker.isFrameIgnored(frameIdentification + nameId)) {
 			frameIdentification += nameId;
 
 			String handle = browser.getWindowHandle();
@@ -627,13 +547,14 @@
 			try {
 				Element toAppendElement = DomUtils.asDocument(toAppend).getDocumentElement();
 				Element importedElement =
-				        (Element) document.importNode(toAppendElement, true);
+						(Element) document.importNode(toAppendElement, true);
 				frameElement.appendChild(importedElement);
 
 				appendFrameContent(importedElement, document, frameIdentification);
-			} catch (DOMException | IOException e) {
+			}
+			catch (DOMException | IOException e) {
 				LOGGER.info(""Got exception while inspecting a frame:"" + frameIdentification
-				        + "" continuing..."", e);
+						+ "" continuing..."", e);
 			}
 		}
 	}
@@ -649,33 +570,17 @@
 				browser.switchTo().frame(frameId);
 			}
 
-		} else {
+		}
+		else {
 			browser.switchTo().frame(frameIdentification);
 		}
 
 	}
 
 	/**
-	 * @return the dom without the iframe contents.
-	 * @see com.crawljax.browser.EmbeddedBrowser#getStrippedDomWithoutIframeContent()
-	 */
-	@Override
-	public String getStrippedDomWithoutIframeContent() {
-		try {
-			String dom = browser.getPageSource();
-			String result = toUniformDOM(dom);
-			return result;
-		} catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return """";
-		}
-	}
-
-	/**
-	 * @param input
-	 *            the input to be filled.
+	 * @param input the input to be filled.
 	 * @return FormInput with random value assigned if possible. If no values were set it returns
-	 *         <code>null</code>
+	 * <code>null</code>
 	 */
 	@Override
 	public FormInput getInputWithRandomValue(FormInput input) {
@@ -686,7 +591,8 @@
 			if (!webElement.isDisplayed()) {
 				return null;
 			}
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return null;
 		}
@@ -694,7 +600,8 @@
 		Set<InputValue> values = new HashSet<>();
 		try {
 			setRandomValues(input, webElement, values);
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return null;
 		}
@@ -710,19 +617,22 @@
 		String inputString = input.getType().toLowerCase();
 		if (inputString.startsWith(""text"")) {
 			values.add(new InputValue(new RandomInputValueGenerator()
-			        .getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
-		} else if (inputString.equals(""checkbox"") || inputString.equals(""radio"")
-		        && !webElement.isSelected()) {
+					.getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
+		}
+		else if (inputString.equals(""checkbox"") || inputString.equals(""radio"")
+				&& !webElement.isSelected()) {
 			if (new RandomInputValueGenerator().getCheck()) {
 				values.add(new InputValue(""1"", true));
-			} else {
+			}
+			else {
 				values.add(new InputValue(""0"", false));
 			}
-		} else if (inputString.equals(""select"")) {
+		}
+		else if (inputString.equals(""select"")) {
 			Select select = new Select(webElement);
 			if (!select.getOptions().isEmpty()) {
 				WebElement option =
-				        new RandomInputValueGenerator().getRandomItem(select.getOptions());
+						new RandomInputValueGenerator().getRandomItem(select.getOptions());
 				values.add(new InputValue(option.getText(), true));
 			}
 
@@ -741,15 +651,15 @@
 			browser.switchTo().defaultContent();
 
 			return frameDom;
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return """";
 		}
 	}
 
 	/**
-	 * @param identification
-	 *            the identification of the element.
+	 * @param identification the identification of the element.
 	 * @return true if the element can be found in the DOM tree.
 	 */
 	@Override
@@ -760,73 +670,58 @@
 			// NoSuchElementExcpetion will be
 			// thrown, catched below.
 			return el != null;
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throwIfConnectionException(e);
 			return false;
 		}
 	}
 
 	/**
-	 * @param identification
-	 *            the identification of the element.
+	 * @param identification the identification of the element.
 	 * @return the found element.
 	 */
 	@Override
 	public WebElement getWebElement(Identification identification) {
 		try {
 			return browser.findElement(identification.getWebDriverBy());
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
 	}
 
-	/**
-	 * @return the period to wait after an event.
-	 */
-	protected long getCrawlWaitEvent() {
-		return crawlWaitEvent;
-	}
-
-	/**
-	 * @return the list of attributes to be filtered from DOM.
-	 */
-	protected ImmutableSortedSet<String> getFilterAttributes() {
-		return filterAttributes;
-	}
-
-	/**
-	 * @return the period to waint after a reload.
-	 */
-	protected long getCrawlWaitReload() {
-		return crawlWaitReload;
-	}
-
 	@Override
 	public void saveScreenShot(File file) throws CrawljaxException {
 		try {
 			File tmpfile = takeScreenShotOnBrowser(browser, OutputType.FILE);
 			try {
 				Files.copy(tmpfile, file);
-			} catch (IOException e) {
+			}
+			catch (IOException e) {
 				throw new CrawljaxException(e);
 			}
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
 	}
 
 	private <T> T takeScreenShotOnBrowser(WebDriver driver, OutputType<T> outType)
-	        throws CrawljaxException {
+			throws CrawljaxException {
 		if (driver instanceof TakesScreenshot) {
 			T screenshot = ((TakesScreenshot) driver).getScreenshotAs(outType);
 			removeCanvasGeneratedByFirefoxDriverForScreenshots();
 			return screenshot;
-		} else if (driver instanceof RemoteWebDriver) {
+		}
+		else if (driver instanceof RemoteWebDriver) {
 			WebDriver augmentedWebdriver = new Augmenter().augment(driver);
 			return takeScreenShotOnBrowser(augmentedWebdriver, outType);
-		} else if (driver instanceof WrapsDriver) {
+		}
+		else if (driver instanceof WrapsDriver) {
 			return takeScreenShotOnBrowser(((WrapsDriver) driver).getWrappedDriver(), outType);
-		} else {
+		}
+		else {
 			throw new CrawljaxException(""Your current WebDriver doesn't support screenshots."");
 		}
 	}
@@ -835,7 +730,8 @@
 	public byte[] getScreenShot() throws CrawljaxException {
 		try {
 			return takeScreenShotOnBrowser(browser, OutputType.BYTES);
-		} catch (WebDriverException e) {
+		}
+		catch (WebDriverException e) {
 			throw wrapWebDriverExceptionIfConnectionException(e);
 		}
 	}
@@ -848,9 +744,10 @@
 		js += ""}"";
 		try {
 			executeJavaScript(js);
-		} catch (CrawljaxException e) {
+		}
+		catch (CrawljaxException e) {
 			LOGGER.error(""Removing of Canvas Generated By FirefoxDriver failed,""
-			        + "" most likely leaving it in the browser"", e);
+					+ "" most likely leaving it in the browser"", e);
 		}
 	}
 
@@ -863,11 +760,11 @@
 
 	private boolean exceptionIsConnectionException(WebDriverException exception) {
 		return exception != null && exception.getCause() != null
-		        && exception.getCause() instanceof IOException;
+				&& exception.getCause() instanceof IOException;
 	}
 
 	private RuntimeException wrapWebDriverExceptionIfConnectionException(
-	        WebDriverException exception) {
+			WebDriverException exception) {
 		if (exceptionIsConnectionException(exception)) {
 			return new BrowserConnectionException(exception);
 		}
@@ -879,4 +776,7 @@
 			throw wrapWebDriverExceptionIfConnectionException(exception);
 		}
 	}
+
+
+
 }
"
855bd9bae493962c658964aadaa061f014869ae5,Alex Nederlof,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URI url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index f8ec514..1ef6231 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -14,6 +14,10 @@
 import com.crawljax.core.configuration.CrawlRules.CrawlRulesBuilder;
 import com.crawljax.core.plugin.Plugin;
 import com.crawljax.core.state.StateVertexFactory;
+import com.crawljax.domcomparators.DomTextContentStripper;
+import com.crawljax.domcomparators.AttributesStripper;
+import com.crawljax.domcomparators.DomStripper;
+import com.crawljax.domcomparators.ValidDomStripper;
 import com.google.common.base.Objects;
 import com.google.common.base.Preconditions;
 import com.google.common.collect.ImmutableList;
@@ -26,6 +30,8 @@
 	public static class CrawljaxConfigurationBuilder {
 
 		private final ImmutableList.Builder<Plugin> pluginBuilder = ImmutableList.builder();
+		private final ImmutableList.Builder<ValidDomStripper> validStrippers = ImmutableList.builder();
+		private final ImmutableList.Builder<DomStripper> strippers = ImmutableList.builder();
 		private final CrawljaxConfiguration config;
 		private final CrawlRulesBuilder crawlRules;
 
@@ -37,8 +43,8 @@
 		}
 
 		/**
-		 * If the website uses <a
-		 * href=""http://en.wikipedia.org/wiki/Basic_access_authentication"">Basic auth</a> you can
+		 * If the website uses <a href=""http://en.wikipedia.org/wiki/Basic_access_authentication"">Basic auth</a> you
+		 * can
 		 * set the username and password here.
 		 *
 		 * @param username The username for the website.
@@ -59,8 +65,7 @@
 		}
 
 		/**
-		 * @param states The maximum number of states the Crawler should crawl. The default is
-		 *               unlimited.
+		 * @param states The maximum number of states the Crawler should crawl. The default is unlimited.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumStates(int states) {
 			checkArgument(states > 1, ""Number of maximum states should be larger than 1"");
@@ -98,7 +103,7 @@
 		 */
 		public CrawljaxConfigurationBuilder setMaximumDepth(int depth) {
 			Preconditions.checkArgument(depth >= 0,
-			  ""Depth should be 0 for infinite, or larger for a certain depth."");
+					""Depth should be 0 for infinite, or larger for a certain depth."");
 			config.maximumDepth = depth;
 			return this;
 		}
@@ -112,11 +117,8 @@
 		}
 
 		/**
-		 * Add plugins to Crawljax. Note that without plugins, Crawljax won't give any ouput. For
-		 * basic output at least enable the CrawlOverviewPlugin.
-		 * <p>
-		 * You can call this method several times to add multiple plugins
-		 * </p>
+		 * Add plugins to Crawljax. Note that without plugins, Crawljax won't give any ouput. For basic output at least
+		 * enable the CrawlOverviewPlugin. <p> You can call this method several times to add multiple plugins </p>
 		 *
 		 * @param plugins the plugins you would like to enable.
 		 */
@@ -142,8 +144,8 @@
 		}
 
 		/**
-		 * @param configuration a custom {@link BrowserConfiguration}. The default is a single
-		 *                      {@link BrowserType#FIREFOX} browser.
+		 * @param configuration a custom {@link BrowserConfiguration}. The default is a single {@link
+		 *                      BrowserType#FIREFOX} browser.
 		 */
 		public CrawljaxConfigurationBuilder setBrowserConfig(BrowserConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -152,11 +154,11 @@
 		}
 
 		/**
-		 * Set a custom {@link com.crawljax.core.state.StateVertexFactory} to be able to use your own
-		 * {@link com.crawljax.core.state.StateVertex} objects. This is useful when you want to have a custom
-		 * comparator
-		 * in the stateflowgraph which relies on the {@link Object#hashCode()} or {@link Object#equals(Object)} of the
-		 * {@link com.crawljax.core.state.StateVertex}.
+		 * Set a custom {@link com.crawljax.core.state.StateVertexFactory} to be able to use your own {@link
+		 * com.crawljax.core.state.StateVertex} objects. This is useful when you want to have a custom comparator in
+		 * the
+		 * stateflowgraph which relies on the {@link Object#hashCode()} or {@link Object#equals(Object)} of the {@link
+		 * com.crawljax.core.state.StateVertex}.
 		 *
 		 * @param vertexFactory The factory you want to use.
 		 * @return The builder for method chaining.
@@ -168,8 +170,8 @@
 		}
 
 		/**
-		 * Set the output folder for any {@link Plugin} you might configure. Crawljax itself doesn't
-		 * need an output folder but many plug-ins do.
+		 * Set the output folder for any {@link Plugin} you might configure. Crawljax itself doesn't need an output
+		 * folder but many plug-ins do.
 		 *
 		 * @param output The output folder. If it does not exist it will be created.
 		 * @throws IllegalStateException if the specified file is not writable or exists but isn't a folder.
@@ -180,22 +182,86 @@
 			return this;
 		}
 
+		/**
+		 * Add a {@link com.crawljax.domcomparators.DomStripper}.
+		 *
+		 * <p>
+		 * If no {@link com.crawljax.domcomparators.DomStripper} or
+		 * {@link com.crawljax.domcomparators.ValidDomStripper} is added,
+		 * Crawljax uses the build-in {@link com.crawljax.domcomparators.DomStructureStripper}
+		 *  and {@link com.crawljax.domcomparators.AttributesStripper}</p>
+		 *
+		 * <p>
+		 * Out-of-the-box available strippers are:
+		 * <ul>
+		 * <li>{@link com.crawljax.domcomparators.DomTextContentStripper}</li>
+		 * <li>{@link com.crawljax.domcomparators.DomStructureStripper}</li>
+		 * <li>{@link com.crawljax.domcomparators.DomTextContentStripper}</li>
+		 * <li>{@link com.crawljax.domcomparators.WhiteSpaceStripper}</li>
+		 * </ul>
+		 * </p>
+		 * <p/>
+		 * @param stripper The stripper you want to add. Order matters. Duplicates are allowed.
+		 * @return the builder for method chaining.
+		 */
+		public CrawljaxConfigurationBuilder addDomStripper(DomStripper stripper) {
+			strippers.add(stripper);
+			return this;
+		}
+
+		/**
+		 * Add a {@link com.crawljax.domcomparators.ValidDomStripper}.
+		 *
+		 * <p>If no {@link com.crawljax.domcomparators.DomStripper} or {@link com.crawljax.domcomparators
+		 * .ValidDomStripper} is added, Crawljax uses the build-in
+		 * {@link com.crawljax.domcomparators.DomTextContentStripper}
+		 * and {@link com.crawljax.domcomparators.AttributesStripper}</p>
+		 *
+		 * <p>
+		 * Out-of-the-box available strippers are:
+		 * <ul>
+		 * <li>{@link com.crawljax.domcomparators.DomTextContentStripper}</li>
+		 * <li>{@link com.crawljax.domcomparators.DomStructureStripper}</li>
+		 * <li>{@link com.crawljax.domcomparators.ByCssSelectorStripper}</li>
+		 * <li>{@link com.crawljax.domcomparators.WhiteSpaceStripper}</li>
+		 * <li>{@link com.crawljax.domcomparators.AttributesStripper}</li>
+		 * </ul>
+		 * </p>
+		 * <p/>
+		 *
+		 * @param stripper The stripper you want to add. Order matters. Duplicates are allowed.
+		 * @return the builder for method chaining.
+		 */
+		public CrawljaxConfigurationBuilder addValidDomStripper(ValidDomStripper stripper) {
+			validStrippers.add(stripper);
+			return this;
+		}
+
 		private void checkOutputDirWritable() {
 			if (!config.output.exists()) {
 				Preconditions.checkState(config.output.mkdirs(),
-				  ""Could not create the output directory %s "", config.output);
+						""Could not create the output directory %s "", config.output);
 			}
 			else {
 				Preconditions.checkArgument(config.output.isDirectory(),
-				  ""Output directory %s is not a folder"", config.output);
+						""Output directory %s is not a folder"", config.output);
 				Preconditions.checkState(config.output.canWrite(),
-				  ""Output directory %s is not writable"", config.output);
+						""Output directory %s is not writable"", config.output);
 			}
 		}
 
 		public CrawljaxConfiguration build() {
 			config.plugins = pluginBuilder.build();
 			config.crawlRules = crawlRules.build();
+			config.strippers = strippers.build();
+			config.validStrippers = validStrippers.build();
+
+			if (config.strippers.isEmpty() && config.validStrippers.isEmpty()) {
+				config.strippers = ImmutableList.of(
+						new DomTextContentStripper(),
+						new AttributesStripper()
+				);
+			}
 			return config;
 		}
 
@@ -222,6 +288,8 @@
 
 	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.FIREFOX);
 	private ImmutableList<Plugin> plugins;
+	private ImmutableList<DomStripper> strippers;
+	private ImmutableList<ValidDomStripper> validStrippers;
 	private ProxyConfiguration proxyConfiguration = ProxyConfiguration.noProxy();
 
 	private CrawlRules crawlRules;
@@ -273,6 +341,13 @@
 		return output;
 	}
 
+	public ImmutableList<DomStripper> getStrippers() {
+		return strippers;
+	}
+
+	public ImmutableList<ValidDomStripper> getValidStrippers() {
+		return validStrippers;
+	}
 
 	public StateVertexFactory getStateVertexFactory() {
 		return stateVertexFactory;
@@ -281,7 +356,7 @@
 	@Override
 	public int hashCode() {
 		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
-		  maximumStates, maximumRuntime, maximumDepth);
+				maximumStates, maximumRuntime, maximumDepth, strippers, validStrippers);
 	}
 
 	@Override
@@ -289,13 +364,15 @@
 		if (object instanceof CrawljaxConfiguration) {
 			CrawljaxConfiguration that = (CrawljaxConfiguration) object;
 			return Objects.equal(this.url, that.url)
-			  && Objects.equal(this.browserConfig, that.browserConfig)
-			  && Objects.equal(this.plugins, that.plugins)
-			  && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
-			  && Objects.equal(this.crawlRules, that.crawlRules)
-			  && Objects.equal(this.maximumStates, that.maximumStates)
-			  && Objects.equal(this.maximumRuntime, that.maximumRuntime)
-			  && Objects.equal(this.maximumDepth, that.maximumDepth);
+					&& Objects.equal(this.browserConfig, that.browserConfig)
+					&& Objects.equal(this.plugins, that.plugins)
+					&& Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
+					&& Objects.equal(this.crawlRules, that.crawlRules)
+					&& Objects.equal(this.maximumStates, that.maximumStates)
+					&& Objects.equal(this.maximumRuntime, that.maximumRuntime)
+					&& Objects.equal(this.maximumDepth, that.maximumDepth)
+					&& Objects.equal(this.strippers, that.strippers)
+					&& Objects.equal(this.validStrippers, that.validStrippers);
 		}
 		return false;
 	}
@@ -303,15 +380,15 @@
 	@Override
 	public String toString() {
 		return Objects.toStringHelper(this)
-					  .add(""url"", url)
-					  .add(""browserConfig"", browserConfig)
-					  .add(""plugins"", plugins)
-					  .add(""proxyConfiguration"", proxyConfiguration)
-					  .add(""crawlRules"", crawlRules)
-					  .add(""maximumStates"", maximumStates)
-					  .add(""maximumRuntime"", maximumRuntime)
-					  .add(""maximumDepth"", maximumDepth)
-					  .toString();
+				.add(""url"", url)
+				.add(""browserConfig"", browserConfig)
+				.add(""plugins"", plugins)
+				.add(""proxyConfiguration"", proxyConfiguration)
+				.add(""crawlRules"", crawlRules)
+				.add(""maximumStates"", maximumStates)
+				.add(""maximumRuntime"", maximumRuntime)
+				.add(""maximumDepth"", maximumDepth)
+				.toString();
 	}
 
 }
\ No newline at end of file
"
855bd9bae493962c658964aadaa061f014869ae5,Alex Nederlof,ElementResolver.java,MODIFY,resolve -> [boolean logging] | [],"diff --git a/core/src/main/java/com/crawljax/util/ElementResolver.java b/core/src/main/java/com/crawljax/util/ElementResolver.java
index c1ebb1d..c0390da 100644
--- a/core/src/main/java/com/crawljax/util/ElementResolver.java
+++ b/core/src/main/java/com/crawljax/util/ElementResolver.java
@@ -1,19 +1,18 @@
 package com.crawljax.util;
 
-import java.io.IOException;
-
 import javax.xml.xpath.XPathExpressionException;
 
+import java.io.IOException;
+
+import com.crawljax.browser.EmbeddedBrowser;
+import com.crawljax.core.state.Element;
+import com.crawljax.core.state.Eventable;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.w3c.dom.Document;
 import org.w3c.dom.Node;
 import org.w3c.dom.NodeList;
 
-import com.crawljax.browser.EmbeddedBrowser;
-import com.crawljax.core.state.Element;
-import com.crawljax.core.state.Eventable;
-
 /**
  * Finds and checks elements.
  */
@@ -52,7 +51,7 @@
 	public String resolve(boolean logging) {
 		Document dom = null;
 		try {
-			dom = DomUtils.asDocument(browser.getStrippedDom());
+			dom = DomUtils.asDocument(browser.getDom());
 		} catch (IOException e) {
 			LOGGER.error(e.getMessage(), e);
 			return """";
"
a216f967ff6a8d816a901c91a01eb9ca371046aa,Keheliya Gallaba,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index bb40117..f934f5e 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -173,7 +173,7 @@
 		} catch (Exception e) {
 			// TODO Stefan; refactor this catch, this will definitely result in
 			// NullPointers, why
-			// not throw RuntimeExcption direct?
+			// not throw RuntimeException direct?
 			LOGGER.error(""Received unknown exception while creating the ""
 			        + ""HttpCommandExecutor, can not continue!"", e);
 			return null;
@@ -457,8 +457,8 @@
 
 					switchToFrame(eventable.getRelatedFrame());
 				} catch (NoSuchFrameException e) {
-					LOGGER.debug(""Frame not found, possibily while back-tracking.."", e);
-					// TODO Stefan, This exception is catched to prevent stopping
+					LOGGER.debug(""Frame not found, possibly while back-tracking.."", e);
+					// TODO Stefan, This exception is caught to prevent stopping
 					// from working
 					// This was the case on the Gmail case; find out if not switching
 					// (catching)
@@ -763,8 +763,8 @@
 		try {
 			WebElement el = browser.findElement(identification.getWebDriverBy());
 			// TODO Stefan; I think el will never be null as a
-			// NoSuchElementExcpetion will be
-			// thrown, catched below.
+			// NoSuchElementException will be
+			// thrown, caught below.
 			return el != null;
 		} catch (WebDriverException e) {
 			throwIfConnectionException(e);
@@ -801,7 +801,7 @@
 	}
 
 	/**
-	 * @return the period to waint after a reload.
+	 * @return the period to wait after a reload.
 	 */
 	protected long getCrawlWaitReload() {
 		return crawlWaitReload;
"
a216f967ff6a8d816a901c91a01eb9ca371046aa,Keheliya Gallaba,CandidateElementExtractor.java,MODIFY,"addFramesCandidates -> [List results, String relatedFrame, NodeList frameNodes] | [Document dom, List results, String relatedFrame, NodeList frameNodes]","diff --git a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
index f0e36d4..236e88b 100644
--- a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
+++ b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
@@ -225,12 +225,12 @@
 				evaluateElement(results, relatedFrame, crawl, sourceElement);
 			}
 		} catch (CrawljaxException e) {
-			LOG.warn(""Catched exception during NodeList For Tag Element retrieval"", e);
+			LOG.warn(""Caught exception during NodeList For Tag Element retrieval"", e);
 		}
 	}
 
 	/**
-	 * Returns a list of Elements form the DOM tree, matching the tag element.
+	 * Returns a list of Elements from the DOM tree, matching the tag element.
 	 */
 	private ImmutableList<Element> getNodeListForTagElement(Document dom,
 	        CrawlElement crawlElement,
@@ -328,7 +328,7 @@
 				URI uri = URI.create(href);
 				return !uri.getHost().equalsIgnoreCase(siteHostName);
 			} catch (IllegalArgumentException e) {
-				LOG.info(""Unreadable externa link {}"", href);
+				LOG.info(""Unreadable external link {}"", href);
 			}
 		}
 		return false;
"
a216f967ff6a8d816a901c91a01eb9ca371046aa,Keheliya Gallaba,CrawlActionsBuilder.java,MODIFY,click -> [String tagNames] | [String tagName],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
index 9dea6fe..f7de016 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
@@ -65,7 +65,7 @@
 	}
 
 	/**
-	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
+	 * Set of HTML elements Crawljax will click during crawling For example 1) <a.../> 2) <div/>
 	 * click(""a"") will only include 1 if clickOnce is true (default). This set can be restricted by
 	 * {@link #dontClick(String)}.
 	 * 
@@ -82,7 +82,7 @@
 	}
 
 	/**
-	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
+	 * Set of HTML elements Crawljax will click during crawling For example 1) <a.../> 2) <div/>
 	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}. If
 	 * no clicks are specified, {@link #clickDefaultElements()} is enabled.
 	 * 
@@ -130,7 +130,7 @@
 	}
 
 	/**
-	 * Click no childer of the specified parent element.
+	 * Click no children of the specified parent element.
 	 * 
 	 * @param tagname
 	 *            The tagname of which no children should be clicked.
"
a216f967ff6a8d816a901c91a01eb9ca371046aa,Keheliya Gallaba,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URI url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index f8ec514..0b1ef6c 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -112,7 +112,7 @@
 		}
 
 		/**
-		 * Add plugins to Crawljax. Note that without plugins, Crawljax won't give any ouput. For
+		 * Add plugins to Crawljax. Note that without plugins, Crawljax won't give any output. For
 		 * basic output at least enable the CrawlOverviewPlugin.
 		 * <p>
 		 * You can call this method several times to add multiple plugins
"
a216f967ff6a8d816a901c91a01eb9ca371046aa,Keheliya Gallaba,FormInputField.java,MODIFY,setValues -> [boolean values] | [String values],"diff --git a/core/src/main/java/com/crawljax/core/configuration/FormInputField.java b/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
index dc6e88c..e1370a1 100644
--- a/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
@@ -18,7 +18,7 @@
 public class FormInputField extends InputField {
 
 	/**
-	 * Sets the valus of this input field with a text input. Applicable to all form elements except
+	 * Sets the values of this input field with a text input. Applicable to all form elements except
 	 * checkboxes and a radio buttons.
 	 * 
 	 * @param values
"
a216f967ff6a8d816a901c91a01eb9ca371046aa,Keheliya Gallaba,InMemoryStateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
index b71c424..3d0c7b3 100644
--- a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
@@ -30,7 +30,7 @@
 import org.slf4j.LoggerFactory;
 
 /**
- * The State-Flow Graph is a multi-edge directed graph with states (StateVetex) on the vertices and
+ * The State-Flow Graph is a multi-edge directed graph with states (StateVertex) on the vertices and
  * clickables (Eventable) on the edges.
  */
 @Singleton
"
a216f967ff6a8d816a901c91a01eb9ca371046aa,Keheliya Gallaba,EditDistanceComparator.java,MODIFY,"getThreshold -> [String x, String y, double p] | []","diff --git a/core/src/main/java/com/crawljax/oraclecomparator/comparators/EditDistanceComparator.java b/core/src/main/java/com/crawljax/oraclecomparator/comparators/EditDistanceComparator.java
index 64cdc92..0e218fc 100644
--- a/core/src/main/java/com/crawljax/oraclecomparator/comparators/EditDistanceComparator.java
+++ b/core/src/main/java/com/crawljax/oraclecomparator/comparators/EditDistanceComparator.java
@@ -5,12 +5,12 @@
 import com.crawljax.oraclecomparator.AbstractComparator;
 
 /**
- * Oracle Comparator that uses the Levenshtein Edit Distance to determince wheter two states are
+ * Oracle Comparator that uses the Levenshtein Edit Distance to determine whether two states are
  * equivalent.
  */
 public class EditDistanceComparator extends AbstractComparator {
 
-	private double treshold = 1;
+	private double threshold = 1;
 
 	/**
 	 * Default constructor with edit distance treshold = 1.
@@ -20,11 +20,11 @@
 	}
 
 	/**
-	 * @param treshold
-	 *            the edit distance treshold. 1 is no difference, 0 is totally different
+	 * @param threshold
+	 *            the edit distance threshold. 1 is no difference, 0 is totally different
 	 */
-	public EditDistanceComparator(double treshold) {
-		this.treshold = treshold;
+	public EditDistanceComparator(double threshold) {
+		this.threshold = threshold;
 	}
 
 	/**
@@ -32,22 +32,22 @@
 	 */
 	@Override
 	public boolean isEquivalent(String oldDom, String newDom) {
-		return isClone(oldDom, newDom, getTreshold());
+		return isClone(oldDom, newDom, getThreshold());
 	}
 
 	/**
-	 * @return the treshold
+	 * @return the threshold
 	 */
-	public double getTreshold() {
-		return treshold;
+	public double getThreshold() {
+		return threshold;
 	}
 
 	/**
-	 * @param treshold
-	 *            the treshold to set
+	 * @param threshold
+	 *            the threshold to set
 	 */
-	public void setTreshold(double treshold) {
-		this.treshold = treshold;
+	public void setThreshold(double threshold) {
+		this.threshold = threshold;
 	}
 
 	/**
"
0a477d51fe6ef7da5946d56ac49f5e4606426cac,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index c42807a..ded16f0 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -6,9 +6,7 @@
 import java.net.URI;
 import java.net.URL;
 import java.util.ArrayList;
-import java.util.HashSet;
 import java.util.List;
-import java.util.Set;
 
 import com.crawljax.core.CrawljaxException;
 import com.crawljax.core.configuration.AcceptAllFramesChecker;
@@ -16,10 +14,6 @@
 import com.crawljax.core.exception.BrowserConnectionException;
 import com.crawljax.core.state.Eventable;
 import com.crawljax.core.state.Identification;
-import com.crawljax.forms.FormHandler;
-import com.crawljax.forms.FormInput;
-import com.crawljax.forms.InputValue;
-import com.crawljax.forms.RandomInputValueGenerator;
 import com.crawljax.util.DomUtils;
 import com.google.common.io.Files;
 import org.openqa.selenium.ElementNotVisibleException;
@@ -39,7 +33,6 @@
 import org.openqa.selenium.remote.ErrorHandler.UnknownServerException;
 import org.openqa.selenium.remote.HttpCommandExecutor;
 import org.openqa.selenium.remote.RemoteWebDriver;
-import org.openqa.selenium.support.ui.Select;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 import org.w3c.dom.DOMException;
@@ -577,68 +570,6 @@
 
 	}
 
-	/**
-	 * @param input the input to be filled.
-	 * @return FormInput with random value assigned if possible. If no values were set it returns
-	 * <code>null</code>
-	 */
-	@Override
-	public FormInput getInputWithRandomValue(FormInput input) {
-
-		WebElement webElement;
-		try {
-			webElement = browser.findElement(input.getIdentification().getWebDriverBy());
-			if (!webElement.isDisplayed()) {
-				return null;
-			}
-		}
-		catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return null;
-		}
-
-		Set<InputValue> values = new HashSet<>();
-		try {
-			setRandomValues(input, webElement, values);
-		}
-		catch (WebDriverException e) {
-			throwIfConnectionException(e);
-			return null;
-		}
-		if (values.isEmpty()) {
-			return null;
-		}
-		input.setInputValues(values);
-		return input;
-
-	}
-
-	private void setRandomValues(FormInput input, WebElement webElement, Set<InputValue> values) {
-		String inputString = input.getType().toLowerCase();
-		if (inputString.startsWith(""text"")) {
-			values.add(new InputValue(new RandomInputValueGenerator()
-					.getRandomString(FormHandler.RANDOM_STRING_LENGTH), true));
-		}
-		else if (inputString.equals(""checkbox"") || inputString.equals(""radio"")
-				&& !webElement.isSelected()) {
-			if (new RandomInputValueGenerator().getCheck()) {
-				values.add(new InputValue(""1"", true));
-			}
-			else {
-				values.add(new InputValue(""0"", false));
-			}
-		}
-		else if (inputString.equals(""select"")) {
-			Select select = new Select(webElement);
-			if (!select.getOptions().isEmpty()) {
-				WebElement option =
-						new RandomInputValueGenerator().getRandomItem(select.getOptions());
-				values.add(new InputValue(option.getText(), true));
-			}
-
-		}
-	}
-
 	@Override
 	public String getFrameDom(String iframeIdentification) {
 		try {
"
0a477d51fe6ef7da5946d56ac49f5e4606426cac,Alex Nederlof,CandidateElementExtractor.java,MODIFY,"addFramesCandidates -> [Document dom, List results, String relatedFrame, NodeList frameNodes] | [List results, String relatedFrame, NodeList frameNodes]","diff --git a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
index 3c22850..73cc0f1 100644
--- a/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
+++ b/core/src/main/java/com/crawljax/core/CandidateElementExtractor.java
@@ -5,7 +5,6 @@
 
 import java.io.IOException;
 import java.net.URI;
-import java.util.ArrayList;
 import java.util.Collections;
 import java.util.LinkedList;
 import java.util.List;
@@ -21,7 +20,6 @@
 import com.crawljax.core.configuration.PreCrawlConfiguration;
 import com.crawljax.core.state.Identification;
 import com.crawljax.core.state.StateVertex;
-import com.crawljax.forms.FormHandler;
 import com.crawljax.util.DomUtils;
 import com.crawljax.util.XPathHelper;
 import com.google.common.base.Strings;
@@ -48,7 +46,6 @@
 	private final ExtractorManager checkedElements;
 	private final EmbeddedBrowser browser;
 
-	private final FormHandler formHandler;
 	private final boolean crawlFrames;
 	private final ImmutableMultimap<String, CrawlElement> excludeCrawlElements;
 	private final ImmutableList<CrawlElement> includedCrawlElements;
@@ -64,30 +61,24 @@
 
 	/**
 	 * Create a new CandidateElementExtractor.
-	 * 
+	 *
 	 * @param checker
-	 *            the ExtractorManager to use for marking handled elements and retrieve the
-	 *            EventableConditionChecker
+	 * 		the ExtractorManager to use for marking handled elements and retrieve the
+	 * 		EventableConditionChecker
 	 * @param browser
-	 *            the current browser instance used in the Crawler
-	 * @param formHandler
-	 *            the form handler.
+	 * 		the current browser instance used in the Crawler
 	 * @param config
-	 *            the checker used to determine if a certain frame must be ignored.
+	 * 		the checker used to determine if a certain frame must be ignored.
 	 */
 	@Inject
 	public CandidateElementExtractor(ExtractorManager checker, @Assisted EmbeddedBrowser browser,
-	        FormHandler formHandler, CrawljaxConfiguration config) {
+			CrawljaxConfiguration config) {
 		checkedElements = checker;
 		this.browser = browser;
-		this.formHandler = formHandler;
 		CrawlRules rules = config.getCrawlRules();
 		PreCrawlConfiguration preCrawlConfig = rules.getPreCrawlConfig();
 		this.excludeCrawlElements = asMultiMap(preCrawlConfig.getExcludedElements());
-		this.includedCrawlElements = ImmutableList.<CrawlElement> builder()
-		        .addAll(preCrawlConfig.getIncludedElements())
-		        .addAll(rules.getInputSpecification().getCrawlElements())
-		        .build();
+		this.includedCrawlElements = preCrawlConfig.getIncludedElements();
 		crawlFrames = rules.shouldCrawlFrames();
 		clickOnce = rules.isClickOnce();
 		randomizeElementsOrder = rules.isRandomizeCandidateElements();
@@ -97,7 +88,7 @@
 	}
 
 	private ImmutableMultimap<String, CrawlElement> asMultiMap(
-	        ImmutableList<CrawlElement> elements) {
+			ImmutableList<CrawlElement> elements) {
 		ImmutableMultimap.Builder<String, CrawlElement> builder = ImmutableMultimap.builder();
 		for (CrawlElement elem : elements) {
 			builder.put(elem.getTagName(), elem);
@@ -108,15 +99,15 @@
 	/**
 	 * This method extracts candidate elements from the current DOM tree in the browser, based on
 	 * the crawl tags defined by the user.
-	 * 
+	 *
 	 * @param currentState
-	 *            the state in which this extract method is requested.
+	 * 		the state in which this extract method is requested.
 	 * @return a list of candidate elements that are not excluded.
 	 * @throws CrawljaxException
-	 *             if the method fails.
+	 * 		if the method fails.
 	 */
 	public ImmutableList<CandidateElement> extract(StateVertex currentState)
-	        throws CrawljaxException {
+			throws CrawljaxException {
 		LinkedList<CandidateElement> results = new LinkedList<>();
 
 		if (!checkedElements.checkCrawlCondition(browser)) {
@@ -141,7 +132,7 @@
 	}
 
 	private void extractElements(Document dom, List<CandidateElement> results,
-	        String relatedFrame) {
+			String relatedFrame) {
 		LOG.debug(""Extracting elements for related frame '{}'"", relatedFrame);
 		for (CrawlElement tag : includedCrawlElements) {
 			LOG.debug(""Extracting TAG: {}"", tag);
@@ -158,7 +149,7 @@
 	}
 
 	private void addFramesCandidates(List<CandidateElement> results,
-	        String relatedFrame, NodeList frameNodes) {
+			String relatedFrame, NodeList frameNodes) {
 
 		if (frameNodes == null) {
 			return;
@@ -185,11 +176,11 @@
 
 				try {
 					Document frameDom =
-					        DomUtils.asDocument(browser.getFrameDom(frameIdentification));
+							DomUtils.asDocument(browser.getFrameDom(frameIdentification));
 					extractElements(frameDom, results, frameIdentification);
 				} catch (IOException e) {
 					LOG.info(""Got exception while inspecting a frame: {} continuing..."",
-					        frameIdentification, e);
+							frameIdentification, e);
 				}
 			}
 		}
@@ -211,11 +202,11 @@
 	}
 
 	private void evaluateElements(Document dom, CrawlElement crawl,
-	        List<CandidateElement> results, String relatedFrame) {
+			List<CandidateElement> results, String relatedFrame) {
 		try {
 			List<Element> nodeListForCrawlElement =
-			        getNodeListForTagElement(dom, crawl,
-			                checkedElements.getEventableConditionChecker());
+					getNodeListForTagElement(dom, crawl,
+							checkedElements.getEventableConditionChecker());
 
 			for (Element sourceElement : nodeListForCrawlElement) {
 				evaluateElement(results, relatedFrame, crawl, sourceElement);
@@ -226,11 +217,11 @@
 	}
 
 	/**
-	 * Returns a list of Elements form the DOM tree, matching the tag element.
+	 * Returns a list of Elements from the DOM tree, matching the tag element.
 	 */
 	private ImmutableList<Element> getNodeListForTagElement(Document dom,
-	        CrawlElement crawlElement,
-	        EventableConditionChecker eventableConditionChecker) {
+			CrawlElement crawlElement,
+			EventableConditionChecker eventableConditionChecker) {
 
 		Builder<Element> result = ImmutableList.builder();
 
@@ -239,7 +230,7 @@
 		}
 
 		EventableCondition eventableCondition =
-		        eventableConditionChecker.getEventableCondition(crawlElement.getId());
+				eventableConditionChecker.getEventableCondition(crawlElement.getId());
 		// TODO Stefan; this part of the code should be re-factored, Hack-ed it this way to prevent
 		// performance problems.
 		ImmutableList<String> expressions = getFullXpathForGivenXpath(dom, eventableCondition);
@@ -250,17 +241,17 @@
 
 			Element element = (Element) nodeList.item(k);
 			boolean matchesXpath =
-			        elementMatchesXpath(eventableConditionChecker, eventableCondition,
-			                expressions, element);
+					elementMatchesXpath(eventableConditionChecker, eventableCondition,
+							expressions, element);
 			LOG.debug(""Element {} matches Xpath={}"", DomUtils.getElementString(element),
-			        matchesXpath);
+					matchesXpath);
 			/*
 			 * TODO Stefan This is a possible Thread-Interleaving problem, as / isChecked can return
 			 * false and when needed to add it can return true. / check if element is a candidate
 			 */
 			String id = element.getNodeName() + "": "" + DomUtils.getAllElementAttributes(element);
 			if (matchesXpath && !checkedElements.isChecked(id)
-			        && !isExcluded(dom, element, eventableConditionChecker)) {
+					&& !isExcluded(dom, element, eventableConditionChecker)) {
 				addElement(element, result, crawlElement);
 			} else {
 				LOG.debug(""Element {} was not added"", element);
@@ -270,14 +261,14 @@
 	}
 
 	private boolean elementMatchesXpath(EventableConditionChecker eventableConditionChecker,
-	        EventableCondition eventableCondition, ImmutableList<String> expressions,
-	        Element element) {
+			EventableCondition eventableCondition, ImmutableList<String> expressions,
+			Element element) {
 		boolean matchesXpath = true;
 		if (eventableCondition != null && eventableCondition.getInXPath() != null) {
 			try {
 				matchesXpath =
-				        eventableConditionChecker.checkXPathUnderXPaths(
-				                XPathHelper.getXPathExpression(element), expressions);
+						eventableConditionChecker.checkXPathUnderXPaths(
+								XPathHelper.getXPathExpression(element), expressions);
 			} catch (RuntimeException e) {
 				matchesXpath = false;
 			}
@@ -286,20 +277,20 @@
 	}
 
 	private ImmutableList<String> getFullXpathForGivenXpath(Document dom,
-	        EventableCondition eventableCondition) {
+			EventableCondition eventableCondition) {
 		if (eventableCondition != null && eventableCondition.getInXPath() != null) {
 			try {
 				ImmutableList<String> result =
-				        XPathHelper.getXpathForXPathExpressions(dom,
-				                eventableCondition.getInXPath());
+						XPathHelper.getXpathForXPathExpressions(dom,
+								eventableCondition.getInXPath());
 				LOG.debug(""Xpath {} resolved to xpaths in document: {}"",
-				        eventableCondition.getInXPath(), result);
+						eventableCondition.getInXPath(), result);
 				return result;
 			} catch (XPathExpressionException e) {
 				LOG.debug(""Could not load XPath expressions for {}"", eventableCondition, e);
 			}
 		}
-		return ImmutableList.<String> of();
+		return ImmutableList.<String>of();
 	}
 
 	private void addElement(Element element, Builder<Element> builder, CrawlElement crawlElement) {
@@ -314,8 +305,8 @@
 	private boolean hrefShouldBeIgnored(Element element) {
 		String href = Strings.nullToEmpty(element.getAttribute(""href""));
 		return isFileForDownloading(href)
-		        || href.startsWith(""mailto:"")
-		        || (!followExternalLinks && isExternal(href));
+				|| href.startsWith(""mailto:"")
+				|| (!followExternalLinks && isExternal(href));
 	}
 
 	private boolean isExternal(String href) {
@@ -332,7 +323,7 @@
 
 	/**
 	 * @param href
-	 *            the string to check
+	 * 		the string to check
 	 * @return true if href has the pdf or ps pattern.
 	 */
 	private boolean isFileForDownloading(String href) {
@@ -347,70 +338,52 @@
 	}
 
 	private void evaluateElement(List<CandidateElement> results, String relatedFrame,
-	        CrawlElement crawl, Element sourceElement) {
+			CrawlElement crawl, Element sourceElement) {
 		EventableCondition eventableCondition =
-		        checkedElements.getEventableConditionChecker().getEventableCondition(
-		                crawl.getId());
+				checkedElements.getEventableConditionChecker().getEventableCondition(
+						crawl.getId());
 		String xpath = XPathHelper.getXPathExpression(sourceElement);
 		// get multiple candidate elements when there are input
 		// fields connected to this element
 
-		List<CandidateElement> candidateElements = new ArrayList<CandidateElement>();
-		if (eventableCondition != null && eventableCondition.getLinkedInputFields() != null
-		        && eventableCondition.getLinkedInputFields().size() > 0) {
-			// add multiple candidate elements, for every input
-			// value combination
-			candidateElements =
-			        formHandler.getCandidateElementsForInputs(sourceElement, eventableCondition);
-		} else {
-			// just add default element
-			candidateElements.add(new CandidateElement(sourceElement, new Identification(
-			        Identification.How.xpath, xpath), relatedFrame));
-		}
-
-		for (CandidateElement candidateElement : candidateElements) {
-			if (!clickOnce || checkedElements.markChecked(candidateElement)) {
-				LOG.debug(""Found new candidate element: {} with eventableCondition {}"",
-				        candidateElement.getUniqueString(), eventableCondition);
-				candidateElement.setEventableCondition(eventableCondition);
-				results.add(candidateElement);
-				/**
-				 * TODO add element to checkedElements after the event is fired! also add string
-				 * without 'atusa' attribute to make sure an form action element is only clicked for
-				 * its defined values
-				 */
-			}
+		CandidateElement candidateElement = new CandidateElement(sourceElement, new Identification(
+				Identification.How.xpath, xpath), relatedFrame);
+		if (!clickOnce || checkedElements.markChecked(candidateElement)) {
+			LOG.debug(""Found new candidate element: {} with eventableCondition {}"",
+					candidateElement.getUniqueString(), eventableCondition);
+			candidateElement.setEventableCondition(eventableCondition);
+			results.add(candidateElement);
 		}
 	}
 
 	/**
 	 * @return true if element should be excluded. Also when an ancestor of the given element is
-	 *         marked for exclusion, which allows for recursive exclusion of elements from
-	 *         candidates.
+	 * marked for exclusion, which allows for recursive exclusion of elements from
+	 * candidates.
 	 */
 	private boolean isExcluded(Document dom, Element element,
-	        EventableConditionChecker eventableConditionChecker) {
+			EventableConditionChecker eventableConditionChecker) {
 
 		Node parent = element.getParentNode();
 
 		if (parent instanceof Element
-		        && isExcluded(dom, (Element) parent, eventableConditionChecker)) {
+				&& isExcluded(dom, (Element) parent, eventableConditionChecker)) {
 			return true;
 		}
 
 		for (CrawlElement crawlElem : excludeCrawlElements
-		        .get(element.getTagName().toUpperCase())) {
+				.get(element.getTagName().toUpperCase())) {
 			boolean matchesXPath = false;
 			EventableCondition eventableCondition =
-			        eventableConditionChecker.getEventableCondition(crawlElem.getId());
+					eventableConditionChecker.getEventableCondition(crawlElem.getId());
 			try {
 				String asXpath = XPathHelper.getXPathExpression(element);
 				matchesXPath =
-				        eventableConditionChecker.checkXpathStartsWithXpathEventableCondition(
-				                dom, eventableCondition, asXpath);
+						eventableConditionChecker.checkXpathStartsWithXpathEventableCondition(
+								dom, eventableCondition, asXpath);
 			} catch (CrawljaxException | XPathExpressionException e) {
 				LOG.debug(""Could not check exclusion by Xpath for element because {}"",
-				        e.getMessage());
+						e.getMessage());
 				matchesXPath = false;
 			}
 
"
94ffac6e2a26a567e413f63077066cdba0ab88e9,Alex Nederlof,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index ded16f0..f0f8626 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -16,6 +16,7 @@
 import com.crawljax.core.state.Identification;
 import com.crawljax.util.DomUtils;
 import com.google.common.io.Files;
+import org.openqa.selenium.By;
 import org.openqa.selenium.ElementNotVisibleException;
 import org.openqa.selenium.JavascriptExecutor;
 import org.openqa.selenium.NoSuchElementException;
@@ -197,6 +198,17 @@
 		return new WebDriverBackedEmbeddedBrowser(driver);
 	}
 
+
+	@Override
+	public WebElement findElement(By by) {
+		return browser.findElement(by);
+	}
+
+	@Override
+	public List<WebElement> findElements(By by) {
+		return browser.findElements(by);
+	}
+
 	/**
 	 * @param url The URL.
 	 */
"
dfcb0fa82b9a580c1ac2e9b6bf50f9775210cb89,Keheliya Gallaba,WebDriverBrowserBuilder.java,MODIFY,"newFireFoxBrowser -> [long crawlWaitReload, long crawlWaitEvent] | [ImmutableSortedSet filterAttributes, long crawlWaitReload, long crawlWaitEvent]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java b/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java
index 18aa122..fe49c1e 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBrowserBuilder.java
@@ -51,32 +51,38 @@
 
 		// Determine the requested browser type
 		EmbeddedBrowser browser = null;
-		switch (configuration.getBrowserConfig().getBrowsertype()) {
-			case FIREFOX:
-				browser = newFireFoxBrowser(filterAttributes, crawlWaitReload, crawlWaitEvent);
-				break;
-			case INTERNET_EXPLORER:
-				browser =
-				        WebDriverBackedEmbeddedBrowser.withDriver(new InternetExplorerDriver(),
-				                filterAttributes, crawlWaitEvent, crawlWaitReload);
-				break;
-			case CHROME:
-				browser = newChromeBrowser(filterAttributes, crawlWaitReload, crawlWaitEvent);
-				break;
-
-			case REMOTE:
-				browser =
-				        WebDriverBackedEmbeddedBrowser.withRemoteDriver(configuration
-				                .getBrowserConfig().getRemoteHubUrl(), filterAttributes,
-				                crawlWaitEvent, crawlWaitReload);
-				break;
-			case PHANTOMJS:
-				browser = newPhantomJSDriver(filterAttributes, crawlWaitReload, crawlWaitEvent);
-
-				break;
-			default:
-				throw new IllegalStateException(""Unrecognized browsertype ""
-				        + configuration.getBrowserConfig().getBrowsertype());
+		EmbeddedBrowser.BrowserType browserType = configuration.getBrowserConfig().getBrowsertype();
+		try {
+			switch (browserType) {
+				case FIREFOX:
+					browser =
+					        newFireFoxBrowser(filterAttributes, crawlWaitReload, crawlWaitEvent);
+					break;
+				case INTERNET_EXPLORER:
+					browser =
+					        WebDriverBackedEmbeddedBrowser.withDriver(
+					                new InternetExplorerDriver(),
+					                filterAttributes, crawlWaitEvent, crawlWaitReload);
+					break;
+				case CHROME:
+					browser = newChromeBrowser(filterAttributes, crawlWaitReload, crawlWaitEvent);
+					break;
+				case REMOTE:
+					browser =
+					        WebDriverBackedEmbeddedBrowser.withRemoteDriver(configuration
+					                .getBrowserConfig().getRemoteHubUrl(), filterAttributes,
+					                crawlWaitEvent, crawlWaitReload);
+					break;
+				case PHANTOMJS:
+					browser =
+					        newPhantomJSDriver(filterAttributes, crawlWaitReload, crawlWaitEvent);
+					break;
+				default:
+					throw new IllegalStateException(""Unrecognized browsertype ""
+					        + configuration.getBrowserConfig().getBrowsertype());
+			}
+		} catch (IllegalStateException e) {
+			LOGGER.error(""Crawling with {} failed: "" + e.getMessage(), browserType.toString());
 		}
 		plugins.runOnBrowserCreatedPlugins(browser);
 		return browser;
"
1160f3ffd32e6400a2f500dcb687266e8b11c3ce,Ivan Plantevin,InMemoryStateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
index b71c424..8627423 100644
--- a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
@@ -192,7 +192,7 @@
 	}
 
 	@Override
-	public ImmutableSet<Eventable> getIncomingClickable(StateVertex stateVertix) {
+	public ImmutableSet<Eventable> getIncomingClickables(StateVertex stateVertix) {
 		readLock.lock();
 		try {
 			return ImmutableSet.copyOf(sfg.incomingEdgesOf(stateVertix));
@@ -357,4 +357,14 @@
 		return ImmutableSet.copyOf(result);
 	}
 
+	@Override
+	public ImmutableSet<StateVertex> getIncomingStates(StateVertex stateVertix) {
+		final Set<StateVertex> result = new HashSet<>();
+
+		for (Eventable c : getIncomingClickables(stateVertix)) {
+			result.add(sfg.getEdgeSource(c));
+		}
+
+		return ImmutableSet.copyOf(result);
+	}
 }
"
55ead0491537e13cbd6db0a20a2f5759caf1c671,Alex Nederlof,InMemoryStateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
index b71c424..8627423 100644
--- a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
@@ -192,7 +192,7 @@
 	}
 
 	@Override
-	public ImmutableSet<Eventable> getIncomingClickable(StateVertex stateVertix) {
+	public ImmutableSet<Eventable> getIncomingClickables(StateVertex stateVertix) {
 		readLock.lock();
 		try {
 			return ImmutableSet.copyOf(sfg.incomingEdgesOf(stateVertix));
@@ -357,4 +357,14 @@
 		return ImmutableSet.copyOf(result);
 	}
 
+	@Override
+	public ImmutableSet<StateVertex> getIncomingStates(StateVertex stateVertix) {
+		final Set<StateVertex> result = new HashSet<>();
+
+		for (Eventable c : getIncomingClickables(stateVertix)) {
+			result.add(sfg.getEdgeSource(c));
+		}
+
+		return ImmutableSet.copyOf(result);
+	}
 }
"
9ec4c9dfc7073920c6371db71f28dd70f24689b5,Ivan Plantevin,UnfiredCandidateActions.java,MODIFY,"addActions -> [Collection actions, StateVertex state] | [ImmutableList extract, StateVertex currentState]","diff --git a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
index 4e1beb3..de6183f 100644
--- a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
+++ b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
@@ -12,6 +12,7 @@
 import javax.inject.Provider;
 import javax.inject.Singleton;
 
+import com.codahale.metrics.Gauge;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -55,6 +56,12 @@
 		        registry.register(MetricsModule.EVENTS_PREFIX + ""crawler_lost"", new Counter());
 		unfiredActionsCount =
 		        registry.register(MetricsModule.EVENTS_PREFIX + ""unfired_actions"", new Counter());
+		registry.register(MetricsModule.EVENTS_PREFIX + ""states_with_candidates"", new Gauge<Integer>() {
+			@Override
+			public Integer getValue() {
+				return statesWithCandidates.size();
+			}
+		});
 	}
 
 	/**
"
a04a15d8d3436fd9e648c64d49d796106ea74ae6,Alex Nederlof,UnfiredCandidateActions.java,MODIFY,"addActions -> [Collection actions, StateVertex state] | [ImmutableList extract, StateVertex currentState]","diff --git a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
index 4e1beb3..de6183f 100644
--- a/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
+++ b/core/src/main/java/com/crawljax/core/UnfiredCandidateActions.java
@@ -12,6 +12,7 @@
 import javax.inject.Provider;
 import javax.inject.Singleton;
 
+import com.codahale.metrics.Gauge;
 import org.slf4j.Logger;
 import org.slf4j.LoggerFactory;
 
@@ -55,6 +56,12 @@
 		        registry.register(MetricsModule.EVENTS_PREFIX + ""crawler_lost"", new Counter());
 		unfiredActionsCount =
 		        registry.register(MetricsModule.EVENTS_PREFIX + ""unfired_actions"", new Counter());
+		registry.register(MetricsModule.EVENTS_PREFIX + ""states_with_candidates"", new Gauge<Integer>() {
+			@Override
+			public Integer getValue() {
+				return statesWithCandidates.size();
+			}
+		});
 	}
 
 	/**
"
cfe26421dc78a8e9929919459ca2dcae2a243dab,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URI url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index f8ec514..b327a10 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -41,8 +41,10 @@
 		 * href=""http://en.wikipedia.org/wiki/Basic_access_authentication"">Basic auth</a> you can
 		 * set the username and password here.
 		 *
-		 * @param username The username for the website.
-		 * @param password The password for the website.
+		 * @param username
+		 *            The username for the website.
+		 * @param password
+		 *            The password for the website.
 		 * @return {@link CrawljaxConfigurationBuilder} for method chaining.
 		 */
 		public CrawljaxConfigurationBuilder setBasicAuth(String username, String password) {
@@ -50,17 +52,19 @@
 				String encodedUsername = URLEncoder.encode(username, ""UTF-8"");
 				String encodedPassword = URLEncoder.encode(password, ""UTF-8"");
 				String hostPrefix = encodedUsername + "":"" + encodedPassword + ""@"";
-				config.url = URI.create(config.url.toString().replaceFirst(""://"", ""://"" + hostPrefix));
-			}
-			catch (UnsupportedEncodingException e) {
+				config.basicAuthUrl =
+				        URI.create(config.url.toString().replaceFirst(""://"", ""://"" + hostPrefix));
+
+			} catch (UnsupportedEncodingException e) {
 				throw new CrawljaxException(""Could not parse the username/password to a URL"", e);
 			}
 			return this;
 		}
 
 		/**
-		 * @param states The maximum number of states the Crawler should crawl. The default is
-		 *               unlimited.
+		 * @param states
+		 *            The maximum number of states the Crawler should crawl. The default is
+		 *            unlimited.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumStates(int states) {
 			checkArgument(states > 1, ""Number of maximum states should be larger than 1"");
@@ -77,7 +81,8 @@
 		}
 
 		/**
-		 * @param time The maximum time the crawler should run. Default is one hour.
+		 * @param time
+		 *            The maximum time the crawler should run. Default is one hour.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumRunTime(long time, TimeUnit unit) {
 			checkArgument(time >= 0, ""Time should be larger than 0, or 0 for infinate."");
@@ -94,11 +99,12 @@
 		}
 
 		/**
-		 * @param depth The maximum depth the crawler can reach. The default is <code>2</code>.
+		 * @param depth
+		 *            The maximum depth the crawler can reach. The default is <code>2</code>.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumDepth(int depth) {
 			Preconditions.checkArgument(depth >= 0,
-			  ""Depth should be 0 for infinite, or larger for a certain depth."");
+			        ""Depth should be 0 for infinite, or larger for a certain depth."");
 			config.maximumDepth = depth;
 			return this;
 		}
@@ -118,7 +124,8 @@
 		 * You can call this method several times to add multiple plugins
 		 * </p>
 		 *
-		 * @param plugins the plugins you would like to enable.
+		 * @param plugins
+		 *            the plugins you would like to enable.
 		 */
 		public CrawljaxConfigurationBuilder addPlugin(Plugin... plugins) {
 			pluginBuilder.add(plugins);
@@ -126,7 +133,8 @@
 		}
 
 		/**
-		 * @param configuration The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
+		 * @param configuration
+		 *            The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
 		 */
 		public CrawljaxConfigurationBuilder setProxyConfig(ProxyConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -142,8 +150,9 @@
 		}
 
 		/**
-		 * @param configuration a custom {@link BrowserConfiguration}. The default is a single
-		 *                      {@link BrowserType#FIREFOX} browser.
+		 * @param configuration
+		 *            a custom {@link BrowserConfiguration}. The default is a single
+		 *            {@link BrowserType#FIREFOX} browser.
 		 */
 		public CrawljaxConfigurationBuilder setBrowserConfig(BrowserConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -152,13 +161,14 @@
 		}
 
 		/**
-		 * Set a custom {@link com.crawljax.core.state.StateVertexFactory} to be able to use your own
-		 * {@link com.crawljax.core.state.StateVertex} objects. This is useful when you want to have a custom
-		 * comparator
-		 * in the stateflowgraph which relies on the {@link Object#hashCode()} or {@link Object#equals(Object)} of the
+		 * Set a custom {@link com.crawljax.core.state.StateVertexFactory} to be able to use your
+		 * own {@link com.crawljax.core.state.StateVertex} objects. This is useful when you want to
+		 * have a custom comparator in the stateflowgraph which relies on the
+		 * {@link Object#hashCode()} or {@link Object#equals(Object)} of the
 		 * {@link com.crawljax.core.state.StateVertex}.
 		 *
-		 * @param vertexFactory The factory you want to use.
+		 * @param vertexFactory
+		 *            The factory you want to use.
 		 * @return The builder for method chaining.
 		 */
 		public CrawljaxConfigurationBuilder setStateVertexFactory(StateVertexFactory vertexFactory) {
@@ -171,8 +181,10 @@
 		 * Set the output folder for any {@link Plugin} you might configure. Crawljax itself doesn't
 		 * need an output folder but many plug-ins do.
 		 *
-		 * @param output The output folder. If it does not exist it will be created.
-		 * @throws IllegalStateException if the specified file is not writable or exists but isn't a folder.
+		 * @param output
+		 *            The output folder. If it does not exist it will be created.
+		 * @throws IllegalStateException
+		 *             if the specified file is not writable or exists but isn't a folder.
 		 */
 		public CrawljaxConfigurationBuilder setOutputDirectory(File output) {
 			config.output = output;
@@ -183,13 +195,12 @@
 		private void checkOutputDirWritable() {
 			if (!config.output.exists()) {
 				Preconditions.checkState(config.output.mkdirs(),
-				  ""Could not create the output directory %s "", config.output);
-			}
-			else {
+				        ""Could not create the output directory %s "", config.output);
+			} else {
 				Preconditions.checkArgument(config.output.isDirectory(),
-				  ""Output directory %s is not a folder"", config.output);
+				        ""Output directory %s is not a folder"", config.output);
 				Preconditions.checkState(config.output.canWrite(),
-				  ""Output directory %s is not writable"", config.output);
+				        ""Output directory %s is not writable"", config.output);
 			}
 		}
 
@@ -202,7 +213,8 @@
 	}
 
 	/**
-	 * @param url The url you want to setup a configuration for
+	 * @param url
+	 *            The url you want to setup a configuration for
 	 * @return The builder to configure the crawler.
 	 */
 	public static CrawljaxConfigurationBuilder builderFor(URI url) {
@@ -211,7 +223,8 @@
 	}
 
 	/**
-	 * @param url The url you want to setup a configuration for
+	 * @param url
+	 *            The url you want to setup a configuration for
 	 * @return The builder to configure the crawler.
 	 */
 	public static CrawljaxConfigurationBuilder builderFor(String url) {
@@ -219,6 +232,7 @@
 	}
 
 	private URI url;
+	private URI basicAuthUrl;
 
 	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.FIREFOX);
 	private ImmutableList<Plugin> plugins;
@@ -227,8 +241,7 @@
 	private CrawlRules crawlRules;
 
 	private int maximumStates = 0;
-	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);
-	;
+	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);;
 	private int maximumDepth = 2;
 	private File output = new File(""out"");
 
@@ -241,6 +254,10 @@
 		return url;
 	}
 
+	public URI getBasicAuthUrl() {
+		return basicAuthUrl;
+	}
+
 	public BrowserConfiguration getBrowserConfig() {
 		return browserConfig;
 	}
@@ -273,7 +290,6 @@
 		return output;
 	}
 
-
 	public StateVertexFactory getStateVertexFactory() {
 		return stateVertexFactory;
 	}
@@ -281,7 +297,7 @@
 	@Override
 	public int hashCode() {
 		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
-		  maximumStates, maximumRuntime, maximumDepth);
+		        maximumStates, maximumRuntime, maximumDepth);
 	}
 
 	@Override
@@ -289,29 +305,24 @@
 		if (object instanceof CrawljaxConfiguration) {
 			CrawljaxConfiguration that = (CrawljaxConfiguration) object;
 			return Objects.equal(this.url, that.url)
-			  && Objects.equal(this.browserConfig, that.browserConfig)
-			  && Objects.equal(this.plugins, that.plugins)
-			  && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
-			  && Objects.equal(this.crawlRules, that.crawlRules)
-			  && Objects.equal(this.maximumStates, that.maximumStates)
-			  && Objects.equal(this.maximumRuntime, that.maximumRuntime)
-			  && Objects.equal(this.maximumDepth, that.maximumDepth);
+			        && Objects.equal(this.browserConfig, that.browserConfig)
+			        && Objects.equal(this.plugins, that.plugins)
+			        && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
+			        && Objects.equal(this.crawlRules, that.crawlRules)
+			        && Objects.equal(this.maximumStates, that.maximumStates)
+			        && Objects.equal(this.maximumRuntime, that.maximumRuntime)
+			        && Objects.equal(this.maximumDepth, that.maximumDepth);
 		}
 		return false;
 	}
 
 	@Override
 	public String toString() {
-		return Objects.toStringHelper(this)
-					  .add(""url"", url)
-					  .add(""browserConfig"", browserConfig)
-					  .add(""plugins"", plugins)
-					  .add(""proxyConfiguration"", proxyConfiguration)
-					  .add(""crawlRules"", crawlRules)
-					  .add(""maximumStates"", maximumStates)
-					  .add(""maximumRuntime"", maximumRuntime)
-					  .add(""maximumDepth"", maximumDepth)
-					  .toString();
+		return Objects.toStringHelper(this).add(""url"", url).add(""browserConfig"", browserConfig)
+		        .add(""plugins"", plugins).add(""proxyConfiguration"", proxyConfiguration)
+		        .add(""crawlRules"", crawlRules).add(""maximumStates"", maximumStates)
+		        .add(""maximumRuntime"", maximumRuntime).add(""maximumDepth"", maximumDepth)
+		        .toString();
 	}
 
 }
\ No newline at end of file
"
1566b49a312093782e024c098ba89be84fe85ddc,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URI url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index f8ec514..b327a10 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -41,8 +41,10 @@
 		 * href=""http://en.wikipedia.org/wiki/Basic_access_authentication"">Basic auth</a> you can
 		 * set the username and password here.
 		 *
-		 * @param username The username for the website.
-		 * @param password The password for the website.
+		 * @param username
+		 *            The username for the website.
+		 * @param password
+		 *            The password for the website.
 		 * @return {@link CrawljaxConfigurationBuilder} for method chaining.
 		 */
 		public CrawljaxConfigurationBuilder setBasicAuth(String username, String password) {
@@ -50,17 +52,19 @@
 				String encodedUsername = URLEncoder.encode(username, ""UTF-8"");
 				String encodedPassword = URLEncoder.encode(password, ""UTF-8"");
 				String hostPrefix = encodedUsername + "":"" + encodedPassword + ""@"";
-				config.url = URI.create(config.url.toString().replaceFirst(""://"", ""://"" + hostPrefix));
-			}
-			catch (UnsupportedEncodingException e) {
+				config.basicAuthUrl =
+				        URI.create(config.url.toString().replaceFirst(""://"", ""://"" + hostPrefix));
+
+			} catch (UnsupportedEncodingException e) {
 				throw new CrawljaxException(""Could not parse the username/password to a URL"", e);
 			}
 			return this;
 		}
 
 		/**
-		 * @param states The maximum number of states the Crawler should crawl. The default is
-		 *               unlimited.
+		 * @param states
+		 *            The maximum number of states the Crawler should crawl. The default is
+		 *            unlimited.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumStates(int states) {
 			checkArgument(states > 1, ""Number of maximum states should be larger than 1"");
@@ -77,7 +81,8 @@
 		}
 
 		/**
-		 * @param time The maximum time the crawler should run. Default is one hour.
+		 * @param time
+		 *            The maximum time the crawler should run. Default is one hour.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumRunTime(long time, TimeUnit unit) {
 			checkArgument(time >= 0, ""Time should be larger than 0, or 0 for infinate."");
@@ -94,11 +99,12 @@
 		}
 
 		/**
-		 * @param depth The maximum depth the crawler can reach. The default is <code>2</code>.
+		 * @param depth
+		 *            The maximum depth the crawler can reach. The default is <code>2</code>.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumDepth(int depth) {
 			Preconditions.checkArgument(depth >= 0,
-			  ""Depth should be 0 for infinite, or larger for a certain depth."");
+			        ""Depth should be 0 for infinite, or larger for a certain depth."");
 			config.maximumDepth = depth;
 			return this;
 		}
@@ -118,7 +124,8 @@
 		 * You can call this method several times to add multiple plugins
 		 * </p>
 		 *
-		 * @param plugins the plugins you would like to enable.
+		 * @param plugins
+		 *            the plugins you would like to enable.
 		 */
 		public CrawljaxConfigurationBuilder addPlugin(Plugin... plugins) {
 			pluginBuilder.add(plugins);
@@ -126,7 +133,8 @@
 		}
 
 		/**
-		 * @param configuration The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
+		 * @param configuration
+		 *            The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
 		 */
 		public CrawljaxConfigurationBuilder setProxyConfig(ProxyConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -142,8 +150,9 @@
 		}
 
 		/**
-		 * @param configuration a custom {@link BrowserConfiguration}. The default is a single
-		 *                      {@link BrowserType#FIREFOX} browser.
+		 * @param configuration
+		 *            a custom {@link BrowserConfiguration}. The default is a single
+		 *            {@link BrowserType#FIREFOX} browser.
 		 */
 		public CrawljaxConfigurationBuilder setBrowserConfig(BrowserConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -152,13 +161,14 @@
 		}
 
 		/**
-		 * Set a custom {@link com.crawljax.core.state.StateVertexFactory} to be able to use your own
-		 * {@link com.crawljax.core.state.StateVertex} objects. This is useful when you want to have a custom
-		 * comparator
-		 * in the stateflowgraph which relies on the {@link Object#hashCode()} or {@link Object#equals(Object)} of the
+		 * Set a custom {@link com.crawljax.core.state.StateVertexFactory} to be able to use your
+		 * own {@link com.crawljax.core.state.StateVertex} objects. This is useful when you want to
+		 * have a custom comparator in the stateflowgraph which relies on the
+		 * {@link Object#hashCode()} or {@link Object#equals(Object)} of the
 		 * {@link com.crawljax.core.state.StateVertex}.
 		 *
-		 * @param vertexFactory The factory you want to use.
+		 * @param vertexFactory
+		 *            The factory you want to use.
 		 * @return The builder for method chaining.
 		 */
 		public CrawljaxConfigurationBuilder setStateVertexFactory(StateVertexFactory vertexFactory) {
@@ -171,8 +181,10 @@
 		 * Set the output folder for any {@link Plugin} you might configure. Crawljax itself doesn't
 		 * need an output folder but many plug-ins do.
 		 *
-		 * @param output The output folder. If it does not exist it will be created.
-		 * @throws IllegalStateException if the specified file is not writable or exists but isn't a folder.
+		 * @param output
+		 *            The output folder. If it does not exist it will be created.
+		 * @throws IllegalStateException
+		 *             if the specified file is not writable or exists but isn't a folder.
 		 */
 		public CrawljaxConfigurationBuilder setOutputDirectory(File output) {
 			config.output = output;
@@ -183,13 +195,12 @@
 		private void checkOutputDirWritable() {
 			if (!config.output.exists()) {
 				Preconditions.checkState(config.output.mkdirs(),
-				  ""Could not create the output directory %s "", config.output);
-			}
-			else {
+				        ""Could not create the output directory %s "", config.output);
+			} else {
 				Preconditions.checkArgument(config.output.isDirectory(),
-				  ""Output directory %s is not a folder"", config.output);
+				        ""Output directory %s is not a folder"", config.output);
 				Preconditions.checkState(config.output.canWrite(),
-				  ""Output directory %s is not writable"", config.output);
+				        ""Output directory %s is not writable"", config.output);
 			}
 		}
 
@@ -202,7 +213,8 @@
 	}
 
 	/**
-	 * @param url The url you want to setup a configuration for
+	 * @param url
+	 *            The url you want to setup a configuration for
 	 * @return The builder to configure the crawler.
 	 */
 	public static CrawljaxConfigurationBuilder builderFor(URI url) {
@@ -211,7 +223,8 @@
 	}
 
 	/**
-	 * @param url The url you want to setup a configuration for
+	 * @param url
+	 *            The url you want to setup a configuration for
 	 * @return The builder to configure the crawler.
 	 */
 	public static CrawljaxConfigurationBuilder builderFor(String url) {
@@ -219,6 +232,7 @@
 	}
 
 	private URI url;
+	private URI basicAuthUrl;
 
 	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.FIREFOX);
 	private ImmutableList<Plugin> plugins;
@@ -227,8 +241,7 @@
 	private CrawlRules crawlRules;
 
 	private int maximumStates = 0;
-	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);
-	;
+	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);;
 	private int maximumDepth = 2;
 	private File output = new File(""out"");
 
@@ -241,6 +254,10 @@
 		return url;
 	}
 
+	public URI getBasicAuthUrl() {
+		return basicAuthUrl;
+	}
+
 	public BrowserConfiguration getBrowserConfig() {
 		return browserConfig;
 	}
@@ -273,7 +290,6 @@
 		return output;
 	}
 
-
 	public StateVertexFactory getStateVertexFactory() {
 		return stateVertexFactory;
 	}
@@ -281,7 +297,7 @@
 	@Override
 	public int hashCode() {
 		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
-		  maximumStates, maximumRuntime, maximumDepth);
+		        maximumStates, maximumRuntime, maximumDepth);
 	}
 
 	@Override
@@ -289,29 +305,24 @@
 		if (object instanceof CrawljaxConfiguration) {
 			CrawljaxConfiguration that = (CrawljaxConfiguration) object;
 			return Objects.equal(this.url, that.url)
-			  && Objects.equal(this.browserConfig, that.browserConfig)
-			  && Objects.equal(this.plugins, that.plugins)
-			  && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
-			  && Objects.equal(this.crawlRules, that.crawlRules)
-			  && Objects.equal(this.maximumStates, that.maximumStates)
-			  && Objects.equal(this.maximumRuntime, that.maximumRuntime)
-			  && Objects.equal(this.maximumDepth, that.maximumDepth);
+			        && Objects.equal(this.browserConfig, that.browserConfig)
+			        && Objects.equal(this.plugins, that.plugins)
+			        && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
+			        && Objects.equal(this.crawlRules, that.crawlRules)
+			        && Objects.equal(this.maximumStates, that.maximumStates)
+			        && Objects.equal(this.maximumRuntime, that.maximumRuntime)
+			        && Objects.equal(this.maximumDepth, that.maximumDepth);
 		}
 		return false;
 	}
 
 	@Override
 	public String toString() {
-		return Objects.toStringHelper(this)
-					  .add(""url"", url)
-					  .add(""browserConfig"", browserConfig)
-					  .add(""plugins"", plugins)
-					  .add(""proxyConfiguration"", proxyConfiguration)
-					  .add(""crawlRules"", crawlRules)
-					  .add(""maximumStates"", maximumStates)
-					  .add(""maximumRuntime"", maximumRuntime)
-					  .add(""maximumDepth"", maximumDepth)
-					  .toString();
+		return Objects.toStringHelper(this).add(""url"", url).add(""browserConfig"", browserConfig)
+		        .add(""plugins"", plugins).add(""proxyConfiguration"", proxyConfiguration)
+		        .add(""crawlRules"", crawlRules).add(""maximumStates"", maximumStates)
+		        .add(""maximumRuntime"", maximumRuntime).add(""maximumDepth"", maximumDepth)
+		        .toString();
 	}
 
 }
\ No newline at end of file
"
796fea3e52df38d1d40c6537c856bff1fe1b0537,Ali Mesbah,WebDriverBackedEmbeddedBrowser.java,MODIFY,"withRemoteDriver -> [String hubUrl] | [String hubUrl, ImmutableSortedSet filterAttributes, long crawlWaitEvent, long crawlWaitReload]","diff --git a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
index 41cd3de..bb40117 100644
--- a/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
+++ b/core/src/main/java/com/crawljax/browser/WebDriverBackedEmbeddedBrowser.java
@@ -375,7 +375,7 @@
 		String htmlFormatted = m.replaceAll("""");
 
 		p = Pattern.compile(""<\\?xml:(.*?)>"");
-		m = p.matcher(html);
+		m = p.matcher(htmlFormatted);
 		htmlFormatted = m.replaceAll("""");
 
 		htmlFormatted = filterAttributes(htmlFormatted);
"
796fea3e52df38d1d40c6537c856bff1fe1b0537,Ali Mesbah,CrawljaxConfiguration.java,MODIFY,builderFor -> [String url] | [URI url],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
index 869887c..b327a10 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawljaxConfiguration.java
@@ -41,28 +41,30 @@
 		 * href=""http://en.wikipedia.org/wiki/Basic_access_authentication"">Basic auth</a> you can
 		 * set the username and password here.
 		 *
-		 * @param username The username for the website.
-		 * @param password The password for the website.
+		 * @param username
+		 *            The username for the website.
+		 * @param password
+		 *            The password for the website.
 		 * @return {@link CrawljaxConfigurationBuilder} for method chaining.
 		 */
 		public CrawljaxConfigurationBuilder setBasicAuth(String username, String password) {
 			try {
 				String encodedUsername = URLEncoder.encode(username, ""UTF-8"");
 				String encodedPassword = URLEncoder.encode(password, ""UTF-8"");
-				config.url = URI.create(config.url.getScheme()
-				  + ""://"" + encodedUsername
-				  + "":"" + encodedPassword + ""@"" + config.url.getAuthority()
-				  + config.url.getPath());
-			}
-			catch (UnsupportedEncodingException e) {
+				String hostPrefix = encodedUsername + "":"" + encodedPassword + ""@"";
+				config.basicAuthUrl =
+				        URI.create(config.url.toString().replaceFirst(""://"", ""://"" + hostPrefix));
+
+			} catch (UnsupportedEncodingException e) {
 				throw new CrawljaxException(""Could not parse the username/password to a URL"", e);
 			}
 			return this;
 		}
 
 		/**
-		 * @param states The maximum number of states the Crawler should crawl. The default is
-		 *               unlimited.
+		 * @param states
+		 *            The maximum number of states the Crawler should crawl. The default is
+		 *            unlimited.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumStates(int states) {
 			checkArgument(states > 1, ""Number of maximum states should be larger than 1"");
@@ -79,7 +81,8 @@
 		}
 
 		/**
-		 * @param time The maximum time the crawler should run. Default is one hour.
+		 * @param time
+		 *            The maximum time the crawler should run. Default is one hour.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumRunTime(long time, TimeUnit unit) {
 			checkArgument(time >= 0, ""Time should be larger than 0, or 0 for infinate."");
@@ -96,11 +99,12 @@
 		}
 
 		/**
-		 * @param depth The maximum depth the crawler can reach. The default is <code>2</code>.
+		 * @param depth
+		 *            The maximum depth the crawler can reach. The default is <code>2</code>.
 		 */
 		public CrawljaxConfigurationBuilder setMaximumDepth(int depth) {
 			Preconditions.checkArgument(depth >= 0,
-			  ""Depth should be 0 for infinite, or larger for a certain depth."");
+			        ""Depth should be 0 for infinite, or larger for a certain depth."");
 			config.maximumDepth = depth;
 			return this;
 		}
@@ -120,7 +124,8 @@
 		 * You can call this method several times to add multiple plugins
 		 * </p>
 		 *
-		 * @param plugins the plugins you would like to enable.
+		 * @param plugins
+		 *            the plugins you would like to enable.
 		 */
 		public CrawljaxConfigurationBuilder addPlugin(Plugin... plugins) {
 			pluginBuilder.add(plugins);
@@ -128,7 +133,8 @@
 		}
 
 		/**
-		 * @param configuration The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
+		 * @param configuration
+		 *            The proxy configuration. Default is {@link ProxyConfiguration#noProxy()}
 		 */
 		public CrawljaxConfigurationBuilder setProxyConfig(ProxyConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -144,8 +150,9 @@
 		}
 
 		/**
-		 * @param configuration a custom {@link BrowserConfiguration}. The default is a single
-		 *                      {@link BrowserType#FIREFOX} browser.
+		 * @param configuration
+		 *            a custom {@link BrowserConfiguration}. The default is a single
+		 *            {@link BrowserType#FIREFOX} browser.
 		 */
 		public CrawljaxConfigurationBuilder setBrowserConfig(BrowserConfiguration configuration) {
 			Preconditions.checkNotNull(configuration);
@@ -154,13 +161,14 @@
 		}
 
 		/**
-		 * Set a custom {@link com.crawljax.core.state.StateVertexFactory} to be able to use your own
-		 * {@link com.crawljax.core.state.StateVertex} objects. This is useful when you want to have a custom
-		 * comparator
-		 * in the stateflowgraph which relies on the {@link Object#hashCode()} or {@link Object#equals(Object)} of the
+		 * Set a custom {@link com.crawljax.core.state.StateVertexFactory} to be able to use your
+		 * own {@link com.crawljax.core.state.StateVertex} objects. This is useful when you want to
+		 * have a custom comparator in the stateflowgraph which relies on the
+		 * {@link Object#hashCode()} or {@link Object#equals(Object)} of the
 		 * {@link com.crawljax.core.state.StateVertex}.
 		 *
-		 * @param vertexFactory The factory you want to use.
+		 * @param vertexFactory
+		 *            The factory you want to use.
 		 * @return The builder for method chaining.
 		 */
 		public CrawljaxConfigurationBuilder setStateVertexFactory(StateVertexFactory vertexFactory) {
@@ -173,8 +181,10 @@
 		 * Set the output folder for any {@link Plugin} you might configure. Crawljax itself doesn't
 		 * need an output folder but many plug-ins do.
 		 *
-		 * @param output The output folder. If it does not exist it will be created.
-		 * @throws IllegalStateException if the specified file is not writable or exists but isn't a folder.
+		 * @param output
+		 *            The output folder. If it does not exist it will be created.
+		 * @throws IllegalStateException
+		 *             if the specified file is not writable or exists but isn't a folder.
 		 */
 		public CrawljaxConfigurationBuilder setOutputDirectory(File output) {
 			config.output = output;
@@ -185,13 +195,12 @@
 		private void checkOutputDirWritable() {
 			if (!config.output.exists()) {
 				Preconditions.checkState(config.output.mkdirs(),
-				  ""Could not create the output directory %s "", config.output);
-			}
-			else {
+				        ""Could not create the output directory %s "", config.output);
+			} else {
 				Preconditions.checkArgument(config.output.isDirectory(),
-				  ""Output directory %s is not a folder"", config.output);
+				        ""Output directory %s is not a folder"", config.output);
 				Preconditions.checkState(config.output.canWrite(),
-				  ""Output directory %s is not writable"", config.output);
+				        ""Output directory %s is not writable"", config.output);
 			}
 		}
 
@@ -204,7 +213,8 @@
 	}
 
 	/**
-	 * @param url The url you want to setup a configuration for
+	 * @param url
+	 *            The url you want to setup a configuration for
 	 * @return The builder to configure the crawler.
 	 */
 	public static CrawljaxConfigurationBuilder builderFor(URI url) {
@@ -213,7 +223,8 @@
 	}
 
 	/**
-	 * @param url The url you want to setup a configuration for
+	 * @param url
+	 *            The url you want to setup a configuration for
 	 * @return The builder to configure the crawler.
 	 */
 	public static CrawljaxConfigurationBuilder builderFor(String url) {
@@ -221,6 +232,7 @@
 	}
 
 	private URI url;
+	private URI basicAuthUrl;
 
 	private BrowserConfiguration browserConfig = new BrowserConfiguration(BrowserType.FIREFOX);
 	private ImmutableList<Plugin> plugins;
@@ -229,8 +241,7 @@
 	private CrawlRules crawlRules;
 
 	private int maximumStates = 0;
-	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);
-	;
+	private long maximumRuntime = TimeUnit.HOURS.toMillis(1);;
 	private int maximumDepth = 2;
 	private File output = new File(""out"");
 
@@ -243,6 +254,10 @@
 		return url;
 	}
 
+	public URI getBasicAuthUrl() {
+		return basicAuthUrl;
+	}
+
 	public BrowserConfiguration getBrowserConfig() {
 		return browserConfig;
 	}
@@ -275,7 +290,6 @@
 		return output;
 	}
 
-
 	public StateVertexFactory getStateVertexFactory() {
 		return stateVertexFactory;
 	}
@@ -283,7 +297,7 @@
 	@Override
 	public int hashCode() {
 		return Objects.hashCode(url, browserConfig, plugins, proxyConfiguration, crawlRules,
-		  maximumStates, maximumRuntime, maximumDepth);
+		        maximumStates, maximumRuntime, maximumDepth);
 	}
 
 	@Override
@@ -291,29 +305,24 @@
 		if (object instanceof CrawljaxConfiguration) {
 			CrawljaxConfiguration that = (CrawljaxConfiguration) object;
 			return Objects.equal(this.url, that.url)
-			  && Objects.equal(this.browserConfig, that.browserConfig)
-			  && Objects.equal(this.plugins, that.plugins)
-			  && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
-			  && Objects.equal(this.crawlRules, that.crawlRules)
-			  && Objects.equal(this.maximumStates, that.maximumStates)
-			  && Objects.equal(this.maximumRuntime, that.maximumRuntime)
-			  && Objects.equal(this.maximumDepth, that.maximumDepth);
+			        && Objects.equal(this.browserConfig, that.browserConfig)
+			        && Objects.equal(this.plugins, that.plugins)
+			        && Objects.equal(this.proxyConfiguration, that.proxyConfiguration)
+			        && Objects.equal(this.crawlRules, that.crawlRules)
+			        && Objects.equal(this.maximumStates, that.maximumStates)
+			        && Objects.equal(this.maximumRuntime, that.maximumRuntime)
+			        && Objects.equal(this.maximumDepth, that.maximumDepth);
 		}
 		return false;
 	}
 
 	@Override
 	public String toString() {
-		return Objects.toStringHelper(this)
-					  .add(""url"", url)
-					  .add(""browserConfig"", browserConfig)
-					  .add(""plugins"", plugins)
-					  .add(""proxyConfiguration"", proxyConfiguration)
-					  .add(""crawlRules"", crawlRules)
-					  .add(""maximumStates"", maximumStates)
-					  .add(""maximumRuntime"", maximumRuntime)
-					  .add(""maximumDepth"", maximumDepth)
-					  .toString();
+		return Objects.toStringHelper(this).add(""url"", url).add(""browserConfig"", browserConfig)
+		        .add(""plugins"", plugins).add(""proxyConfiguration"", proxyConfiguration)
+		        .add(""crawlRules"", crawlRules).add(""maximumStates"", maximumStates)
+		        .add(""maximumRuntime"", maximumRuntime).add(""maximumDepth"", maximumDepth)
+		        .toString();
 	}
 
 }
\ No newline at end of file
"
796fea3e52df38d1d40c6537c856bff1fe1b0537,Ali Mesbah,RunWithWebServer.java,MODIFY,newConfigBuilder -> [String context] | [],"diff --git a/core/src/test/java/com/crawljax/test/RunWithWebServer.java b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
index 6229ff1..9f3cc2f 100644
--- a/core/src/test/java/com/crawljax/test/RunWithWebServer.java
+++ b/core/src/test/java/com/crawljax/test/RunWithWebServer.java
@@ -2,16 +2,17 @@
 
 import java.net.URI;
 
+import com.crawljax.browser.BrowserProvider;
+import com.crawljax.core.configuration.BrowserConfiguration;
+import com.crawljax.core.configuration.CrawljaxConfiguration;
+import com.crawljax.core.configuration.CrawljaxConfiguration.CrawljaxConfigurationBuilder;
+import com.google.common.base.Preconditions;
 import org.eclipse.jetty.server.Server;
 import org.eclipse.jetty.server.ServerConnector;
 import org.eclipse.jetty.server.handler.ResourceHandler;
 import org.eclipse.jetty.util.resource.Resource;
 import org.junit.rules.ExternalResource;
 
-import com.crawljax.core.configuration.CrawljaxConfiguration;
-import com.crawljax.core.configuration.CrawljaxConfiguration.CrawljaxConfigurationBuilder;
-import com.google.common.base.Preconditions;
-
 public class RunWithWebServer extends ExternalResource {
 
 	private final Resource resource;
@@ -22,8 +23,7 @@
 	private boolean started;
 
 	/**
-	 * @param classPathResource
-	 *            The name of the resource. This resource must be on the test or regular classpath.
+	 * @param classPathResource The name of the resource. This resource must be on the test or regular classpath.
 	 */
 	public RunWithWebServer(String classPathResource) {
 		resource = Resource.newClassPathResource(classPathResource);
@@ -40,7 +40,7 @@
 
 	/**
 	 * Override this method to configure custom server settings.
-	 * 
+	 *
 	 * @return a {@link Server}.
 	 */
 	protected Server newWebServer() {
@@ -57,7 +57,8 @@
 			if (server != null) {
 				server.stop();
 			}
-		} catch (Exception e) {
+		}
+		catch (Exception e) {
 			throw new RuntimeException(""Could not stop the server"", e);
 		}
 	}
@@ -73,11 +74,13 @@
 	}
 
 	public CrawljaxConfigurationBuilder newConfigBuilder() {
-		return CrawljaxConfiguration.builderFor(getSiteUrl());
+		return CrawljaxConfiguration.builderFor(getSiteUrl())
+		                            .setBrowserConfig(new BrowserConfiguration(BrowserProvider.getBrowserType()));
 	}
 
 	public CrawljaxConfigurationBuilder newConfigBuilder(String context) {
-		return CrawljaxConfiguration.builderFor(getSiteUrl() + context);
+		return CrawljaxConfiguration.builderFor(getSiteUrl() + context)
+		                            .setBrowserConfig(new BrowserConfiguration(BrowserProvider.getBrowserType()));
 	}
 
 	public void stop() throws Exception {
"
b1528d6e4d432b80f32a54616355862c29df6862,Noriaki Tatsumi,InMemoryStateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
index b71c424..72f39d3 100644
--- a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
@@ -4,10 +4,7 @@
 import javax.inject.Singleton;
 
 import java.io.Serializable;
-import java.util.ArrayList;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
+import java.util.*;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.locks.Lock;
@@ -50,7 +47,8 @@
 	 */
 	private final AtomicInteger stateCounter = new AtomicInteger();
 	private final AtomicInteger nextStateNameCounter = new AtomicInteger();
-	private final ConcurrentMap<Integer, StateVertex> stateById;
+	private final Map<Integer, StateVertex> stateById;
+
 	private final ExitNotifier exitNotifier;
 	private final StateVertexFactory vertexFactory;
 
@@ -65,7 +63,7 @@
 		this.exitNotifier = exitNotifier;
 		this.vertexFactory = vertexFactory;
 		sfg = new DirectedMultigraph<>(Eventable.class);
-		stateById = Maps.newConcurrentMap();
+		stateById = Collections.synchronizedMap(new HashMap<Integer, StateVertex>());
 		LOG.debug(""Initialized the stateflowgraph"");
 		ReadWriteLock lock = new ReentrantReadWriteLock();
 		readLock = lock.readLock();
"
73eb51233a2feacf7ef7c52ac78102fe75d9910e,Noriaki Tatsumi,FormHandler.java,MODIFY,"handleCheckBoxes -> [Node element, FormInput input] | [FormInput input]","diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index ea780e2..82b6ca8 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -1,20 +1,5 @@
 package com.crawljax.forms;
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.List;
-
-import javax.inject.Inject;
-import javax.xml.xpath.XPathExpressionException;
-
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-import org.w3c.dom.Document;
-import org.w3c.dom.Element;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.CandidateElement;
@@ -23,6 +8,20 @@
 import com.crawljax.util.DomUtils;
 import com.crawljax.util.XPathHelper;
 import com.google.inject.assistedinject.Assisted;
+import org.openqa.selenium.WebElement;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.w3c.dom.Document;
+import org.w3c.dom.Element;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+
+import javax.inject.Inject;
+import javax.xml.xpath.XPathExpressionException;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
 
 /**
  * Handles form values and fills in the form input elements with random values of the defined
@@ -52,8 +51,7 @@
 	{ ""text"", ""radio"", ""checkbox"", ""password"" };
 
 	/**
-	 * Fills in the element with the InputValues for input TODO: improve this by using WebDriver
-	 * options?
+	 * Fills in the element with the InputValues for input
 	 */
 	private void setInputElementValue(Node element, FormInput input) {
 
@@ -65,13 +63,13 @@
 			if (input.getType().toLowerCase().startsWith(""text"")
 			        || input.getType().equalsIgnoreCase(""password"")
 			        || input.getType().equalsIgnoreCase(""hidden"")) {
-				handleText(element, input);
+				handleText(input);
 			} else if (""checkbox"".equals(input.getType())) {
-				handleCheckBoxes(element, input);
+				handleCheckBoxes(input);
 			} else if (input.getType().equals(""radio"")) {
-				handleRadioSwitches(element, input);
+				handleRadioSwitches(input);
 			} else if (input.getType().startsWith(""select"")) {
-				handleSelectBoxes(element, input);
+				handleSelectBoxes(input);
 			}
 		} catch (BrowserConnectionException e) {
 			throw e;
@@ -80,66 +78,48 @@
 		}
 	}
 
-	private void handleCheckBoxes(Node element, FormInput input) {
-		for (InputValue inputValue : input.getInputValues()) {
-			String js =
-			        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-			boolean check;
-			if (!randomFieldValue) {
-				check = inputValue.isChecked();
-			} else {
+    private void handleCheckBoxes(FormInput input) {
+        for (InputValue inputValue : input.getInputValues()) {
+            boolean check;
+            if (!randomFieldValue) {
+                check = inputValue.isChecked();
+            } else {
 
-				check = Math.random() >= HALF;
-			}
-			String value;
-			if (check) {
-				value = ""true"";
-			} else {
-				value = ""false"";
-			}
-			js += ""try{ATUSA_element.checked="" + value + "";}catch(e){}"";
-			browser.executeJavaScript(js);
+                check = Math.random() >= HALF;
+            }
+            WebElement inputElement = browser.getWebElement(input.getIdentification());
+            if (check && !inputElement.isSelected()) {
+                inputElement.click();
+            } else if (!check && inputElement.isSelected()) {
+                inputElement.click();
+            }
+        }
+    }
 
-		}
-	}
+    private void handleRadioSwitches(FormInput input) {
+        for (InputValue inputValue : input.getInputValues()) {
+            if (inputValue.isChecked()) {
+                WebElement inputElement = browser.getWebElement(input.getIdentification());
+                inputElement.click();
+            }
+        }
+    }
 
-	private void handleRadioSwitches(Node element, FormInput input) {
-		for (InputValue inputValue : input.getInputValues()) {
-			if (inputValue.isChecked()) {
-				String js =
-				        DomUtils.getJSGetElement(XPathHelper
-				                .getXPathExpression(element));
-				js += ""try{ATUSA_element.checked=true;}catch(e){}"";
-				browser.executeJavaScript(js);
-			}
-		}
-	}
+    private void handleSelectBoxes(FormInput input) {
+        for (InputValue inputValue : input.getInputValues()) {
+            WebElement inputElement = browser.getWebElement(input.getIdentification());
+            inputElement.sendKeys(inputValue.getValue());
+        }
+    }
 
-	private void handleSelectBoxes(Node element, FormInput input) {
-		for (InputValue inputValue : input.getInputValues()) {
-			String js =
-			        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-			js +=
-			        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
-			                + ""if(ATUSA_element.options[i].value=='""
-			                + inputValue.getValue()
-			                + ""' || ATUSA_element.options[i].text=='""
-			                + inputValue.getValue() + ""'){""
-			                + ""ATUSA_element.options[i].selected=true;"" + ""break;""
-			                + ""}"" + ""};"" + ""}catch(e){}"";
-			browser.executeJavaScript(js);
-		}
-	}
-
-	private void handleText(Node element, FormInput input) {
-		String text = input.getInputValues().iterator().next().getValue();
-		if ("""".equals(text)) {
-			return;
-		}
-		String js = DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-		js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
-		browser.executeJavaScript(js);
-	}
+    private void handleText(FormInput input) {
+        String text = input.getInputValues().iterator().next().getValue();
+        if (null == text || text.length() == 0) {
+            return;
+        }
+        WebElement inputElement = browser.getWebElement(input.getIdentification());
+        inputElement.sendKeys(text);
+    }
 
 	/**
 	 * @return all input element in dom
"
73eb51233a2feacf7ef7c52ac78102fe75d9910e,Noriaki Tatsumi,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index 3e16f5b..93729c0 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -437,54 +437,6 @@
 	}
 
 	/**
-	 * @param xpath
-	 *            The xpath of the element.
-	 * @return The JavaScript to get an element.
-	 */
-	public static String getJSGetElement(String xpath) {
-		String js =
-		        ""function ATUSA_getElementInNodes(nodes, tagName, number){""
-		                + ""try{""
-		                + ""var pos = 1;""
-		                + ""for(i=0; i<nodes.length; i++){""
-		                + ""if(nodes[i]!=null && nodes[i].tagName!=null && ""
-		                + ""nodes[i].tagName.toLowerCase() == tagName){""
-		                + ""if(number==pos){""
-		                + ""return nodes[i];""
-		                + ""}else{""
-		                + ""pos++;""
-		                + ""}""
-		                + ""}""
-		                + ""}""
-		                + ""}catch(e){}""
-		                + ""return null;""
-		                + ""}""
-		                + ""function ATUSA_getElementByXpath(xpath){""
-		                + ""try{""
-		                + ""var elements = xpath.toLowerCase().split('/');""
-		                + ""var curNode = window.document.body;""
-		                + ""var tagName, number;""
-		                + ""for(j=0; j<elements.length; j++){""
-		                + ""if(elements[j]!=''){""
-		                + ""if(elements[j].indexOf('[')==-1){""
-		                + ""tagName = elements[j];""
-		                + ""number = 1;""
-		                + ""}else{""
-		                + ""tagName = elements[j].substring(0, elements[j].indexOf('['));""
-		                + ""number = elements[j].substring(elements[j].indexOf('[')+1, ""
-		                + ""elements[j].lastIndexOf(']'));""
-		                + ""}""
-		                + ""if(tagName!='body' && tagName!='html'){""
-		                + ""curNode = ATUSA_getElementInNodes(curNode.childNodes, tagName, number);""
-		                + ""if(curNode==null){"" + ""return null;"" + ""}"" + ""}"" + ""}"" + ""}""
-		                + ""}catch(e){return null;}"" + ""return curNode;"" + ""}""
-		                + ""try{var ATUSA_element = ATUSA_getElementByXpath('"" + xpath
-		                + ""');}catch(e){return null;}"";
-
-		return js;
-	}
-
-	/**
 	 * @param frame
 	 *            the frame element.
 	 * @return the name or id of this element if they are present, otherwise null.
"
95954e8e0fe3165781931b46b8fea75d71994790,Ali Mesbah,FormHandler.java,MODIFY,handleFormElements -> [List formInputs] | [],"diff --git a/core/src/main/java/com/crawljax/forms/FormHandler.java b/core/src/main/java/com/crawljax/forms/FormHandler.java
index ea780e2..82b6ca8 100644
--- a/core/src/main/java/com/crawljax/forms/FormHandler.java
+++ b/core/src/main/java/com/crawljax/forms/FormHandler.java
@@ -1,20 +1,5 @@
 package com.crawljax.forms;
 
-import java.io.IOException;
-import java.util.ArrayList;
-import java.util.Arrays;
-import java.util.List;
-
-import javax.inject.Inject;
-import javax.xml.xpath.XPathExpressionException;
-
-import org.slf4j.Logger;
-import org.slf4j.LoggerFactory;
-import org.w3c.dom.Document;
-import org.w3c.dom.Element;
-import org.w3c.dom.Node;
-import org.w3c.dom.NodeList;
-
 import com.crawljax.browser.EmbeddedBrowser;
 import com.crawljax.condition.eventablecondition.EventableCondition;
 import com.crawljax.core.CandidateElement;
@@ -23,6 +8,20 @@
 import com.crawljax.util.DomUtils;
 import com.crawljax.util.XPathHelper;
 import com.google.inject.assistedinject.Assisted;
+import org.openqa.selenium.WebElement;
+import org.slf4j.Logger;
+import org.slf4j.LoggerFactory;
+import org.w3c.dom.Document;
+import org.w3c.dom.Element;
+import org.w3c.dom.Node;
+import org.w3c.dom.NodeList;
+
+import javax.inject.Inject;
+import javax.xml.xpath.XPathExpressionException;
+import java.io.IOException;
+import java.util.ArrayList;
+import java.util.Arrays;
+import java.util.List;
 
 /**
  * Handles form values and fills in the form input elements with random values of the defined
@@ -52,8 +51,7 @@
 	{ ""text"", ""radio"", ""checkbox"", ""password"" };
 
 	/**
-	 * Fills in the element with the InputValues for input TODO: improve this by using WebDriver
-	 * options?
+	 * Fills in the element with the InputValues for input
 	 */
 	private void setInputElementValue(Node element, FormInput input) {
 
@@ -65,13 +63,13 @@
 			if (input.getType().toLowerCase().startsWith(""text"")
 			        || input.getType().equalsIgnoreCase(""password"")
 			        || input.getType().equalsIgnoreCase(""hidden"")) {
-				handleText(element, input);
+				handleText(input);
 			} else if (""checkbox"".equals(input.getType())) {
-				handleCheckBoxes(element, input);
+				handleCheckBoxes(input);
 			} else if (input.getType().equals(""radio"")) {
-				handleRadioSwitches(element, input);
+				handleRadioSwitches(input);
 			} else if (input.getType().startsWith(""select"")) {
-				handleSelectBoxes(element, input);
+				handleSelectBoxes(input);
 			}
 		} catch (BrowserConnectionException e) {
 			throw e;
@@ -80,66 +78,48 @@
 		}
 	}
 
-	private void handleCheckBoxes(Node element, FormInput input) {
-		for (InputValue inputValue : input.getInputValues()) {
-			String js =
-			        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-			boolean check;
-			if (!randomFieldValue) {
-				check = inputValue.isChecked();
-			} else {
+    private void handleCheckBoxes(FormInput input) {
+        for (InputValue inputValue : input.getInputValues()) {
+            boolean check;
+            if (!randomFieldValue) {
+                check = inputValue.isChecked();
+            } else {
 
-				check = Math.random() >= HALF;
-			}
-			String value;
-			if (check) {
-				value = ""true"";
-			} else {
-				value = ""false"";
-			}
-			js += ""try{ATUSA_element.checked="" + value + "";}catch(e){}"";
-			browser.executeJavaScript(js);
+                check = Math.random() >= HALF;
+            }
+            WebElement inputElement = browser.getWebElement(input.getIdentification());
+            if (check && !inputElement.isSelected()) {
+                inputElement.click();
+            } else if (!check && inputElement.isSelected()) {
+                inputElement.click();
+            }
+        }
+    }
 
-		}
-	}
+    private void handleRadioSwitches(FormInput input) {
+        for (InputValue inputValue : input.getInputValues()) {
+            if (inputValue.isChecked()) {
+                WebElement inputElement = browser.getWebElement(input.getIdentification());
+                inputElement.click();
+            }
+        }
+    }
 
-	private void handleRadioSwitches(Node element, FormInput input) {
-		for (InputValue inputValue : input.getInputValues()) {
-			if (inputValue.isChecked()) {
-				String js =
-				        DomUtils.getJSGetElement(XPathHelper
-				                .getXPathExpression(element));
-				js += ""try{ATUSA_element.checked=true;}catch(e){}"";
-				browser.executeJavaScript(js);
-			}
-		}
-	}
+    private void handleSelectBoxes(FormInput input) {
+        for (InputValue inputValue : input.getInputValues()) {
+            WebElement inputElement = browser.getWebElement(input.getIdentification());
+            inputElement.sendKeys(inputValue.getValue());
+        }
+    }
 
-	private void handleSelectBoxes(Node element, FormInput input) {
-		for (InputValue inputValue : input.getInputValues()) {
-			String js =
-			        DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-			js +=
-			        ""try{"" + ""for(i=0; i<ATUSA_element.options.length; i++){""
-			                + ""if(ATUSA_element.options[i].value=='""
-			                + inputValue.getValue()
-			                + ""' || ATUSA_element.options[i].text=='""
-			                + inputValue.getValue() + ""'){""
-			                + ""ATUSA_element.options[i].selected=true;"" + ""break;""
-			                + ""}"" + ""};"" + ""}catch(e){}"";
-			browser.executeJavaScript(js);
-		}
-	}
-
-	private void handleText(Node element, FormInput input) {
-		String text = input.getInputValues().iterator().next().getValue();
-		if ("""".equals(text)) {
-			return;
-		}
-		String js = DomUtils.getJSGetElement(XPathHelper.getXPathExpression(element));
-		js += ""try{ATUSA_element.value='"" + text + ""';}catch(e){}"";
-		browser.executeJavaScript(js);
-	}
+    private void handleText(FormInput input) {
+        String text = input.getInputValues().iterator().next().getValue();
+        if (null == text || text.length() == 0) {
+            return;
+        }
+        WebElement inputElement = browser.getWebElement(input.getIdentification());
+        inputElement.sendKeys(text);
+    }
 
 	/**
 	 * @return all input element in dom
"
95954e8e0fe3165781931b46b8fea75d71994790,Ali Mesbah,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index 3e16f5b..93729c0 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -437,54 +437,6 @@
 	}
 
 	/**
-	 * @param xpath
-	 *            The xpath of the element.
-	 * @return The JavaScript to get an element.
-	 */
-	public static String getJSGetElement(String xpath) {
-		String js =
-		        ""function ATUSA_getElementInNodes(nodes, tagName, number){""
-		                + ""try{""
-		                + ""var pos = 1;""
-		                + ""for(i=0; i<nodes.length; i++){""
-		                + ""if(nodes[i]!=null && nodes[i].tagName!=null && ""
-		                + ""nodes[i].tagName.toLowerCase() == tagName){""
-		                + ""if(number==pos){""
-		                + ""return nodes[i];""
-		                + ""}else{""
-		                + ""pos++;""
-		                + ""}""
-		                + ""}""
-		                + ""}""
-		                + ""}catch(e){}""
-		                + ""return null;""
-		                + ""}""
-		                + ""function ATUSA_getElementByXpath(xpath){""
-		                + ""try{""
-		                + ""var elements = xpath.toLowerCase().split('/');""
-		                + ""var curNode = window.document.body;""
-		                + ""var tagName, number;""
-		                + ""for(j=0; j<elements.length; j++){""
-		                + ""if(elements[j]!=''){""
-		                + ""if(elements[j].indexOf('[')==-1){""
-		                + ""tagName = elements[j];""
-		                + ""number = 1;""
-		                + ""}else{""
-		                + ""tagName = elements[j].substring(0, elements[j].indexOf('['));""
-		                + ""number = elements[j].substring(elements[j].indexOf('[')+1, ""
-		                + ""elements[j].lastIndexOf(']'));""
-		                + ""}""
-		                + ""if(tagName!='body' && tagName!='html'){""
-		                + ""curNode = ATUSA_getElementInNodes(curNode.childNodes, tagName, number);""
-		                + ""if(curNode==null){"" + ""return null;"" + ""}"" + ""}"" + ""}"" + ""}""
-		                + ""}catch(e){return null;}"" + ""return curNode;"" + ""}""
-		                + ""try{var ATUSA_element = ATUSA_getElementByXpath('"" + xpath
-		                + ""');}catch(e){return null;}"";
-
-		return js;
-	}
-
-	/**
 	 * @param frame
 	 *            the frame element.
 	 * @return the name or id of this element if they are present, otherwise null.
"
9cb52ad3cd7e54e4595ef0e2488513d4dee84cde,Ali Mesbah,InMemoryStateFlowGraph.java,MODIFY,"putIfAbsent -> [StateVertex stateVertix, boolean correctName] | [StateVertex stateVertix]","diff --git a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
index b71c424..72f39d3 100644
--- a/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
+++ b/core/src/main/java/com/crawljax/core/state/InMemoryStateFlowGraph.java
@@ -4,10 +4,7 @@
 import javax.inject.Singleton;
 
 import java.io.Serializable;
-import java.util.ArrayList;
-import java.util.HashSet;
-import java.util.List;
-import java.util.Set;
+import java.util.*;
 import java.util.concurrent.ConcurrentMap;
 import java.util.concurrent.atomic.AtomicInteger;
 import java.util.concurrent.locks.Lock;
@@ -50,7 +47,8 @@
 	 */
 	private final AtomicInteger stateCounter = new AtomicInteger();
 	private final AtomicInteger nextStateNameCounter = new AtomicInteger();
-	private final ConcurrentMap<Integer, StateVertex> stateById;
+	private final Map<Integer, StateVertex> stateById;
+
 	private final ExitNotifier exitNotifier;
 	private final StateVertexFactory vertexFactory;
 
@@ -65,7 +63,7 @@
 		this.exitNotifier = exitNotifier;
 		this.vertexFactory = vertexFactory;
 		sfg = new DirectedMultigraph<>(Eventable.class);
-		stateById = Maps.newConcurrentMap();
+		stateById = Collections.synchronizedMap(new HashMap<Integer, StateVertex>());
 		LOG.debug(""Initialized the stateflowgraph"");
 		ReadWriteLock lock = new ReentrantReadWriteLock();
 		readLock = lock.readLock();
"
488618a8c58e8d6c443c246eea080839dad1baf2,Quinn Hanam,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/core/src/main/java/com/crawljax/core/CrawlQueue.java b/core/src/main/java/com/crawljax/core/CrawlQueue.java
index bb9e752..eb88690 100644
--- a/core/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/core/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -8,13 +8,15 @@
 import net.jcip.annotations.GuardedBy;
 
 /**
- * This class implements a BlockingQueue with Runnable as its Generic type and extends Stack with
- * also Runnable as generic type. This class is used in the ThreadPoolExecutor and its used to store
- * separate threads in a Queue like fashion (FILO).
+ * This class implements a BlockingQueue with Runnable as its Generic type and
+ * extends Stack with also Runnable as generic type. This class is used in the
+ * ThreadPoolExecutor and its used to store separate threads in a Queue like
+ * fashion (FILO).
  * 
- * @author Stefan Lenselink <S.R.Lenselink@student.tudelft.nl>
+ * @author Stefan Lenselink &lt;S.R.Lenselink@student.tudelft.nl&gt;
  */
-public class CrawlQueue extends Stack<Runnable> implements BlockingQueue<Runnable> {
+public class CrawlQueue extends Stack<Runnable> implements
+		BlockingQueue<Runnable> {
 
 	/**
 	 * Auto generated serialVersionUID.
@@ -27,7 +29,8 @@
 	}
 
 	@Override
-	public synchronized int drainTo(Collection<? super Runnable> c, int maxRunnablelements) {
+	public synchronized int drainTo(Collection<? super Runnable> c,
+			int maxRunnablelements) {
 		int counter = 0;
 		for (Runnable object : this) {
 			counter++;
"
488618a8c58e8d6c443c246eea080839dad1baf2,Quinn Hanam,CrawlActionsBuilder.java,MODIFY,click -> [String tagNames] | [String tagName],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
index 9dea6fe..b511d13 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
@@ -13,7 +13,8 @@
 
 public class CrawlActionsBuilder {
 
-	private static final Logger LOG = LoggerFactory.getLogger(CrawlActionsBuilder.class);
+	private static final Logger LOG = LoggerFactory
+			.getLogger(CrawlActionsBuilder.class);
 
 	public static class ExcludeByParentBuilder {
 		private final String tagname;
@@ -34,11 +35,14 @@
 		}
 
 		private String asExcludeXpath(String identifier, String value) {
-			return new StringBuilder().append(""//"").append(tagname.toUpperCase()).append(""[@"")
-			        .append(identifier).append(""='"").append(value).append(""']//*"").toString();
+			return new StringBuilder().append(""//"")
+					.append(tagname.toUpperCase()).append(""[@"")
+					.append(identifier).append(""='"").append(value)
+					.append(""']//*"").toString();
 		}
 
-		private ImmutableList<CrawlElement> asExcludeList(List<CrawlElement> includes) {
+		private ImmutableList<CrawlElement> asExcludeList(
+				List<CrawlElement> includes) {
 			String xpath;
 			if (id != null) {
 				xpath = asExcludeXpath(""id"", id);
@@ -47,26 +51,30 @@
 			} else {
 				xpath = ""//"" + tagname.toUpperCase() + ""//*"";
 			}
-			ImmutableList.Builder<CrawlElement> builder = ImmutableList.builder();
+			ImmutableList.Builder<CrawlElement> builder = ImmutableList
+					.builder();
 			for (CrawlElement include : includes) {
-				builder.add(new CrawlElement(EventType.click, include.getTagName())
-				        .underXPath(xpath));
+				builder.add(new CrawlElement(EventType.click, include
+						.getTagName()).underXPath(xpath));
 			}
 			return builder.build();
 		}
 	}
 
 	private final List<CrawlElement> crawlElements = Lists.newLinkedList();
-	private final List<CrawlElement> crawlElementsExcluded = Lists.newLinkedList();
-	private final List<ExcludeByParentBuilder> crawlParentsExcluded = Lists.newLinkedList();
+	private final List<CrawlElement> crawlElementsExcluded = Lists
+			.newLinkedList();
+	private final List<ExcludeByParentBuilder> crawlParentsExcluded = Lists
+			.newLinkedList();
 	private ImmutableList<CrawlElement> resultingElementsExcluded = null;
 
 	CrawlActionsBuilder() {
 	}
 
 	/**
-	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
-	 * click(""a"") will only include 1 if clickOnce is true (default). This set can be restricted by
+	 * Set of HTML elements Crawljax will click during crawling For exmple 1)
+	 * &gt;a.../&lt; 2) &lt;div/&gt; click(""a"") will only include 1 if clickOnce
+	 * is true (default). This set can be restricted by
 	 * {@link #dontClick(String)}.
 	 * 
 	 * @param tagName
@@ -76,15 +84,17 @@
 	public CrawlElement click(String tagName) {
 		checkNotRead();
 		Preconditions.checkNotNull(tagName, ""Tagname cannot be null"");
-		CrawlElement crawlTag = new CrawlElement(EventType.click, tagName.toUpperCase());
+		CrawlElement crawlTag = new CrawlElement(EventType.click,
+				tagName.toUpperCase());
 		crawlElements.add(crawlTag);
 		return crawlTag;
 	}
 
 	/**
-	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
-	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}. If
-	 * no clicks are specified, {@link #clickDefaultElements()} is enabled.
+	 * Set of HTML elements Crawljax will click during crawling For exmple 1)
+	 * &lt;a.../&gt; 2) &lt;div/&gt; click(""a"") will only include 1 This set can
+	 * be restricted by {@link #dontClick(String)}. If no clicks are specified,
+	 * {@link #clickDefaultElements()} is enabled.
 	 * 
 	 * @param tagNames
 	 *            the tag name of the elements to be included
@@ -96,8 +106,8 @@
 	}
 
 	/**
-	 * Specifies that Crawljax should click all the default clickable elements. These include: All
-	 * anchor tags All buttons
+	 * Specifies that Crawljax should click all the default clickable elements.
+	 * These include: All anchor tags All buttons
 	 */
 	public void clickDefaultElements() {
 		click(""a"");
@@ -108,14 +118,16 @@
 
 	private void checkNotRead() {
 		Preconditions.checkState(resultingElementsExcluded == null,
-		        ""You cannot modify crawlactions once it's read"");
+				""You cannot modify crawlactions once it's read"");
 	}
 
 	/**
-	 * Set of HTML elements Crawljax will NOT click during crawling When an HTML is present in the
-	 * click and dontClick sets, then the element will not be clicked. For example: 1) <a
-	 * href=""#"">Some text</a> 2) <a class=""foo"" .../> 3) <div class=""foo"" .../> click(""a"")
-	 * dontClick(""a"").withAttribute(""class"", ""foo""); Will include only include HTML element 2
+	 * Set of HTML elements Crawljax will NOT click during crawling When an HTML
+	 * is present in the click and dontClick sets, then the element will not be
+	 * clicked. For example: 1) &lt;a href=""#""&gt;Some text&lt;/a&gt; 2) &lt;a
+	 * class=""foo"" .../&gt; 3) &lt;div class=""foo"" .../&gt; click(""a"")
+	 * dontClick(""a"").withAttribute(""class"", ""foo""); Will include only include
+	 * HTML element 2
 	 * 
 	 * @param tagName
 	 *            the tag name of the elements to be excluded
@@ -124,7 +136,8 @@
 	public CrawlElement dontClick(String tagName) {
 		checkNotRead();
 		Preconditions.checkNotNull(tagName, ""Tagname cannot be null"");
-		CrawlElement crawlTag = new CrawlElement(EventType.click, tagName.toUpperCase());
+		CrawlElement crawlTag = new CrawlElement(EventType.click,
+				tagName.toUpperCase());
 		crawlElementsExcluded.add(crawlTag);
 		return crawlTag;
 	}
@@ -139,7 +152,8 @@
 	public ExcludeByParentBuilder dontClickChildrenOf(String tagname) {
 		checkNotRead();
 		Preconditions.checkNotNull(tagname);
-		ExcludeByParentBuilder exclude = new ExcludeByParentBuilder(tagname.toUpperCase());
+		ExcludeByParentBuilder exclude = new ExcludeByParentBuilder(
+				tagname.toUpperCase());
 		crawlParentsExcluded.add(exclude);
 		return exclude;
 	}
@@ -160,7 +174,8 @@
 	private ImmutableList<CrawlElement> getCrawlElementsExcluded() {
 		synchronized (this) {
 			if (resultingElementsExcluded == null) {
-				ImmutableList.Builder<CrawlElement> builder = ImmutableList.builder();
+				ImmutableList.Builder<CrawlElement> builder = ImmutableList
+						.builder();
 				builder.addAll(crawlElementsExcluded);
 				for (ExcludeByParentBuilder exclude : crawlParentsExcluded) {
 					builder.addAll(exclude.asExcludeList(crawlElements));
"
488618a8c58e8d6c443c246eea080839dad1baf2,Quinn Hanam,FormInputField.java,MODIFY,setValues -> [boolean values] | [String values],"diff --git a/core/src/main/java/com/crawljax/core/configuration/FormInputField.java b/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
index dc6e88c..fbb126c 100644
--- a/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
@@ -1,15 +1,17 @@
 package com.crawljax.core.configuration;
 
 /**
- * Represents a form input field NOTE: In general FormInputField is not designed to be instantiated
- * directly. For example: <input type=""text"" name=""foo"" /> <input type=""checkbox"" id=""bar"" />
- * FormInputSpecification input = new FormInputSpecification() Form form = new Form();
+ * Represents a form input field NOTE: In general FormInputField is not designed
+ * to be instantiated directly. For example: &lt;input type=""text"" name=""foo""
+ * /&gt; &lt;input type=""checkbox"" id=""bar"" /&gt; FormInputSpecification input =
+ * new FormInputSpecification() Form form = new Form();
  * input.field(""foo"").setValues(""Crawljax"", ""Crawler"", ""Automatic"");
  * input.field(""bar"").setValues(true, true, false);
- * input.setValuesInForm(contactForm).beforeClickTag(""a"").withText(""Search""); Crawljax will set the
- * text value of the foo text field and the bar checkbox three times when clicked on the anchor
- * element with the test Search to: 1) foo=Crawljax; bar=checked 2) foo=Crawler; bar=checked 3)
- * foo=Automatic; bar=unchecked
+ * input.setValuesInForm(contactForm).beforeClickTag(""a"").withText(""Search"");
+ * Crawljax will set the text value of the foo text field and the bar checkbox
+ * three times when clicked on the anchor element with the test Search to: 1)
+ * foo=Crawljax; bar=checked 2) foo=Crawler; bar=checked 3) foo=Automatic;
+ * bar=unchecked
  * 
  * @see Form
  * @see Form#field(String)
@@ -18,8 +20,8 @@
 public class FormInputField extends InputField {
 
 	/**
-	 * Sets the valus of this input field with a text input. Applicable to all form elements except
-	 * checkboxes and a radio buttons.
+	 * Sets the valus of this input field with a text input. Applicable to all
+	 * form elements except checkboxes and a radio buttons.
 	 * 
 	 * @param values
 	 *            Values to set.
@@ -33,7 +35,8 @@
 	}
 
 	/**
-	 * Sets the values of this input field. Only Applicable checkboxes and a radio buttons.
+	 * Sets the values of this input field. Only Applicable checkboxes and a
+	 * radio buttons.
 	 * 
 	 * @param values
 	 *            Values to set.
"
488618a8c58e8d6c443c246eea080839dad1baf2,Quinn Hanam,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/core/src/main/java/com/crawljax/core/configuration/InputField.java b/core/src/main/java/com/crawljax/core/configuration/InputField.java
index b25765c..8c33c48 100644
--- a/core/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -4,11 +4,12 @@
 import java.util.List;
 
 /**
- * Represents a form input field NOTE: In general InputField is not designed to be instantiated
- * directly. For example: <input type=""text"" name=""foo"" /> <input type=""checkbox"" id=""bar"" />
- * FormInputSpecification input = new FormInputSpecification()
- * input.field(""foo"").setValue(""Crawljax""); input.field(""bar"").setValue(true); Crawljax will set the
- * text value of the foo text field to ""Crawljax"" and checks the checkbox with id bar.
+ * Represents a form input field NOTE: In general InputField is not designed to
+ * be instantiated directly. For example: &lt;input type=""text"" name=""foo"" /&gt;
+ * &lt;input type=""checkbox"" id=""bar"" /&gt; FormInputSpecification input = new
+ * FormInputSpecification() input.field(""foo"").setValue(""Crawljax"");
+ * input.field(""bar"").setValue(true); Crawljax will set the text value of the
+ * foo text field to ""Crawljax"" and checks the checkbox with id bar.
  * 
  * @see InputSpecification#field(String)
  * @see InputSpecification#fields(String...)
@@ -28,8 +29,8 @@
 	}
 
 	/**
-	 * Sets the value of this input field with a text input. Applicable to all form elements except
-	 * checkboxes and a radio buttons.
+	 * Sets the value of this input field with a text input. Applicable to all
+	 * form elements except checkboxes and a radio buttons.
 	 * 
 	 * @param value
 	 *            Value to set.
@@ -41,7 +42,8 @@
 	}
 
 	/**
-	 * Sets the value of this input field. Only Applicable checkboxes and a radio buttons.
+	 * Sets the value of this input field. Only Applicable checkboxes and a
+	 * radio buttons.
 	 * 
 	 * @param value
 	 *            Value to set.
"
488618a8c58e8d6c443c246eea080839dad1baf2,Quinn Hanam,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index 93729c0..a7b91c3 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -48,34 +48,38 @@
 import com.google.common.collect.Lists;
 
 /**
- * Utility class that contains a number of helper functions used by Crawljax and some plugins.
+ * Utility class that contains a number of helper functions used by Crawljax and
+ * some plugins.
  */
 public final class DomUtils {
 
-	private static final Logger LOGGER = LoggerFactory.getLogger(DomUtils.class.getName());
+	private static final Logger LOGGER = LoggerFactory.getLogger(DomUtils.class
+			.getName());
 
 	static final int BASE_LENGTH = 3;
 
 	private static final int TEXT_CUTOFF = 50;
 
 	/**
-	 * transforms a string into a Document object. TODO This needs more optimizations. As it seems
-	 * the getDocument is called way too much times causing a lot of parsing which is slow and not
-	 * necessary.
+	 * transforms a string into a Document object. TODO This needs more
+	 * optimizations. As it seems the getDocument is called way too much times
+	 * causing a lot of parsing which is slow and not necessary.
 	 * 
 	 * @param html
 	 *            the HTML string.
 	 * @return The DOM Document version of the HTML string.
 	 * @throws IOException
 	 *             if an IO failure occurs.
-	 * @throws SAXException
-	 *             if an exception occurs while parsing the HTML string.
 	 */
 	public static Document asDocument(String html) throws IOException {
 		DOMParser domParser = new DOMParser();
 		try {
-			domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
-			domParser.setFeature(""http://xml.org/sax/features/namespaces"", false);
+			domParser
+					.setProperty(
+							""http://cyberneko.org/html/properties/names/elems"",
+							""match"");
+			domParser.setFeature(""http://xml.org/sax/features/namespaces"",
+					false);
 			domParser.parse(new InputSource(new StringReader(html)));
 		} catch (SAXException e) {
 			throw new IOException(""Error while reading HTML: "" + html, e);
@@ -92,10 +96,13 @@
 	 * @throws IOException
 	 *             if an IO failure occurs.
 	 */
-	public static Document getDocumentNoBalance(String html) throws SAXException, IOException {
+	public static Document getDocumentNoBalance(String html)
+			throws SAXException, IOException {
 		DOMParser domParser = new DOMParser();
-		domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
-		domParser.setFeature(""http://cyberneko.org/html/features/balance-tags"", false);
+		domParser.setProperty(
+				""http://cyberneko.org/html/properties/names/elems"", ""match"");
+		domParser.setFeature(""http://cyberneko.org/html/features/balance-tags"",
+				false);
 		domParser.parse(new InputSource(new StringReader(html)));
 		return domParser.getDocument();
 	}
@@ -114,9 +121,11 @@
 	 *            The DOM Element.
 	 * @param exclude
 	 *            the list of exclude strings.
-	 * @return A string representation of the element's attributes excluding exclude.
+	 * @return A string representation of the element's attributes excluding
+	 *         exclude.
 	 */
-	public static String getElementAttributes(Element element, ImmutableSet<String> exclude) {
+	public static String getElementAttributes(Element element,
+			ImmutableSet<String> exclude) {
 		StringBuilder buffer = new StringBuilder();
 		if (element != null) {
 			NamedNodeMap attributes = element.getAttributes();
@@ -128,8 +137,8 @@
 		return buffer.toString().trim();
 	}
 
-	private static void addAttributesToString(ImmutableSet<String> exclude, StringBuilder buffer,
-	        NamedNodeMap attributes) {
+	private static void addAttributesToString(ImmutableSet<String> exclude,
+			StringBuilder buffer, NamedNodeMap attributes) {
 		for (int i = 0; i < attributes.getLength(); i++) {
 			Attr attr = (Attr) attributes.item(i);
 			if (!exclude.contains(attr.getNodeName())) {
@@ -145,14 +154,16 @@
 	 * @return a string representation of the element including its attributes.
 	 */
 	public static String getElementString(Element element) {
-		String text = DomUtils.removeNewLines(DomUtils.getTextValue(element)).trim();
+		String text = DomUtils.removeNewLines(DomUtils.getTextValue(element))
+				.trim();
 		StringBuilder info = new StringBuilder();
 		if (!Strings.isNullOrEmpty(text)) {
 			info.append(""\"""").append(text).append(""\"" "");
 		}
 		if (element != null) {
 			if (element.hasAttribute(""id"")) {
-				info.append(""ID: "").append(element.getAttribute(""id"")).append("" "");
+				info.append(""ID: "").append(element.getAttribute(""id""))
+						.append("" "");
 			}
 			info.append(DomUtils.getAllElementAttributes(element)).append("" "");
 		}
@@ -169,7 +180,7 @@
 	 *             if the xpath fails.
 	 */
 	public static Element getElementByXpath(Document dom, String xpath)
-	        throws XPathExpressionException {
+			throws XPathExpressionException {
 		XPath xp = XPathFactory.newInstance().newXPath();
 		xp.setNamespaceContext(new HtmlNamespace());
 
@@ -177,7 +188,7 @@
 	}
 
 	/**
-	 * Removes all the <SCRIPT/> tags from the document.
+	 * Removes all the &lt;SCRIPT/&gt; tags from the document.
 	 * 
 	 * @param dom
 	 *            the document object.
@@ -199,7 +210,8 @@
 	public static Document removeTags(Document dom, String tagName) {
 		NodeList list;
 		try {
-			list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
+			list = XPathHelper.evaluateXpathExpression(dom,
+					""//"" + tagName.toUpperCase());
 
 			while (list.getLength() > 0) {
 				Node sc = list.item(0);
@@ -208,7 +220,8 @@
 					sc.getParentNode().removeChild(sc);
 				}
 
-				list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
+				list = XPathHelper.evaluateXpathExpression(dom,
+						""//"" + tagName.toUpperCase());
 			}
 		} catch (XPathExpressionException e) {
 			LOGGER.error(""Error while removing tag "" + tagName, e);
@@ -231,7 +244,8 @@
 			TransformerFactory factory = TransformerFactory.newInstance();
 			Transformer transformer = factory.newTransformer();
 			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
-			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""yes"");
+			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION,
+					""yes"");
 			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
 			transformer.transform(source, result);
 			return stringWriter.getBuffer().toString();
@@ -254,12 +268,15 @@
 
 			Transformer transformer = tFactory.newTransformer();
 			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
-			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
+			transformer
+					.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
 			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
 			// TODO should be fixed to read doctype declaration
-			transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			        ""-//W3C//DTD XHTML 1.0 Strict//EN\"" ""
-			                + ""\""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"");
+			transformer
+					.setOutputProperty(
+							OutputKeys.DOCTYPE_PUBLIC,
+							""-//W3C//DTD XHTML 1.0 Strict//EN\"" ""
+									+ ""\""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"");
 
 			DOMSource source = new DOMSource(dom);
 
@@ -269,15 +286,16 @@
 
 			return out.toByteArray();
 		} catch (TransformerException e) {
-			LOGGER.error(""Error while converting the document to a byte array"", e);
+			LOGGER.error(""Error while converting the document to a byte array"",
+					e);
 		}
 		return null;
 
 	}
 
 	/**
-	 * Returns the text value of an element (title, alt or contents). Note that the result is 50
-	 * characters or less in length.
+	 * Returns the text value of an element (title, alt or contents). Note that
+	 * the result is 50 characters or less in length.
 	 * 
 	 * @param element
 	 *            The element.
@@ -309,8 +327,10 @@
 	 *            The test dom.
 	 * @return The differences.
 	 */
-	public static List<Difference> getDifferences(String controlDom, String testDom) {
-		return getDifferences(controlDom, testDom, Lists.<String> newArrayList());
+	public static List<Difference> getDifferences(String controlDom,
+			String testDom) {
+		return getDifferences(controlDom, testDom,
+				Lists.<String> newArrayList());
 	}
 
 	/**
@@ -325,12 +345,14 @@
 	 * @return The differences.
 	 */
 	@SuppressWarnings(""unchecked"")
-	public static List<Difference> getDifferences(String controlDom, String testDom,
-	        final List<String> ignoreAttributes) {
+	public static List<Difference> getDifferences(String controlDom,
+			String testDom, final List<String> ignoreAttributes) {
 		try {
-			Diff d = new Diff(DomUtils.asDocument(controlDom), DomUtils.asDocument(testDom));
+			Diff d = new Diff(DomUtils.asDocument(controlDom),
+					DomUtils.asDocument(testDom));
 			DetailedDiff dd = new DetailedDiff(d);
-			dd.overrideDifferenceListener(new DomDifferenceListener(ignoreAttributes));
+			dd.overrideDifferenceListener(new DomDifferenceListener(
+					ignoreAttributes));
 
 			return dd.getAllDifferences();
 		} catch (IOException e) {
@@ -357,9 +379,11 @@
 	 *            The regular expression.
 	 * @param replace
 	 *            What to replace it with.
-	 * @return replaces regex in str by replace where the dot sign also supports newlines
+	 * @return replaces regex in str by replace where the dot sign also supports
+	 *         newlines
 	 */
-	public static String replaceString(String string, String regex, String replace) {
+	public static String replaceString(String string, String regex,
+			String replace) {
 		Pattern p = Pattern.compile(regex, Pattern.DOTALL);
 		Matcher m = p.matcher(string);
 		String replaced = m.replaceAll(replace);
@@ -384,8 +408,8 @@
 	}
 
 	/**
-	 * Returns the filename in a path. For example with path = ""foo/bar/crawljax.txt"" returns
-	 * ""crawljax.txt""
+	 * Returns the filename in a path. For example with path =
+	 * ""foo/bar/crawljax.txt"" returns ""crawljax.txt""
 	 * 
 	 * @param path
 	 * @return the filename from the path
@@ -401,8 +425,8 @@
 	}
 
 	/**
-	 * Retrieves the content of the filename. Also reads from JAR Searches for the resource in the
-	 * root folder in the jar
+	 * Retrieves the content of the filename. Also reads from JAR Searches for
+	 * the resource in the root folder in the jar
 	 * 
 	 * @param fname
 	 *            Filename.
@@ -413,18 +437,21 @@
 	public static String getTemplateAsString(String fname) throws IOException {
 		// in .jar file
 		String fnameJar = getFileNameInPath(fname);
-		InputStream inStream = DomUtils.class.getResourceAsStream(""/"" + fnameJar);
+		InputStream inStream = DomUtils.class.getResourceAsStream(""/""
+				+ fnameJar);
 		if (inStream == null) {
 			// try to find file normally
 			File f = new File(fname);
 			if (f.exists()) {
 				inStream = new FileInputStream(f);
 			} else {
-				throw new IOException(""Cannot find "" + fname + "" or "" + fnameJar);
+				throw new IOException(""Cannot find "" + fname + "" or ""
+						+ fnameJar);
 			}
 		}
 
-		BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inStream));
+		BufferedReader bufferedReader = new BufferedReader(
+				new InputStreamReader(inStream));
 		String line;
 		StringBuilder stringBuilder = new StringBuilder();
 
@@ -439,17 +466,20 @@
 	/**
 	 * @param frame
 	 *            the frame element.
-	 * @return the name or id of this element if they are present, otherwise null.
+	 * @return the name or id of this element if they are present, otherwise
+	 *         null.
 	 */
 	public static String getFrameIdentification(Element frame) {
 
 		Attr attr = frame.getAttributeNode(""id"");
-		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
+		if (attr != null && attr.getNodeValue() != null
+				&& !attr.getNodeValue().equals("""")) {
 			return attr.getNodeValue();
 		}
 
 		attr = frame.getAttributeNode(""name"");
-		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
+		if (attr != null && attr.getNodeValue() != null
+				&& !attr.getNodeValue().equals("""")) {
 			return attr.getNodeValue();
 		}
 
@@ -473,16 +503,18 @@
 	 * @throws IOException
 	 *             if an IO exception occurs.
 	 */
-	public static void writeDocumentToFile(Document document, String filePathname, String method,
-	        int indent) throws TransformerException, IOException {
+	public static void writeDocumentToFile(Document document,
+			String filePathname, String method, int indent)
+			throws TransformerException, IOException {
 
-		Transformer transformer = TransformerFactory.newInstance().newTransformer();
+		Transformer transformer = TransformerFactory.newInstance()
+				.newTransformer();
 		transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
 		transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
 		transformer.setOutputProperty(OutputKeys.METHOD, method);
 
-		transformer.transform(new DOMSource(document), new StreamResult(new FileOutputStream(
-		        filePathname)));
+		transformer.transform(new DOMSource(document), new StreamResult(
+				new FileOutputStream(filePathname)));
 	}
 
 	private DomUtils() {
"
a351828462bec14918f13214dfe41c35ade50fe0,Ali Mesbah,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/core/src/main/java/com/crawljax/core/CrawlQueue.java b/core/src/main/java/com/crawljax/core/CrawlQueue.java
index bb9e752..eb88690 100644
--- a/core/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/core/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -8,13 +8,15 @@
 import net.jcip.annotations.GuardedBy;
 
 /**
- * This class implements a BlockingQueue with Runnable as its Generic type and extends Stack with
- * also Runnable as generic type. This class is used in the ThreadPoolExecutor and its used to store
- * separate threads in a Queue like fashion (FILO).
+ * This class implements a BlockingQueue with Runnable as its Generic type and
+ * extends Stack with also Runnable as generic type. This class is used in the
+ * ThreadPoolExecutor and its used to store separate threads in a Queue like
+ * fashion (FILO).
  * 
- * @author Stefan Lenselink <S.R.Lenselink@student.tudelft.nl>
+ * @author Stefan Lenselink &lt;S.R.Lenselink@student.tudelft.nl&gt;
  */
-public class CrawlQueue extends Stack<Runnable> implements BlockingQueue<Runnable> {
+public class CrawlQueue extends Stack<Runnable> implements
+		BlockingQueue<Runnable> {
 
 	/**
 	 * Auto generated serialVersionUID.
@@ -27,7 +29,8 @@
 	}
 
 	@Override
-	public synchronized int drainTo(Collection<? super Runnable> c, int maxRunnablelements) {
+	public synchronized int drainTo(Collection<? super Runnable> c,
+			int maxRunnablelements) {
 		int counter = 0;
 		for (Runnable object : this) {
 			counter++;
"
a351828462bec14918f13214dfe41c35ade50fe0,Ali Mesbah,CrawlActionsBuilder.java,MODIFY,click -> [String tagNames] | [String tagName],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
index 9dea6fe..b511d13 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
@@ -13,7 +13,8 @@
 
 public class CrawlActionsBuilder {
 
-	private static final Logger LOG = LoggerFactory.getLogger(CrawlActionsBuilder.class);
+	private static final Logger LOG = LoggerFactory
+			.getLogger(CrawlActionsBuilder.class);
 
 	public static class ExcludeByParentBuilder {
 		private final String tagname;
@@ -34,11 +35,14 @@
 		}
 
 		private String asExcludeXpath(String identifier, String value) {
-			return new StringBuilder().append(""//"").append(tagname.toUpperCase()).append(""[@"")
-			        .append(identifier).append(""='"").append(value).append(""']//*"").toString();
+			return new StringBuilder().append(""//"")
+					.append(tagname.toUpperCase()).append(""[@"")
+					.append(identifier).append(""='"").append(value)
+					.append(""']//*"").toString();
 		}
 
-		private ImmutableList<CrawlElement> asExcludeList(List<CrawlElement> includes) {
+		private ImmutableList<CrawlElement> asExcludeList(
+				List<CrawlElement> includes) {
 			String xpath;
 			if (id != null) {
 				xpath = asExcludeXpath(""id"", id);
@@ -47,26 +51,30 @@
 			} else {
 				xpath = ""//"" + tagname.toUpperCase() + ""//*"";
 			}
-			ImmutableList.Builder<CrawlElement> builder = ImmutableList.builder();
+			ImmutableList.Builder<CrawlElement> builder = ImmutableList
+					.builder();
 			for (CrawlElement include : includes) {
-				builder.add(new CrawlElement(EventType.click, include.getTagName())
-				        .underXPath(xpath));
+				builder.add(new CrawlElement(EventType.click, include
+						.getTagName()).underXPath(xpath));
 			}
 			return builder.build();
 		}
 	}
 
 	private final List<CrawlElement> crawlElements = Lists.newLinkedList();
-	private final List<CrawlElement> crawlElementsExcluded = Lists.newLinkedList();
-	private final List<ExcludeByParentBuilder> crawlParentsExcluded = Lists.newLinkedList();
+	private final List<CrawlElement> crawlElementsExcluded = Lists
+			.newLinkedList();
+	private final List<ExcludeByParentBuilder> crawlParentsExcluded = Lists
+			.newLinkedList();
 	private ImmutableList<CrawlElement> resultingElementsExcluded = null;
 
 	CrawlActionsBuilder() {
 	}
 
 	/**
-	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
-	 * click(""a"") will only include 1 if clickOnce is true (default). This set can be restricted by
+	 * Set of HTML elements Crawljax will click during crawling For exmple 1)
+	 * &gt;a.../&lt; 2) &lt;div/&gt; click(""a"") will only include 1 if clickOnce
+	 * is true (default). This set can be restricted by
 	 * {@link #dontClick(String)}.
 	 * 
 	 * @param tagName
@@ -76,15 +84,17 @@
 	public CrawlElement click(String tagName) {
 		checkNotRead();
 		Preconditions.checkNotNull(tagName, ""Tagname cannot be null"");
-		CrawlElement crawlTag = new CrawlElement(EventType.click, tagName.toUpperCase());
+		CrawlElement crawlTag = new CrawlElement(EventType.click,
+				tagName.toUpperCase());
 		crawlElements.add(crawlTag);
 		return crawlTag;
 	}
 
 	/**
-	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
-	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}. If
-	 * no clicks are specified, {@link #clickDefaultElements()} is enabled.
+	 * Set of HTML elements Crawljax will click during crawling For exmple 1)
+	 * &lt;a.../&gt; 2) &lt;div/&gt; click(""a"") will only include 1 This set can
+	 * be restricted by {@link #dontClick(String)}. If no clicks are specified,
+	 * {@link #clickDefaultElements()} is enabled.
 	 * 
 	 * @param tagNames
 	 *            the tag name of the elements to be included
@@ -96,8 +106,8 @@
 	}
 
 	/**
-	 * Specifies that Crawljax should click all the default clickable elements. These include: All
-	 * anchor tags All buttons
+	 * Specifies that Crawljax should click all the default clickable elements.
+	 * These include: All anchor tags All buttons
 	 */
 	public void clickDefaultElements() {
 		click(""a"");
@@ -108,14 +118,16 @@
 
 	private void checkNotRead() {
 		Preconditions.checkState(resultingElementsExcluded == null,
-		        ""You cannot modify crawlactions once it's read"");
+				""You cannot modify crawlactions once it's read"");
 	}
 
 	/**
-	 * Set of HTML elements Crawljax will NOT click during crawling When an HTML is present in the
-	 * click and dontClick sets, then the element will not be clicked. For example: 1) <a
-	 * href=""#"">Some text</a> 2) <a class=""foo"" .../> 3) <div class=""foo"" .../> click(""a"")
-	 * dontClick(""a"").withAttribute(""class"", ""foo""); Will include only include HTML element 2
+	 * Set of HTML elements Crawljax will NOT click during crawling When an HTML
+	 * is present in the click and dontClick sets, then the element will not be
+	 * clicked. For example: 1) &lt;a href=""#""&gt;Some text&lt;/a&gt; 2) &lt;a
+	 * class=""foo"" .../&gt; 3) &lt;div class=""foo"" .../&gt; click(""a"")
+	 * dontClick(""a"").withAttribute(""class"", ""foo""); Will include only include
+	 * HTML element 2
 	 * 
 	 * @param tagName
 	 *            the tag name of the elements to be excluded
@@ -124,7 +136,8 @@
 	public CrawlElement dontClick(String tagName) {
 		checkNotRead();
 		Preconditions.checkNotNull(tagName, ""Tagname cannot be null"");
-		CrawlElement crawlTag = new CrawlElement(EventType.click, tagName.toUpperCase());
+		CrawlElement crawlTag = new CrawlElement(EventType.click,
+				tagName.toUpperCase());
 		crawlElementsExcluded.add(crawlTag);
 		return crawlTag;
 	}
@@ -139,7 +152,8 @@
 	public ExcludeByParentBuilder dontClickChildrenOf(String tagname) {
 		checkNotRead();
 		Preconditions.checkNotNull(tagname);
-		ExcludeByParentBuilder exclude = new ExcludeByParentBuilder(tagname.toUpperCase());
+		ExcludeByParentBuilder exclude = new ExcludeByParentBuilder(
+				tagname.toUpperCase());
 		crawlParentsExcluded.add(exclude);
 		return exclude;
 	}
@@ -160,7 +174,8 @@
 	private ImmutableList<CrawlElement> getCrawlElementsExcluded() {
 		synchronized (this) {
 			if (resultingElementsExcluded == null) {
-				ImmutableList.Builder<CrawlElement> builder = ImmutableList.builder();
+				ImmutableList.Builder<CrawlElement> builder = ImmutableList
+						.builder();
 				builder.addAll(crawlElementsExcluded);
 				for (ExcludeByParentBuilder exclude : crawlParentsExcluded) {
 					builder.addAll(exclude.asExcludeList(crawlElements));
"
a351828462bec14918f13214dfe41c35ade50fe0,Ali Mesbah,FormInputField.java,MODIFY,setValues -> [boolean values] | [String values],"diff --git a/core/src/main/java/com/crawljax/core/configuration/FormInputField.java b/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
index dc6e88c..fbb126c 100644
--- a/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
@@ -1,15 +1,17 @@
 package com.crawljax.core.configuration;
 
 /**
- * Represents a form input field NOTE: In general FormInputField is not designed to be instantiated
- * directly. For example: <input type=""text"" name=""foo"" /> <input type=""checkbox"" id=""bar"" />
- * FormInputSpecification input = new FormInputSpecification() Form form = new Form();
+ * Represents a form input field NOTE: In general FormInputField is not designed
+ * to be instantiated directly. For example: &lt;input type=""text"" name=""foo""
+ * /&gt; &lt;input type=""checkbox"" id=""bar"" /&gt; FormInputSpecification input =
+ * new FormInputSpecification() Form form = new Form();
  * input.field(""foo"").setValues(""Crawljax"", ""Crawler"", ""Automatic"");
  * input.field(""bar"").setValues(true, true, false);
- * input.setValuesInForm(contactForm).beforeClickTag(""a"").withText(""Search""); Crawljax will set the
- * text value of the foo text field and the bar checkbox three times when clicked on the anchor
- * element with the test Search to: 1) foo=Crawljax; bar=checked 2) foo=Crawler; bar=checked 3)
- * foo=Automatic; bar=unchecked
+ * input.setValuesInForm(contactForm).beforeClickTag(""a"").withText(""Search"");
+ * Crawljax will set the text value of the foo text field and the bar checkbox
+ * three times when clicked on the anchor element with the test Search to: 1)
+ * foo=Crawljax; bar=checked 2) foo=Crawler; bar=checked 3) foo=Automatic;
+ * bar=unchecked
  * 
  * @see Form
  * @see Form#field(String)
@@ -18,8 +20,8 @@
 public class FormInputField extends InputField {
 
 	/**
-	 * Sets the valus of this input field with a text input. Applicable to all form elements except
-	 * checkboxes and a radio buttons.
+	 * Sets the valus of this input field with a text input. Applicable to all
+	 * form elements except checkboxes and a radio buttons.
 	 * 
 	 * @param values
 	 *            Values to set.
@@ -33,7 +35,8 @@
 	}
 
 	/**
-	 * Sets the values of this input field. Only Applicable checkboxes and a radio buttons.
+	 * Sets the values of this input field. Only Applicable checkboxes and a
+	 * radio buttons.
 	 * 
 	 * @param values
 	 *            Values to set.
"
a351828462bec14918f13214dfe41c35ade50fe0,Ali Mesbah,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/core/src/main/java/com/crawljax/core/configuration/InputField.java b/core/src/main/java/com/crawljax/core/configuration/InputField.java
index b25765c..8c33c48 100644
--- a/core/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -4,11 +4,12 @@
 import java.util.List;
 
 /**
- * Represents a form input field NOTE: In general InputField is not designed to be instantiated
- * directly. For example: <input type=""text"" name=""foo"" /> <input type=""checkbox"" id=""bar"" />
- * FormInputSpecification input = new FormInputSpecification()
- * input.field(""foo"").setValue(""Crawljax""); input.field(""bar"").setValue(true); Crawljax will set the
- * text value of the foo text field to ""Crawljax"" and checks the checkbox with id bar.
+ * Represents a form input field NOTE: In general InputField is not designed to
+ * be instantiated directly. For example: &lt;input type=""text"" name=""foo"" /&gt;
+ * &lt;input type=""checkbox"" id=""bar"" /&gt; FormInputSpecification input = new
+ * FormInputSpecification() input.field(""foo"").setValue(""Crawljax"");
+ * input.field(""bar"").setValue(true); Crawljax will set the text value of the
+ * foo text field to ""Crawljax"" and checks the checkbox with id bar.
  * 
  * @see InputSpecification#field(String)
  * @see InputSpecification#fields(String...)
@@ -28,8 +29,8 @@
 	}
 
 	/**
-	 * Sets the value of this input field with a text input. Applicable to all form elements except
-	 * checkboxes and a radio buttons.
+	 * Sets the value of this input field with a text input. Applicable to all
+	 * form elements except checkboxes and a radio buttons.
 	 * 
 	 * @param value
 	 *            Value to set.
@@ -41,7 +42,8 @@
 	}
 
 	/**
-	 * Sets the value of this input field. Only Applicable checkboxes and a radio buttons.
+	 * Sets the value of this input field. Only Applicable checkboxes and a
+	 * radio buttons.
 	 * 
 	 * @param value
 	 *            Value to set.
"
a351828462bec14918f13214dfe41c35ade50fe0,Ali Mesbah,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index 93729c0..a7b91c3 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -48,34 +48,38 @@
 import com.google.common.collect.Lists;
 
 /**
- * Utility class that contains a number of helper functions used by Crawljax and some plugins.
+ * Utility class that contains a number of helper functions used by Crawljax and
+ * some plugins.
  */
 public final class DomUtils {
 
-	private static final Logger LOGGER = LoggerFactory.getLogger(DomUtils.class.getName());
+	private static final Logger LOGGER = LoggerFactory.getLogger(DomUtils.class
+			.getName());
 
 	static final int BASE_LENGTH = 3;
 
 	private static final int TEXT_CUTOFF = 50;
 
 	/**
-	 * transforms a string into a Document object. TODO This needs more optimizations. As it seems
-	 * the getDocument is called way too much times causing a lot of parsing which is slow and not
-	 * necessary.
+	 * transforms a string into a Document object. TODO This needs more
+	 * optimizations. As it seems the getDocument is called way too much times
+	 * causing a lot of parsing which is slow and not necessary.
 	 * 
 	 * @param html
 	 *            the HTML string.
 	 * @return The DOM Document version of the HTML string.
 	 * @throws IOException
 	 *             if an IO failure occurs.
-	 * @throws SAXException
-	 *             if an exception occurs while parsing the HTML string.
 	 */
 	public static Document asDocument(String html) throws IOException {
 		DOMParser domParser = new DOMParser();
 		try {
-			domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
-			domParser.setFeature(""http://xml.org/sax/features/namespaces"", false);
+			domParser
+					.setProperty(
+							""http://cyberneko.org/html/properties/names/elems"",
+							""match"");
+			domParser.setFeature(""http://xml.org/sax/features/namespaces"",
+					false);
 			domParser.parse(new InputSource(new StringReader(html)));
 		} catch (SAXException e) {
 			throw new IOException(""Error while reading HTML: "" + html, e);
@@ -92,10 +96,13 @@
 	 * @throws IOException
 	 *             if an IO failure occurs.
 	 */
-	public static Document getDocumentNoBalance(String html) throws SAXException, IOException {
+	public static Document getDocumentNoBalance(String html)
+			throws SAXException, IOException {
 		DOMParser domParser = new DOMParser();
-		domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
-		domParser.setFeature(""http://cyberneko.org/html/features/balance-tags"", false);
+		domParser.setProperty(
+				""http://cyberneko.org/html/properties/names/elems"", ""match"");
+		domParser.setFeature(""http://cyberneko.org/html/features/balance-tags"",
+				false);
 		domParser.parse(new InputSource(new StringReader(html)));
 		return domParser.getDocument();
 	}
@@ -114,9 +121,11 @@
 	 *            The DOM Element.
 	 * @param exclude
 	 *            the list of exclude strings.
-	 * @return A string representation of the element's attributes excluding exclude.
+	 * @return A string representation of the element's attributes excluding
+	 *         exclude.
 	 */
-	public static String getElementAttributes(Element element, ImmutableSet<String> exclude) {
+	public static String getElementAttributes(Element element,
+			ImmutableSet<String> exclude) {
 		StringBuilder buffer = new StringBuilder();
 		if (element != null) {
 			NamedNodeMap attributes = element.getAttributes();
@@ -128,8 +137,8 @@
 		return buffer.toString().trim();
 	}
 
-	private static void addAttributesToString(ImmutableSet<String> exclude, StringBuilder buffer,
-	        NamedNodeMap attributes) {
+	private static void addAttributesToString(ImmutableSet<String> exclude,
+			StringBuilder buffer, NamedNodeMap attributes) {
 		for (int i = 0; i < attributes.getLength(); i++) {
 			Attr attr = (Attr) attributes.item(i);
 			if (!exclude.contains(attr.getNodeName())) {
@@ -145,14 +154,16 @@
 	 * @return a string representation of the element including its attributes.
 	 */
 	public static String getElementString(Element element) {
-		String text = DomUtils.removeNewLines(DomUtils.getTextValue(element)).trim();
+		String text = DomUtils.removeNewLines(DomUtils.getTextValue(element))
+				.trim();
 		StringBuilder info = new StringBuilder();
 		if (!Strings.isNullOrEmpty(text)) {
 			info.append(""\"""").append(text).append(""\"" "");
 		}
 		if (element != null) {
 			if (element.hasAttribute(""id"")) {
-				info.append(""ID: "").append(element.getAttribute(""id"")).append("" "");
+				info.append(""ID: "").append(element.getAttribute(""id""))
+						.append("" "");
 			}
 			info.append(DomUtils.getAllElementAttributes(element)).append("" "");
 		}
@@ -169,7 +180,7 @@
 	 *             if the xpath fails.
 	 */
 	public static Element getElementByXpath(Document dom, String xpath)
-	        throws XPathExpressionException {
+			throws XPathExpressionException {
 		XPath xp = XPathFactory.newInstance().newXPath();
 		xp.setNamespaceContext(new HtmlNamespace());
 
@@ -177,7 +188,7 @@
 	}
 
 	/**
-	 * Removes all the <SCRIPT/> tags from the document.
+	 * Removes all the &lt;SCRIPT/&gt; tags from the document.
 	 * 
 	 * @param dom
 	 *            the document object.
@@ -199,7 +210,8 @@
 	public static Document removeTags(Document dom, String tagName) {
 		NodeList list;
 		try {
-			list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
+			list = XPathHelper.evaluateXpathExpression(dom,
+					""//"" + tagName.toUpperCase());
 
 			while (list.getLength() > 0) {
 				Node sc = list.item(0);
@@ -208,7 +220,8 @@
 					sc.getParentNode().removeChild(sc);
 				}
 
-				list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
+				list = XPathHelper.evaluateXpathExpression(dom,
+						""//"" + tagName.toUpperCase());
 			}
 		} catch (XPathExpressionException e) {
 			LOGGER.error(""Error while removing tag "" + tagName, e);
@@ -231,7 +244,8 @@
 			TransformerFactory factory = TransformerFactory.newInstance();
 			Transformer transformer = factory.newTransformer();
 			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
-			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""yes"");
+			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION,
+					""yes"");
 			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
 			transformer.transform(source, result);
 			return stringWriter.getBuffer().toString();
@@ -254,12 +268,15 @@
 
 			Transformer transformer = tFactory.newTransformer();
 			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
-			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
+			transformer
+					.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
 			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
 			// TODO should be fixed to read doctype declaration
-			transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			        ""-//W3C//DTD XHTML 1.0 Strict//EN\"" ""
-			                + ""\""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"");
+			transformer
+					.setOutputProperty(
+							OutputKeys.DOCTYPE_PUBLIC,
+							""-//W3C//DTD XHTML 1.0 Strict//EN\"" ""
+									+ ""\""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"");
 
 			DOMSource source = new DOMSource(dom);
 
@@ -269,15 +286,16 @@
 
 			return out.toByteArray();
 		} catch (TransformerException e) {
-			LOGGER.error(""Error while converting the document to a byte array"", e);
+			LOGGER.error(""Error while converting the document to a byte array"",
+					e);
 		}
 		return null;
 
 	}
 
 	/**
-	 * Returns the text value of an element (title, alt or contents). Note that the result is 50
-	 * characters or less in length.
+	 * Returns the text value of an element (title, alt or contents). Note that
+	 * the result is 50 characters or less in length.
 	 * 
 	 * @param element
 	 *            The element.
@@ -309,8 +327,10 @@
 	 *            The test dom.
 	 * @return The differences.
 	 */
-	public static List<Difference> getDifferences(String controlDom, String testDom) {
-		return getDifferences(controlDom, testDom, Lists.<String> newArrayList());
+	public static List<Difference> getDifferences(String controlDom,
+			String testDom) {
+		return getDifferences(controlDom, testDom,
+				Lists.<String> newArrayList());
 	}
 
 	/**
@@ -325,12 +345,14 @@
 	 * @return The differences.
 	 */
 	@SuppressWarnings(""unchecked"")
-	public static List<Difference> getDifferences(String controlDom, String testDom,
-	        final List<String> ignoreAttributes) {
+	public static List<Difference> getDifferences(String controlDom,
+			String testDom, final List<String> ignoreAttributes) {
 		try {
-			Diff d = new Diff(DomUtils.asDocument(controlDom), DomUtils.asDocument(testDom));
+			Diff d = new Diff(DomUtils.asDocument(controlDom),
+					DomUtils.asDocument(testDom));
 			DetailedDiff dd = new DetailedDiff(d);
-			dd.overrideDifferenceListener(new DomDifferenceListener(ignoreAttributes));
+			dd.overrideDifferenceListener(new DomDifferenceListener(
+					ignoreAttributes));
 
 			return dd.getAllDifferences();
 		} catch (IOException e) {
@@ -357,9 +379,11 @@
 	 *            The regular expression.
 	 * @param replace
 	 *            What to replace it with.
-	 * @return replaces regex in str by replace where the dot sign also supports newlines
+	 * @return replaces regex in str by replace where the dot sign also supports
+	 *         newlines
 	 */
-	public static String replaceString(String string, String regex, String replace) {
+	public static String replaceString(String string, String regex,
+			String replace) {
 		Pattern p = Pattern.compile(regex, Pattern.DOTALL);
 		Matcher m = p.matcher(string);
 		String replaced = m.replaceAll(replace);
@@ -384,8 +408,8 @@
 	}
 
 	/**
-	 * Returns the filename in a path. For example with path = ""foo/bar/crawljax.txt"" returns
-	 * ""crawljax.txt""
+	 * Returns the filename in a path. For example with path =
+	 * ""foo/bar/crawljax.txt"" returns ""crawljax.txt""
 	 * 
 	 * @param path
 	 * @return the filename from the path
@@ -401,8 +425,8 @@
 	}
 
 	/**
-	 * Retrieves the content of the filename. Also reads from JAR Searches for the resource in the
-	 * root folder in the jar
+	 * Retrieves the content of the filename. Also reads from JAR Searches for
+	 * the resource in the root folder in the jar
 	 * 
 	 * @param fname
 	 *            Filename.
@@ -413,18 +437,21 @@
 	public static String getTemplateAsString(String fname) throws IOException {
 		// in .jar file
 		String fnameJar = getFileNameInPath(fname);
-		InputStream inStream = DomUtils.class.getResourceAsStream(""/"" + fnameJar);
+		InputStream inStream = DomUtils.class.getResourceAsStream(""/""
+				+ fnameJar);
 		if (inStream == null) {
 			// try to find file normally
 			File f = new File(fname);
 			if (f.exists()) {
 				inStream = new FileInputStream(f);
 			} else {
-				throw new IOException(""Cannot find "" + fname + "" or "" + fnameJar);
+				throw new IOException(""Cannot find "" + fname + "" or ""
+						+ fnameJar);
 			}
 		}
 
-		BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inStream));
+		BufferedReader bufferedReader = new BufferedReader(
+				new InputStreamReader(inStream));
 		String line;
 		StringBuilder stringBuilder = new StringBuilder();
 
@@ -439,17 +466,20 @@
 	/**
 	 * @param frame
 	 *            the frame element.
-	 * @return the name or id of this element if they are present, otherwise null.
+	 * @return the name or id of this element if they are present, otherwise
+	 *         null.
 	 */
 	public static String getFrameIdentification(Element frame) {
 
 		Attr attr = frame.getAttributeNode(""id"");
-		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
+		if (attr != null && attr.getNodeValue() != null
+				&& !attr.getNodeValue().equals("""")) {
 			return attr.getNodeValue();
 		}
 
 		attr = frame.getAttributeNode(""name"");
-		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
+		if (attr != null && attr.getNodeValue() != null
+				&& !attr.getNodeValue().equals("""")) {
 			return attr.getNodeValue();
 		}
 
@@ -473,16 +503,18 @@
 	 * @throws IOException
 	 *             if an IO exception occurs.
 	 */
-	public static void writeDocumentToFile(Document document, String filePathname, String method,
-	        int indent) throws TransformerException, IOException {
+	public static void writeDocumentToFile(Document document,
+			String filePathname, String method, int indent)
+			throws TransformerException, IOException {
 
-		Transformer transformer = TransformerFactory.newInstance().newTransformer();
+		Transformer transformer = TransformerFactory.newInstance()
+				.newTransformer();
 		transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
 		transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
 		transformer.setOutputProperty(OutputKeys.METHOD, method);
 
-		transformer.transform(new DOMSource(document), new StreamResult(new FileOutputStream(
-		        filePathname)));
+		transformer.transform(new DOMSource(document), new StreamResult(
+				new FileOutputStream(filePathname)));
 	}
 
 	private DomUtils() {
"
5d412213afd6019b9aa8297300165682d309cf2a,Ali Mesbah,CrawlQueue.java,MODIFY,"drainTo -> [Collection c, int maxRunnablelements] | [Collection c]","diff --git a/core/src/main/java/com/crawljax/core/CrawlQueue.java b/core/src/main/java/com/crawljax/core/CrawlQueue.java
index bb9e752..eb88690 100644
--- a/core/src/main/java/com/crawljax/core/CrawlQueue.java
+++ b/core/src/main/java/com/crawljax/core/CrawlQueue.java
@@ -8,13 +8,15 @@
 import net.jcip.annotations.GuardedBy;
 
 /**
- * This class implements a BlockingQueue with Runnable as its Generic type and extends Stack with
- * also Runnable as generic type. This class is used in the ThreadPoolExecutor and its used to store
- * separate threads in a Queue like fashion (FILO).
+ * This class implements a BlockingQueue with Runnable as its Generic type and
+ * extends Stack with also Runnable as generic type. This class is used in the
+ * ThreadPoolExecutor and its used to store separate threads in a Queue like
+ * fashion (FILO).
  * 
- * @author Stefan Lenselink <S.R.Lenselink@student.tudelft.nl>
+ * @author Stefan Lenselink &lt;S.R.Lenselink@student.tudelft.nl&gt;
  */
-public class CrawlQueue extends Stack<Runnable> implements BlockingQueue<Runnable> {
+public class CrawlQueue extends Stack<Runnable> implements
+		BlockingQueue<Runnable> {
 
 	/**
 	 * Auto generated serialVersionUID.
@@ -27,7 +29,8 @@
 	}
 
 	@Override
-	public synchronized int drainTo(Collection<? super Runnable> c, int maxRunnablelements) {
+	public synchronized int drainTo(Collection<? super Runnable> c,
+			int maxRunnablelements) {
 		int counter = 0;
 		for (Runnable object : this) {
 			counter++;
"
5d412213afd6019b9aa8297300165682d309cf2a,Ali Mesbah,CrawlActionsBuilder.java,MODIFY,click -> [String tagNames] | [String tagName],"diff --git a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
index 9dea6fe..b511d13 100644
--- a/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
+++ b/core/src/main/java/com/crawljax/core/configuration/CrawlActionsBuilder.java
@@ -13,7 +13,8 @@
 
 public class CrawlActionsBuilder {
 
-	private static final Logger LOG = LoggerFactory.getLogger(CrawlActionsBuilder.class);
+	private static final Logger LOG = LoggerFactory
+			.getLogger(CrawlActionsBuilder.class);
 
 	public static class ExcludeByParentBuilder {
 		private final String tagname;
@@ -34,11 +35,14 @@
 		}
 
 		private String asExcludeXpath(String identifier, String value) {
-			return new StringBuilder().append(""//"").append(tagname.toUpperCase()).append(""[@"")
-			        .append(identifier).append(""='"").append(value).append(""']//*"").toString();
+			return new StringBuilder().append(""//"")
+					.append(tagname.toUpperCase()).append(""[@"")
+					.append(identifier).append(""='"").append(value)
+					.append(""']//*"").toString();
 		}
 
-		private ImmutableList<CrawlElement> asExcludeList(List<CrawlElement> includes) {
+		private ImmutableList<CrawlElement> asExcludeList(
+				List<CrawlElement> includes) {
 			String xpath;
 			if (id != null) {
 				xpath = asExcludeXpath(""id"", id);
@@ -47,26 +51,30 @@
 			} else {
 				xpath = ""//"" + tagname.toUpperCase() + ""//*"";
 			}
-			ImmutableList.Builder<CrawlElement> builder = ImmutableList.builder();
+			ImmutableList.Builder<CrawlElement> builder = ImmutableList
+					.builder();
 			for (CrawlElement include : includes) {
-				builder.add(new CrawlElement(EventType.click, include.getTagName())
-				        .underXPath(xpath));
+				builder.add(new CrawlElement(EventType.click, include
+						.getTagName()).underXPath(xpath));
 			}
 			return builder.build();
 		}
 	}
 
 	private final List<CrawlElement> crawlElements = Lists.newLinkedList();
-	private final List<CrawlElement> crawlElementsExcluded = Lists.newLinkedList();
-	private final List<ExcludeByParentBuilder> crawlParentsExcluded = Lists.newLinkedList();
+	private final List<CrawlElement> crawlElementsExcluded = Lists
+			.newLinkedList();
+	private final List<ExcludeByParentBuilder> crawlParentsExcluded = Lists
+			.newLinkedList();
 	private ImmutableList<CrawlElement> resultingElementsExcluded = null;
 
 	CrawlActionsBuilder() {
 	}
 
 	/**
-	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
-	 * click(""a"") will only include 1 if clickOnce is true (default). This set can be restricted by
+	 * Set of HTML elements Crawljax will click during crawling For exmple 1)
+	 * &gt;a.../&lt; 2) &lt;div/&gt; click(""a"") will only include 1 if clickOnce
+	 * is true (default). This set can be restricted by
 	 * {@link #dontClick(String)}.
 	 * 
 	 * @param tagName
@@ -76,15 +84,17 @@
 	public CrawlElement click(String tagName) {
 		checkNotRead();
 		Preconditions.checkNotNull(tagName, ""Tagname cannot be null"");
-		CrawlElement crawlTag = new CrawlElement(EventType.click, tagName.toUpperCase());
+		CrawlElement crawlTag = new CrawlElement(EventType.click,
+				tagName.toUpperCase());
 		crawlElements.add(crawlTag);
 		return crawlTag;
 	}
 
 	/**
-	 * Set of HTML elements Crawljax will click during crawling For exmple 1) <a.../> 2) <div/>
-	 * click(""a"") will only include 1 This set can be restricted by {@link #dontClick(String)}. If
-	 * no clicks are specified, {@link #clickDefaultElements()} is enabled.
+	 * Set of HTML elements Crawljax will click during crawling For exmple 1)
+	 * &lt;a.../&gt; 2) &lt;div/&gt; click(""a"") will only include 1 This set can
+	 * be restricted by {@link #dontClick(String)}. If no clicks are specified,
+	 * {@link #clickDefaultElements()} is enabled.
 	 * 
 	 * @param tagNames
 	 *            the tag name of the elements to be included
@@ -96,8 +106,8 @@
 	}
 
 	/**
-	 * Specifies that Crawljax should click all the default clickable elements. These include: All
-	 * anchor tags All buttons
+	 * Specifies that Crawljax should click all the default clickable elements.
+	 * These include: All anchor tags All buttons
 	 */
 	public void clickDefaultElements() {
 		click(""a"");
@@ -108,14 +118,16 @@
 
 	private void checkNotRead() {
 		Preconditions.checkState(resultingElementsExcluded == null,
-		        ""You cannot modify crawlactions once it's read"");
+				""You cannot modify crawlactions once it's read"");
 	}
 
 	/**
-	 * Set of HTML elements Crawljax will NOT click during crawling When an HTML is present in the
-	 * click and dontClick sets, then the element will not be clicked. For example: 1) <a
-	 * href=""#"">Some text</a> 2) <a class=""foo"" .../> 3) <div class=""foo"" .../> click(""a"")
-	 * dontClick(""a"").withAttribute(""class"", ""foo""); Will include only include HTML element 2
+	 * Set of HTML elements Crawljax will NOT click during crawling When an HTML
+	 * is present in the click and dontClick sets, then the element will not be
+	 * clicked. For example: 1) &lt;a href=""#""&gt;Some text&lt;/a&gt; 2) &lt;a
+	 * class=""foo"" .../&gt; 3) &lt;div class=""foo"" .../&gt; click(""a"")
+	 * dontClick(""a"").withAttribute(""class"", ""foo""); Will include only include
+	 * HTML element 2
 	 * 
 	 * @param tagName
 	 *            the tag name of the elements to be excluded
@@ -124,7 +136,8 @@
 	public CrawlElement dontClick(String tagName) {
 		checkNotRead();
 		Preconditions.checkNotNull(tagName, ""Tagname cannot be null"");
-		CrawlElement crawlTag = new CrawlElement(EventType.click, tagName.toUpperCase());
+		CrawlElement crawlTag = new CrawlElement(EventType.click,
+				tagName.toUpperCase());
 		crawlElementsExcluded.add(crawlTag);
 		return crawlTag;
 	}
@@ -139,7 +152,8 @@
 	public ExcludeByParentBuilder dontClickChildrenOf(String tagname) {
 		checkNotRead();
 		Preconditions.checkNotNull(tagname);
-		ExcludeByParentBuilder exclude = new ExcludeByParentBuilder(tagname.toUpperCase());
+		ExcludeByParentBuilder exclude = new ExcludeByParentBuilder(
+				tagname.toUpperCase());
 		crawlParentsExcluded.add(exclude);
 		return exclude;
 	}
@@ -160,7 +174,8 @@
 	private ImmutableList<CrawlElement> getCrawlElementsExcluded() {
 		synchronized (this) {
 			if (resultingElementsExcluded == null) {
-				ImmutableList.Builder<CrawlElement> builder = ImmutableList.builder();
+				ImmutableList.Builder<CrawlElement> builder = ImmutableList
+						.builder();
 				builder.addAll(crawlElementsExcluded);
 				for (ExcludeByParentBuilder exclude : crawlParentsExcluded) {
 					builder.addAll(exclude.asExcludeList(crawlElements));
"
5d412213afd6019b9aa8297300165682d309cf2a,Ali Mesbah,FormInputField.java,MODIFY,setValues -> [boolean values] | [String values],"diff --git a/core/src/main/java/com/crawljax/core/configuration/FormInputField.java b/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
index dc6e88c..fbb126c 100644
--- a/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/FormInputField.java
@@ -1,15 +1,17 @@
 package com.crawljax.core.configuration;
 
 /**
- * Represents a form input field NOTE: In general FormInputField is not designed to be instantiated
- * directly. For example: <input type=""text"" name=""foo"" /> <input type=""checkbox"" id=""bar"" />
- * FormInputSpecification input = new FormInputSpecification() Form form = new Form();
+ * Represents a form input field NOTE: In general FormInputField is not designed
+ * to be instantiated directly. For example: &lt;input type=""text"" name=""foo""
+ * /&gt; &lt;input type=""checkbox"" id=""bar"" /&gt; FormInputSpecification input =
+ * new FormInputSpecification() Form form = new Form();
  * input.field(""foo"").setValues(""Crawljax"", ""Crawler"", ""Automatic"");
  * input.field(""bar"").setValues(true, true, false);
- * input.setValuesInForm(contactForm).beforeClickTag(""a"").withText(""Search""); Crawljax will set the
- * text value of the foo text field and the bar checkbox three times when clicked on the anchor
- * element with the test Search to: 1) foo=Crawljax; bar=checked 2) foo=Crawler; bar=checked 3)
- * foo=Automatic; bar=unchecked
+ * input.setValuesInForm(contactForm).beforeClickTag(""a"").withText(""Search"");
+ * Crawljax will set the text value of the foo text field and the bar checkbox
+ * three times when clicked on the anchor element with the test Search to: 1)
+ * foo=Crawljax; bar=checked 2) foo=Crawler; bar=checked 3) foo=Automatic;
+ * bar=unchecked
  * 
  * @see Form
  * @see Form#field(String)
@@ -18,8 +20,8 @@
 public class FormInputField extends InputField {
 
 	/**
-	 * Sets the valus of this input field with a text input. Applicable to all form elements except
-	 * checkboxes and a radio buttons.
+	 * Sets the valus of this input field with a text input. Applicable to all
+	 * form elements except checkboxes and a radio buttons.
 	 * 
 	 * @param values
 	 *            Values to set.
@@ -33,7 +35,8 @@
 	}
 
 	/**
-	 * Sets the values of this input field. Only Applicable checkboxes and a radio buttons.
+	 * Sets the values of this input field. Only Applicable checkboxes and a
+	 * radio buttons.
 	 * 
 	 * @param values
 	 *            Values to set.
"
5d412213afd6019b9aa8297300165682d309cf2a,Ali Mesbah,InputField.java,MODIFY,setValue -> [boolean value] | [String value],"diff --git a/core/src/main/java/com/crawljax/core/configuration/InputField.java b/core/src/main/java/com/crawljax/core/configuration/InputField.java
index b25765c..8c33c48 100644
--- a/core/src/main/java/com/crawljax/core/configuration/InputField.java
+++ b/core/src/main/java/com/crawljax/core/configuration/InputField.java
@@ -4,11 +4,12 @@
 import java.util.List;
 
 /**
- * Represents a form input field NOTE: In general InputField is not designed to be instantiated
- * directly. For example: <input type=""text"" name=""foo"" /> <input type=""checkbox"" id=""bar"" />
- * FormInputSpecification input = new FormInputSpecification()
- * input.field(""foo"").setValue(""Crawljax""); input.field(""bar"").setValue(true); Crawljax will set the
- * text value of the foo text field to ""Crawljax"" and checks the checkbox with id bar.
+ * Represents a form input field NOTE: In general InputField is not designed to
+ * be instantiated directly. For example: &lt;input type=""text"" name=""foo"" /&gt;
+ * &lt;input type=""checkbox"" id=""bar"" /&gt; FormInputSpecification input = new
+ * FormInputSpecification() input.field(""foo"").setValue(""Crawljax"");
+ * input.field(""bar"").setValue(true); Crawljax will set the text value of the
+ * foo text field to ""Crawljax"" and checks the checkbox with id bar.
  * 
  * @see InputSpecification#field(String)
  * @see InputSpecification#fields(String...)
@@ -28,8 +29,8 @@
 	}
 
 	/**
-	 * Sets the value of this input field with a text input. Applicable to all form elements except
-	 * checkboxes and a radio buttons.
+	 * Sets the value of this input field with a text input. Applicable to all
+	 * form elements except checkboxes and a radio buttons.
 	 * 
 	 * @param value
 	 *            Value to set.
@@ -41,7 +42,8 @@
 	}
 
 	/**
-	 * Sets the value of this input field. Only Applicable checkboxes and a radio buttons.
+	 * Sets the value of this input field. Only Applicable checkboxes and a
+	 * radio buttons.
 	 * 
 	 * @param value
 	 *            Value to set.
"
5d412213afd6019b9aa8297300165682d309cf2a,Ali Mesbah,DomUtils.java,MODIFY,"getDifferences -> [String controlDom, String testDom, List ignoreAttributes] | [String controlDom, String testDom]","diff --git a/core/src/main/java/com/crawljax/util/DomUtils.java b/core/src/main/java/com/crawljax/util/DomUtils.java
index 93729c0..a7b91c3 100644
--- a/core/src/main/java/com/crawljax/util/DomUtils.java
+++ b/core/src/main/java/com/crawljax/util/DomUtils.java
@@ -48,34 +48,38 @@
 import com.google.common.collect.Lists;
 
 /**
- * Utility class that contains a number of helper functions used by Crawljax and some plugins.
+ * Utility class that contains a number of helper functions used by Crawljax and
+ * some plugins.
  */
 public final class DomUtils {
 
-	private static final Logger LOGGER = LoggerFactory.getLogger(DomUtils.class.getName());
+	private static final Logger LOGGER = LoggerFactory.getLogger(DomUtils.class
+			.getName());
 
 	static final int BASE_LENGTH = 3;
 
 	private static final int TEXT_CUTOFF = 50;
 
 	/**
-	 * transforms a string into a Document object. TODO This needs more optimizations. As it seems
-	 * the getDocument is called way too much times causing a lot of parsing which is slow and not
-	 * necessary.
+	 * transforms a string into a Document object. TODO This needs more
+	 * optimizations. As it seems the getDocument is called way too much times
+	 * causing a lot of parsing which is slow and not necessary.
 	 * 
 	 * @param html
 	 *            the HTML string.
 	 * @return The DOM Document version of the HTML string.
 	 * @throws IOException
 	 *             if an IO failure occurs.
-	 * @throws SAXException
-	 *             if an exception occurs while parsing the HTML string.
 	 */
 	public static Document asDocument(String html) throws IOException {
 		DOMParser domParser = new DOMParser();
 		try {
-			domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
-			domParser.setFeature(""http://xml.org/sax/features/namespaces"", false);
+			domParser
+					.setProperty(
+							""http://cyberneko.org/html/properties/names/elems"",
+							""match"");
+			domParser.setFeature(""http://xml.org/sax/features/namespaces"",
+					false);
 			domParser.parse(new InputSource(new StringReader(html)));
 		} catch (SAXException e) {
 			throw new IOException(""Error while reading HTML: "" + html, e);
@@ -92,10 +96,13 @@
 	 * @throws IOException
 	 *             if an IO failure occurs.
 	 */
-	public static Document getDocumentNoBalance(String html) throws SAXException, IOException {
+	public static Document getDocumentNoBalance(String html)
+			throws SAXException, IOException {
 		DOMParser domParser = new DOMParser();
-		domParser.setProperty(""http://cyberneko.org/html/properties/names/elems"", ""match"");
-		domParser.setFeature(""http://cyberneko.org/html/features/balance-tags"", false);
+		domParser.setProperty(
+				""http://cyberneko.org/html/properties/names/elems"", ""match"");
+		domParser.setFeature(""http://cyberneko.org/html/features/balance-tags"",
+				false);
 		domParser.parse(new InputSource(new StringReader(html)));
 		return domParser.getDocument();
 	}
@@ -114,9 +121,11 @@
 	 *            The DOM Element.
 	 * @param exclude
 	 *            the list of exclude strings.
-	 * @return A string representation of the element's attributes excluding exclude.
+	 * @return A string representation of the element's attributes excluding
+	 *         exclude.
 	 */
-	public static String getElementAttributes(Element element, ImmutableSet<String> exclude) {
+	public static String getElementAttributes(Element element,
+			ImmutableSet<String> exclude) {
 		StringBuilder buffer = new StringBuilder();
 		if (element != null) {
 			NamedNodeMap attributes = element.getAttributes();
@@ -128,8 +137,8 @@
 		return buffer.toString().trim();
 	}
 
-	private static void addAttributesToString(ImmutableSet<String> exclude, StringBuilder buffer,
-	        NamedNodeMap attributes) {
+	private static void addAttributesToString(ImmutableSet<String> exclude,
+			StringBuilder buffer, NamedNodeMap attributes) {
 		for (int i = 0; i < attributes.getLength(); i++) {
 			Attr attr = (Attr) attributes.item(i);
 			if (!exclude.contains(attr.getNodeName())) {
@@ -145,14 +154,16 @@
 	 * @return a string representation of the element including its attributes.
 	 */
 	public static String getElementString(Element element) {
-		String text = DomUtils.removeNewLines(DomUtils.getTextValue(element)).trim();
+		String text = DomUtils.removeNewLines(DomUtils.getTextValue(element))
+				.trim();
 		StringBuilder info = new StringBuilder();
 		if (!Strings.isNullOrEmpty(text)) {
 			info.append(""\"""").append(text).append(""\"" "");
 		}
 		if (element != null) {
 			if (element.hasAttribute(""id"")) {
-				info.append(""ID: "").append(element.getAttribute(""id"")).append("" "");
+				info.append(""ID: "").append(element.getAttribute(""id""))
+						.append("" "");
 			}
 			info.append(DomUtils.getAllElementAttributes(element)).append("" "");
 		}
@@ -169,7 +180,7 @@
 	 *             if the xpath fails.
 	 */
 	public static Element getElementByXpath(Document dom, String xpath)
-	        throws XPathExpressionException {
+			throws XPathExpressionException {
 		XPath xp = XPathFactory.newInstance().newXPath();
 		xp.setNamespaceContext(new HtmlNamespace());
 
@@ -177,7 +188,7 @@
 	}
 
 	/**
-	 * Removes all the <SCRIPT/> tags from the document.
+	 * Removes all the &lt;SCRIPT/&gt; tags from the document.
 	 * 
 	 * @param dom
 	 *            the document object.
@@ -199,7 +210,8 @@
 	public static Document removeTags(Document dom, String tagName) {
 		NodeList list;
 		try {
-			list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
+			list = XPathHelper.evaluateXpathExpression(dom,
+					""//"" + tagName.toUpperCase());
 
 			while (list.getLength() > 0) {
 				Node sc = list.item(0);
@@ -208,7 +220,8 @@
 					sc.getParentNode().removeChild(sc);
 				}
 
-				list = XPathHelper.evaluateXpathExpression(dom, ""//"" + tagName.toUpperCase());
+				list = XPathHelper.evaluateXpathExpression(dom,
+						""//"" + tagName.toUpperCase());
 			}
 		} catch (XPathExpressionException e) {
 			LOGGER.error(""Error while removing tag "" + tagName, e);
@@ -231,7 +244,8 @@
 			TransformerFactory factory = TransformerFactory.newInstance();
 			Transformer transformer = factory.newTransformer();
 			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
-			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""yes"");
+			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION,
+					""yes"");
 			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
 			transformer.transform(source, result);
 			return stringWriter.getBuffer().toString();
@@ -254,12 +268,15 @@
 
 			Transformer transformer = tFactory.newTransformer();
 			transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
-			transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
+			transformer
+					.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
 			transformer.setOutputProperty(OutputKeys.METHOD, ""html"");
 			// TODO should be fixed to read doctype declaration
-			transformer.setOutputProperty(OutputKeys.DOCTYPE_PUBLIC,
-			        ""-//W3C//DTD XHTML 1.0 Strict//EN\"" ""
-			                + ""\""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"");
+			transformer
+					.setOutputProperty(
+							OutputKeys.DOCTYPE_PUBLIC,
+							""-//W3C//DTD XHTML 1.0 Strict//EN\"" ""
+									+ ""\""http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd"");
 
 			DOMSource source = new DOMSource(dom);
 
@@ -269,15 +286,16 @@
 
 			return out.toByteArray();
 		} catch (TransformerException e) {
-			LOGGER.error(""Error while converting the document to a byte array"", e);
+			LOGGER.error(""Error while converting the document to a byte array"",
+					e);
 		}
 		return null;
 
 	}
 
 	/**
-	 * Returns the text value of an element (title, alt or contents). Note that the result is 50
-	 * characters or less in length.
+	 * Returns the text value of an element (title, alt or contents). Note that
+	 * the result is 50 characters or less in length.
 	 * 
 	 * @param element
 	 *            The element.
@@ -309,8 +327,10 @@
 	 *            The test dom.
 	 * @return The differences.
 	 */
-	public static List<Difference> getDifferences(String controlDom, String testDom) {
-		return getDifferences(controlDom, testDom, Lists.<String> newArrayList());
+	public static List<Difference> getDifferences(String controlDom,
+			String testDom) {
+		return getDifferences(controlDom, testDom,
+				Lists.<String> newArrayList());
 	}
 
 	/**
@@ -325,12 +345,14 @@
 	 * @return The differences.
 	 */
 	@SuppressWarnings(""unchecked"")
-	public static List<Difference> getDifferences(String controlDom, String testDom,
-	        final List<String> ignoreAttributes) {
+	public static List<Difference> getDifferences(String controlDom,
+			String testDom, final List<String> ignoreAttributes) {
 		try {
-			Diff d = new Diff(DomUtils.asDocument(controlDom), DomUtils.asDocument(testDom));
+			Diff d = new Diff(DomUtils.asDocument(controlDom),
+					DomUtils.asDocument(testDom));
 			DetailedDiff dd = new DetailedDiff(d);
-			dd.overrideDifferenceListener(new DomDifferenceListener(ignoreAttributes));
+			dd.overrideDifferenceListener(new DomDifferenceListener(
+					ignoreAttributes));
 
 			return dd.getAllDifferences();
 		} catch (IOException e) {
@@ -357,9 +379,11 @@
 	 *            The regular expression.
 	 * @param replace
 	 *            What to replace it with.
-	 * @return replaces regex in str by replace where the dot sign also supports newlines
+	 * @return replaces regex in str by replace where the dot sign also supports
+	 *         newlines
 	 */
-	public static String replaceString(String string, String regex, String replace) {
+	public static String replaceString(String string, String regex,
+			String replace) {
 		Pattern p = Pattern.compile(regex, Pattern.DOTALL);
 		Matcher m = p.matcher(string);
 		String replaced = m.replaceAll(replace);
@@ -384,8 +408,8 @@
 	}
 
 	/**
-	 * Returns the filename in a path. For example with path = ""foo/bar/crawljax.txt"" returns
-	 * ""crawljax.txt""
+	 * Returns the filename in a path. For example with path =
+	 * ""foo/bar/crawljax.txt"" returns ""crawljax.txt""
 	 * 
 	 * @param path
 	 * @return the filename from the path
@@ -401,8 +425,8 @@
 	}
 
 	/**
-	 * Retrieves the content of the filename. Also reads from JAR Searches for the resource in the
-	 * root folder in the jar
+	 * Retrieves the content of the filename. Also reads from JAR Searches for
+	 * the resource in the root folder in the jar
 	 * 
 	 * @param fname
 	 *            Filename.
@@ -413,18 +437,21 @@
 	public static String getTemplateAsString(String fname) throws IOException {
 		// in .jar file
 		String fnameJar = getFileNameInPath(fname);
-		InputStream inStream = DomUtils.class.getResourceAsStream(""/"" + fnameJar);
+		InputStream inStream = DomUtils.class.getResourceAsStream(""/""
+				+ fnameJar);
 		if (inStream == null) {
 			// try to find file normally
 			File f = new File(fname);
 			if (f.exists()) {
 				inStream = new FileInputStream(f);
 			} else {
-				throw new IOException(""Cannot find "" + fname + "" or "" + fnameJar);
+				throw new IOException(""Cannot find "" + fname + "" or ""
+						+ fnameJar);
 			}
 		}
 
-		BufferedReader bufferedReader = new BufferedReader(new InputStreamReader(inStream));
+		BufferedReader bufferedReader = new BufferedReader(
+				new InputStreamReader(inStream));
 		String line;
 		StringBuilder stringBuilder = new StringBuilder();
 
@@ -439,17 +466,20 @@
 	/**
 	 * @param frame
 	 *            the frame element.
-	 * @return the name or id of this element if they are present, otherwise null.
+	 * @return the name or id of this element if they are present, otherwise
+	 *         null.
 	 */
 	public static String getFrameIdentification(Element frame) {
 
 		Attr attr = frame.getAttributeNode(""id"");
-		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
+		if (attr != null && attr.getNodeValue() != null
+				&& !attr.getNodeValue().equals("""")) {
 			return attr.getNodeValue();
 		}
 
 		attr = frame.getAttributeNode(""name"");
-		if (attr != null && attr.getNodeValue() != null && !attr.getNodeValue().equals("""")) {
+		if (attr != null && attr.getNodeValue() != null
+				&& !attr.getNodeValue().equals("""")) {
 			return attr.getNodeValue();
 		}
 
@@ -473,16 +503,18 @@
 	 * @throws IOException
 	 *             if an IO exception occurs.
 	 */
-	public static void writeDocumentToFile(Document document, String filePathname, String method,
-	        int indent) throws TransformerException, IOException {
+	public static void writeDocumentToFile(Document document,
+			String filePathname, String method, int indent)
+			throws TransformerException, IOException {
 
-		Transformer transformer = TransformerFactory.newInstance().newTransformer();
+		Transformer transformer = TransformerFactory.newInstance()
+				.newTransformer();
 		transformer.setOutputProperty(OutputKeys.INDENT, ""yes"");
 		transformer.setOutputProperty(OutputKeys.OMIT_XML_DECLARATION, ""no"");
 		transformer.setOutputProperty(OutputKeys.METHOD, method);
 
-		transformer.transform(new DOMSource(document), new StreamResult(new FileOutputStream(
-		        filePathname)));
+		transformer.transform(new DOMSource(document), new StreamResult(
+				new FileOutputStream(filePathname)));
 	}
 
 	private DomUtils() {
"
